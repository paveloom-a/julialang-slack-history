[{"client_msg_id":"d5dd5d8d-770a-4edb-9f8e-105af38f5865","type":"message","text":"I'm pretty new to DL and big data, I am working on a project with GTZAN data <http://marsyas.info/downloads/datasets.html> and was wondering if with audio data people usually feed it as is into a Conv1D or do they create the mel spectrogram and use a Conv2D? Do you have to preprocess and use filters for audio data prior to the ConvNet or is it truly the case that ConvNets basically remove the need for it? The time series I have is length ~660K does it have to be downsampled for computational purposes? I end up with a n x p of ~700 x 660K which is huge, and I want to try simple models like PCA+Logistic Regression first","user":"U01EF0QVAB0","ts":"1608918941.164400","team":"T68168MUP","edited":{"user":"U01EF0QVAB0","ts":"1608918994.000000"},"blocks":[{"type":"rich_text","block_id":"OxXqo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm pretty new to DL and big data, I am working on a project with GTZAN data "},{"type":"link","url":"http://marsyas.info/downloads/datasets.html"},{"type":"text","text":" and was wondering if with audio data people usually feed it as is into a Conv1D or do they create the mel spectrogram and use a Conv2D? Do you have to preprocess and use filters for audio data prior to the ConvNet or is it truly the case that ConvNets basically remove the need for it? The time series I have is length ~660K does it have to be downsampled for computational purposes? I end up with a n x p of ~700 x 660K which is huge, and I want to try simple models like PCA+Logistic Regression first"}]}]}],"thread_ts":"1608918941.164400","reply_count":12,"reply_users_count":2,"latest_reply":"1608942899.167100","reply_users":["U6A936746","U01EF0QVAB0"],"subscribed":false},{"client_msg_id":"dc31333d-90ab-4a49-a1b2-82b059fa115e","type":"message","text":"&gt;  do they create the mel spectrogram and use a Conv2D\nThat works really well in my limited experience.\n(or other transforms to spectrograms)","user":"U6A936746","ts":"1608924001.164700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"D0Zh","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":" do they create the mel spectrogram and use a Conv2D"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nThat works really well in my limited experience.\n(or other transforms to spectrograms)"}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"9a8a298d-3229-468f-bb8b-a365857b07e8","type":"message","text":"I am starting out with FFT magnitude and remove half of it, and doing PCA to do a visualization. Basically will try classical stat models first. Is this a legit method, to take PCA after FFT? I was pleasantly surprised that Julia's MLJ.jl didn't crash unlike R tidymodels and sklearn PCA on this data locally","user":"U01EF0QVAB0","ts":"1608929573.164900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=pBt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am starting out with FFT magnitude and remove half of it, and doing PCA to do a visualization. Basically will try classical stat models first. Is this a legit method, to take PCA after FFT? I was pleasantly surprised that Julia's MLJ.jl didn't crash unlike R tidymodels and sklearn PCA on this data locally"}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"0b4defe6-625b-4fd8-8ab7-49aef85ebaf7","type":"message","text":"But I also need to figure out how do I get the latest Julia onto colab for later parts","user":"U01EF0QVAB0","ts":"1608929595.165100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ubO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But I also need to figure out how do I get the latest Julia onto colab for later parts"}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"561e7a9a-97c3-43bd-b4a6-b5f1706adb89","type":"message","text":"PCA after FFT is legit.\nDimensionality reduction before classification is less legit, in that is is unsupervised, and you have perfectly good supervised information you are wasting.\nBut in the particular case of PCA it could be good since it's orthongalizing the features. \nMight still be worth trying not.\nWhile the data is \"too big\" fitting PCA vs fitting a logistics regression shouldn't be incredibly different.","user":"U6A936746","ts":"1608931251.165300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fs2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"PCA after FFT is legit.\nDimensionality reduction before classification is less legit, in that is is unsupervised, and you have perfectly good supervised information you are wasting.\nBut in the particular case of PCA it could be good since it's orthongalizing the features. \nMight still be worth trying not.\nWhile the data is \"too big\" fitting PCA vs fitting a logistics regression shouldn't be incredibly different."}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"d107c1f1-0039-47ea-947c-347d68d53e88","type":"message","text":"PCA for vis is legit","user":"U6A936746","ts":"1608931294.165500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=K67","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"PCA for vis is legit"}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"4c1b374d-4c19-4d44-bd0a-234448ea55b5","type":"message","text":"Random hacks:\nZ-standardizimg data before feeding it to Neural Nets or SVMs \nBasically alway good, as it puts things in the centre of the activation functions active region.","user":"U6A936746","ts":"1608931468.165700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NpuG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Random hacks:\nZ-standardizimg data before feeding it to Neural Nets or SVMs \nBasically alway good, as it puts things in the centre of the activation functions active region."}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"a23e082d-f892-466d-9545-b473db622c5b","type":"message","text":"Random hacks 2:\nDon't forget to shuffle when training with minibatchs.\nMakes a ton of difference","user":"U6A936746","ts":"1608931506.165900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hK9Va","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Random hacks 2:\nDon't forget to shuffle when training with minibatchs.\nMakes a ton of difference"}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"d8704fd4-4d33-4de1-8d67-56a3bf17f20c","type":"message","text":"Random hack 3:\nFor convnets on image, initialising your network using data a  pretrained network like VGG or Inception with the top layer replaced with a new one that you train is good.","user":"U6A936746","ts":"1608931681.166100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pRy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Random hack 3:\nFor convnets on image, initialising your network using data a  pretrained network like VGG or Inception with the top layer replaced with a new one that you train is good."}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"8da8746e-bf33-494a-9bae-35f9da11e53f","type":"message","text":"Thanks, I was thinking of using PCA prior to a Logistic Regression because it results in better conditioning which I would think makes it faster. In the case of PCA after FFT, you would keep it unstandardized right? The PCA of FFT amplitudes is on the same units","user":"U01EF0QVAB0","ts":"1608933594.166300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aCQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks, I was thinking of using PCA prior to a Logistic Regression because it results in better conditioning which I would think makes it faster. In the case of PCA after FFT, you would keep it unstandardized right? The PCA of FFT amplitudes is on the same units"}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"1e8f5168-fbed-488c-aaf6-31c70aadaaa5","type":"message","text":"I guess maybe worth trying FFT and then regularized logistic regression directly too","user":"U01EF0QVAB0","ts":"1608933629.166500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yB=8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I guess maybe worth trying FFT and then regularized logistic regression directly too"}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"42801edf-1469-439b-8fda-f1a39139de70","type":"message","text":"I don't recall effect of standardizion on PCA","user":"U6A936746","ts":"1608933762.166700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rLy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't recall effect of standardizion on PCA"}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"},{"client_msg_id":"e0bfd066-0dd0-4df8-96b0-52dcec88ec51","type":"message","text":"Seems like I am forced to practically do PCA before logistic in MLJ, the dimensionality is too high (325K ish) and crashes my comp","user":"U01EF0QVAB0","ts":"1608942899.167100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4K7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Seems like I am forced to practically do PCA before logistic in MLJ, the dimensionality is too high (325K ish) and crashes my comp"}]}]}],"thread_ts":"1608918941.164400","parent_user_id":"U01EF0QVAB0"}]