{"cursor": 1, "messages": [{"client_msg_id":"cf88ec48-9a27-499d-b693-69297c7d1d3e","type":"message","text":"<https://julialang.github.io/Pkg.jl/v1/environments/>","user":"UH24GRBLL","ts":"1612374745.087100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rJmMe","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://julialang.github.io/Pkg.jl/v1/environments/"}]}]}]},{"client_msg_id":"b0c5451a-c5d5-4a0b-9656-0b7be046a0e5","type":"message","text":"that's the basic usage - you either start julia with `julia --project=/dir/to/project` or do `]activate /dir/to/project`","user":"UH24GRBLL","ts":"1612374789.087800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3Ibe9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's the basic usage - you either start julia with "},{"type":"text","text":"julia --project=/dir/to/project","style":{"code":true}},{"type":"text","text":" or do "},{"type":"text","text":"]activate /dir/to/project","style":{"code":true}}]}]}]},{"client_msg_id":"6c5286f6-5ad0-47c4-9140-e5ebd5783511","type":"message","text":"that's very destructionist... there's not one entity creating julia packages","user":"UH24GRBLL","ts":"1612374921.090700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rMaJ+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's very destructionist... there's not one entity creating julia packages"}]}]}],"reactions":[{"name":"+1","users":["U6A936746"],"count":1}]},{"client_msg_id":"916942bb-5564-4ae3-9dc9-972e8e0534c5","type":"message","text":"If you want to know more about using Pkg, <#C67EFTEF3|pkg-usage> is the place to go - this is <#C690QRAA3|machine-learning> after all","user":"UH24GRBLL","ts":"1612374963.091200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UhkG+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you want to know more about using Pkg, "},{"type":"channel","channel_id":"C67EFTEF3"},{"type":"text","text":" is the place to go - this is "},{"type":"channel","channel_id":"C690QRAA3"},{"type":"text","text":" after all"}]}]}],"reactions":[{"name":"+1","users":["UMY1LV01G","U6A936746"],"count":2}]},{"client_msg_id":"8f615676-bf14-4dd6-9162-629ec3cbb785","type":"message","text":"Julia is particularly well placed to do this sort of stuff imo :<https://twitter.com/luislamb/status/1357132138605391872>","user":"UDGT4PM41","ts":"1612402583.092400","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1612402612.000000"},"attachments":[{"fallback":"<https://twitter.com/luislamb|@luislamb>: Neurosymbolic AI panel <https://twitter.com/RealAAAI|@RealAAAI> #AAAI2021 on Sunday Feb 7, 7:30 AM PST. <https://twitter.com/guyvdb|@guyvdb> Marta Kwiatkowska, M. Botvinick, Leslie P Kaelbling <https://twitter.com/kerstingAIML|@kerstingAIML>  <https://twitter.com/mishumausam|@mishumausam> <https://twitter.com/k_leyton_brown|@k_leyton_brown>  suggested foundational readings. <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus> <https://twitter.com/Montreal_AI|@Montreal_AI> <https://twitter.com/ceobillionaire|@ceobillionaire> <https://twitter.com/luislamb/status/1218408958781722624>","ts":1612400490,"author_name":"Luis Lamb","author_link":"https://twitter.com/luislamb/status/1357132138605391872","author_icon":"https://pbs.twimg.com/profile_images/1122684648063152129/TC1QsOE7_normal.png","author_subname":"@luislamb","text":"Neurosymbolic AI panel <https://twitter.com/RealAAAI|@RealAAAI> #AAAI2021 on Sunday Feb 7, 7:30 AM PST. <https://twitter.com/guyvdb|@guyvdb> Marta Kwiatkowska, M. Botvinick, Leslie P Kaelbling <https://twitter.com/kerstingAIML|@kerstingAIML>  <https://twitter.com/mishumausam|@mishumausam> <https://twitter.com/k_leyton_brown|@k_leyton_brown>  suggested foundational readings. <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus> <https://twitter.com/Montreal_AI|@Montreal_AI> <https://twitter.com/ceobillionaire|@ceobillionaire> <https://twitter.com/luislamb/status/1218408958781722624>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/luislamb/status/1357132138605391872","id":1,"original_url":"https://twitter.com/luislamb/status/1357132138605391872","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"},{"fallback":"<https://twitter.com/luislamb|@luislamb>: On neural-symbolic computing: suggested readings on foundations of the field - by <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus>  Barbara Hammer and colleagues <https://pbs.twimg.com/media/EOiocmdX4AEzlmA.png>","ts":1579326307,"author_name":"Luis Lamb","author_link":"https://twitter.com/luislamb/status/1218408958781722624","author_icon":"https://pbs.twimg.com/profile_images/1122684648063152129/TC1QsOE7_normal.png","author_subname":"@luislamb","text":"On neural-symbolic computing: suggested readings on foundations of the field - by <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus>  Barbara Hammer and colleagues <https://pbs.twimg.com/media/EOiocmdX4AEzlmA.png>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/luislamb/status/1218408958781722624","image_url":"https://pbs.twimg.com/media/EOiocmdX4AEzlmA.png","image_width":466,"image_height":698,"image_bytes":298839,"indent":true,"color":"32BBF3","id":2,"footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"},{"text":"<https://pbs.twimg.com/media/EOiocmgXsAIV1-6.png>","image_url":"https://pbs.twimg.com/media/EOiocmgXsAIV1-6.png","image_width":454,"image_height":688,"image_bytes":493762,"indent":true,"color":"32BBF3","id":4}],"blocks":[{"type":"rich_text","block_id":"UZT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Julia is particularly well placed to do this sort of stuff imo :"},{"type":"link","url":"https://twitter.com/luislamb/status/1357132138605391872"}]}]}]},{"client_msg_id":"d713cac6-4800-4670-a053-664e2c1211ef","type":"message","text":"<@UH24GRBLL> Thanks！It works！:open_mouth:","user":"U01AJUF2GEP","ts":"1612430778.093700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8JPi8","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UH24GRBLL"},{"type":"text","text":" Thanks！It works！"},{"type":"emoji","name":"open_mouth"}]}]}],"reactions":[{"name":"tada","users":["UH24GRBLL"],"count":1}]},{"type":"message","text":"I was looking at some ml paper (<https://arxiv.org/pdf/1206.6483.pdf> ). There they report the classification accuracy their methods.\n\nIn the paper they mentioned that they used cross-validation to select the parameters, but they never mention creating a test set (they mention a training set though) Now I was wondering, are such reported results usually just the output of crossvalidation (and the ± is just the estimated standard deviation?). Or is using a test set for reporting so common, that it does not have to be mentioned?","files":[{"id":"F01LJK6S3AB","created":1612440353,"timestamp":1612440353,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UBEF50B7C","editable":false,"size":76567,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01LJK6S3AB/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01LJK6S3AB/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_360.png","thumb_360_w":360,"thumb_360_h":137,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_480.png","thumb_480_w":480,"thumb_480_h":183,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_720.png","thumb_720_w":720,"thumb_720_h":274,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_800.png","thumb_800_w":800,"thumb_800_h":305,"original_w":888,"original_h":338,"thumb_tiny":"AwASADDSJpMn3/KlP3vwpuTigBefU/lRz6n8qTPFGTQAuT7/AJUoPPem5OaVTzQA6jFFFABRiiigAooooA//2Q==","permalink":"https://julialang.slack.com/files/UBEF50B7C/F01LJK6S3AB/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01LJK6S3AB-c3f67c00fb","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"km75/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was looking at some ml paper ("},{"type":"link","url":"https://arxiv.org/pdf/1206.6483.pdf"},{"type":"text","text":" ). There they report the classification accuracy their methods.\n\nIn the paper they mentioned that they used cross-validation to select the parameters, but they never mention creating a test set (they mention a training set though) Now I was wondering, are such reported results usually just the output of crossvalidation (and the ± is just the estimated standard deviation?). Or is using a test set for reporting so common, that it does not have to be mentioned?"}]}]}],"user":"UBEF50B7C","display_as_bot":false,"ts":"1612440716.102500","thread_ts":"1612440716.102500","reply_count":4,"reply_users_count":2,"latest_reply":"1612455756.103700","reply_users":["UMY1LV01G","UBEF50B7C"],"subscribed":false},{"client_msg_id":"1f8134b2-4e7f-4bae-ab4a-67c3b576a6d3","type":"message","text":"Anyone know about this? <https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/|https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/>","user":"UDGT4PM41","ts":"1612539182.106000","team":"T68168MUP","attachments":[{"service_name":"MarkTechPost","title":"Researchers From Google Brain Introduces Symbolic Programming And A Python Library Called PyGlove For Automated machine learning | MarkTechPost","title_link":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/","text":"Researchers From Google Brain Introduces Symbolic Programming And A Python Library Called PyGlove For Automated machine learning","fallback":"MarkTechPost: Researchers From Google Brain Introduces Symbolic Programming And A Python Library Called PyGlove For Automated machine learning | MarkTechPost","thumb_url":"https://i1.wp.com/www.marktechpost.com/wp-content/uploads/2021/02/Screen-Shot-2021-02-03-at-10.20.55-PM.png?fit=1622%2C438&ssl=1","fields":[{"title":"Written by","value":"Tanushree Shenwai","short":true},{"title":"Est. reading time","value":"3 minutes","short":true}],"ts":1612419996,"from_url":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/","thumb_width":1622,"thumb_height":438,"service_icon":"https://i0.wp.com/www.marktechpost.com/wp-content/uploads/2017/06/cropped-Untitled-design-3.png?fit=180%2C180&#038;ssl=1","id":1,"original_url":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/"}],"blocks":[{"type":"rich_text","block_id":"qVs5M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone know about this? "},{"type":"link","url":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/","text":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/"}]}]}]},{"client_msg_id":"50ff4796-f683-4dc6-b5c9-eed625278e5b","type":"message","text":"Automated？\nCan someone explain that term to me？","user":"U01AJUF2GEP","ts":"1612539673.106800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xVB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Automated？\nCan someone explain that term to me？"}]}]}]},{"client_msg_id":"72c5ff91-275c-4783-84e4-dbbad468082a","type":"message","text":"It's about learning the structure of the net as well","user":"UH24GRBLL","ts":"1612540057.107200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zLx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's about learning the structure of the net as well"}]}]}]},{"client_msg_id":"8262a133-423b-4255-a38e-339c7573ee16","type":"message","text":"in \"traditional\" machine learning you basically define some polygon by defining the structure of your approach and let the computer fit the parameters so that the curve fits the data. with this, in theory, you'd be able to learn the structure as well","user":"UH24GRBLL","ts":"1612540118.108600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7dWvN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"in \"traditional\" machine learning you basically define some polygon by defining the structure of your approach and let the computer fit the parameters so that the curve fits the data. with this, in theory, you'd be able to learn the structure as well"}]}]}]},{"client_msg_id":"d24f2b00-5e52-4c47-9481-e7e60b98c3e0","type":"message","text":"i.e., which order of polygon would be best not to over- or underfit the data","user":"UH24GRBLL","ts":"1612540142.109100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LQF0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"i.e., which order of polygon would be best not to over- or underfit the data"}]}]}]},{"client_msg_id":"1c756654-1555-4f84-a000-10cdf00e988f","type":"message","text":"(massively simplifying of course)","user":"UH24GRBLL","ts":"1612540152.109500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Eew5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(massively simplifying of course)"}]}]}]},{"client_msg_id":"516cae09-8065-41ad-8c16-86a544c18acd","type":"message","text":"the article links <https://arxiv.org/pdf/2101.08809.pdf>, for those interested","user":"UH24GRBLL","ts":"1612540197.110500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aX+y=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the article links "},{"type":"link","url":"https://arxiv.org/pdf/2101.08809.pdf"},{"type":"text","text":", for those interested"}]}]}]},{"client_msg_id":"6cf1d13e-5aa8-4d74-8735-0c53adb039b9","type":"message","text":"Which naturally call for the question: who will be the first to propose that a machine learn how to best learn the structure of a network? And if going to increasing higher order will be of any benefit","user":"U017LQ3A59U","ts":"1612540210.110800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Af3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Which naturally call for the question: who will be the first to propose that a machine learn how to best learn the structure of a network? And if going to increasing higher order will be of any benefit"}]}]}]},{"client_msg_id":"14ba0802-11ec-4e85-b007-c9da8840c342","type":"message","text":"that's exactly what this approach tries to do, Benoît","user":"UH24GRBLL","ts":"1612540248.111200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4E2RT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's exactly what this approach tries to do, Benoît"}]}]}]},{"client_msg_id":"7093abc3-f43c-46f2-ae3f-20bc781e64c5","type":"message","text":"as I understand it, from a high level, it doesn't just train one net, but multiple variations. E.g. does the network perform better with ADAM or not, does a bigger input space help, what about different stacks of layers etc","user":"UH24GRBLL","ts":"1612540315.113300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bFSV7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"as I understand it, from a high level, it doesn't just train one net, but multiple variations. E.g. does the network perform better with ADAM or not, does a bigger input space help, what about different stacks of layers etc"}]}]}]},{"client_msg_id":"2f1a8a8b-86c5-4450-a12b-469785290ea7","type":"message","text":"the problem of course is that you still have to train those subnets to find out whether any of them are any good","user":"UH24GRBLL","ts":"1612540357.114400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bER1K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the problem of course is that you still have to train those subnets to find out whether any of them are any good"}]}]}]},{"client_msg_id":"89b23846-1f5a-422a-b2bd-6903a05b74a2","type":"message","text":"That how I understand it too. What I mean is that we started to try to learn a function f(x) = y, with some method. A method to machine learn that is just a function g(x, y) = f. As I understand the paper propose to use machine learning to find this g, that then outputs optimal estimator f. In principle you could then say \"wait we use an algorithm h(x, y) = g to find the best method... we could as well apply machine learning at this level directly\"... and continue the chain of training at higher order to infinity","user":"U017LQ3A59U","ts":"1612540616.117900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qJ67T","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That how I understand it too. What I mean is that we started to try to learn a function f(x) = y, with some method. A method to machine learn that is just a function g(x, y) = f. As I understand the paper propose to use machine learning to find this g, that then outputs optimal estimator f. In principle you could then say \"wait we use an algorithm h(x, y) = g to find the best method... we could as well apply machine learning at this level directly\"... and continue the chain of training at higher order to infinity"}]}]}]},{"client_msg_id":"a7144a9c-9ccb-44a2-a96a-0ec6c9635ec3","type":"message","text":"(now that I had to write it down more clearly it sounds like a terrible idea to go beyond the second level, but there may be some well hidden benefits)","user":"U017LQ3A59U","ts":"1612540697.118900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0JK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(now that I had to write it down more clearly it sounds like a terrible idea to go beyond the second level, but there may be some well hidden benefits)"}]}]}]},{"client_msg_id":"6dfa90a5-747a-4f1f-9962-cd133fe114ba","type":"message","text":"yeah, that's the gist of it","user":"UH24GRBLL","ts":"1612541087.119100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ki2Ng","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, that's the gist of it"}]}]}]},{"client_msg_id":"332d68d8-47ef-4cbf-8714-374ad88972d0","type":"message","text":"the problem of course is that the third order in this chain is the exact same problem as the second order, so there's no benefit to going further","user":"UH24GRBLL","ts":"1612541115.119700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+Oc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the problem of course is that the third order in this chain is the exact same problem as the second order, so there's no benefit to going further"}]}]}]},{"client_msg_id":"8a2f0220-46dd-401c-8bd6-fc87396f9a3e","type":"message","text":"I could see with these huge language models the third scale could factor in things like training time and electricity costs. \"Find the type of architecture that will train the model that fits the required crossvalidation metric adjusted for the amount of compute and dollars you want to throw at it\". Although maybe that's a separate abstract problem","user":"U01724Q3PGW","ts":"1612545928.125000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2md","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I could see with these huge language models the third scale could factor in things like training time and electricity costs. \"Find the type of architecture that will train the model that fits the required crossvalidation metric adjusted for the amount of compute and dollars you want to throw at it\". Although maybe that's a separate abstract problem"}]}]}]},{"client_msg_id":"7fcdc9de-d955-4f2f-b7e9-a7c6a5a2117f","type":"message","text":"no reason not to feed that data into the second order already though","user":"UH24GRBLL","ts":"1612546050.125300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yf2uv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"no reason not to feed that data into the second order already though"}]}]}]},{"client_msg_id":"16effb5c-3479-48ab-aa9b-9030bd9d01f4","type":"message","text":"Another day, another NAS paper?","user":"UMY1LV01G","ts":"1612546299.125600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"euR0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Another day, another NAS paper?"}]}]}],"reactions":[{"name":"heavy_check_mark","users":["U01724Q3PGW"],"count":1}]},{"client_msg_id":"596d541e-9872-4865-831d-bab571f42129","type":"message","text":"What is the best way to display training/validation loss plots during training, to already see how the curves evolve from the beginning? I cannot figure out how to replace a plot in Jupyter lab (and I don't want to render tons of plots with the slightly updated curves...)","user":"UFCNUVC67","ts":"1612708834.130800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WFb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is the best way to display training/validation loss plots during training, to already see how the curves evolve from the beginning? I cannot figure out how to replace a plot in Jupyter lab (and I don't want to render tons of plots with the slightly updated curves...)"}]}]}],"thread_ts":"1612708834.130800","reply_count":3,"reply_users_count":2,"latest_reply":"1612709352.131300","reply_users":["U6A936746","UFCNUVC67"],"subscribed":false},{"client_msg_id":"2f72ebe5-e923-4a8d-ac1b-b01f85b6e146","type":"message","text":"I've been trying to figure out how to parallelize computations involving RNNs in Flux, since the hidden state needs to be kept track of separately for each parallel input of a training batch. I'd hope there's a simple built-in way of doing this.  However, I only found <https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378|a post on discourse> with the same question but no answers.. Can anyone point me in the right direction?","user":"UFCNUVC67","ts":"1612962246.135500","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Parallel feedforward computation with RNN","title_link":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378","text":"Say you have a sample of 3 observations-label as a training set for a standard fully connected NN. To parallelize the computation of the loss (and the gradient) of each label, you can feed the three observations to the NN as a matrix instead of sequentially feeding the three observation vectors. Like so: net = Chain(Dense(10,5,relu),Dense(5,1,relu)) |&gt; gpu x = cu(rand(10,3)) #each column of that matrix is one observation y = cu(rand(1,3)) #each element is one label output = net(x) loss = Flux....","fallback":"JuliaLang: Parallel feedforward computation with RNN","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1563180665,"from_url":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378"}],"blocks":[{"type":"rich_text","block_id":"7fR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've been trying to figure out how to parallelize computations involving RNNs in Flux, since the hidden state needs to be kept track of separately for each parallel input of a training batch. I'd hope there's a simple built-in way of doing this.  However, I only found "},{"type":"link","url":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378","text":"a post on discourse"},{"type":"text","text":" with the same question but no answers.. Can anyone point me in the right direction?"}]}]}]},{"client_msg_id":"e669a85f-6800-4b6f-aa16-9e074ef673b5","type":"message","text":"<https://twitter.com/srush_nlp/status/1360023284126011394?s=19|https://twitter.com/srush_nlp/status/1360023284126011394?s=19>","user":"UDGT4PM41","ts":"1613157061.137400","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/srush_nlp|@srush_nlp>: (since people keep asking) \n\nFor the record: I think einsum is bad. \n\nIt feels like programming with manual register allocation.\n\nWhat the heck are ijk...? \nWhy do I re-allocate them each line? \nWhy does it only support +, *? \n\n(it does have great branding :adult:‍🦳)","ts":1613089793,"author_name":"Sasha Rush","author_link":"https://twitter.com/srush_nlp/status/1360023284126011394","author_icon":"https://pbs.twimg.com/profile_images/1225523236873461760/tVkkzywG_normal.jpg","author_subname":"@srush_nlp","text":"(since people keep asking) \n\nFor the record: I think einsum is bad. \n\nIt feels like programming with manual register allocation.\n\nWhat the heck are ijk...? \nWhy do I re-allocate them each line? \nWhy does it only support +, *? \n\n(it does have great branding :adult:‍🦳)","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19","id":1,"original_url":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"2fcC","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19","text":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19"}]}]}]},{"client_msg_id":"640b85ab-67ce-4b81-9237-589a1b1ed182","type":"message","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer.","user":"U9RDM8ZGT","ts":"1613163846.138700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T/UL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer."}]}]}],"thread_ts":"1613163846.138700","reply_count":2,"reply_users_count":1,"latest_reply":"1613164055.139200","reply_users":["UH24GRBLL"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"<https://julialang.slack.com/archives/C680MM7D4/p1613155571397300>","user":"UH24GRBLL","ts":"1613164038.138800","thread_ts":"1613163846.138700","root":{"client_msg_id":"640b85ab-67ce-4b81-9237-589a1b1ed182","type":"message","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer.","user":"U9RDM8ZGT","ts":"1613163846.138700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T/UL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer."}]}]}],"thread_ts":"1613163846.138700","reply_count":2,"reply_users_count":1,"latest_reply":"1613164055.139200","reply_users":["UH24GRBLL"],"subscribed":false},"attachments":[{"fallback":"<https://twitter.com/texasmichelle|@texasmichelle>: As #S4TF heads into maintenance mode, it’s a bit :exploding_head: to reflect on how much I’ve learned. The community and team members built an incredible space for each other to grow :seedling: Thank you all :heart:","ts":1613152802,"author_name":"Michelle Casbon","author_link":"https://twitter.com/texasmichelle/status/1360287563898974211","author_icon":"https://pbs.twimg.com/profile_images/1007153823054376960/o7G6Yf5j_normal.jpg","author_subname":"@texasmichelle","text":"As #S4TF heads into maintenance mode, it’s a bit :exploding_head: to reflect on how much I’ve learned. The community and team members built an incredible space for each other to grow :seedling: Thank you all :heart:","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/texasmichelle/status/1360287563898974211?s=20","id":1,"original_url":"https://julialang.slack.com/archives/C680MM7D4/p1613155571397300","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"1xkJ","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://julialang.slack.com/archives/C680MM7D4/p1613155571397300"}]}]}],"client_msg_id":"5fe04641-76b8-45f2-8df2-04a87d4336e4"},{"client_msg_id":"f08fee69-1ce6-484d-8fb1-4f70e86ee0f6","type":"message","text":"Well, of the two Julia wins!","user":"U9RDM8ZGT","ts":"1613164146.139500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"khwN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Well, of the two Julia wins!"}]}]}]},{"client_msg_id":"217efef1-a8de-40bc-87d5-b689e60c68e0","type":"message","text":"Apple is still supporting Swift autodiff and ML stuff. We'll have to see where they take things","user":"UDGT4PM41","ts":"1613164175.140200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yA6u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Apple is still supporting Swift autodiff and ML stuff. We'll have to see where they take things"}]}]}]},{"client_msg_id":"224591a7-081c-4c22-94ce-e057ee11e268","type":"message","text":"That's the thing about google: they've got lots of resources to pour into projects, but they're also quite fickle.","user":"U9RDM8ZGT","ts":"1613164185.140500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yee","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's the thing about google: they've got lots of resources to pour into projects, but they're also quite fickle."}]}]}]},{"client_msg_id":"e85ee7bb-952c-423d-ac6e-e320d2147704","type":"message","text":"<https://killedbygoogle.com>  is infamous for this","user":"UH24GRBLL","ts":"1613164205.141000","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1613164223.000000"},"blocks":[{"type":"rich_text","block_id":"tHFjE","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://killedbygoogle.com"},{"type":"text","text":"  is infamous for this"}]}]}]},{"client_msg_id":"b483e542-b3a1-4b51-a24a-0dfdc8fc3e8b","type":"message","text":"But this definitely bodes well for Julia","user":"UDGT4PM41","ts":"1613164216.141300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zOz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But this definitely bodes well for Julia"}]}]}],"thread_ts":"1613164216.141300","reply_count":1,"reply_users_count":1,"latest_reply":"1613164390.141500","reply_users":["UGD4K0Z25"],"subscribed":false},{"client_msg_id":"18a8d9e3-82b8-4336-9a4b-29fb601c0785","type":"message","text":"<https://news.ycombinator.com/item?id=26117453> &lt;&lt; Lots of Julia optimism over on HN in the light of the Swift for Tensorflow canning. Interesting how much of the pessimism one saw over five years ago is slowly fading away.","user":"U677R5Q5A","ts":"1613209138.143000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dO+J","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://news.ycombinator.com/item?id=26117453"},{"type":"text","text":" << Lots of Julia optimism over on HN in the light of the Swift for Tensorflow canning. Interesting how much of the pessimism one saw over five years ago is slowly fading away."}]}]}]},{"client_msg_id":"e46afdc6-0a2c-4970-9389-9e4a69ab43d1","type":"message","text":"There's a lot of Flux love in there too :heart_eyes: :fluxml: \n\nKind of gratifying.","user":"UC4QQPG4A","ts":"1613220305.143900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZKy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's a lot of Flux love in there too "},{"type":"emoji","name":"heart_eyes"},{"type":"text","text":" "},{"type":"emoji","name":"fluxml"},{"type":"text","text":" \n\nKind of gratifying."}]}]}]},{"client_msg_id":"e7003cd6-1fa6-4d31-a7b1-5aa70295b605","type":"message","text":"Hey folks, I was hoping someone might help resolve an ambiguity in some of the Flux and Zygote documentation. So in the `Zygote` docs it says that using implicit parameters works, but is not the recommended method. By implicit parameters, the docs seem to refer to notation like this with the zero argument anonymous function\n```grads = gradient(() -&gt; sum(linear(x)), Params([W, b]))```\n But the docs say `However, implicit parameters exist mainly for compatibility with Flux's current AD; it's recommended to use the other approaches unless you need this.`\nHowever, the `Flux` tutorial uses this type of implicit parameter approach in their 60 minute blitz--provided below. And I see this type of notation popping up everywhere, including the DiffEqFlux docs. So what is the right answer--meaning if the implicit parameter approach is not recommended then it seems to get used a lot ??\n\nHere is the example from the 60 minute blitz\n```using Flux: params\n\nW = randn(3, 5)\nb = zeros(3)\nx = rand(5)\n\ny(x) = sum(W * x .+ b)\n\ngrads = gradient(()-&gt;y(x), params([W, b]))\n\ngrads[W], grads[b]```\nMaybe I am missing something or worrying about something that is not a big deal. Just figured I would check.","user":"UDDSTBX19","ts":"1613411344.151200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2QK2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey folks, I was hoping someone might help resolve an ambiguity in some of the Flux and Zygote documentation. So in the "},{"type":"text","text":"Zygote","style":{"code":true}},{"type":"text","text":" docs it says that using implicit parameters works, but is not the recommended method. By implicit parameters, the docs seem to refer to notation like this with the zero argument anonymous function\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"grads = gradient(() -> sum(linear(x)), Params([W, b]))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":" But the docs say "},{"type":"text","text":"However, implicit parameters exist mainly for compatibility with Flux's current AD; it's recommended to use the other approaches unless you need this.","style":{"code":true}},{"type":"text","text":"\nHowever, the "},{"type":"text","text":"Flux","style":{"code":true}},{"type":"text","text":" tutorial uses this type of implicit parameter approach in their 60 minute blitz--provided below. And I see this type of notation popping up everywhere, including the DiffEqFlux docs. So what is the right answer--meaning if the implicit parameter approach is not recommended then it seems to get used a lot ??\n\nHere is the example from the 60 minute blitz\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Flux: params\n\nW = randn(3, 5)\nb = zeros(3)\nx = rand(5)\n\ny(x) = sum(W * x .+ b)\n\ngrads = gradient(()->y(x), params([W, b]))\n\ngrads[W], grads[b]"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe I am missing something or worrying about something that is not a big deal. Just figured I would check."}]}]}],"thread_ts":"1613411344.151200","reply_count":4,"reply_users_count":2,"latest_reply":"1613412997.151900","reply_users":["UH9KWTTD3","UDDSTBX19"],"subscribed":false},{"client_msg_id":"7cfaffd7-328b-4a29-a8cc-45699e2c12d7","type":"message","text":"Does anyone know what the following error means when getting a gradient for a simple Flux model on Julia 1.6?\n```ERROR: LoadError: MethodError: no method matching eval(::IRTools.Inner.Undefined, ::Symbol)\nClosest candidates are:\n  eval(::Module, ::Any) at boot.jl:360\nStacktrace:\n  [1] macro expansion\n    @ ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0 [inlined]\n  [2] _pullback(::Zygote.Context, ::typeof(Core.eval), ::IRTools.Inner.Undefined, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:9\n  [3] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:76 [inlined]\n  [4] _pullback(ctx::Zygote.Context, f::typeof(Dagger.get_type), args::String)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [5] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:29 [inlined]\n  [6] _pullback\n    @ ./dict.jl:465 [inlined]\n  [7] _pullback(::Zygote.Context, ::typeof(get!), ::Dagger.var\"#89#91\", ::Dict{Symbol, Any}, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [8] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n  [9] _pullback(::Zygote.Context, ::Dagger.var\"##compute#88\", ::Nothing, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [10] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n [11] _pullback(::Zygote.Context, ::Dagger.var\"#compute##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [12] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [13] _pullback(::Zygote.Context, ::Dagger.var\"##collect#84\", ::Nothing, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [14] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [15] _pullback(::Zygote.Context, ::Base.var\"#collect##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [16] _pullback```","user":"U6A0PD8CR","ts":"1613422353.154300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YdA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know what the following error means when getting a gradient for a simple Flux model on Julia 1.6?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ERROR: LoadError: MethodError: no method matching eval(::IRTools.Inner.Undefined, ::Symbol)\nClosest candidates are:\n  eval(::Module, ::Any) at boot.jl:360\nStacktrace:\n  [1] macro expansion\n    @ ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0 [inlined]\n  [2] _pullback(::Zygote.Context, ::typeof(Core.eval), ::IRTools.Inner.Undefined, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:9\n  [3] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:76 [inlined]\n  [4] _pullback(ctx::Zygote.Context, f::typeof(Dagger.get_type), args::String)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [5] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:29 [inlined]\n  [6] _pullback\n    @ ./dict.jl:465 [inlined]\n  [7] _pullback(::Zygote.Context, ::typeof(get!), ::Dagger.var\"#89#91\", ::Dict{Symbol, Any}, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [8] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n  [9] _pullback(::Zygote.Context, ::Dagger.var\"##compute#88\", ::Nothing, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [10] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n [11] _pullback(::Zygote.Context, ::Dagger.var\"#compute##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [12] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [13] _pullback(::Zygote.Context, ::Dagger.var\"##collect#84\", ::Nothing, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [14] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [15] _pullback(::Zygote.Context, ::Base.var\"#collect##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [16] _pullback"}]}]}],"thread_ts":"1613422353.154300","reply_count":20,"reply_users_count":2,"latest_reply":"1613423819.158600","reply_users":["UM30MT6RF","U6A0PD8CR"],"subscribed":false},{"client_msg_id":"591a1946-ed3b-4ed8-be79-6cf0ad9d0c93","type":"message","text":"I'm on IRTools master and Zygote 0.6.2","user":"U6A0PD8CR","ts":"1613422382.154600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wuuA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm on IRTools master and Zygote 0.6.2"}]}]}]},{"client_msg_id":"8ba996c2-c2fa-4c73-a25d-97728585656f","type":"message","text":"Are there any benchmarks on the performance of doing ML with Julia vs doing it with pytorch on GPUs?","user":"U7PD3M3L5","ts":"1613487586.160000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hpgq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any benchmarks on the performance of doing ML with Julia vs doing it with pytorch on GPUs?"}]}]}],"thread_ts":"1613487586.160000","reply_count":1,"reply_users_count":1,"latest_reply":"1613488047.160100","reply_users":["U01C3624SGJ"],"subscribed":false},{"client_msg_id":"dc17b825-3478-4f09-b13c-577a05d98808","type":"message","text":"Hi, I'm trying to move a neural network from CPU to GPU and met with this error. Seems that the the pullback failed on GPU. Just wonder anything I should do here. I'm using Zygote 0.6.3. The lossg is just a simple MSE loss function stored on GPU.\n```  for (x,y) in trainDataG\n    train_loss, back = Zygote.pullback(() -&gt; lossg(x,y),gθ)\n    back(one(train_loss))\n  end```\n&gt; DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 0 and 81\")","user":"U01977X150R","ts":"1613527067.167000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n5/i6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I'm trying to move a neural network from CPU to GPU and met with this error. Seems that the the pullback failed on GPU. Just wonder anything I should do here. I'm using Zygote 0.6.3. The lossg is just a simple MSE loss function stored on GPU.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"  for (x,y) in trainDataG\n    train_loss, back = Zygote.pullback(() -> lossg(x,y),gθ)\n    back(one(train_loss))\n  end"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 0 and 81\")"}]}]}]},{"client_msg_id":"d83b4434-01c0-4486-8aba-df5ebab415ae","type":"message","text":"Are there any packages with ELM already implemented? There is ELM.jl but it is archived and its last commit is from 2014","user":"U01C3624SGJ","ts":"1613572969.170500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jiyxC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any packages with ELM already implemented? There is ELM.jl but it is archived and its last commit is from 2014"}]}]}]},{"client_msg_id":"1dfaeedb-97c0-49a4-a08b-dded61d31c25","type":"message","text":"```@load LinearRegressor pkg=MLJLinearModels\nmdl = LinearRegressor()```\nhas stopped working in the recent releases of MLJ\n```julia&gt; mdl = LinearRegressor()\nERROR: UndefVarError: LinearRegressor not defined\nStacktrace:\n [1] top-level scope\n   @ REPL[16]:1```","user":"U01AJUF2GEP","ts":"1613828372.000800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n/g+","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"@load LinearRegressor pkg=MLJLinearModels\nmdl = LinearRegressor()"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"has stopped working in the recent releases of MLJ\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> mdl = LinearRegressor()\nERROR: UndefVarError: LinearRegressor not defined\nStacktrace:\n [1] top-level scope\n   @ REPL[16]:1"}]}]}],"thread_ts":"1613828372.000800","reply_count":2,"reply_users_count":1,"latest_reply":"1613828856.002200","reply_users":["U7THT3TM3"],"subscribed":false},{"client_msg_id":"143b27dd-03a0-4843-a61c-5e225d9b14a0","type":"message","text":"Any idea anyone?","user":"U01AJUF2GEP","ts":"1613828381.001100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oL+vx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any idea anyone?"}]}]}]},{"client_msg_id":"f0fd6d32-17e4-49be-b39a-16adf9e7cfb4","type":"message","text":"<https://github.com/FluxML/MLJFlux.jl#loss-functions|https://github.com/FluxML/MLJFlux.jl#loss-functions> suggests that we can't use some loss functions, could someone help explain why? Are there issues with differentiating with Zygote? <@UD0SQV5LL>  thoughts?","user":"UC4QQPG4A","ts":"1614002851.010700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"su=","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/FluxML/MLJFlux.jl#loss-functions","text":"https://github.com/FluxML/MLJFlux.jl#loss-functions"},{"type":"text","text":" suggests that we can't use some loss functions, could someone help explain why? Are there issues with differentiating with Zygote? "},{"type":"user","user_id":"UD0SQV5LL"},{"type":"text","text":"  thoughts?"}]}]}]},{"client_msg_id":"b6cfbdda-6308-4cf2-873a-f2d0e27e90ab","type":"message","text":"Is there a quickstart on how to convert a tensorflow/python notebook to Flux? (I know almost nothing of Flux.)","user":"U01CQTKB86N","ts":"1614004830.011500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Y5Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a quickstart on how to convert a tensorflow/python notebook to Flux? (I know almost nothing of Flux.)"}]}]}],"thread_ts":"1614004830.011500","reply_count":6,"reply_users_count":2,"latest_reply":"1614006515.012600","reply_users":["U01CQTKB86N","UH9KWTTD3"],"subscribed":false},{"client_msg_id":"619299b6-793d-4f06-807b-de624bd64564","type":"message","text":"Say, I was searching for any libraries for relation-extraction or named entity recognition from text in Julia. This would probably fall under NLP. I could not find anything, so I was wondering if anyone knew of any julia implementations?","user":"UDDSTBX19","ts":"1614007366.014200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1scl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Say, I was searching for any libraries for relation-extraction or named entity recognition from text in Julia. This would probably fall under NLP. I could not find anything, so I was wondering if anyone knew of any julia implementations?"}]}]}]},{"client_msg_id":"5d0ac6e8-48b5-4e93-9b63-dcaba7eac686","type":"message","text":"Are there any tutorials for using LDA (Linear Discriminant Analysis) as a dimensionality reduction on julia?","user":"U01C3624SGJ","ts":"1614088537.016300","team":"T68168MUP","edited":{"user":"U01C3624SGJ","ts":"1614088993.000000"},"blocks":[{"type":"rich_text","block_id":"CVCEx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any tutorials for using LDA (Linear Discriminant Analysis) as a dimensionality reduction on julia?"}]}]}],"thread_ts":"1614088537.016300","reply_count":5,"reply_users_count":2,"latest_reply":"1614088972.017400","reply_users":["UJ7DVTVQ8","U01C3624SGJ"],"subscribed":false},{"client_msg_id":"dfef5759-0244-48af-9042-3dbfd58a8e2a","type":"message","text":"Hi <@U8MPCDJAY> how would you characterize the difference between ObjectDetector.jl and YOLO.jl ?","user":"U679VPJ8L","ts":"1614092145.018800","team":"T68168MUP","edited":{"user":"U679VPJ8L","ts":"1614092167.000000"},"blocks":[{"type":"rich_text","block_id":"BxiY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi "},{"type":"user","user_id":"U8MPCDJAY"},{"type":"text","text":" how would you characterize the difference between ObjectDetector.jl and YOLO.jl ?"}]}]}],"thread_ts":"1614092145.018800","reply_count":5,"reply_users_count":1,"latest_reply":"1614092553.023100","reply_users":["U8MPCDJAY"],"subscribed":false},{"client_msg_id":"cc266ff9-240c-4547-b696-0a0973936a96","type":"message","text":"<https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/>","user":"U67BJLYCS","ts":"1614221247.027400","team":"T68168MUP","attachments":[{"service_name":"Bart Wronski","service_url":"http://bartwronski.com","title":"Bilinear down/upsampling, aligning pixel grids, and that infamous GPU half pixel offset","title_link":"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/","author_name":"bartwronski","author_link":"https://bartwronski.com/author/bartwronski/","thumb_url":"https://bartwronski.files.wordpress.com/2021/02/box_then_even_odd-6.gif?fit=200%2C150","thumb_width":150,"thumb_height":150,"text":"See this ugly pixel shift when upsampling a downsampled image? My post describes where it can come from and how to avoid those! \n\n\n\nIt&rsquo;s been more than two decades of me using bilinear texture filtering, a few months since I&rsquo;ve written about bilinear resampling, but only two days since I discovered a bug of mine related to it. &#128517; Similarly, just last week a colleague asked for a very fast implementation of bilinear on a CPU and it caused a series of questions &ldquo;which kind of bilinear?&rdquo;.\n\n\n\nSo I figured it&rsquo;s an opportunity for another short blog post &ndash; on bilinear filtering, but in context of down/upsampling. We will touch here on GPU half pixel offsets, aligning pixel grids, a bug / confusion in Tensorflow, deeper signal processing analysis of what&rsquo;s going on during bilinear operations, and analysis of the magic of the famous &ldquo;magic kernel&rdquo;.\n\n\n\nI highly recommend my previous post as a primer on the topic, as I&rsquo;ll use some of the tools and terminology from there, but it&rsquo;s not strictly required. Let&rsquo;s go!\n\n\n\nBilinear confusion\n\n\n\nThe term bilinear upsampling and downsampling is used a lot, but what does it mean?&nbsp;\n\n\n\nOne of the few ideas I&rsquo;d like to convey in this post is that bilinear upsampling / downsampling doesn&rsquo;t have a single meaning or a consensus around this term use. Which is kind of surprising for a bread and butter type of image processing operation that is used all the time!\n\n\n\nIt&rsquo;s also surprisingly hard to get it right even by image processing professionals, and a source of long standing bugs and confusion in top libraries (and I know of some actual production bugs caused by this Tensorflow inconsistency)!\n\n\n\nEdit: there&rsquo;s a blog post titled &ldquo;How Tensorflow&rsquo;s tf.image.resize stole 60 days of my life&rdquo; and it&rsquo;s describing same issue. I know of some of my colleagues that spent months on fixing it in Tensorflow 2 &ndash; imagine effort of fixing incorrect uses and &ldquo;fixing&rdquo; already trained models that were trained around this bug&hellip; \n\n\n\nImage credit/source: Oleksandr Savsunenko\n\n\n\nSome parts of it like phase shifting are so tricky that a famous blog post of &ldquo;magic kernel&rdquo; comes up every few years and again, experts re(read) it a few times to figure out what&rsquo;s going on there, while the author simply rediscovered the bilinear! (Important note: I don&rsquo;t want to pick on the author, far from it, as he is a super smart and knowledgeable person, and willingness to share insights is always respect worthy. &ldquo;Magic kernel&rdquo; is just an example of why it&rsquo;s so hard and confusing to talk about &ldquo;bilinear&rdquo;. I also respect how he amended and improved the post multiple times. But there is no &ldquo;magic kernel&rdquo;.)\n\n\n\nSo let&rsquo;s have a look at what&rsquo;s the problem. I will focus here exclusively on 2x up/downsampling and hope that some thought framework I propose and use here will be beneficial for you to also look at and analyze different (and non-integer factors).\n\n\n\nBecause of bilinear separability, I will again abuse the notation and call &ldquo;bilinear&rdquo; a filter when applied to 1D signals and generally a lot of my analysis will be in 1D.\n\n\n\nBilinear downsampling and upsampling\n\n\n\nWhat do we mean by bilinear upsampling?\n\n\n\nLet&rsquo;s start with the most simple explanation, without the nitty gritty: it is creating a larger resolution image where every sample is created from bilinear filtering of a smaller resolution image.\n\n\n\nFor the bilinear downsampling, things get a bit muddy. It is using a bilinear filter to prevent signal aliasing when decimating the input image &ndash; ugh, lots of technical terms. I will circle back to it, but first address the first common confusion.\n\n\n\nIs this box or bilinear downsampling? Two ways of addressing it\n\n\n\nWhen downsampling images by 2, we every often use terms box filter and bilinear filter interchangeably. And both can be correct. How so?\n\n\n\nLet&rsquo;s have a look at the following diagram:&nbsp;\n\n\n\n(Bi)linear vs box downsampling give us the same effective weights. Black dots represent pixel centers, upper row is the target/low resolution texture, and the bottom row the source, higher resolution one. Blue lines represents discretized weights of the kernel. \n\n\n\nWe can see that a 2 tap box filter is the same as a 2 tap bilinear filter. The reason for it is that in this case, both filters are centered between the pixels. After discretizing them (evaluating filter weights at sample points), there is no difference, as we no longer know what was the formula to generate them, and how the filter kernel looked outside of the evaluation points.\n\n\n\nThe most typical way of doing bilinear downsampling is the same as box downsampling. Using those two names for 2x downsampling interchangeably is both correct! (Side note: Things diverge when taking about more than 2x downsampling. This might be a good topic for another blog post.) For 1D signals it means averaging every two elements together, for 2D images averaging 4 elements to produce a single one.\n\n\n\nYou might have noticed something that I implicitly assumed there &ndash; pixel centers there were shifted by half a pixel, and the edges/corners were aligned.\n\n\n\nThere is &ldquo;another way&rdquo; of doing bilinear downsampling, like this:\n\n\n\nA second take on bilinear downsampling &ndash; this time with pixel centers (black dots) aligned. Again the source image / signal is on the bottom, target signal on the top.\n\n\n\nThis one definitely and clearly is also a linear tent, and it doesn&rsquo;t shift pixel centers. The resulting filter weights of [0.25 0.5 0.25] are also called a [1 2 1] filter, or the simplest case of a binomial filter, a very reasonable approximation to a Gaussian filter. (To understand why, see what happens to the binomial distribution as the trial count goes to infinity!). It&rsquo;s probably the filter I use the most in my work, but I digress. &#128578;\n\n\n\nWhy this second method is not used that much? This is by design and a reason for half texel shifts in GPU coordinates / samplers, and you might have noticed the problem &ndash; the last texel of high resolution array gets discarded. But let&rsquo;s not get ahead of ourselves, first we can have a look at the relationship with upsampling.\n\n\n\nTwo ways of bilinear upsampling &ndash; which one is &ldquo;proper&rdquo;?\n\n\n\nIf you were to design a bilinear upsampling algorithm, there are a few ways to address it.\n\n\n\nLet me start with a &ldquo;naive&rdquo; one that can have problems. We can take every original pixel, and between them just place averages of the other ones.\n\n\n\nNaive bilinear upsampling when pixel centers are aligned. Some pixels receive a copy of the source (green line), the other ones (alternating) a blend between two neighbors.\n\n\n\nIs it bilinear / tent? Yes, it&rsquo;s a tent filter on zero-inserted image (more on it later). It has an unusual property; some pixels get blurred, some pixels stay &ldquo;sharp&rdquo; (original copied).\n\n\n\nBut more importantly, if you do box/bilinear downsampling as described above, and then upsample an image, it will be shifted:\n\n\n\nUsing box downsampling, and then copy / interpolate upsampling shifts the image by half a pixel. This is a wrong way to do it! \n\n\n\nOr rather &ndash; it will not correct for the half pixel shift created by downsampling.\n\n\n\nIt will work however with downsampling using the second method. The second method interpolates every single output pixel; all are interpolated:\n\n\n\nWhen done properly, bilinear down/upsample doesn&rsquo;t shift the image.\n\n\n\nThis another way of doing bilinear upsampling that might first feel initially unintuitive: every pixel is 0.75 of one pixel, and 0.25 of another one, alternating &ldquo;to the left&rdquo; and &ldquo;to the right&rdquo;. This is exactly what a GPU does when you upsample a texture by 2x:\n\n\n\n\n\n\n\nThe…","fallback":"Bart Wronski Link: Bilinear down/upsampling, aligning pixel grids, and that infamous GPU half pixel&nbsp;offset","from_url":"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/","service_icon":"https://s2.wp.com/i/webclip.png","id":1,"original_url":"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/"}],"blocks":[{"type":"rich_text","block_id":"V2pej","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/"}]}]}]},{"client_msg_id":"acb186dc-1365-4c17-834a-8ca2fe6e8c09","type":"message","text":"Hi, I'm trying to use Neural ODE with DiFEqFlux. My equation is :\n```function true_ode(du,u,p,t)\n    true_A, true_B = p\n    if t &lt; tc\n        du[1] =true_A*0.041 - true_B*u[1]\n    else\n         du[1] = - true_B*u[1]\n    end\nend```\nAnd I want to put her in the neural network :\n```dudt = FastChain((u,p) -&gt; true_ode(u),\n        FastDense(1, 50, tanh),\n        FastDense(50, 1))```\nDo you think it's possible in spite the \"if\" temporal condition ?","user":"U01NRTNRCDV","ts":"1614269275.030400","team":"T68168MUP","edited":{"user":"U01NRTNRCDV","ts":"1614269321.000000"},"blocks":[{"type":"rich_text","block_id":"Nopxw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I'm trying to use Neural ODE with DiFEqFlux. My equation is :\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function true_ode(du,u,p,t)\n    true_A, true_B = p\n    if t < tc\n        du[1] =true_A*0.041 - true_B*u[1]\n    else\n         du[1] = - true_B*u[1]\n    end\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"And I want to put her in the neural network :\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"dudt = FastChain((u,p) -> true_ode(u),\n        FastDense(1, 50, tanh),\n        FastDense(50, 1))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Do you think it's possible in spite the \"if\" temporal condition ?"}]}]}]},{"client_msg_id":"fc11b06e-2844-42d5-9f5e-afd835e3cf06","type":"message","text":"Anyone here tackled outlier detection on images in Julia? Any learnings to share? Models used, results, does and don'ts? Thanks!","user":"USFR23ZHQ","ts":"1614282157.032600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HEKB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone here tackled outlier detection on images in Julia? Any learnings to share? Models used, results, does and don'ts? Thanks!"}]}]}]},{"client_msg_id":"d806afc7-fe0d-493f-9d1c-cba298ef8d24","type":"message","text":"Is it possible to set part of a large matrix to not be trainable? It seems the Flux.Zeros method relies on setting an entire parameter to non-trainable.","user":"U01L0KU0SDV","ts":"1614311246.033900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gUa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it possible to set part of a large matrix to not be trainable? It seems the Flux.Zeros method relies on setting an entire parameter to non-trainable."}]}]}]},{"client_msg_id":"68b17398-12de-428e-ae3a-438ea035a471","type":"message","text":"Reason being, I'm creating a new type of convolution, where it is hollow in the middle, essentially a \"perimeter convolution.\" And I'd like to piggyback on the existing convolutional layers, and simply just zero out the innards, and also make them not part of the Flux.params or Flux.trainable properties.","user":"U01L0KU0SDV","ts":"1614311323.035400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xLh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Reason being, I'm creating a new type of convolution, where it is hollow in the middle, essentially a \"perimeter convolution.\" And I'd like to piggyback on the existing convolutional layers, and simply just zero out the innards, and also make them not part of the Flux.params or Flux.trainable properties."}]}]}]},{"client_msg_id":"31c7f33a-0e86-4586-a620-a4d104335b53","type":"message","text":"This doesn't seem to be answered: <https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197> :disappointed:","user":"U01L0KU0SDV","ts":"1614311537.035600","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"How to enforce weight matrix to be of a certain form (train a subset) in Flux?","title_link":"https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197","text":"For example, I want a layer specified by a symmetric or a tridiagonal matrix. Obviously, train! does not know about it, and an error is raised: ArgumentError: cannot set entry (3, 1) off the tridiagonal band to a nonzero value (0.03524077074068107). How to tell Flux to train only a certain subset of parameters (diagonals/upper half, etc)?","fallback":"JuliaLang: How to enforce weight matrix to be of a certain form (train a subset) in Flux?","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1578667877,"from_url":"https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197"}],"blocks":[{"type":"rich_text","block_id":"2ZMr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This doesn't seem to be answered: "},{"type":"link","url":"https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197"},{"type":"text","text":" "},{"type":"emoji","name":"disappointed"}]}]}]},{"client_msg_id":"660155a6-aaa3-4225-876d-184fd66b90d1","type":"message","text":"Was thinking maybe I could use this? <https://github.com/ahwillia/CatViews.jl>","user":"U01L0KU0SDV","ts":"1614312440.035900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FL4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Was thinking maybe I could use this? "},{"type":"link","url":"https://github.com/ahwillia/CatViews.jl"}]}]}]},{"client_msg_id":"a915bce4-c46c-4414-98c0-435ad9de4ea0","type":"message","text":"<@U6A936746> I am considering DataDeps.jl for managing pre-trained model weights. They are hosted in a separate repo from the package w/ git lfs. Came across this line “DataDeps.jl does not provide for versioning of data – you can’t force users to download new copies of your data using DataDeps.”","user":"UH9KWTTD3","ts":"1614360740.042000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n36/w","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U6A936746"},{"type":"text","text":" I am considering DataDeps.jl for managing pre-trained model weights. They are hosted in a separate repo from the package w/ git lfs. Came across this line “DataDeps.jl does not provide for versioning of data – you can’t force users to download new copies of your data using DataDeps.”"}]}]}]},{"client_msg_id":"cbd87050-9576-43cf-86e6-3ea4342a8c6c","type":"message","text":"Sounds to me like Pkg artifacts will be a better choice for what I need. Just wanted to double check there wasn’t something I’m missing since DataDeps.jl was suggested to me.","user":"UH9KWTTD3","ts":"1614360781.042900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5r8G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sounds to me like Pkg artifacts will be a better choice for what I need. Just wanted to double check there wasn’t something I’m missing since DataDeps.jl was suggested to me."}]}]}]},{"client_msg_id":"79838b35-f1c9-4b7b-b2c8-ee2b9e6c3406","type":"message","text":"I think data artifacts are a much better long term idea, since we can version and distribute them fairly cheaply and reliably","user":"UC4QQPG4A","ts":"1614363227.044300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V0+jS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think data artifacts are a much better long term idea, since we can version and distribute them fairly cheaply and reliably"}]}]}],"thread_ts":"1614363227.044300","reply_count":3,"reply_users_count":2,"latest_reply":"1614363555.044800","reply_users":["UH9KWTTD3","UC4QQPG4A"],"subscribed":false},{"client_msg_id":"a36e0c4c-4928-49ab-8a57-5a15f7e64567","type":"message","text":"is there a natural gradient implemented in Julia somewhere?","user":"UC6SUUPRC","ts":"1614368026.045300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gny14","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a natural gradient implemented in Julia somewhere?"}]}]}],"thread_ts":"1614368026.045300","reply_count":1,"reply_users_count":1,"latest_reply":"1614368514.046500","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"04b27987-d790-406b-b470-640d1591fd59","type":"message","text":"I find there are fisher info matrix defined in StatsBase, but it seems not for gradients","user":"UC6SUUPRC","ts":"1614368040.045700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gXt2a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I find there are fisher info matrix defined in StatsBase, but it seems not for gradients"}]}]}]},{"client_msg_id":"95393e2b-209b-4f74-9151-bcb7e842ae9f","type":"message","text":"New papers from the s4tf project: <https://twitter.com/bsaeta/status/1366271405285801984?s=19|https://twitter.com/bsaeta/status/1366271405285801984?s=19> interesting take on  optimizer and model interface","user":"UDGT4PM41","ts":"1614607367.053000","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1614607464.000000"},"attachments":[{"fallback":"<https://twitter.com/bsaeta|@bsaeta>: As promised ~2 weeks ago, some academic papers about #S4TF are now available! First up is “the overview paper\" (<https://arxiv.org/abs/2102.13243>); highlights include: (1) a discussion on how mutable value semantics is incredibly powerful (especially for autodiff &amp; hw acclrs), and …","ts":1614579461,"author_name":"Brennan Saeta","author_link":"https://twitter.com/bsaeta/status/1366271405285801984","author_icon":"https://pbs.twimg.com/profile_images/314609740/DJKarat_normal.png","author_subname":"@bsaeta","text":"As promised ~2 weeks ago, some academic papers about #S4TF are now available! First up is “the overview paper\" (<https://arxiv.org/abs/2102.13243>); highlights include: (1) a discussion on how mutable value semantics is incredibly powerful (especially for autodiff &amp; hw acclrs), and …","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/bsaeta/status/1366271405285801984?s=19","id":1,"original_url":"https://twitter.com/bsaeta/status/1366271405285801984?s=19","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"ZYlQX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"New papers from the s4tf project: "},{"type":"link","url":"https://twitter.com/bsaeta/status/1366271405285801984?s=19","text":"https://twitter.com/bsaeta/status/1366271405285801984?s=19"},{"type":"text","text":" interesting take on  optimizer and model interface"}]}]}]},{"client_msg_id":"de7c3ec8-fee1-4fea-ae8b-a49908d30b66","type":"message","text":"<https://twitter.com/bsaeta/status/1366271591852642306?s=19|https://twitter.com/bsaeta/status/1366271591852642306?s=19>","user":"UDGT4PM41","ts":"1614607496.055200","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/bsaeta|@bsaeta>: … And finally, we have <https://twitter.com/apaszke|@apaszke> ‘s intern paper on static shape analysis for ML programs called “Tensors Fitting Perfectly”: <https://arxiv.org/abs/2102.13254> . While I’m sad #S4TF is now in archive mode, the team did awesome work, and I’m glad we’ve been able to share some lessons …","ts":1614579506,"author_name":"Brennan Saeta","author_link":"https://twitter.com/bsaeta/status/1366271591852642306","author_icon":"https://pbs.twimg.com/profile_images/314609740/DJKarat_normal.png","author_subname":"@bsaeta","text":"… And finally, we have <https://twitter.com/apaszke|@apaszke> ‘s intern paper on static shape analysis for ML programs called “Tensors Fitting Perfectly”: <https://arxiv.org/abs/2102.13254> . While I’m sad #S4TF is now in archive mode, the team did awesome work, and I’m glad we’ve been able to share some lessons …","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/bsaeta/status/1366271591852642306?s=19","id":1,"original_url":"https://twitter.com/bsaeta/status/1366271591852642306?s=19","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"uzKkZ","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/bsaeta/status/1366271591852642306?s=19","text":"https://twitter.com/bsaeta/status/1366271591852642306?s=19"}]}]}]},{"client_msg_id":"d8cd6129-63d2-4ce1-875d-ee4b550069a0","type":"message","text":"<@U674T3KB3>  and <@U01K2JB9GPJ>  might be interested in that one","user":"UDGT4PM41","ts":"1614607520.055900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hmL","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U674T3KB3"},{"type":"text","text":"  and "},{"type":"user","user_id":"U01K2JB9GPJ"},{"type":"text","text":"  might be interested in that one"}]}]}]},{"type":"message","subtype":"channel_join","ts":"1614607525.056100","user":"U01K2JB9GPJ","text":"<@U01K2JB9GPJ> has joined the channel","inviter":"UDGT4PM41"}]}