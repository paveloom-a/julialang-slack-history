{"cursor": 0, "messages": [{"client_msg_id":"6623fe13-7857-434c-bb03-ac1e7892762f","type":"message","text":"Just curious if anyone knows any good resources for understanding how fast the universal approximation theorem holds true in very idealized cases?","user":"UEP056STX","ts":"1608090496.111000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eM+TM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just curious if anyone knows any good resources for understanding how fast the universal approximation theorem holds true in very idealized cases?"}]}]}]},{"client_msg_id":"2a90ff81-9d98-4b3d-92ae-eeb268ea639f","type":"message","text":"Obviously y = NN(x) = f(Wx + b) can approximate y = x exactly with one layer of size 1, but what about y = x^2 or y = sin(x), or what about y = exp(x^2 + y^2) or vector-valued functions? How many layers do you need before NN(x) approximates the function to machine epsilon over the entire real line (if that's even possible)?","user":"UEP056STX","ts":"1608090516.111300","team":"T68168MUP","edited":{"user":"UEP056STX","ts":"1608090579.000000"},"blocks":[{"type":"rich_text","block_id":"QobD0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Obviously y = NN(x) = f(Wx + b) can approximate y = x exactly with one layer of size 1, but what about y = x^2 or y = sin(x), or what about y = exp(x^2 + y^2) or vector-valued functions? How many layers do you need before NN(x) approximates the function to machine epsilon over the entire real line (if that's even possible)?"}]}]}],"reactions":[{"name":"+1","users":["U7THT3TM3"],"count":1}]},{"client_msg_id":"0bc26f57-2639-42a2-8139-dcc3b7c6600f","type":"message","text":"Not sure this exercise is even useful to think about, but was wondering whether it would provide any insight into picking neural network architectures for scientific machine learning purposes.","user":"UEP056STX","ts":"1608090536.111700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HLAu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not sure this exercise is even useful to think about, but was wondering whether it would provide any insight into picking neural network architectures for scientific machine learning purposes."}]}]}]},{"type":"message","text":"<https://github.com/lorenzoh/FluxTraining.jl|FluxTraining.jl> is awesome in VSCode by the way!","files":[{"id":"F01GTPHUF1U","created":1608096063,"timestamp":1608096063,"name":"Screen Shot 2020-12-16 at 12.20.59 AM.png","title":"Screen Shot 2020-12-16 at 12.20.59 AM.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01BG0NN34J","editable":false,"size":34534,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01GTPHUF1U/screen_shot_2020-12-16_at_12.20.59_am.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01GTPHUF1U/download/screen_shot_2020-12-16_at_12.20.59_am.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_360.png","thumb_360_w":360,"thumb_360_h":20,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_480.png","thumb_480_w":480,"thumb_480_h":27,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_720.png","thumb_720_w":720,"thumb_720_h":41,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_800.png","thumb_800_w":800,"thumb_800_h":45,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_960.png","thumb_960_w":960,"thumb_960_h":54,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_1024.png","thumb_1024_w":1024,"thumb_1024_h":58,"original_w":2270,"original_h":128,"thumb_tiny":"AwACADC/3FRv981J3FRyffNSyJDaKKKkkfFyTnmpenSoovvH6VKapFrY/9k=","permalink":"https://julialang.slack.com/files/U01BG0NN34J/F01GTPHUF1U/screen_shot_2020-12-16_at_12.20.59_am.png","permalink_public":"https://slack-files.com/T68168MUP-F01GTPHUF1U-0fce09ef08","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"Yck","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/lorenzoh/FluxTraining.jl","text":"FluxTraining.jl"},{"type":"text","text":" is awesome in VSCode by the way!"}]}]}],"user":"U01BG0NN34J","display_as_bot":false,"ts":"1608096083.112600","reactions":[{"name":"100","users":["U01724Q3PGW","U7THT3TM3","U9J14HBSR","UH9KWTTD3","U6795JH6H","U90JR0C80","U66M57AN4","U01C15GH58B","UE76KFRFX"],"count":9},{"name":"hushed","users":["U01G14RTVM2","U90JR0C80","UE76KFRFX"],"count":3}]},{"client_msg_id":"be433626-eeee-4dbc-8a3f-dfa2be428a2a","type":"message","text":"Looks really nice!","user":"U7THT3TM3","ts":"1608098184.114000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2p6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looks really nice!"}]}]}]},{"client_msg_id":"971b8d3c-bf3f-4d9f-ac5c-64efd7e0f920","type":"message","text":"So it doesn't use our progress UI? :(","user":"U6BNE7LTZ","ts":"1608218281.115300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V3jR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So it doesn't use our progress UI? :("}]}]}]},{"client_msg_id":"c726fa6b-5dfa-40d3-b9bf-52d1e1281abd","type":"message","text":"It implements ProgressMeter.jl","user":"UC4QQPG4A","ts":"1608218529.116400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mkS0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It implements ProgressMeter.jl"}]}]}]},{"client_msg_id":"d12fb7d4-a2ac-47e6-b73c-bfce1c0f7cae","type":"message","text":"ah, it'd need ProgressLogging support for VSCode's progress UI","user":"U6BNE7LTZ","ts":"1608219724.116800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nXqr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ah, it'd need ProgressLogging support for VSCode's progress UI"}]}]}]},{"client_msg_id":"6760ad42-dcb8-45b1-8e42-48864f05cd8d","type":"message","text":"Any existing packages or examples that save activations for each batch's forward pass? ","user":"U01EK81V5GF","ts":"1608282920.119200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nEzOr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any existing packages or examples that save activations for each batch's forward pass? ","style":{"unlink":true}}]}]}],"thread_ts":"1608282920.119200","reply_count":2,"reply_users_count":2,"latest_reply":"1608493927.128700","reply_users":["UMY1LV01G","U01EK81V5GF"],"subscribed":false},{"client_msg_id":"be9689b4-80f4-4510-9c41-f184983908ec","type":"message","text":"You could do that by saving and plotting the parameters","user":"UC4QQPG4A","ts":"1608284698.120100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=Sv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You could do that by saving and plotting the parameters"}]}]}]},{"client_msg_id":"afcd158a-bdc9-49c1-b312-8f7508f37be2","type":"message","text":"Hi all, I may take a ML/DL online course during holiday period. Which are the trends, and which will benefit more someone like me who work in computer vision and love Julia. Is fastai the best choice?","user":"U6CCK2SCV","ts":"1608337284.121000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JHG15","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all, I may take a ML/DL online course during holiday period. Which are the trends, and which will benefit more someone like me who work in computer vision and love Julia. Is fastai the best choice?"}]}]}],"thread_ts":"1608337284.121000","reply_count":5,"reply_users_count":3,"latest_reply":"1608484875.125600","reply_users":["U01CMBH4MQE","U6CCK2SCV","U01724Q3PGW"],"subscribed":false},{"client_msg_id":"017A70A9-48CA-4DCF-AF51-A3691EAE66FF","type":"message","text":"Have to do a project in pytorch - is there anything equivalent to MLDataPattern.jl 'slidingwindow' out there in Python?","user":"U01BG0NN34J","ts":"1608435754.123700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Q6J","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Have to do a project in pytorch - is there anything equivalent to MLDataPattern.jl 'slidingwindow' out there in Python?"}]}]}],"thread_ts":"1608435754.123700","reply_count":7,"reply_users_count":5,"latest_reply":"1608542454.129600","reply_users":["U01GMP3HF9C","UBVE598BC","U014QLCKTDE","U01BG0NN34J","UC4QQPG4A"],"subscribed":false},{"client_msg_id":"5cdad04b-500a-4bee-b19d-fb2da643553d","type":"message","text":"Anyone ever gotten `ERROR: LoadError: CUDA error: an illegal memory access was encountered (code 700, ERROR_ILLEGAL_ADDRESS)`  after loading a saved model and trying to continue training? The error is in the backwards pass. Any idea what is going wrong?","user":"U01EK81V5GF","ts":"1608493739.128500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G8FK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone ever gotten "},{"type":"text","text":"ERROR: LoadError: CUDA error: an illegal memory access was encountered (code 700, ERROR_ILLEGAL_ADDRESS)","style":{"code":true}},{"type":"text","text":"  after loading a saved model and trying to continue training? The error is in the backwards pass. Any idea what is going wrong?"}]}]}],"thread_ts":"1608493739.128500","reply_count":9,"reply_users_count":3,"latest_reply":"1608632626.146800","reply_users":["UM30MT6RF","UC4QQPG4A","U01EK81V5GF"],"subscribed":false},{"client_msg_id":"b3110fa4-59a3-4114-bc17-6c372f60f4f8","type":"message","text":"Simple Flux question - if I have two arrays (let’s say both of size  `(10, 10, 3, 20)` ) and I want to stack along `dim = 3` , is there a simple call for this ?","user":"UKA81L34J","ts":"1608565164.130700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2LU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Simple Flux question - if I have two arrays (let’s say both of size  "},{"type":"text","text":"(10, 10, 3, 20)","style":{"code":true}},{"type":"text","text":" ) and I want to stack along "},{"type":"text","text":"dim = 3","style":{"code":true}},{"type":"text","text":" , is there a simple call for this ?"}]}]}],"thread_ts":"1608565164.130700","reply_count":5,"reply_users_count":2,"latest_reply":"1608565604.131600","reply_users":["UM30MT6RF","UKA81L34J"],"subscribed":false},{"client_msg_id":"e7885a9b-6ddd-4dc1-9aff-a77cde06c151","type":"message","text":"Is there a way to use type parameters with `Flux.@functor` ?","user":"UKA81L34J","ts":"1608570370.132000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zhB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a way to use type parameters with "},{"type":"text","text":"Flux.@functor","style":{"code":true}},{"type":"text","text":" ?"}]}]}]},{"client_msg_id":"239cb764-6faf-4884-8d24-883a8c7a840d","type":"message","text":"By default it picks up arrays only, but you can add the fields you want it to pick up or use Flux.trainable","user":"UC4QQPG4A","ts":"1608571401.133200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"j=7Nt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"By default it picks up arrays only, but you can add the fields you want it to pick up or use Flux.trainable"}]}]}]},{"client_msg_id":"793e75c6-fdd5-4dad-b5f2-ecf5e6a916ad","type":"message","text":"You probably want to overload `Flux.functor` for anything more advanced.","user":"UM30MT6RF","ts":"1608572117.133700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eic","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You probably want to overload "},{"type":"text","text":"Flux.functor","style":{"code":true}},{"type":"text","text":" for anything more advanced."}]}]}],"reactions":[{"name":"point_up","users":["UMY1LV01G","UKA81L34J"],"count":2}]},{"client_msg_id":"5dbea6ad-44ef-42b6-b0f8-e27f6f69eaf8","type":"message","text":"<@UM30MT6RF> think this is the right way - I just want to define a model struct which is a bit more complex. If I define:\n```Flux.functor(model::NewType, fn)```\nwill `fmap` pick it up ?","user":"UKA81L34J","ts":"1608572625.134700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"D5ak","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UM30MT6RF"},{"type":"text","text":" think this is the right way - I just want to define a model struct which is a bit more complex. If I define:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Flux.functor(model::NewType, fn)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"will "},{"type":"text","text":"fmap","style":{"code":true}},{"type":"text","text":" pick it up ?"}]}]}]},{"client_msg_id":"f04f8da9-ce67-4c72-9054-bba5a62de532","type":"message","text":"It should","user":"UM30MT6RF","ts":"1608572651.134900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"B4V1O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It should"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"The error still occurs when I explicitly move the model to CPU before saving and use `--check-bounds=yes` to start Julia","user":"U01EK81V5GF","ts":"1608627982.135900","thread_ts":"1608493739.128500","root":{"client_msg_id":"5cdad04b-500a-4bee-b19d-fb2da643553d","type":"message","text":"Anyone ever gotten `ERROR: LoadError: CUDA error: an illegal memory access was encountered (code 700, ERROR_ILLEGAL_ADDRESS)`  after loading a saved model and trying to continue training? The error is in the backwards pass. Any idea what is going wrong?","user":"U01EK81V5GF","ts":"1608493739.128500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G8FK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone ever gotten "},{"type":"text","text":"ERROR: LoadError: CUDA error: an illegal memory access was encountered (code 700, ERROR_ILLEGAL_ADDRESS)","style":{"code":true}},{"type":"text","text":"  after loading a saved model and trying to continue training? The error is in the backwards pass. Any idea what is going wrong?"}]}]}],"thread_ts":"1608493739.128500","reply_count":9,"reply_users_count":3,"latest_reply":"1608632626.146800","reply_users":["UM30MT6RF","UC4QQPG4A","U01EK81V5GF"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"91RXp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The error still occurs when I explicitly move the model to CPU before saving and use "},{"type":"text","text":"--check-bounds=yes","style":{"code":true}},{"type":"text","text":" to start Julia"}]}]}],"client_msg_id":"09055d71-f9b4-46d4-8480-73762f99d746","edited":{"user":"U01EK81V5GF","ts":"1608628003.000000"}},{"client_msg_id":"f339de8f-3a29-493f-a026-c945ad8596b0","type":"message","text":"Just curious, I've seen in general that documentation in Flux is usually not that extensive as is usually the case with same functionality in PyTorch, is it intentionally kept as such or the focus of Flux (atleast currently) is to catch with providing the matching functionalities in PyTorch as a priori, instead of focusing on providing extensive documentation.\n\nOr is it expected of the user of Flux to be able to understand from the source code instead as to what each and everything means?","user":"U01891GQRFZ","ts":"1608630733.141000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=bW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just curious, I've seen in general that documentation in Flux is usually not that extensive as is usually the case with same functionality in PyTorch, is it intentionally kept as such or the focus of Flux (atleast currently) is to catch with providing the matching functionalities in PyTorch as a priori, instead of focusing on providing extensive documentation.\n\nOr is it expected of the user of Flux to be able to understand from the source code instead as to what each and everything means?"}]}]}]},{"client_msg_id":"d2474830-53bc-4517-a8a9-9d57aaf1ef75","type":"message","text":"It's definitely not intentional, it's just that Flux is still quite young and it's difficult to write good documentation, so I think the sparse documentation is mostly due to limited resources of Flux developers. Contributions to documentation are always very welcome, especially from people new to Flux, since you probably know better what additional documentation would be most helpful to other newcomers!","user":"UM30MT6RF","ts":"1608631210.144500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QLe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's definitely not intentional, it's just that Flux is still quite young and it's difficult to write good documentation, so I think the sparse documentation is mostly due to limited resources of Flux developers. Contributions to documentation are always very welcome, especially from people new to Flux, since you probably know better what additional documentation would be most helpful to other newcomers!"}]}]}],"reactions":[{"name":"+1","users":["UMY1LV01G"],"count":1}]},{"client_msg_id":"b0f103e9-a7d6-462a-b073-7b56a6c29c5d","type":"message","text":"That said, Flux definitely makes understanding functions just from their source code a lot easier, since everything is implemented in Julia, but that doesn't mean we shouldn't have better documentation as well.","user":"UM30MT6RF","ts":"1608631368.146300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+KQIj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That said, Flux definitely makes understanding functions just from their source code a lot easier, since everything is implemented in Julia, but that doesn't mean we shouldn't have better documentation as well."}]}]}]},{"client_msg_id":"9a3adcaa-5afb-4ecb-8dc1-21555eaccadd","type":"message","text":"Agreed, thanks Simeon. :slightly_smiling_face:","user":"U01891GQRFZ","ts":"1608631427.146700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"agI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Agreed, thanks Simeon. "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"type":"message","text":"I’m trying to diagnose a training loss instability","files":[{"id":"F01HN70NBMJ","created":1608660950,"timestamp":1608660950,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UKA81L34J","editable":false,"size":178987,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HN70NBMJ/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HN70NBMJ/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_360.png","thumb_360_w":360,"thumb_360_h":326,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_480.png","thumb_480_w":480,"thumb_480_h":435,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_720.png","thumb_720_w":720,"thumb_720_h":652,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_800.png","thumb_800_w":800,"thumb_800_h":725,"original_w":938,"original_h":850,"thumb_tiny":"AwArADClQDiikoAdvOMYH5Ubz6D8hTaKAFJyc0lLRQACkpR1oIxQAlFFFABRRRQAtGafgccDpSgDA4FADMn0oyfSnCmZoACc0H60lFAH/9k=","permalink":"https://julialang.slack.com/files/UKA81L34J/F01HN70NBMJ/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HN70NBMJ-6c98804170","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"x46kr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m trying to diagnose a training loss instability"}]}]}],"user":"UKA81L34J","display_as_bot":false,"ts":"1608660953.148200","thread_ts":"1608660953.148200","reply_count":3,"reply_users_count":2,"latest_reply":"1608661634.149300","reply_users":["UJ7DVTVQ8","UKA81L34J"],"subscribed":false},{"client_msg_id":"b7f429c4-83c6-4345-b8ce-d26638c74eaa","type":"message","text":"any ideas what could cause a curve to suddenly go sour like this ?","user":"UKA81L34J","ts":"1608660967.148700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"K110","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"any ideas what could cause a curve to suddenly go sour like this ?"}]}]}],"reactions":[{"name":"lemon","users":["U680THK2S"],"count":1}]},{"client_msg_id":"7670713d-3e1b-4256-9c96-94066b877ae9","type":"message","text":"yep, denominator of normalization expression suddenly goes to NaN","user":"UKA81L34J","ts":"1608662836.149800","team":"T68168MUP","edited":{"user":"UKA81L34J","ts":"1608662861.000000"},"blocks":[{"type":"rich_text","block_id":"oHv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yep, denominator of normalization expression suddenly goes to NaN"}]}]}],"thread_ts":"1608662836.149800","reply_count":1,"reply_users_count":1,"latest_reply":"1608663863.151100","reply_users":["UTRAUNYDA"],"subscribed":false},{"client_msg_id":"a85925e7-c9b4-41f0-baa4-945141602718","type":"message","text":"Is there a GPUified `LogSumExp` ?","user":"UKA81L34J","ts":"1608751876.152400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fM2W","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a GPUified "},{"type":"text","text":"LogSumExp","style":{"code":true}},{"type":"text","text":" ?"}]}]}],"thread_ts":"1608751876.152400","reply_count":6,"reply_users_count":2,"latest_reply":"1608752659.154600","reply_users":["UD0NS8PDF","UKA81L34J"],"subscribed":false},{"client_msg_id":"1679d72a-8bf9-4e68-8193-32ad16dc380e","type":"message","text":"That version appears to be include the usage of `setindex!`  - I’m not sure of the runtime cost","user":"UKA81L34J","ts":"1608752509.154200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V4o7Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That version appears to be include the usage of "},{"type":"text","text":"setindex!","style":{"code":true}},{"type":"text","text":"  - I’m not sure of the runtime cost"}]}]}]},{"client_msg_id":"042f8052-3450-4afe-b7eb-a1162292d3f0","type":"message","text":"at least, CUDA is yelling at me for that","user":"UKA81L34J","ts":"1608752519.154500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Shh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"at least, CUDA is yelling at me for that"}]}]}]},{"client_msg_id":"ad6c9da5-65ad-458a-b9f9-6ea933eb15bd","type":"message","text":"A while ago I remember running across a paper where the goal was to learn an optimization algorithm, e.g. . a neural network that can be iteratively queried with f(x) and gradf(x) values to produce a series of solution estimates towards the optimum of f(x). It was then favorably compared to human-produced algorithms such as Adam or Adagrad. I cannot find it now, does anyone know which one I mean? And has anyone seen the same idea but for constrained optimization, where a constraint c(x) and its gradient is also supplied to an iterative algorithm we want to learn?","user":"UFCNUVC67","ts":"1608821900.159700","team":"T68168MUP","edited":{"user":"UFCNUVC67","ts":"1608821948.000000"},"blocks":[{"type":"rich_text","block_id":"/Ij","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"A while ago I remember running across a paper where the goal was to learn an optimization algorithm, e.g. . a neural network that can be iteratively queried with f(x) and gradf(x) values to produce a series of solution estimates towards the optimum of f(x). It was then favorably compared to human-produced algorithms such as Adam or Adagrad. I cannot find it now, does anyone know which one I mean? And has anyone seen the same idea but for constrained optimization, where a constraint c(x) and its gradient is also supplied to an iterative algorithm we want to learn?"}]}]}],"thread_ts":"1608821900.159700","reply_count":1,"reply_users_count":1,"latest_reply":"1608822318.160000","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"d5dd5d8d-770a-4edb-9f8e-105af38f5865","type":"message","text":"I'm pretty new to DL and big data, I am working on a project with GTZAN data <http://marsyas.info/downloads/datasets.html> and was wondering if with audio data people usually feed it as is into a Conv1D or do they create the mel spectrogram and use a Conv2D? Do you have to preprocess and use filters for audio data prior to the ConvNet or is it truly the case that ConvNets basically remove the need for it? The time series I have is length ~660K does it have to be downsampled for computational purposes? I end up with a n x p of ~700 x 660K which is huge, and I want to try simple models like PCA+Logistic Regression first","user":"U01EF0QVAB0","ts":"1608918941.164400","team":"T68168MUP","edited":{"user":"U01EF0QVAB0","ts":"1608918994.000000"},"blocks":[{"type":"rich_text","block_id":"OxXqo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm pretty new to DL and big data, I am working on a project with GTZAN data "},{"type":"link","url":"http://marsyas.info/downloads/datasets.html"},{"type":"text","text":" and was wondering if with audio data people usually feed it as is into a Conv1D or do they create the mel spectrogram and use a Conv2D? Do you have to preprocess and use filters for audio data prior to the ConvNet or is it truly the case that ConvNets basically remove the need for it? The time series I have is length ~660K does it have to be downsampled for computational purposes? I end up with a n x p of ~700 x 660K which is huge, and I want to try simple models like PCA+Logistic Regression first"}]}]}]},{"type":"message","text":"So I am running into some trouble with the example here <https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/stacking/#basic_stacking_using_out-of-sample_base_learner_predictions|https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/stacking/#basic_stacking_using_out-of[…]ple_base_learner_predictions> when applied to my case. It seems the problem is the predictions in a multiclass situation are in this very strange type structure UnivariateFinite{MultiClass{10}} that looks like a vector of a Dict but it isn't. I simply need to add 0.5 of this to the yRF() prediction but the addition (+) and (*) are not defined. Is there any way I can define it myself?","files":[{"id":"F01HTLE0V3N","created":1608956811,"timestamp":1608956811,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01EF0QVAB0","editable":false,"size":176090,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HTLE0V3N/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HTLE0V3N/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_360.png","thumb_360_w":360,"thumb_360_h":188,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_480.png","thumb_480_w":480,"thumb_480_h":251,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_720.png","thumb_720_w":720,"thumb_720_h":377,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_800.png","thumb_800_w":800,"thumb_800_h":419,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_960.png","thumb_960_w":960,"thumb_960_h":502,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":536,"original_w":1586,"original_h":830,"thumb_tiny":"AwAZADCn+VGaX86PzpgJ+FGfYUZNGaACkoooAdijB9KRetSUgGYPpSYNPpaLjsR0YpT1opiP/9k=","permalink":"https://julialang.slack.com/files/U01EF0QVAB0/F01HTLE0V3N/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HTLE0V3N-44db6b4363","is_starred":false,"has_rich_preview":false},{"id":"F01HMFMAY66","created":1608956977,"timestamp":1608956977,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01EF0QVAB0","editable":false,"size":145398,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HMFMAY66/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HMFMAY66/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_360.png","thumb_360_w":360,"thumb_360_h":84,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_480.png","thumb_480_w":480,"thumb_480_h":113,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_720.png","thumb_720_w":720,"thumb_720_h":169,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_800.png","thumb_800_w":800,"thumb_800_h":188,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_960.png","thumb_960_w":960,"thumb_960_h":225,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":240,"original_w":1960,"original_h":460,"thumb_tiny":"AwALADCtx6Un4CjNFMA/AUY9hSUUALgelGB6UlFAH//Z","permalink":"https://julialang.slack.com/files/U01EF0QVAB0/F01HMFMAY66/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HMFMAY66-c4e24856f3","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"UOp3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So I am running into some trouble with the example here "},{"type":"link","url":"https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/stacking/#basic_stacking_using_out-of-sample_base_learner_predictions","text":"https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/stacking/#basic_stacking_using_out-of[…]ple_base_learner_predictions"},{"type":"text","text":" when applied to my case. It seems the problem is the predictions in a multiclass situation are in this very strange type structure UnivariateFinite{MultiClass{10}} that looks like a vector of a Dict but it isn't. I simply need to add 0.5 of this to the yRF() prediction but the addition (+) and (*) are not defined. Is there any way I can define it myself?"}]}]}],"user":"U01EF0QVAB0","ts":"1608957004.169500"},{"client_msg_id":"805c4ab4-c399-4934-83c5-24857504cf7b","type":"message","text":"Which julia package can you recommend for support vector regression?","user":"U019PPN3H6J","ts":"1608978439.171200","team":"T68168MUP","edited":{"user":"U019PPN3H6J","ts":"1608978877.000000"},"blocks":[{"type":"rich_text","block_id":"vn7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Which julia package can you recommend for support vector regression?"}]}]}],"thread_ts":"1608978439.171200","reply_count":2,"reply_users_count":2,"latest_reply":"1608979758.172800","reply_users":["U6A936746","U019PPN3H6J"],"subscribed":false},{"client_msg_id":"4530fbb4-66e5-4d0c-b65b-de66f914c62f","type":"message","text":"Did anyone else notice that Google created MuZero that’s an improved version of AlphaZero, and uses reinforcement learning?\n<https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/>","user":"U01CQTKB86N","ts":"1608979182.172000","team":"T68168MUP","attachments":[{"service_name":"Ars Technica","title":"Google develops an AI that can learn both chess and Pac-Man","title_link":"https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/","text":"MuZero handles both rules-based and open-ended games.","fallback":"Ars Technica: Google develops an AI that can learn both chess and Pac-Man","image_url":"https://cdn.arstechnica.net/wp-content/uploads/2020/12/3536942268_68d718be1f_b-760x380.jpg","image_width":500,"image_height":250,"from_url":"https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/","image_bytes":59866,"service_icon":"https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/ars-ios-icon-d9a45f558c.png","id":1,"original_url":"https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/"}],"blocks":[{"type":"rich_text","block_id":"gmUf=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Did anyone else notice that Google created MuZero that’s an improved version of AlphaZero, and uses reinforcement learning?\n"},{"type":"link","url":"https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/"}]}]}],"thread_ts":"1608979182.172000","reply_count":2,"reply_users_count":1,"latest_reply":"1608979727.172600","reply_users":["U01CQTKB86N"],"subscribed":false},{"client_msg_id":"d6ad5daa-23ab-4b67-bb6b-2d6337fe53fc","type":"message","text":"Any idea why is there an overhead with using PCA from MLJ.jl with DataFrames? Its very strange when I try to fit a PCA model and use a matrix I get \"Warning: The scitype of `X`, in `machine(model, X)` is incompatible with `model=PCA @395`:\n`│ scitype(X) = AbstractArray{Continuous,2}`\n`│ input_scitype(model) = Table{var\"#s45\"} where var\"#s45\"&lt;:(AbstractArray{var\"#s13\",1} where var\"#s13\"&lt;:Continuous).\"` but it still fits something anyways much faster. And then when I am using transform(), it is very slow to transform DataFrames but can transform Matrices faster, but then they don't stay as a Matrix nor a DataFrame but can be coerced to a DF then a Matrix","user":"U01EF0QVAB0","ts":"1609220745.181600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tfnE7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any idea why is there an overhead with using PCA from MLJ.jl with DataFrames? Its very strange when I try to fit a PCA model and use a matrix I get \"Warning: The scitype of `X`, in `machine(model, X)` is incompatible with `model=PCA @395`:\n"},{"type":"text","text":"│ scitype(X) = AbstractArray{Continuous,2}","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"│ input_scitype(model) = Table{var\"#s45\"} where var\"#s45\"<:(AbstractArray{var\"#s13\",1} where var\"#s13\"<:Continuous).\"","style":{"code":true}},{"type":"text","text":" but it still fits something anyways much faster. And then when I am using transform(), it is very slow to transform DataFrames but can transform Matrices faster, but then they don't stay as a Matrix nor a DataFrame but can be coerced to a DF then a Matrix"}]}]}]},{"type":"message","subtype":"channel_join","ts":"1609333401.184600","user":"U01HYEN2ES0","text":"<@U01HYEN2ES0> has joined the channel","inviter":"UEP056STX"},{"client_msg_id":"175639e3-c2c8-4d0e-aa1d-6ed3539921ae","type":"message","text":"Hey people, what's an interesting dataset to test a recurrent neural network on? I have some of my own, but they are quite niche, and I'm interested in benchmarking with datasets that are familiar to the community.","user":"UAL8DLH7D","ts":"1609343719.186000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TuRV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey people, what's an interesting dataset to test a recurrent neural network on? I have some of my own, but they are quite niche, and I'm interested in benchmarking with datasets that are familiar to the community."}]}]}],"thread_ts":"1609343719.186000","reply_count":4,"reply_users_count":1,"latest_reply":"1609344133.186900","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"f99c4f03-c983-43d3-9161-567ea61fcfb9","type":"message","text":"Wasn't there something like this done in Julia recently? <https://zongyi-li.github.io/blog/2020/fourier-pde/>","user":"U9RDM8ZGT","ts":"1609357342.187500","team":"T68168MUP","attachments":[{"title":"Zongyi Li | Fourier Neural Operator","title_link":"https://zongyi-li.github.io/blog/2020/fourier-pde/","text":"Zongyi's personal website.","fallback":"Zongyi Li | Fourier Neural Operator","from_url":"https://zongyi-li.github.io/blog/2020/fourier-pde/","service_name":"zongyi-li.github.io","id":1,"original_url":"https://zongyi-li.github.io/blog/2020/fourier-pde/"}],"blocks":[{"type":"rich_text","block_id":"2Ui7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Wasn't there something like this done in Julia recently? "},{"type":"link","url":"https://zongyi-li.github.io/blog/2020/fourier-pde/"}]}]}]},{"client_msg_id":"6a2391a6-feb2-4d34-97a0-d7ac2439090c","type":"message","text":"we're going to be implementing it in NeuralPDE.jl. The discussion on that was in <#CN04R7WKE|sciml>","user":"U69BL50BF","ts":"1609358096.188000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oC3m","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"we're going to be implementing it in NeuralPDE.jl. The discussion on that was in "},{"type":"channel","channel_id":"CN04R7WKE"}]}]}],"reactions":[{"name":"+1","users":["U9RDM8ZGT"],"count":1}]},{"client_msg_id":"eafd3db0-26e1-4dd2-aeed-d24621a668c7","type":"message","text":"is there a GPU compat way to take two arrays of different dims and multiply them along a compatible dimension?\nE.g.\n```x = randn((10, 5))\nz = randn((100, 10, 10))\nspecial_call(x, y; dim = 2) # =&gt; sizeof(...) = (100, 5, 10)```","user":"UKA81L34J","ts":"1609876316.194200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lzmif","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a GPU compat way to take two arrays of different dims and multiply them along a compatible dimension?\nE.g.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"x = randn((10, 5))\nz = randn((100, 10, 10))\nspecial_call(x, y; dim = 2) # => sizeof(...) = (100, 5, 10)"}]}]}],"thread_ts":"1609876316.194200","reply_count":1,"reply_users_count":1,"latest_reply":"1609876545.195400","reply_users":["UD0NS8PDF"],"subscribed":false},{"client_msg_id":"2ef2a437-cd44-4f27-96f5-fb26b952a88c","type":"message","text":"I guess the correct thing is :\n```z = reshape(z, (10, 100*10))\nout = x * z\nreshape(out, (100, 5, 10))```","user":"UKA81L34J","ts":"1609876546.195600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=cp1x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I guess the correct thing is :\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"z = reshape(z, (10, 100*10))\nout = x * z\nreshape(out, (100, 5, 10))"}]}]}]},{"client_msg_id":"22300fc3-a622-40d8-85d5-5f95a2b18b36","type":"message","text":"I don’t totally understand this CUDA error","user":"UKA81L34J","ts":"1609881787.196200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YBM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don’t totally understand this CUDA error"}]}]}]},{"type":"message","text":"","files":[{"id":"F01J2ATFECB","created":1609881788,"timestamp":1609881788,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UKA81L34J","editable":false,"size":1253477,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01J2ATFECB/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01J2ATFECB/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_360.png","thumb_360_w":330,"thumb_360_h":360,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_480.png","thumb_480_w":440,"thumb_480_h":480,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_720.png","thumb_720_w":659,"thumb_720_h":720,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_800.png","thumb_800_w":800,"thumb_800_h":873,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_960.png","thumb_960_w":879,"thumb_960_h":960,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_1024.png","thumb_1024_w":938,"thumb_1024_h":1024,"original_w":1394,"original_h":1522,"thumb_tiny":"AwAwACurg44z+FJz708H60c56mkAzn3/ADo59/zp2Pr+QpMf5wKYDfm9/wA6MNTuPUfkKTA9R+lADhn0NHOc/NRwB3pCRjrQAuD6mg5A+8aTP0oz9PzNACZ/2qPxpcj2/Ok3D0/WgB+OO9IfxpQeKTnqd35UgE/zmkz7ilIY92/KjDep/wC+aYAD/u/nRk+o/OjDep/75pDn1P5UAf/Z","permalink":"https://julialang.slack.com/files/UKA81L34J/F01J2ATFECB/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01J2ATFECB-e775fdd49e","is_starred":false,"has_rich_preview":false}],"upload":false,"user":"UKA81L34J","display_as_bot":false,"ts":"1609881793.196300","thread_ts":"1609881793.196300","reply_count":8,"reply_users_count":2,"latest_reply":"1609883215.198000","reply_users":["UMY1LV01G","UKA81L34J"],"subscribed":false},{"client_msg_id":"8b1c284e-e20e-417a-acc1-88ee55cb0b33","type":"message","text":"any tricks to hunt down pullback computations which are causing `NaNs` ?","user":"UKA81L34J","ts":"1609948808.198800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"l872i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"any tricks to hunt down pullback computations which are causing "},{"type":"text","text":"NaNs","style":{"code":true}},{"type":"text","text":" ?"}]}]}]},{"client_msg_id":"f352ba36-4e61-4ecc-aadf-5e8714931483","type":"message","text":"`Zygote.@showgrad`, `ignore`\n\nIf there are smaller kernels, that's easier. You can also check code_ir but that's prolly too low level","user":"UC4QQPG4A","ts":"1609950102.201100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eW+M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Zygote.@showgrad","style":{"code":true}},{"type":"text","text":", `ignore`\n\nIf there are smaller kernels, that's easier. You can also check code_ir but that's prolly too low level"}]}]}]},{"type":"message","text":"I have softmax throwing `NaNs` for things which I think are … okay ? Maybe the numbers are too large, not sure.","files":[{"id":"F01JU8KEHLY","created":1609954917,"timestamp":1609954917,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UKA81L34J","editable":false,"size":1046381,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01JU8KEHLY/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01JU8KEHLY/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_360.png","thumb_360_w":356,"thumb_360_h":360,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_480.png","thumb_480_w":474,"thumb_480_h":480,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_720.png","thumb_720_w":711,"thumb_720_h":720,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_800.png","thumb_800_w":800,"thumb_800_h":810,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_960.png","thumb_960_w":948,"thumb_960_h":960,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_1024.png","thumb_1024_w":1011,"thumb_1024_h":1024,"original_w":1432,"original_h":1450,"thumb_tiny":"AwAwAC+mvPFOwMZxSI5Uk9eO9PZ0K8Z3H8qQyPHt+lGD/d/Sjd/nFJk0xB+ApKXJoyaAJMtj71Jz6/pS0UAJg+tJg4606g0AN+b1/WnEAL99vpijvSHpSAWjvTgjEcDIppG04PBFACUnH93NLmlxTAbgf3aCOOBTwrHoM0FGAyRQB//Z","permalink":"https://julialang.slack.com/files/UKA81L34J/F01JU8KEHLY/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01JU8KEHLY-0a0533cb51","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"UjFB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have softmax throwing "},{"type":"text","text":"NaNs","style":{"code":true}},{"type":"text","text":" for things which I think are … okay ? Maybe the numbers are too large, not sure."}]}]}],"user":"UKA81L34J","display_as_bot":false,"ts":"1609954923.201700"},{"client_msg_id":"8cd32149-20a2-4648-af0e-041cd3d56496","type":"message","text":"if this is not okay, I wonder how to solve this issue (implementing a self-attention block). The implementation is accurate to the paper.","user":"UKA81L34J","ts":"1609954987.202800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1L2Pg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if this is not okay, I wonder how to solve this issue (implementing a self-attention block). The implementation is accurate to the paper."}]}]}]},{"client_msg_id":"208bc512-211f-4caa-a45f-143613bbcbd4","type":"message","text":"I think this is a GPU issue","user":"UKA81L34J","ts":"1609956335.203000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Li4O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think this is a GPU issue"}]}]}]},{"client_msg_id":"97521694-85a6-4742-8e41-cdf643e1f882","type":"message","text":"```julia&gt; x = Float32.(rand(Normal(1000, 5000), (8, 8)))\n8×8 Array{Float32,2}:\n -3964.74   2589.43    353.542  …   5739.63   -9249.16   -2261.62\n -2906.62  -4961.38   3806.42       5289.22   -1641.34   -2714.45\n  2631.91  -5205.12  -9457.25       -828.516    547.219   1672.61\n  1063.99   9839.1    1015.35        120.756   2368.13   -2053.6\n  4159.93   2475.06   4742.76       3449.55   -1954.95    2495.51\n  2762.14   2851.15  -1772.85   …  -1387.07    8878.1    -3331.67\n -2036.93   5332.2   -3068.55       7775.97    7075.53    1439.79\n  1529.58   6816.89   4004.75      -4904.47   -6143.29    5725.86\n\njulia&gt; softmax(x)\n8×8 Array{Float32,2}:\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0\n 1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0```","user":"UKA81L34J","ts":"1609956349.203300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3SR1","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> x = Float32.(rand(Normal(1000, 5000), (8, 8)))\n8×8 Array{Float32,2}:\n -3964.74   2589.43    353.542  …   5739.63   -9249.16   -2261.62\n -2906.62  -4961.38   3806.42       5289.22   -1641.34   -2714.45\n  2631.91  -5205.12  -9457.25       -828.516    547.219   1672.61\n  1063.99   9839.1    1015.35        120.756   2368.13   -2053.6\n  4159.93   2475.06   4742.76       3449.55   -1954.95    2495.51\n  2762.14   2851.15  -1772.85   …  -1387.07    8878.1    -3331.67\n -2036.93   5332.2   -3068.55       7775.97    7075.53    1439.79\n  1529.58   6816.89   4004.75      -4904.47   -6143.29    5725.86\n\njulia> softmax(x)\n8×8 Array{Float32,2}:\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0\n 1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0"}]}]}]},{"client_msg_id":"c1e691ec-0e19-4d99-b55b-c0ad7a1266c4","type":"message","text":"yep","user":"UKA81L34J","ts":"1609956465.203500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V74","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yep"}]}]}]},{"client_msg_id":"4d1ac1b7-f606-4518-a035-ccb49bd08ab4","type":"message","text":"should I post this on `NNlib` or `CUDA` ?","user":"UKA81L34J","ts":"1609956490.203800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"amHuH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"should I post this on "},{"type":"text","text":"NNlib","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"CUDA","style":{"code":true}},{"type":"text","text":" ?"}]}]}]},{"client_msg_id":"f91d7aaf-cb53-417b-8331-603a69494407","type":"message","text":"Perhaps related to <https://github.com/JuliaGPU/CUDA.jl/pull/523#issuecomment-753416384>?","user":"UMY1LV01G","ts":"1609959134.204200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7EZE4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Perhaps related to "},{"type":"link","url":"https://github.com/JuliaGPU/CUDA.jl/pull/523#issuecomment-753416384"},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"715d9e25-4571-4b96-98bf-f64b21da1bd0","type":"message","text":"it looks like `CUDNN_SOFTMAX_ACCURATE` is the default now ?","user":"UKA81L34J","ts":"1609959393.204600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T+Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it looks like "},{"type":"text","text":"CUDNN_SOFTMAX_ACCURATE","style":{"code":true}},{"type":"text","text":" is the default now ?"}]}]}]},{"client_msg_id":"f3210a48-d9c6-439f-8e10-b77993b85830","type":"message","text":"your example works OK for me btw, but for some reason I'm on an older version of CUDA (in a fresh session; ~maybe CUDA 2 requires julia 1.6?~ just needed an explicit `up` for some reason)\n```julia&gt; using Distributions, CUDA, NNlib\n\njulia&gt; x = Float32.(rand(Normal(1000, 5000), (8, 8)))\n8×8 Array{Float32,2}:\n 10929.8    -827.791   3975.23   4571.25   -2578.11    3236.93     807.547    186.267\n -4886.28  14463.1    11163.5     289.532    444.538   1002.29    5984.53   -3821.62\n  5320.05  -4313.7    -3746.56   -727.577    641.654  -5851.06   -7113.68    -596.851\n  1219.08    780.571   4153.41   -279.646  -7849.32   -3537.99    -148.493  -2227.9\n  4217.94   4555.9    -3237.11   6036.93    5102.21   11041.5     1709.73    3534.94\n  1315.21  -3911.77    2479.11  -1178.5     7613.43    3699.27    8300.34    7121.03\n  2160.52   -379.444   5821.29   -974.758   5859.66    6086.66   10810.9     5877.44\n  4791.66   5207.67    1509.5    6044.1     6407.24     721.443   6796.54   -5439.79\n\njulia&gt; softmax(x)\n8×8 Array{Float32,2}:\n 1.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  1.0  1.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.000764676  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0          1.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0          0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.999235     0.0  0.0  0.0  0.0\n\njulia&gt; softmax(cu(copy(x)))\n8×8 CuArray{Float32,2}:\n 1.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  1.0  1.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.000764676  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0          1.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0          0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.999235     0.0  0.0  0.0  0.0\n\njulia&gt; versioninfo()\nJulia Version 1.5.3\nCommit 788b2c77c1 (2020-11-09 13:37 UTC)\nPlatform Info:\n  OS: Linux (x86_64-pc-linux-gnu)\n  CPU: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)\n\n(misc) pkg&gt; st\nStatus `~/Beacon/misc/Project.toml`\n  [052768ef] CUDA v1.3.3\n  [31c24e10] Distributions v0.24.10\n  [872c559c] NNlib v0.7.10```","user":"UCZ7VBGUD","ts":"1609959947.205500","team":"T68168MUP","edited":{"user":"UCZ7VBGUD","ts":"1609960150.000000"},"blocks":[{"type":"rich_text","block_id":"Dd6U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"your example works OK for me btw, but for some reason I'm on an older version of CUDA (in a fresh session; "},{"type":"text","text":"maybe CUDA 2 requires julia 1.6?","style":{"strike":true}},{"type":"text","text":" just needed an explicit "},{"type":"text","text":"up","style":{"code":true}},{"type":"text","text":" for some reason)\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> using Distributions, CUDA, NNlib\n\njulia> x = Float32.(rand(Normal(1000, 5000), (8, 8)))\n8×8 Array{Float32,2}:\n 10929.8    -827.791   3975.23   4571.25   -2578.11    3236.93     807.547    186.267\n -4886.28  14463.1    11163.5     289.532    444.538   1002.29    5984.53   -3821.62\n  5320.05  -4313.7    -3746.56   -727.577    641.654  -5851.06   -7113.68    -596.851\n  1219.08    780.571   4153.41   -279.646  -7849.32   -3537.99    -148.493  -2227.9\n  4217.94   4555.9    -3237.11   6036.93    5102.21   11041.5     1709.73    3534.94\n  1315.21  -3911.77    2479.11  -1178.5     7613.43    3699.27    8300.34    7121.03\n  2160.52   -379.444   5821.29   -974.758   5859.66    6086.66   10810.9     5877.44\n  4791.66   5207.67    1509.5    6044.1     6407.24     721.443   6796.54   -5439.79\n\njulia> softmax(x)\n8×8 Array{Float32,2}:\n 1.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  1.0  1.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.000764676  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0          1.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0          0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.999235     0.0  0.0  0.0  0.0\n\njulia> softmax(cu(copy(x)))\n8×8 CuArray{Float32,2}:\n 1.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  1.0  1.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.000764676  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0          1.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0          0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.999235     0.0  0.0  0.0  0.0\n\njulia> versioninfo()\nJulia Version 1.5.3\nCommit 788b2c77c1 (2020-11-09 13:37 UTC)\nPlatform Info:\n  OS: Linux (x86_64-pc-linux-gnu)\n  CPU: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)\n\n(misc) pkg> st\nStatus `~/Beacon/misc/Project.toml`\n  [052768ef] CUDA v1.3.3\n  [31c24e10] Distributions v0.24.10\n  [872c559c] NNlib v0.7.10"}]}]}]},{"client_msg_id":"41954058-2ee1-4d3a-8472-c325332cceb1","type":"message","text":"<@UCZ7VBGUD> see above - I think they switched `CUDNN` default softmax to a faster, unstable version at some point.","user":"UKA81L34J","ts":"1609960112.205700","team":"T68168MUP","edited":{"user":"UKA81L34J","ts":"1609960144.000000"},"blocks":[{"type":"rich_text","block_id":"574V","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UCZ7VBGUD"},{"type":"text","text":" see above - I think they switched "},{"type":"text","text":"CUDNN","style":{"code":true}},{"type":"text","text":" default softmax to a faster, unstable version at some point."}]}]}],"reactions":[{"name":"+1","users":["UCZ7VBGUD"],"count":1}]}]}