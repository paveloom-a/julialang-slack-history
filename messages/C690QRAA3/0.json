{"cursor": 0, "messages": [{"client_msg_id":"6623fe13-7857-434c-bb03-ac1e7892762f","type":"message","text":"Just curious if anyone knows any good resources for understanding how fast the universal approximation theorem holds true in very idealized cases?","user":"UEP056STX","ts":"1608090496.111000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eM+TM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just curious if anyone knows any good resources for understanding how fast the universal approximation theorem holds true in very idealized cases?"}]}]}]},{"client_msg_id":"2a90ff81-9d98-4b3d-92ae-eeb268ea639f","type":"message","text":"Obviously y = NN(x) = f(Wx + b) can approximate y = x exactly with one layer of size 1, but what about y = x^2 or y = sin(x), or what about y = exp(x^2 + y^2) or vector-valued functions? How many layers do you need before NN(x) approximates the function to machine epsilon over the entire real line (if that's even possible)?","user":"UEP056STX","ts":"1608090516.111300","team":"T68168MUP","edited":{"user":"UEP056STX","ts":"1608090579.000000"},"blocks":[{"type":"rich_text","block_id":"QobD0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Obviously y = NN(x) = f(Wx + b) can approximate y = x exactly with one layer of size 1, but what about y = x^2 or y = sin(x), or what about y = exp(x^2 + y^2) or vector-valued functions? How many layers do you need before NN(x) approximates the function to machine epsilon over the entire real line (if that's even possible)?"}]}]}],"reactions":[{"name":"+1","users":["U7THT3TM3"],"count":1}]},{"client_msg_id":"0bc26f57-2639-42a2-8139-dcc3b7c6600f","type":"message","text":"Not sure this exercise is even useful to think about, but was wondering whether it would provide any insight into picking neural network architectures for scientific machine learning purposes.","user":"UEP056STX","ts":"1608090536.111700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HLAu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not sure this exercise is even useful to think about, but was wondering whether it would provide any insight into picking neural network architectures for scientific machine learning purposes."}]}]}]},{"type":"message","text":"<https://github.com/lorenzoh/FluxTraining.jl|FluxTraining.jl> is awesome in VSCode by the way!","files":[{"id":"F01GTPHUF1U","created":1608096063,"timestamp":1608096063,"name":"Screen Shot 2020-12-16 at 12.20.59 AM.png","title":"Screen Shot 2020-12-16 at 12.20.59 AM.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01BG0NN34J","editable":false,"size":34534,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01GTPHUF1U/screen_shot_2020-12-16_at_12.20.59_am.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01GTPHUF1U/download/screen_shot_2020-12-16_at_12.20.59_am.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_360.png","thumb_360_w":360,"thumb_360_h":20,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_480.png","thumb_480_w":480,"thumb_480_h":27,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_720.png","thumb_720_w":720,"thumb_720_h":41,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_800.png","thumb_800_w":800,"thumb_800_h":45,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_960.png","thumb_960_w":960,"thumb_960_h":54,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01GTPHUF1U-42cf22b7b9/screen_shot_2020-12-16_at_12.20.59_am_1024.png","thumb_1024_w":1024,"thumb_1024_h":58,"original_w":2270,"original_h":128,"thumb_tiny":"AwACADC/3FRv981J3FRyffNSyJDaKKKkkfFyTnmpenSoovvH6VKapFrY/9k=","permalink":"https://julialang.slack.com/files/U01BG0NN34J/F01GTPHUF1U/screen_shot_2020-12-16_at_12.20.59_am.png","permalink_public":"https://slack-files.com/T68168MUP-F01GTPHUF1U-0fce09ef08","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"Yck","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/lorenzoh/FluxTraining.jl","text":"FluxTraining.jl"},{"type":"text","text":" is awesome in VSCode by the way!"}]}]}],"user":"U01BG0NN34J","display_as_bot":false,"ts":"1608096083.112600","reactions":[{"name":"100","users":["U01724Q3PGW","U7THT3TM3","U9J14HBSR","UH9KWTTD3","U6795JH6H","U90JR0C80","U66M57AN4","U01C15GH58B","UE76KFRFX"],"count":9},{"name":"hushed","users":["U01G14RTVM2","U90JR0C80","UE76KFRFX"],"count":3}]},{"client_msg_id":"be433626-eeee-4dbc-8a3f-dfa2be428a2a","type":"message","text":"Looks really nice!","user":"U7THT3TM3","ts":"1608098184.114000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2p6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looks really nice!"}]}]}]},{"client_msg_id":"971b8d3c-bf3f-4d9f-ac5c-64efd7e0f920","type":"message","text":"So it doesn't use our progress UI? :(","user":"U6BNE7LTZ","ts":"1608218281.115300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V3jR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So it doesn't use our progress UI? :("}]}]}]},{"client_msg_id":"c726fa6b-5dfa-40d3-b9bf-52d1e1281abd","type":"message","text":"It implements ProgressMeter.jl","user":"UC4QQPG4A","ts":"1608218529.116400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mkS0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It implements ProgressMeter.jl"}]}]}]},{"client_msg_id":"d12fb7d4-a2ac-47e6-b73c-bfce1c0f7cae","type":"message","text":"ah, it'd need ProgressLogging support for VSCode's progress UI","user":"U6BNE7LTZ","ts":"1608219724.116800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nXqr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ah, it'd need ProgressLogging support for VSCode's progress UI"}]}]}]},{"client_msg_id":"6760ad42-dcb8-45b1-8e42-48864f05cd8d","type":"message","text":"Any existing packages or examples that save activations for each batch's forward pass? ","user":"U01EK81V5GF","ts":"1608282920.119200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nEzOr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any existing packages or examples that save activations for each batch's forward pass? ","style":{"unlink":true}}]}]}],"thread_ts":"1608282920.119200","reply_count":2,"reply_users_count":2,"latest_reply":"1608493927.128700","reply_users":["UMY1LV01G","U01EK81V5GF"],"subscribed":false},{"client_msg_id":"be9689b4-80f4-4510-9c41-f184983908ec","type":"message","text":"You could do that by saving and plotting the parameters","user":"UC4QQPG4A","ts":"1608284698.120100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=Sv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You could do that by saving and plotting the parameters"}]}]}]},{"client_msg_id":"afcd158a-bdc9-49c1-b312-8f7508f37be2","type":"message","text":"Hi all, I may take a ML/DL online course during holiday period. Which are the trends, and which will benefit more someone like me who work in computer vision and love Julia. Is fastai the best choice?","user":"U6CCK2SCV","ts":"1608337284.121000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JHG15","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all, I may take a ML/DL online course during holiday period. Which are the trends, and which will benefit more someone like me who work in computer vision and love Julia. Is fastai the best choice?"}]}]}],"thread_ts":"1608337284.121000","reply_count":5,"reply_users_count":3,"latest_reply":"1608484875.125600","reply_users":["U01CMBH4MQE","U6CCK2SCV","U01724Q3PGW"],"subscribed":false},{"client_msg_id":"017A70A9-48CA-4DCF-AF51-A3691EAE66FF","type":"message","text":"Have to do a project in pytorch - is there anything equivalent to MLDataPattern.jl 'slidingwindow' out there in Python?","user":"U01BG0NN34J","ts":"1608435754.123700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Q6J","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Have to do a project in pytorch - is there anything equivalent to MLDataPattern.jl 'slidingwindow' out there in Python?"}]}]}],"thread_ts":"1608435754.123700","reply_count":7,"reply_users_count":5,"latest_reply":"1608542454.129600","reply_users":["U01GMP3HF9C","UBVE598BC","U014QLCKTDE","U01BG0NN34J","UC4QQPG4A"],"subscribed":false},{"client_msg_id":"5cdad04b-500a-4bee-b19d-fb2da643553d","type":"message","text":"Anyone ever gotten `ERROR: LoadError: CUDA error: an illegal memory access was encountered (code 700, ERROR_ILLEGAL_ADDRESS)`  after loading a saved model and trying to continue training? The error is in the backwards pass. Any idea what is going wrong?","user":"U01EK81V5GF","ts":"1608493739.128500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G8FK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone ever gotten "},{"type":"text","text":"ERROR: LoadError: CUDA error: an illegal memory access was encountered (code 700, ERROR_ILLEGAL_ADDRESS)","style":{"code":true}},{"type":"text","text":"  after loading a saved model and trying to continue training? The error is in the backwards pass. Any idea what is going wrong?"}]}]}],"thread_ts":"1608493739.128500","reply_count":9,"reply_users_count":3,"latest_reply":"1608632626.146800","reply_users":["UM30MT6RF","UC4QQPG4A","U01EK81V5GF"],"subscribed":false},{"client_msg_id":"b3110fa4-59a3-4114-bc17-6c372f60f4f8","type":"message","text":"Simple Flux question - if I have two arrays (let’s say both of size  `(10, 10, 3, 20)` ) and I want to stack along `dim = 3` , is there a simple call for this ?","user":"UKA81L34J","ts":"1608565164.130700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2LU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Simple Flux question - if I have two arrays (let’s say both of size  "},{"type":"text","text":"(10, 10, 3, 20)","style":{"code":true}},{"type":"text","text":" ) and I want to stack along "},{"type":"text","text":"dim = 3","style":{"code":true}},{"type":"text","text":" , is there a simple call for this ?"}]}]}],"thread_ts":"1608565164.130700","reply_count":5,"reply_users_count":2,"latest_reply":"1608565604.131600","reply_users":["UM30MT6RF","UKA81L34J"],"subscribed":false},{"client_msg_id":"e7885a9b-6ddd-4dc1-9aff-a77cde06c151","type":"message","text":"Is there a way to use type parameters with `Flux.@functor` ?","user":"UKA81L34J","ts":"1608570370.132000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zhB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a way to use type parameters with "},{"type":"text","text":"Flux.@functor","style":{"code":true}},{"type":"text","text":" ?"}]}]}]},{"client_msg_id":"239cb764-6faf-4884-8d24-883a8c7a840d","type":"message","text":"By default it picks up arrays only, but you can add the fields you want it to pick up or use Flux.trainable","user":"UC4QQPG4A","ts":"1608571401.133200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"j=7Nt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"By default it picks up arrays only, but you can add the fields you want it to pick up or use Flux.trainable"}]}]}]},{"client_msg_id":"793e75c6-fdd5-4dad-b5f2-ecf5e6a916ad","type":"message","text":"You probably want to overload `Flux.functor` for anything more advanced.","user":"UM30MT6RF","ts":"1608572117.133700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eic","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You probably want to overload "},{"type":"text","text":"Flux.functor","style":{"code":true}},{"type":"text","text":" for anything more advanced."}]}]}],"reactions":[{"name":"point_up","users":["UMY1LV01G","UKA81L34J"],"count":2}]},{"client_msg_id":"5dbea6ad-44ef-42b6-b0f8-e27f6f69eaf8","type":"message","text":"<@UM30MT6RF> think this is the right way - I just want to define a model struct which is a bit more complex. If I define:\n```Flux.functor(model::NewType, fn)```\nwill `fmap` pick it up ?","user":"UKA81L34J","ts":"1608572625.134700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"D5ak","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UM30MT6RF"},{"type":"text","text":" think this is the right way - I just want to define a model struct which is a bit more complex. If I define:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Flux.functor(model::NewType, fn)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"will "},{"type":"text","text":"fmap","style":{"code":true}},{"type":"text","text":" pick it up ?"}]}]}]},{"client_msg_id":"f04f8da9-ce67-4c72-9054-bba5a62de532","type":"message","text":"It should","user":"UM30MT6RF","ts":"1608572651.134900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"B4V1O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It should"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"The error still occurs when I explicitly move the model to CPU before saving and use `--check-bounds=yes` to start Julia","user":"U01EK81V5GF","ts":"1608627982.135900","thread_ts":"1608493739.128500","root":{"client_msg_id":"5cdad04b-500a-4bee-b19d-fb2da643553d","type":"message","text":"Anyone ever gotten `ERROR: LoadError: CUDA error: an illegal memory access was encountered (code 700, ERROR_ILLEGAL_ADDRESS)`  after loading a saved model and trying to continue training? The error is in the backwards pass. Any idea what is going wrong?","user":"U01EK81V5GF","ts":"1608493739.128500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G8FK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone ever gotten "},{"type":"text","text":"ERROR: LoadError: CUDA error: an illegal memory access was encountered (code 700, ERROR_ILLEGAL_ADDRESS)","style":{"code":true}},{"type":"text","text":"  after loading a saved model and trying to continue training? The error is in the backwards pass. Any idea what is going wrong?"}]}]}],"thread_ts":"1608493739.128500","reply_count":9,"reply_users_count":3,"latest_reply":"1608632626.146800","reply_users":["UM30MT6RF","UC4QQPG4A","U01EK81V5GF"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"91RXp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The error still occurs when I explicitly move the model to CPU before saving and use "},{"type":"text","text":"--check-bounds=yes","style":{"code":true}},{"type":"text","text":" to start Julia"}]}]}],"client_msg_id":"09055d71-f9b4-46d4-8480-73762f99d746","edited":{"user":"U01EK81V5GF","ts":"1608628003.000000"}},{"client_msg_id":"f339de8f-3a29-493f-a026-c945ad8596b0","type":"message","text":"Just curious, I've seen in general that documentation in Flux is usually not that extensive as is usually the case with same functionality in PyTorch, is it intentionally kept as such or the focus of Flux (atleast currently) is to catch with providing the matching functionalities in PyTorch as a priori, instead of focusing on providing extensive documentation.\n\nOr is it expected of the user of Flux to be able to understand from the source code instead as to what each and everything means?","user":"U01891GQRFZ","ts":"1608630733.141000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=bW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just curious, I've seen in general that documentation in Flux is usually not that extensive as is usually the case with same functionality in PyTorch, is it intentionally kept as such or the focus of Flux (atleast currently) is to catch with providing the matching functionalities in PyTorch as a priori, instead of focusing on providing extensive documentation.\n\nOr is it expected of the user of Flux to be able to understand from the source code instead as to what each and everything means?"}]}]}]},{"client_msg_id":"d2474830-53bc-4517-a8a9-9d57aaf1ef75","type":"message","text":"It's definitely not intentional, it's just that Flux is still quite young and it's difficult to write good documentation, so I think the sparse documentation is mostly due to limited resources of Flux developers. Contributions to documentation are always very welcome, especially from people new to Flux, since you probably know better what additional documentation would be most helpful to other newcomers!","user":"UM30MT6RF","ts":"1608631210.144500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QLe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's definitely not intentional, it's just that Flux is still quite young and it's difficult to write good documentation, so I think the sparse documentation is mostly due to limited resources of Flux developers. Contributions to documentation are always very welcome, especially from people new to Flux, since you probably know better what additional documentation would be most helpful to other newcomers!"}]}]}],"reactions":[{"name":"+1","users":["UMY1LV01G"],"count":1}]},{"client_msg_id":"b0f103e9-a7d6-462a-b073-7b56a6c29c5d","type":"message","text":"That said, Flux definitely makes understanding functions just from their source code a lot easier, since everything is implemented in Julia, but that doesn't mean we shouldn't have better documentation as well.","user":"UM30MT6RF","ts":"1608631368.146300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+KQIj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That said, Flux definitely makes understanding functions just from their source code a lot easier, since everything is implemented in Julia, but that doesn't mean we shouldn't have better documentation as well."}]}]}]},{"client_msg_id":"9a3adcaa-5afb-4ecb-8dc1-21555eaccadd","type":"message","text":"Agreed, thanks Simeon. :slightly_smiling_face:","user":"U01891GQRFZ","ts":"1608631427.146700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"agI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Agreed, thanks Simeon. "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"type":"message","text":"I’m trying to diagnose a training loss instability","files":[{"id":"F01HN70NBMJ","created":1608660950,"timestamp":1608660950,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UKA81L34J","editable":false,"size":178987,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HN70NBMJ/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HN70NBMJ/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_360.png","thumb_360_w":360,"thumb_360_h":326,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_480.png","thumb_480_w":480,"thumb_480_h":435,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_720.png","thumb_720_w":720,"thumb_720_h":652,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01HN70NBMJ-0dc58f482f/image_800.png","thumb_800_w":800,"thumb_800_h":725,"original_w":938,"original_h":850,"thumb_tiny":"AwArADClQDiikoAdvOMYH5Ubz6D8hTaKAFJyc0lLRQACkpR1oIxQAlFFFABRRRQAtGafgccDpSgDA4FADMn0oyfSnCmZoACc0H60lFAH/9k=","permalink":"https://julialang.slack.com/files/UKA81L34J/F01HN70NBMJ/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HN70NBMJ-6c98804170","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"x46kr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m trying to diagnose a training loss instability"}]}]}],"user":"UKA81L34J","display_as_bot":false,"ts":"1608660953.148200","thread_ts":"1608660953.148200","reply_count":3,"reply_users_count":2,"latest_reply":"1608661634.149300","reply_users":["UJ7DVTVQ8","UKA81L34J"],"subscribed":false},{"client_msg_id":"b7f429c4-83c6-4345-b8ce-d26638c74eaa","type":"message","text":"any ideas what could cause a curve to suddenly go sour like this ?","user":"UKA81L34J","ts":"1608660967.148700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"K110","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"any ideas what could cause a curve to suddenly go sour like this ?"}]}]}],"reactions":[{"name":"lemon","users":["U680THK2S"],"count":1}]},{"client_msg_id":"7670713d-3e1b-4256-9c96-94066b877ae9","type":"message","text":"yep, denominator of normalization expression suddenly goes to NaN","user":"UKA81L34J","ts":"1608662836.149800","team":"T68168MUP","edited":{"user":"UKA81L34J","ts":"1608662861.000000"},"blocks":[{"type":"rich_text","block_id":"oHv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yep, denominator of normalization expression suddenly goes to NaN"}]}]}],"thread_ts":"1608662836.149800","reply_count":1,"reply_users_count":1,"latest_reply":"1608663863.151100","reply_users":["UTRAUNYDA"],"subscribed":false},{"client_msg_id":"a85925e7-c9b4-41f0-baa4-945141602718","type":"message","text":"Is there a GPUified `LogSumExp` ?","user":"UKA81L34J","ts":"1608751876.152400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fM2W","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a GPUified "},{"type":"text","text":"LogSumExp","style":{"code":true}},{"type":"text","text":" ?"}]}]}],"thread_ts":"1608751876.152400","reply_count":6,"reply_users_count":2,"latest_reply":"1608752659.154600","reply_users":["UD0NS8PDF","UKA81L34J"],"subscribed":false},{"client_msg_id":"1679d72a-8bf9-4e68-8193-32ad16dc380e","type":"message","text":"That version appears to be include the usage of `setindex!`  - I’m not sure of the runtime cost","user":"UKA81L34J","ts":"1608752509.154200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V4o7Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That version appears to be include the usage of "},{"type":"text","text":"setindex!","style":{"code":true}},{"type":"text","text":"  - I’m not sure of the runtime cost"}]}]}]},{"client_msg_id":"042f8052-3450-4afe-b7eb-a1162292d3f0","type":"message","text":"at least, CUDA is yelling at me for that","user":"UKA81L34J","ts":"1608752519.154500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Shh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"at least, CUDA is yelling at me for that"}]}]}]},{"client_msg_id":"ad6c9da5-65ad-458a-b9f9-6ea933eb15bd","type":"message","text":"A while ago I remember running across a paper where the goal was to learn an optimization algorithm, e.g. . a neural network that can be iteratively queried with f(x) and gradf(x) values to produce a series of solution estimates towards the optimum of f(x). It was then favorably compared to human-produced algorithms such as Adam or Adagrad. I cannot find it now, does anyone know which one I mean? And has anyone seen the same idea but for constrained optimization, where a constraint c(x) and its gradient is also supplied to an iterative algorithm we want to learn?","user":"UFCNUVC67","ts":"1608821900.159700","team":"T68168MUP","edited":{"user":"UFCNUVC67","ts":"1608821948.000000"},"blocks":[{"type":"rich_text","block_id":"/Ij","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"A while ago I remember running across a paper where the goal was to learn an optimization algorithm, e.g. . a neural network that can be iteratively queried with f(x) and gradf(x) values to produce a series of solution estimates towards the optimum of f(x). It was then favorably compared to human-produced algorithms such as Adam or Adagrad. I cannot find it now, does anyone know which one I mean? And has anyone seen the same idea but for constrained optimization, where a constraint c(x) and its gradient is also supplied to an iterative algorithm we want to learn?"}]}]}],"thread_ts":"1608821900.159700","reply_count":1,"reply_users_count":1,"latest_reply":"1608822318.160000","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"d5dd5d8d-770a-4edb-9f8e-105af38f5865","type":"message","text":"I'm pretty new to DL and big data, I am working on a project with GTZAN data <http://marsyas.info/downloads/datasets.html> and was wondering if with audio data people usually feed it as is into a Conv1D or do they create the mel spectrogram and use a Conv2D? Do you have to preprocess and use filters for audio data prior to the ConvNet or is it truly the case that ConvNets basically remove the need for it? The time series I have is length ~660K does it have to be downsampled for computational purposes? I end up with a n x p of ~700 x 660K which is huge, and I want to try simple models like PCA+Logistic Regression first","user":"U01EF0QVAB0","ts":"1608918941.164400","team":"T68168MUP","edited":{"user":"U01EF0QVAB0","ts":"1608918994.000000"},"blocks":[{"type":"rich_text","block_id":"OxXqo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm pretty new to DL and big data, I am working on a project with GTZAN data "},{"type":"link","url":"http://marsyas.info/downloads/datasets.html"},{"type":"text","text":" and was wondering if with audio data people usually feed it as is into a Conv1D or do they create the mel spectrogram and use a Conv2D? Do you have to preprocess and use filters for audio data prior to the ConvNet or is it truly the case that ConvNets basically remove the need for it? The time series I have is length ~660K does it have to be downsampled for computational purposes? I end up with a n x p of ~700 x 660K which is huge, and I want to try simple models like PCA+Logistic Regression first"}]}]}]},{"type":"message","text":"So I am running into some trouble with the example here <https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/stacking/#basic_stacking_using_out-of-sample_base_learner_predictions|https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/stacking/#basic_stacking_using_out-of[…]ple_base_learner_predictions> when applied to my case. It seems the problem is the predictions in a multiclass situation are in this very strange type structure UnivariateFinite{MultiClass{10}} that looks like a vector of a Dict but it isn't. I simply need to add 0.5 of this to the yRF() prediction but the addition (+) and (*) are not defined. Is there any way I can define it myself?","files":[{"id":"F01HTLE0V3N","created":1608956811,"timestamp":1608956811,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01EF0QVAB0","editable":false,"size":176090,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HTLE0V3N/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HTLE0V3N/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_360.png","thumb_360_w":360,"thumb_360_h":188,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_480.png","thumb_480_w":480,"thumb_480_h":251,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_720.png","thumb_720_w":720,"thumb_720_h":377,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_800.png","thumb_800_w":800,"thumb_800_h":419,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_960.png","thumb_960_w":960,"thumb_960_h":502,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01HTLE0V3N-5a7877a1ca/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":536,"original_w":1586,"original_h":830,"thumb_tiny":"AwAZADCn+VGaX86PzpgJ+FGfYUZNGaACkoooAdijB9KRetSUgGYPpSYNPpaLjsR0YpT1opiP/9k=","permalink":"https://julialang.slack.com/files/U01EF0QVAB0/F01HTLE0V3N/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HTLE0V3N-44db6b4363","is_starred":false,"has_rich_preview":false},{"id":"F01HMFMAY66","created":1608956977,"timestamp":1608956977,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01EF0QVAB0","editable":false,"size":145398,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HMFMAY66/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HMFMAY66/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_360.png","thumb_360_w":360,"thumb_360_h":84,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_480.png","thumb_480_w":480,"thumb_480_h":113,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_720.png","thumb_720_w":720,"thumb_720_h":169,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_800.png","thumb_800_w":800,"thumb_800_h":188,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_960.png","thumb_960_w":960,"thumb_960_h":225,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01HMFMAY66-5961187085/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":240,"original_w":1960,"original_h":460,"thumb_tiny":"AwALADCtx6Un4CjNFMA/AUY9hSUUALgelGB6UlFAH//Z","permalink":"https://julialang.slack.com/files/U01EF0QVAB0/F01HMFMAY66/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HMFMAY66-c4e24856f3","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"UOp3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So I am running into some trouble with the example here "},{"type":"link","url":"https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/stacking/#basic_stacking_using_out-of-sample_base_learner_predictions","text":"https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/stacking/#basic_stacking_using_out-of[…]ple_base_learner_predictions"},{"type":"text","text":" when applied to my case. It seems the problem is the predictions in a multiclass situation are in this very strange type structure UnivariateFinite{MultiClass{10}} that looks like a vector of a Dict but it isn't. I simply need to add 0.5 of this to the yRF() prediction but the addition (+) and (*) are not defined. Is there any way I can define it myself?"}]}]}],"user":"U01EF0QVAB0","ts":"1608957004.169500"},{"client_msg_id":"805c4ab4-c399-4934-83c5-24857504cf7b","type":"message","text":"Which julia package can you recommend for support vector regression?","user":"U019PPN3H6J","ts":"1608978439.171200","team":"T68168MUP","edited":{"user":"U019PPN3H6J","ts":"1608978877.000000"},"blocks":[{"type":"rich_text","block_id":"vn7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Which julia package can you recommend for support vector regression?"}]}]}],"thread_ts":"1608978439.171200","reply_count":2,"reply_users_count":2,"latest_reply":"1608979758.172800","reply_users":["U6A936746","U019PPN3H6J"],"subscribed":false},{"client_msg_id":"4530fbb4-66e5-4d0c-b65b-de66f914c62f","type":"message","text":"Did anyone else notice that Google created MuZero that’s an improved version of AlphaZero, and uses reinforcement learning?\n<https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/>","user":"U01CQTKB86N","ts":"1608979182.172000","team":"T68168MUP","attachments":[{"service_name":"Ars Technica","title":"Google develops an AI that can learn both chess and Pac-Man","title_link":"https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/","text":"MuZero handles both rules-based and open-ended games.","fallback":"Ars Technica: Google develops an AI that can learn both chess and Pac-Man","image_url":"https://cdn.arstechnica.net/wp-content/uploads/2020/12/3536942268_68d718be1f_b-760x380.jpg","image_width":500,"image_height":250,"from_url":"https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/","image_bytes":59866,"service_icon":"https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/ars-ios-icon-d9a45f558c.png","id":1,"original_url":"https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/"}],"blocks":[{"type":"rich_text","block_id":"gmUf=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Did anyone else notice that Google created MuZero that’s an improved version of AlphaZero, and uses reinforcement learning?\n"},{"type":"link","url":"https://arstechnica.com/science/2020/12/google-develops-an-ai-that-can-learn-both-chess-and-pac-man/"}]}]}],"thread_ts":"1608979182.172000","reply_count":2,"reply_users_count":1,"latest_reply":"1608979727.172600","reply_users":["U01CQTKB86N"],"subscribed":false},{"client_msg_id":"d6ad5daa-23ab-4b67-bb6b-2d6337fe53fc","type":"message","text":"Any idea why is there an overhead with using PCA from MLJ.jl with DataFrames? Its very strange when I try to fit a PCA model and use a matrix I get \"Warning: The scitype of `X`, in `machine(model, X)` is incompatible with `model=PCA @395`:\n`│ scitype(X) = AbstractArray{Continuous,2}`\n`│ input_scitype(model) = Table{var\"#s45\"} where var\"#s45\"&lt;:(AbstractArray{var\"#s13\",1} where var\"#s13\"&lt;:Continuous).\"` but it still fits something anyways much faster. And then when I am using transform(), it is very slow to transform DataFrames but can transform Matrices faster, but then they don't stay as a Matrix nor a DataFrame but can be coerced to a DF then a Matrix","user":"U01EF0QVAB0","ts":"1609220745.181600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tfnE7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any idea why is there an overhead with using PCA from MLJ.jl with DataFrames? Its very strange when I try to fit a PCA model and use a matrix I get \"Warning: The scitype of `X`, in `machine(model, X)` is incompatible with `model=PCA @395`:\n"},{"type":"text","text":"│ scitype(X) = AbstractArray{Continuous,2}","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"│ input_scitype(model) = Table{var\"#s45\"} where var\"#s45\"<:(AbstractArray{var\"#s13\",1} where var\"#s13\"<:Continuous).\"","style":{"code":true}},{"type":"text","text":" but it still fits something anyways much faster. And then when I am using transform(), it is very slow to transform DataFrames but can transform Matrices faster, but then they don't stay as a Matrix nor a DataFrame but can be coerced to a DF then a Matrix"}]}]}]},{"type":"message","subtype":"channel_join","ts":"1609333401.184600","user":"U01HYEN2ES0","text":"<@U01HYEN2ES0> has joined the channel","inviter":"UEP056STX"},{"client_msg_id":"175639e3-c2c8-4d0e-aa1d-6ed3539921ae","type":"message","text":"Hey people, what's an interesting dataset to test a recurrent neural network on? I have some of my own, but they are quite niche, and I'm interested in benchmarking with datasets that are familiar to the community.","user":"UAL8DLH7D","ts":"1609343719.186000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TuRV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey people, what's an interesting dataset to test a recurrent neural network on? I have some of my own, but they are quite niche, and I'm interested in benchmarking with datasets that are familiar to the community."}]}]}],"thread_ts":"1609343719.186000","reply_count":4,"reply_users_count":1,"latest_reply":"1609344133.186900","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"f99c4f03-c983-43d3-9161-567ea61fcfb9","type":"message","text":"Wasn't there something like this done in Julia recently? <https://zongyi-li.github.io/blog/2020/fourier-pde/>","user":"U9RDM8ZGT","ts":"1609357342.187500","team":"T68168MUP","attachments":[{"title":"Zongyi Li | Fourier Neural Operator","title_link":"https://zongyi-li.github.io/blog/2020/fourier-pde/","text":"Zongyi's personal website.","fallback":"Zongyi Li | Fourier Neural Operator","from_url":"https://zongyi-li.github.io/blog/2020/fourier-pde/","service_name":"zongyi-li.github.io","id":1,"original_url":"https://zongyi-li.github.io/blog/2020/fourier-pde/"}],"blocks":[{"type":"rich_text","block_id":"2Ui7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Wasn't there something like this done in Julia recently? "},{"type":"link","url":"https://zongyi-li.github.io/blog/2020/fourier-pde/"}]}]}]},{"client_msg_id":"6a2391a6-feb2-4d34-97a0-d7ac2439090c","type":"message","text":"we're going to be implementing it in NeuralPDE.jl. The discussion on that was in <#CN04R7WKE|sciml>","user":"U69BL50BF","ts":"1609358096.188000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oC3m","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"we're going to be implementing it in NeuralPDE.jl. The discussion on that was in "},{"type":"channel","channel_id":"CN04R7WKE"}]}]}],"reactions":[{"name":"+1","users":["U9RDM8ZGT"],"count":1}]},{"client_msg_id":"eafd3db0-26e1-4dd2-aeed-d24621a668c7","type":"message","text":"is there a GPU compat way to take two arrays of different dims and multiply them along a compatible dimension?\nE.g.\n```x = randn((10, 5))\nz = randn((100, 10, 10))\nspecial_call(x, y; dim = 2) # =&gt; sizeof(...) = (100, 5, 10)```","user":"UKA81L34J","ts":"1609876316.194200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lzmif","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a GPU compat way to take two arrays of different dims and multiply them along a compatible dimension?\nE.g.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"x = randn((10, 5))\nz = randn((100, 10, 10))\nspecial_call(x, y; dim = 2) # => sizeof(...) = (100, 5, 10)"}]}]}],"thread_ts":"1609876316.194200","reply_count":1,"reply_users_count":1,"latest_reply":"1609876545.195400","reply_users":["UD0NS8PDF"],"subscribed":false},{"client_msg_id":"2ef2a437-cd44-4f27-96f5-fb26b952a88c","type":"message","text":"I guess the correct thing is :\n```z = reshape(z, (10, 100*10))\nout = x * z\nreshape(out, (100, 5, 10))```","user":"UKA81L34J","ts":"1609876546.195600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=cp1x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I guess the correct thing is :\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"z = reshape(z, (10, 100*10))\nout = x * z\nreshape(out, (100, 5, 10))"}]}]}]},{"client_msg_id":"22300fc3-a622-40d8-85d5-5f95a2b18b36","type":"message","text":"I don’t totally understand this CUDA error","user":"UKA81L34J","ts":"1609881787.196200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YBM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don’t totally understand this CUDA error"}]}]}]},{"type":"message","text":"","files":[{"id":"F01J2ATFECB","created":1609881788,"timestamp":1609881788,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UKA81L34J","editable":false,"size":1253477,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01J2ATFECB/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01J2ATFECB/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_360.png","thumb_360_w":330,"thumb_360_h":360,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_480.png","thumb_480_w":440,"thumb_480_h":480,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_720.png","thumb_720_w":659,"thumb_720_h":720,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_800.png","thumb_800_w":800,"thumb_800_h":873,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_960.png","thumb_960_w":879,"thumb_960_h":960,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01J2ATFECB-857a0c939a/image_1024.png","thumb_1024_w":938,"thumb_1024_h":1024,"original_w":1394,"original_h":1522,"thumb_tiny":"AwAwACurg44z+FJz708H60c56mkAzn3/ADo59/zp2Pr+QpMf5wKYDfm9/wA6MNTuPUfkKTA9R+lADhn0NHOc/NRwB3pCRjrQAuD6mg5A+8aTP0oz9PzNACZ/2qPxpcj2/Ok3D0/WgB+OO9IfxpQeKTnqd35UgE/zmkz7ilIY92/KjDep/wC+aYAD/u/nRk+o/OjDep/75pDn1P5UAf/Z","permalink":"https://julialang.slack.com/files/UKA81L34J/F01J2ATFECB/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01J2ATFECB-e775fdd49e","is_starred":false,"has_rich_preview":false}],"upload":false,"user":"UKA81L34J","display_as_bot":false,"ts":"1609881793.196300","thread_ts":"1609881793.196300","reply_count":8,"reply_users_count":2,"latest_reply":"1609883215.198000","reply_users":["UMY1LV01G","UKA81L34J"],"subscribed":false},{"client_msg_id":"8b1c284e-e20e-417a-acc1-88ee55cb0b33","type":"message","text":"any tricks to hunt down pullback computations which are causing `NaNs` ?","user":"UKA81L34J","ts":"1609948808.198800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"l872i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"any tricks to hunt down pullback computations which are causing "},{"type":"text","text":"NaNs","style":{"code":true}},{"type":"text","text":" ?"}]}]}]},{"client_msg_id":"f352ba36-4e61-4ecc-aadf-5e8714931483","type":"message","text":"`Zygote.@showgrad`, `ignore`\n\nIf there are smaller kernels, that's easier. You can also check code_ir but that's prolly too low level","user":"UC4QQPG4A","ts":"1609950102.201100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eW+M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Zygote.@showgrad","style":{"code":true}},{"type":"text","text":", `ignore`\n\nIf there are smaller kernels, that's easier. You can also check code_ir but that's prolly too low level"}]}]}]},{"type":"message","text":"I have softmax throwing `NaNs` for things which I think are … okay ? Maybe the numbers are too large, not sure.","files":[{"id":"F01JU8KEHLY","created":1609954917,"timestamp":1609954917,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UKA81L34J","editable":false,"size":1046381,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01JU8KEHLY/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01JU8KEHLY/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_360.png","thumb_360_w":356,"thumb_360_h":360,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_480.png","thumb_480_w":474,"thumb_480_h":480,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_720.png","thumb_720_w":711,"thumb_720_h":720,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_800.png","thumb_800_w":800,"thumb_800_h":810,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_960.png","thumb_960_w":948,"thumb_960_h":960,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01JU8KEHLY-3949fd908e/image_1024.png","thumb_1024_w":1011,"thumb_1024_h":1024,"original_w":1432,"original_h":1450,"thumb_tiny":"AwAwAC+mvPFOwMZxSI5Uk9eO9PZ0K8Z3H8qQyPHt+lGD/d/Sjd/nFJk0xB+ApKXJoyaAJMtj71Jz6/pS0UAJg+tJg4606g0AN+b1/WnEAL99vpijvSHpSAWjvTgjEcDIppG04PBFACUnH93NLmlxTAbgf3aCOOBTwrHoM0FGAyRQB//Z","permalink":"https://julialang.slack.com/files/UKA81L34J/F01JU8KEHLY/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01JU8KEHLY-0a0533cb51","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"UjFB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have softmax throwing "},{"type":"text","text":"NaNs","style":{"code":true}},{"type":"text","text":" for things which I think are … okay ? Maybe the numbers are too large, not sure."}]}]}],"user":"UKA81L34J","display_as_bot":false,"ts":"1609954923.201700"},{"client_msg_id":"8cd32149-20a2-4648-af0e-041cd3d56496","type":"message","text":"if this is not okay, I wonder how to solve this issue (implementing a self-attention block). The implementation is accurate to the paper.","user":"UKA81L34J","ts":"1609954987.202800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1L2Pg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if this is not okay, I wonder how to solve this issue (implementing a self-attention block). The implementation is accurate to the paper."}]}]}]},{"client_msg_id":"208bc512-211f-4caa-a45f-143613bbcbd4","type":"message","text":"I think this is a GPU issue","user":"UKA81L34J","ts":"1609956335.203000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Li4O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think this is a GPU issue"}]}]}]},{"client_msg_id":"97521694-85a6-4742-8e41-cdf643e1f882","type":"message","text":"```julia&gt; x = Float32.(rand(Normal(1000, 5000), (8, 8)))\n8×8 Array{Float32,2}:\n -3964.74   2589.43    353.542  …   5739.63   -9249.16   -2261.62\n -2906.62  -4961.38   3806.42       5289.22   -1641.34   -2714.45\n  2631.91  -5205.12  -9457.25       -828.516    547.219   1672.61\n  1063.99   9839.1    1015.35        120.756   2368.13   -2053.6\n  4159.93   2475.06   4742.76       3449.55   -1954.95    2495.51\n  2762.14   2851.15  -1772.85   …  -1387.07    8878.1    -3331.67\n -2036.93   5332.2   -3068.55       7775.97    7075.53    1439.79\n  1529.58   6816.89   4004.75      -4904.47   -6143.29    5725.86\n\njulia&gt; softmax(x)\n8×8 Array{Float32,2}:\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0\n 1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0```","user":"UKA81L34J","ts":"1609956349.203300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3SR1","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> x = Float32.(rand(Normal(1000, 5000), (8, 8)))\n8×8 Array{Float32,2}:\n -3964.74   2589.43    353.542  …   5739.63   -9249.16   -2261.62\n -2906.62  -4961.38   3806.42       5289.22   -1641.34   -2714.45\n  2631.91  -5205.12  -9457.25       -828.516    547.219   1672.61\n  1063.99   9839.1    1015.35        120.756   2368.13   -2053.6\n  4159.93   2475.06   4742.76       3449.55   -1954.95    2495.51\n  2762.14   2851.15  -1772.85   …  -1387.07    8878.1    -3331.67\n -2036.93   5332.2   -3068.55       7775.97    7075.53    1439.79\n  1529.58   6816.89   4004.75      -4904.47   -6143.29    5725.86\n\njulia> softmax(x)\n8×8 Array{Float32,2}:\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0\n 1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0"}]}]}]},{"client_msg_id":"c1e691ec-0e19-4d99-b55b-c0ad7a1266c4","type":"message","text":"yep","user":"UKA81L34J","ts":"1609956465.203500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V74","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yep"}]}]}]},{"client_msg_id":"4d1ac1b7-f606-4518-a035-ccb49bd08ab4","type":"message","text":"should I post this on `NNlib` or `CUDA` ?","user":"UKA81L34J","ts":"1609956490.203800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"amHuH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"should I post this on "},{"type":"text","text":"NNlib","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"CUDA","style":{"code":true}},{"type":"text","text":" ?"}]}]}]},{"client_msg_id":"f91d7aaf-cb53-417b-8331-603a69494407","type":"message","text":"Perhaps related to <https://github.com/JuliaGPU/CUDA.jl/pull/523#issuecomment-753416384>?","user":"UMY1LV01G","ts":"1609959134.204200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7EZE4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Perhaps related to "},{"type":"link","url":"https://github.com/JuliaGPU/CUDA.jl/pull/523#issuecomment-753416384"},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"715d9e25-4571-4b96-98bf-f64b21da1bd0","type":"message","text":"it looks like `CUDNN_SOFTMAX_ACCURATE` is the default now ?","user":"UKA81L34J","ts":"1609959393.204600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T+Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it looks like "},{"type":"text","text":"CUDNN_SOFTMAX_ACCURATE","style":{"code":true}},{"type":"text","text":" is the default now ?"}]}]}]},{"client_msg_id":"f3210a48-d9c6-439f-8e10-b77993b85830","type":"message","text":"your example works OK for me btw, but for some reason I'm on an older version of CUDA (in a fresh session; ~maybe CUDA 2 requires julia 1.6?~ just needed an explicit `up` for some reason)\n```julia&gt; using Distributions, CUDA, NNlib\n\njulia&gt; x = Float32.(rand(Normal(1000, 5000), (8, 8)))\n8×8 Array{Float32,2}:\n 10929.8    -827.791   3975.23   4571.25   -2578.11    3236.93     807.547    186.267\n -4886.28  14463.1    11163.5     289.532    444.538   1002.29    5984.53   -3821.62\n  5320.05  -4313.7    -3746.56   -727.577    641.654  -5851.06   -7113.68    -596.851\n  1219.08    780.571   4153.41   -279.646  -7849.32   -3537.99    -148.493  -2227.9\n  4217.94   4555.9    -3237.11   6036.93    5102.21   11041.5     1709.73    3534.94\n  1315.21  -3911.77    2479.11  -1178.5     7613.43    3699.27    8300.34    7121.03\n  2160.52   -379.444   5821.29   -974.758   5859.66    6086.66   10810.9     5877.44\n  4791.66   5207.67    1509.5    6044.1     6407.24     721.443   6796.54   -5439.79\n\njulia&gt; softmax(x)\n8×8 Array{Float32,2}:\n 1.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  1.0  1.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.000764676  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0          1.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0          0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.999235     0.0  0.0  0.0  0.0\n\njulia&gt; softmax(cu(copy(x)))\n8×8 CuArray{Float32,2}:\n 1.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  1.0  1.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.000764676  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0          1.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0          0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.999235     0.0  0.0  0.0  0.0\n\njulia&gt; versioninfo()\nJulia Version 1.5.3\nCommit 788b2c77c1 (2020-11-09 13:37 UTC)\nPlatform Info:\n  OS: Linux (x86_64-pc-linux-gnu)\n  CPU: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)\n\n(misc) pkg&gt; st\nStatus `~/Beacon/misc/Project.toml`\n  [052768ef] CUDA v1.3.3\n  [31c24e10] Distributions v0.24.10\n  [872c559c] NNlib v0.7.10```","user":"UCZ7VBGUD","ts":"1609959947.205500","team":"T68168MUP","edited":{"user":"UCZ7VBGUD","ts":"1609960150.000000"},"blocks":[{"type":"rich_text","block_id":"Dd6U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"your example works OK for me btw, but for some reason I'm on an older version of CUDA (in a fresh session; "},{"type":"text","text":"maybe CUDA 2 requires julia 1.6?","style":{"strike":true}},{"type":"text","text":" just needed an explicit "},{"type":"text","text":"up","style":{"code":true}},{"type":"text","text":" for some reason)\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> using Distributions, CUDA, NNlib\n\njulia> x = Float32.(rand(Normal(1000, 5000), (8, 8)))\n8×8 Array{Float32,2}:\n 10929.8    -827.791   3975.23   4571.25   -2578.11    3236.93     807.547    186.267\n -4886.28  14463.1    11163.5     289.532    444.538   1002.29    5984.53   -3821.62\n  5320.05  -4313.7    -3746.56   -727.577    641.654  -5851.06   -7113.68    -596.851\n  1219.08    780.571   4153.41   -279.646  -7849.32   -3537.99    -148.493  -2227.9\n  4217.94   4555.9    -3237.11   6036.93    5102.21   11041.5     1709.73    3534.94\n  1315.21  -3911.77    2479.11  -1178.5     7613.43    3699.27    8300.34    7121.03\n  2160.52   -379.444   5821.29   -974.758   5859.66    6086.66   10810.9     5877.44\n  4791.66   5207.67    1509.5    6044.1     6407.24     721.443   6796.54   -5439.79\n\njulia> softmax(x)\n8×8 Array{Float32,2}:\n 1.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  1.0  1.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.000764676  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0          1.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0          0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.999235     0.0  0.0  0.0  0.0\n\njulia> softmax(cu(copy(x)))\n8×8 CuArray{Float32,2}:\n 1.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  1.0  1.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0          0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.000764676  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0          1.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0          0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.999235     0.0  0.0  0.0  0.0\n\njulia> versioninfo()\nJulia Version 1.5.3\nCommit 788b2c77c1 (2020-11-09 13:37 UTC)\nPlatform Info:\n  OS: Linux (x86_64-pc-linux-gnu)\n  CPU: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)\n\n(misc) pkg> st\nStatus `~/Beacon/misc/Project.toml`\n  [052768ef] CUDA v1.3.3\n  [31c24e10] Distributions v0.24.10\n  [872c559c] NNlib v0.7.10"}]}]}]},{"client_msg_id":"41954058-2ee1-4d3a-8472-c325332cceb1","type":"message","text":"<@UCZ7VBGUD> see above - I think they switched `CUDNN` default softmax to a faster, unstable version at some point.","user":"UKA81L34J","ts":"1609960112.205700","team":"T68168MUP","edited":{"user":"UKA81L34J","ts":"1609960144.000000"},"blocks":[{"type":"rich_text","block_id":"574V","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UCZ7VBGUD"},{"type":"text","text":" see above - I think they switched "},{"type":"text","text":"CUDNN","style":{"code":true}},{"type":"text","text":" default softmax to a faster, unstable version at some point."}]}]}],"reactions":[{"name":"+1","users":["UCZ7VBGUD"],"count":1}]},{"client_msg_id":"330c3a4d-41fc-46e3-a1e0-b9d8b9e76315","type":"message","text":"is there a package that implement gradient estimation on noisy/non closed form objectives? I see FiniteDifferences.jl but are there any others (e.g. the technique of fitting say a quadratic to the local space and using that to estimate derivatives, etc etc, Im not sure what its called)","user":"U01GRS159T8","ts":"1610220787.209800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+mcle","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a package that implement gradient estimation on noisy/non closed form objectives? I see FiniteDifferences.jl but are there any others (e.g. the technique of fitting say a quadratic to the local space and using that to estimate derivatives, etc etc, Im not sure what its called)"}]}]}]},{"client_msg_id":"c8fac36f-b04a-449c-8eaa-91738c17b5ff","type":"message","text":"According to the Flux docs the Conv layer assumes WHCN order (width, height, # channels, batch size) <https://fluxml.ai/Flux.jl/stable/models/layers/#Flux.Conv>. I have a non-image  dataset but want to try convolution along a specific dimension. In particular my data points are tensors of dimension 2x16x32 (where the first 2 are real/imaginary components, the last is a time index) and I would like to create a Conv layer across  the last (time) dimension. How should I go about achieving this in Flux? Any points to tutorials, or relevant examples are highly appreciated.","user":"U01G3TX4F9A","ts":"1610315830.219200","team":"T68168MUP","edited":{"user":"U01G3TX4F9A","ts":"1610315906.000000"},"blocks":[{"type":"rich_text","block_id":"opihb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"According to the Flux docs the Conv layer assumes WHCN order (width, height, # channels, batch size) "},{"type":"link","url":"https://fluxml.ai/Flux.jl/stable/models/layers/#Flux.Conv"},{"type":"text","text":". I have a non-image  dataset but want to try convolution along a specific dimension. In particular my data points are tensors of dimension 2x16x32 (where the first 2 are real/imaginary components, the last is a time index) and I would like to create a Conv layer across  the last (time) dimension. How should I go about achieving this in Flux? Any points to tutorials, or relevant examples are highly appreciated."}]}]}],"thread_ts":"1610315830.219200","reply_count":10,"reply_users_count":2,"latest_reply":"1610316942.222000","reply_users":["UMY1LV01G","U01G3TX4F9A"],"subscribed":false},{"client_msg_id":"a42beb74-4c67-4b88-85af-38a863658937","type":"message","text":"I've been using a global (temporal) mean pooling for timeseries classification (many-to-one). I've seen this in other papers and it felt right to try to retrieve a global vector representing the whole timeseries without prioritizing recent events (which would happen if I used only the last hidden state, for example). However, max pooling would work (in principle) just as well. Has anyone experienced with both? A third alternative would be attention-based, of course.","user":"UAL8DLH7D","ts":"1610539412.234600","team":"T68168MUP","edited":{"user":"UAL8DLH7D","ts":"1610539422.000000"},"blocks":[{"type":"rich_text","block_id":"D0M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've been using a global (temporal) mean pooling for timeseries classification (many-to-one). I've seen this in other papers and it felt right to try to retrieve a global vector representing the whole timeseries without prioritizing recent events (which would happen if I used only the last hidden state, for example). However, max pooling would work (in principle) just as well. Has anyone experienced with both? A third alternative would be attention-based, of course."}]}]}]},{"type":"message","text":"I'm relatively new to deep learning and I am working on the GTZAN audio dataset for practice, split into train/val/test. I am attempting 1D conv nets but my validation accuracy remains around 30% with the following architecture. The data set is 655001 (~30 s) of audio. How do you exactly systematically go about building a CNN? Even without neural nets, I was able to get around 70% accuracy with just semi-classical method of FFT-&gt;log transform-&gt;PCA of untransformed FFT take 100, PCA of log take first 20 -&gt;concat these and random forest. And I am thinking neural nets have got to do better on audio data than a semi-classical method so I must be doing something wrong","files":[{"id":"F01JTA7LTFU","created":1610690606,"timestamp":1610690606,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01EF0QVAB0","editable":false,"size":110740,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01JTA7LTFU/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01JTA7LTFU/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01JTA7LTFU-b4bdc4f7bb/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01JTA7LTFU-b4bdc4f7bb/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01JTA7LTFU-b4bdc4f7bb/image_360.png","thumb_360_w":360,"thumb_360_h":252,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01JTA7LTFU-b4bdc4f7bb/image_480.png","thumb_480_w":480,"thumb_480_h":336,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01JTA7LTFU-b4bdc4f7bb/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01JTA7LTFU-b4bdc4f7bb/image_720.png","thumb_720_w":720,"thumb_720_h":504,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01JTA7LTFU-b4bdc4f7bb/image_800.png","thumb_800_w":800,"thumb_800_h":560,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01JTA7LTFU-b4bdc4f7bb/image_960.png","thumb_960_w":960,"thumb_960_h":672,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01JTA7LTFU-b4bdc4f7bb/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":716,"original_w":1232,"original_h":862,"thumb_tiny":"AwAhADDQweeKUfSkxz0/SgD04/CgBST2oBPeg9R3/CgDn/61AASe1KOnNIacKAGY5/8ArUAenH4CkIPPFKM/SgBT1HegUuAev86MD/JoAKUUmAaUUAFFFFABRRRQAUUUUAf/2Q==","permalink":"https://julialang.slack.com/files/U01EF0QVAB0/F01JTA7LTFU/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01JTA7LTFU-5872eaa848","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"HAsr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm relatively new to deep learning and I am working on the GTZAN audio dataset for practice, split into train/val/test. I am attempting 1D conv nets but my validation accuracy remains around 30% with the following architecture. The data set is 655001 (~30 s) of audio. How do you exactly systematically go about building a CNN? Even without neural nets, I was able to get around 70% accuracy with just semi-classical method of FFT->log transform->PCA of untransformed FFT take 100, PCA of log take first 20 ->concat these and random forest. And I am thinking neural nets have got to do better on audio data than a semi-classical method so I must be doing something wrong"}]}]}],"user":"U01EF0QVAB0","display_as_bot":false,"ts":"1610690769.005400","edited":{"user":"U01EF0QVAB0","ts":"1610690815.000000"}},{"client_msg_id":"6d2260c2-f6d7-4536-91b5-8a39e5e535f0","type":"message","text":"I’m training a NN using flux for a classification use case, but need to port the classification part of the algorithm (not the training) to C++ as the classification functionality needs to run on an embedded system. Is there a better option than to reimplement the whole net and retrain in c++ (or tensorflow light)? Is there any tooling that could help me translate the prediction part of the flux algorithm to c++?","user":"U01G3TX4F9A","ts":"1610717892.011300","team":"T68168MUP","edited":{"user":"U01G3TX4F9A","ts":"1610717981.000000"},"blocks":[{"type":"rich_text","block_id":"IF1FO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m training a NN using flux for a classification use case, but need to port the classification part of the algorithm (not the training) to C++ as the classification functionality needs to run on an embedded system. Is there a better option than to reimplement the whole net and retrain in c++ (or tensorflow light)? Is there any tooling that could help me translate the prediction part of the flux algorithm to c++?"}]}]}],"thread_ts":"1610717892.011300","reply_count":1,"reply_users_count":1,"latest_reply":"1610717994.011500","reply_users":["U01J62981NK"],"subscribed":false},{"client_msg_id":"5f8e20fd-14ef-4ef9-aa5a-46137597910e","type":"message","text":"There's a discussion about fusion and cpu optimizations on zulip, along with vmap (jax and avx ). Instead of special casing , does  Dex get all this for free with its constrained loop/index notation? Maybe we should move in that direction: <@UMY1LV01G> <@UAUPJLBQX> <@U6A936746>","user":"UDGT4PM41","ts":"1610721822.014700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SNMS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's a discussion about fusion and cpu optimizations on zulip, along with vmap (jax and avx ). Instead of special casing , does  Dex get all this for free with its constrained loop/index notation? Maybe we should move in that direction: "},{"type":"user","user_id":"UMY1LV01G"},{"type":"text","text":" "},{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":" "},{"type":"user","user_id":"U6A936746"}]}]}]},{"type":"message","subtype":"tombstone","text":"This message was deleted.","user":"USLACKBOT","hidden":true,"ts":"1610721849.015600","thread_ts":"1610721849.015600","reply_count":3,"reply_users_count":2,"latest_reply":"1610722302.018900","reply_users":["U6A936746","UDGT4PM41"],"subscribed":false},{"client_msg_id":"fc8f0b2b-ef2a-436f-8ba3-7e1f946f1b05","type":"message","text":"<@UD0NS8PDF>","user":"UDGT4PM41","ts":"1610721906.015800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"puay","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UD0NS8PDF"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"Ok I tagged you","user":"UDGT4PM41","ts":"1610722302.018900","thread_ts":"1610721849.015600","root":{"type":"message","subtype":"tombstone","text":"This message was deleted.","user":"USLACKBOT","hidden":true,"ts":"1610721849.015600","thread_ts":"1610721849.015600","reply_count":3,"reply_users_count":2,"latest_reply":"1610722302.018900","reply_users":["U6A936746","UDGT4PM41"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"+=h","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok I tagged you"}]}]}],"client_msg_id":"a06f2786-f594-41b1-b4b5-3748237cd677"},{"client_msg_id":"273bbfce-23c8-4a7d-b69e-aae4fd7ff57f","type":"message","text":"See zulip <https://julialang.zulipchat.com/#narrow/stream/237432-ml-ecosystem-coordination/topic/ML.20and.20AD.20dev.20call|thread> for the  discussion about fusion, vmap (Jax and AVX) dex etc. Trying to consolidate to one place","user":"UDGT4PM41","ts":"1610723803.019900","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1610724375.000000"},"blocks":[{"type":"rich_text","block_id":"+yG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"See zulip "},{"type":"link","url":"https://julialang.zulipchat.com/#narrow/stream/237432-ml-ecosystem-coordination/topic/ML.20and.20AD.20dev.20call","text":"thread"},{"type":"text","text":" for the  discussion about fusion, vmap (Jax and AVX) dex etc. Trying to consolidate to one place"}]}]}]},{"client_msg_id":"2e8a3dee-b48d-4518-8b2c-e98675a93569","type":"message","text":"Hi everyone, I'm using the MLJ package to train an SVM on a 100x3500 dataset with a binary target variable. I am searching for the optimal values of :cost and :gamma using a 3x3 grid (using the function TunedModel()). Although that works fine, when I increase the resolution of the grid to 4 or over, the whole session crashes. I get a very quick error message on the REPL before it terminates and the following pop-up message appears (see below). I have used this method to tune other models over grids of much larger size (hundreds and even thousands of grid cells in total). Any idea of what might be happening? I am using VSCode v1.52.1\n\nThe terminal process \"C:\\Users\\ivica\\AppData\\Local\\Programs\\Julia\\Julia-1.4.2\\bin\\julia.exe '-i', '--banner=no', '--project=c:\\Users\\ivica\\Documents\\GitHub\\Mozzie_diagnostics', 'c:\\Users\\ivica.vscode\\extensions\\julialang.language-julia-1.0.10\\scripts\\terminalserver\\terminalserver.jl', '\\.\\pipe\\vsc-julia-repl-21120', '\\.\\pipe\\vsc-jl-cr-21120', 'USE_REVISE=true', 'USE_PLOTPANE=true', 'DEBUG_MODE=undefined'\" terminated with exit code: 1.\n\n<https://stackoverflow.com/questions/65277479/vscode-terminal-crashes-when-training-hyperparameters-of-machine-learning-model?noredirect=1#comment115413140_65277479|https://stackoverflow.com/questions/65277479/vscode-terminal-crashes-when-training-hyperparameters-of-machine-learning-model?noredirect=1#com[…]7479>","user":"U01CLK6GX96","ts":"1610989339.028800","team":"T68168MUP","edited":{"user":"U01CLK6GX96","ts":"1610989660.000000"},"attachments":[{"service_name":"Stack Overflow","title":"VSCode terminal crashes when training hyperparameters of machine learning model in Julia","title_link":"https://stackoverflow.com/questions/65277479/vscode-terminal-crashes-when-training-hyperparameters-of-machine-learning-model?noredirect=1#comment115413140_65277479","text":"I am working on VSCode trying to use MLJ to learn classification models in Julia. My dataset is of medium size (100 instances, 3500 predictor features of comparable magnitude and 2 classes in which...","fallback":"Stack Overflow: VSCode terminal crashes when training hyperparameters of machine learning model in Julia","thumb_url":"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded","from_url":"https://stackoverflow.com/questions/65277479/vscode-terminal-crashes-when-training-hyperparameters-of-machine-learning-model?noredirect=1#comment115413140_65277479","thumb_width":316,"thumb_height":316,"service_icon":"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a","id":1,"original_url":"https://stackoverflow.com/questions/65277479/vscode-terminal-crashes-when-training-hyperparameters-of-machine-learning-model?noredirect=1#comment115413140_65277479"}],"blocks":[{"type":"rich_text","block_id":"V+K8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi everyone, I'm using the MLJ package to train an SVM on a 100x3500 dataset with a binary target variable. I am searching for the optimal values of :cost and :gamma using a 3x3 grid (using the function TunedModel()). Although that works fine, when I increase the resolution of the grid to 4 or over, the whole session crashes. I get a very quick error message on the REPL before it terminates and the following pop-up message appears (see below). I have used this method to tune other models over grids of much larger size (hundreds and even thousands of grid cells in total). Any idea of what might be happening? I am using VSCode v1.52.1\n\nThe terminal process \"C:\\Users\\ivica\\AppData\\Local\\Programs\\Julia\\Julia-1.4.2\\bin\\julia.exe '-i', '--banner=no', '--project=c:\\Users\\ivica\\Documents\\GitHub\\Mozzie_diagnostics', 'c:\\Users\\ivica.vscode\\extensions\\julialang.language-julia-1.0.10\\scripts\\terminalserver\\terminalserver.jl', '\\.\\pipe\\vsc-julia-repl-21120', '\\.\\pipe\\vsc-jl-cr-21120', 'USE_REVISE=true', 'USE_PLOTPANE=true', 'DEBUG_MODE=undefined'\" terminated with exit code: 1.\n\n"},{"type":"link","url":"https://stackoverflow.com/questions/65277479/vscode-terminal-crashes-when-training-hyperparameters-of-machine-learning-model?noredirect=1#comment115413140_65277479","text":"https://stackoverflow.com/questions/65277479/vscode-terminal-crashes-when-training-hyperparameters-of-machine-learning-model?noredirect=1#com[…]7479"}]}]}],"thread_ts":"1610989339.028800","reply_count":6,"reply_users_count":2,"latest_reply":"1611693545.045100","reply_users":["UAZP7LJLU","U01CLK6GX96"],"subscribed":false},{"client_msg_id":"c67f59ec-72ed-4c8f-89ea-a54abe9674ea","type":"message","text":"Any ideas on how to make a gpu-friendly layer that outputs just a striding? I.e. if the layer has a stride of 2 and the input is 32x32x3x8, then the output should be 16x16x3x8. The value of the output doesn't matter as it will be zeroed anyway.","user":"U01EK81V5GF","ts":"1610995134.030600","team":"T68168MUP","edited":{"user":"U01EK81V5GF","ts":"1610995153.000000"},"blocks":[{"type":"rich_text","block_id":"KEty","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any ideas on how to make a gpu-friendly layer that outputs just a striding? I.e. if the layer has a stride of 2 and the input is 32x32x3x8, then the output should be 16x16x3x8. The value of the output doesn't matter as it will be zeroed anyway."}]}]}],"thread_ts":"1610995134.030600","reply_count":9,"reply_users_count":2,"latest_reply":"1611067664.036000","reply_users":["UD0NS8PDF","U01EK81V5GF"],"subscribed":false},{"client_msg_id":"140b787d-2235-412c-aa20-7a661f0cb1b8","type":"message","text":"Not sure whether this is the right channel to post this question, but I was wondering: do we have something like Halide (<https://halide-lang.org/>) in julia? It basically allows one to write stencil operations in a backend independent way. Looks very useful when one wants something that is a bit more low-level than the premade convolution kernels, but more high level than writing CUDA kernels.","user":"U6BJ9E351","ts":"1611065892.034900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+0QLQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not sure whether this is the right channel to post this question, but I was wondering: do we have something like Halide ("},{"type":"link","url":"https://halide-lang.org/"},{"type":"text","text":") in julia? It basically allows one to write stencil operations in a backend independent way. Looks very useful when one wants something that is a bit more low-level than the premade convolution kernels, but more high level than writing CUDA kernels."}]}]}],"thread_ts":"1611065892.034900","reply_count":7,"reply_users_count":4,"latest_reply":"1611132973.037500","reply_users":["UH24GRBLL","UM30MT6RF","U6BJ9E351","UPAS00UNQ"],"subscribed":false},{"client_msg_id":"490895e5-05e6-483c-aa1d-15f8236e2b0a","type":"message","text":"Hey ! I have created a study plan for the Applied Predictive Modeling (<http://appliedpredictivemodeling.com/toc>) book. The code base is in R but I’d like to learn Julia along the way so I was thinking about creating my own Pluto notebooks — some people have partially done the same in Python (<https://github.com/LeiG/Applied-Predictive-Modeling-with-Python>).\nThe thing is, I am a bit overwhelmed by all the packages that exist in Julia for visualization, metrics, machine learning models etc. Based on the table of content or your guess, what are the packages I should look into?","user":"U01EZ6VN118","ts":"1611246655.002600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"N0M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey ! I have created a study plan for the Applied Predictive Modeling ("},{"type":"link","url":"http://appliedpredictivemodeling.com/toc"},{"type":"text","text":") book. The code base is in R but I’d like to learn Julia along the way so I was thinking about creating my own Pluto notebooks — some people have partially done the same in Python ("},{"type":"link","url":"https://github.com/LeiG/Applied-Predictive-Modeling-with-Python"},{"type":"text","text":").\nThe thing is, I am a bit overwhelmed by all the packages that exist in Julia for visualization, metrics, machine learning models etc. Based on the table of content or your guess, what are the packages I should look into?"}]}]}],"thread_ts":"1611246655.002600","reply_count":13,"reply_users_count":3,"latest_reply":"1611247945.005200","reply_users":["UGD4K0Z25","UDGT4PM41","U01EZ6VN118"],"subscribed":false},{"client_msg_id":"823c0a1e-4cbf-45a7-a71c-a0299b79bb8e","type":"message","text":"Hello! What's your advice on learning to implement machine learning papers? My biggest challenge is translating equations to code. Thanks!","user":"U01HNPYMZ4M","ts":"1611277595.008300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FwGk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello! What's your advice on learning to implement machine learning papers? My biggest challenge is translating equations to code. Thanks!"}]}]}],"thread_ts":"1611277595.008300","reply_count":2,"reply_users_count":1,"latest_reply":"1611350142.012100","reply_users":["USSNH7BGT"],"subscribed":false},{"client_msg_id":"7b180a1e-ab2f-4155-8475-24896f545a0b","type":"message","text":"I have a classic ML problem: train on training matrix, predict. Regression problem. All models seem to fail... does anyone know of a model that works here, i.e. &lt;5% relative error? Fully contained example:","user":"U69BL50BF","ts":"1611380894.013900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5qAnq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a classic ML problem: train on training matrix, predict. Regression problem. All models seem to fail... does anyone know of a model that works here, i.e. <5% relative error? Fully contained example:"}]}]}]},{"type":"message","text":"","files":[{"id":"F01KN25FH1Q","created":1611380901,"timestamp":1611380901,"name":"Untitled","title":"Untitled","mimetype":"text/plain","filetype":"text","pretty_type":"Plain Text","user":"U69BL50BF","editable":true,"size":725676,"mode":"snippet","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01KN25FH1Q/untitled","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01KN25FH1Q/download/untitled","permalink":"https://julialang.slack.com/files/U69BL50BF/F01KN25FH1Q/untitled","permalink_public":"https://slack-files.com/T68168MUP-F01KN25FH1Q-b47ae028a8","edit_link":"https://julialang.slack.com/files/U69BL50BF/F01KN25FH1Q/untitled/edit","preview":" X = [1.3229600000000001 1.1422400000000001 1.3964 1.29704 1.21312 1.1348 1.21696 1.4216000000000002 1.35296 1.38856 1.1548 1.39704 1.4204 1.3864 1.31072 1.3767200000000002 1.17216 1.34216 1.35408 1.5088 1.44392 1.1727200000000002 1.1214400000000002 1.29392 1.1467200000000002 1.40088 1.31064 1.4412800000000001 1.34832 1.1298400000000002 1.1380000000000001 1.34528 1.41944 1.41128 1.39968 1.26648 1.1700000000000002 1.2794400000000001 1.1707200000000002 1.42296 1.22496 1.3068 1.248 1.1238400000000002 1.48176 1.2040000000000002 1.20968 1.2945600000000002 1.5176 1.24336 1.2232 1.25464 1.51616 1.2481600000000002 1.49496 1.4155200000000001 1.3613600000000001 1.2608000000000001 1.50448 1.15008 1.30224 1.50864 1.48648 1.14656 1.1213600000000001 1.49912 1.2117600000000002 1.19592 1.46136 1.18472 1.26904 1.19384 1.3258400000000001 1.1832 1.13864 1.49288 1.39112 1.29272 1.3338400000000001 1.32088 1.17496 1.2479200000000001 1.40504 1.28936 1.46936 1.27848 1.36792 1.42608 1.4137600000000001 1.3065600000000002 1.31992 1.444...","preview_highlight":"<div class=\"CodeMirror cm-s-default CodeMirrorServer\" oncopy=\"if(event.clipboardData){event.clipboardData.setData('text/plain',window.getSelection().toString().replace(/\\u200b/g,''));event.preventDefault();event.stopPropagation();}\">\n<div class=\"CodeMirror-code\">\n<div><pre> X = [1.3229600000000001 1.1422400000000001 1.3964 1.29704 1.21312 1.1348 1.21696 1.4216000000000002 1.35296 1.38856 1.1548 1.39704 1.4204 1.3864 1.31072 1.3767200000000002 1.17216 1.34216 1.35408 1.5088 1.44392 1.1727200000000002 1.1214400000000002 1.29392 1.1467200000000002 1.40088 1.31064 1.4412800000000001 1.34832 1.1298400000000002 1.1380000000000001 1.34528 1.41944 1.41128 1.39968 1.26648 1.1700000000000002 1.2794400000000001 1.1707200000000002 1.42296 1.22496 1.3068 1.248 1.1238400000000002 1.48176 1.2040000000000002 1.20968 1.2945600000000002 1.5176 1.24336 1.2232 1.25464 1.51616 1.2481600000000002 1.49496 1.4155200000000001 1.3613600000000001 1.2608000000000001 1.50448 1.15008 1.30224 1.50864 1.48648 1.14656 1.1213600000000001 1.49912 1.2117600000000002 1.19592 1.46136 1.18472 1.26904 1.19384 1.3258400000000001 1.1832 1.13864 1.49288 1.39112 1.29272 1.3338400000000001 1.32088 1.17496 1.2479200000000001 1.40504 1.28936 1.46936 1.27848 1.36792 1.42608 1.4137600000000001 1.3065600000000002 1.31992 1.444...</pre></div>\n</div>\n</div>\n","lines":16,"lines_more":15,"preview_is_truncated":true,"is_starred":false,"has_rich_preview":false}],"upload":true,"user":"U69BL50BF","display_as_bot":false,"ts":"1611380904.014000","client_msg_id":"9f12637c-c827-4884-8dae-b5fe07a8d870"},{"client_msg_id":"47a112bf-73ed-487a-a196-d5141f03815c","type":"message","text":"It looks long but the data is just a Julia matrix, so you can evaluate it and at the bottom is 2000% error predictions from LIBSVM :scream:","user":"U69BL50BF","ts":"1611380926.014700","team":"T68168MUP","edited":{"user":"U69BL50BF","ts":"1611380950.000000"},"blocks":[{"type":"rich_text","block_id":"ivOT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It looks long but the data is just a Julia matrix, so you can evaluate it and at the bottom is 2000% error predictions from LIBSVM "},{"type":"emoji","name":"scream"}]}]}],"thread_ts":"1611380926.014700","reply_count":2,"reply_users_count":2,"latest_reply":"1611430208.027900","reply_users":["U6C82JCSK","U69CM6160"],"subscribed":false},{"client_msg_id":"be14cc0d-f840-401d-9a92-9c80ebdb3c9e","type":"message","text":"Hello！\nI want to introduce Deep Learning and Julia to a person\n\nI'm referring to FASTAI book for studying, but as for Julia, I'm confused between Flux.jl vs Knet.jl vs (especially) Photon.jl\n\nI remember I had a hard time getting in with Flux as a beginner and Photon(a frontend to Knet), looks PRETTY SIMPLE, although I haven't tried Knet or Photon yet\n\nWhat would you guys recommend？","user":"U01AJUF2GEP","ts":"1611395623.021000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZGl/l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello！\nI want to introduce Deep Learning and Julia to a person\n\nI'm referring to FASTAI book for studying, but as for Julia, I'm confused between Flux.jl vs Knet.jl vs (especially) Photon.jl\n\nI remember I had a hard time getting in with Flux as a beginner and Photon(a frontend to Knet), looks PRETTY SIMPLE, although I haven't tried Knet or Photon yet\n\nWhat would you guys recommend？"}]}]}]},{"client_msg_id":"b4d67ece-c950-47a5-aa5a-c9d93aa71944","type":"message","text":"Photon looks very interesting, but it's quite early in it's development, I guess. You'll probably find Flux much more feature rich at this time. Imo.","user":"U679VPJ8L","ts":"1611401432.022900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BM68","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Photon looks very interesting, but it's quite early in it's development, I guess. You'll probably find Flux much more feature rich at this time. Imo."}]}]}],"reactions":[{"name":"thankyou","users":["U01AJUF2GEP"],"count":1}]},{"client_msg_id":"72349c09-446a-44f3-b80e-bf562f078d58","type":"message","text":"Hello again!\nI hear there were plans of porting the fastai _book_ to Julia!\nWhats the progress on that?","user":"U01AJUF2GEP","ts":"1611411602.025700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tKg2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello again!\nI hear there were plans of porting the fastai "},{"type":"text","text":"book ","style":{"italic":true}},{"type":"text","text":"to Julia!\nWhats the progress on that?"}]}]}],"thread_ts":"1611411602.025700","reply_count":8,"reply_users_count":3,"latest_reply":"1611526483.034400","reply_users":["UGD4K0Z25","UH9KWTTD3","U01AJUF2GEP"],"subscribed":false},{"client_msg_id":"411953db-f888-444f-9753-35847713318b","type":"message","text":"is it possible to define my own optimiser type that would work as an input to <https://github.com/FluxML/Flux.jl/blob/08e79c4ee7d0d6d4fb130d9f996a89a6b4726511/src/optimise/optimisers.jl#L533|Flux.Optimiser>? I would like to use Cosine Annealing, but none of the provided optimisers have that capability. When I tried to implement it myself, I get this error saying that Flux doesn't \"see\" my definition of `apply!(o::CosineAnnealing, x, Δ)`:\n```MethodError: no method matching apply!(::CosineAnnealing, ::CuArray{Float32,4}, ::CuArray{Float32,4})\nClosest candidates are:\n  apply!(::Momentum, ::Any, ::Any) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/optimisers.jl:69\n  apply!(::ADAGrad, ::Any, ::Any) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/optimisers.jl:346\n  apply!(::InvDecay, ::Any, ::Any) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/optimisers.jl:577\n  ...\nStacktrace:\n [1] apply!(::Optimiser, ::CuArray{Float32,4}, ::CuArray{Float32,4}) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/optimisers.jl:553\n [2] update!(::Optimiser, ::CuArray{Float32,4}, ::CuArray{Float32,4}) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/train.jl:23\n...```","user":"U01EK81V5GF","ts":"1611608484.043100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F7d7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is it possible to define my own optimiser type that would work as an input to "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/blob/08e79c4ee7d0d6d4fb130d9f996a89a6b4726511/src/optimise/optimisers.jl#L533","text":"Flux.Optimiser"},{"type":"text","text":"? ","style":{"unlink":true}},{"type":"text","text":"I would like to use Cosine Annealing, but none of the provided optimisers have that capability. When I tried to implement it myself, I get this error saying that Flux doesn't \"see\" my definition of "},{"type":"text","text":"apply!(o::CosineAnnealing, x, Δ)","style":{"code":true}},{"type":"text","text":":\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"MethodError: no method matching apply!(::CosineAnnealing, ::CuArray{Float32,4}, ::CuArray{Float32,4})\nClosest candidates are:\n  apply!(::Momentum, ::Any, ::Any) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/optimisers.jl:69\n  apply!(::ADAGrad, ::Any, ::Any) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/optimisers.jl:346\n  apply!(::InvDecay, ::Any, ::Any) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/optimisers.jl:577\n  ...\nStacktrace:\n [1] apply!(::Optimiser, ::CuArray{Float32,4}, ::CuArray{Float32,4}) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/optimisers.jl:553\n [2] update!(::Optimiser, ::CuArray{Float32,4}, ::CuArray{Float32,4}) at /home/kaitlin/.julia/packages/Flux/AFZ1P/src/optimise/train.jl:23\n..."}]}]}],"thread_ts":"1611608484.043100","reply_count":5,"reply_users_count":4,"latest_reply":"1611660222.044500","reply_users":["U6A936746","U01EK81V5GF","UH9KWTTD3","UC4QQPG4A"],"subscribed":false},{"client_msg_id":"8253b0c6-ff02-4d93-b70c-7500337e61f2","type":"message","text":"Hey everyone, so I was watching a tutorial on Flux, and in the example of the tutor he writes `model.W.grad` ... But when I try to reproduce what he is doing, I get an error, saying that `model.W` does not have this attribute `grad`. Besides, I notice that in his case, `model.W`  is a tracked array, and mine isnt. Any ideas on why this might be happening? Perhaps new versions of Flux changed things?","user":"U01CMBH4MQE","ts":"1611776361.048900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tOi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey everyone, so I was watching a tutorial on Flux, and in the example of the tutor he writes "},{"type":"text","text":"model.W.grad","style":{"code":true}},{"type":"text","text":" ... But when I try to reproduce what he is doing, I get an error, saying that "},{"type":"text","text":"model.W","style":{"code":true}},{"type":"text","text":" does not have this attribute "},{"type":"text","text":"grad","style":{"code":true}},{"type":"text","text":". Besides, I notice that in his case, "},{"type":"text","text":"model.W","style":{"code":true}},{"type":"text","text":"  is a tracked array, and mine isnt. Any ideas on why this might be happening? Perhaps new versions of Flux changed things?"}]}]}],"thread_ts":"1611776361.048900","reply_count":13,"reply_users_count":3,"latest_reply":"1611777025.052400","reply_users":["UMY1LV01G","U01CMBH4MQE","UH24GRBLL"],"subscribed":false},{"client_msg_id":"8db9e892-1259-45ad-979b-f317f441fe38","type":"message","text":"How old was the tutorial?","user":"U6YRZ18GZ","ts":"1611776651.049500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"w+Yq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How old was the tutorial?"}]}]}]},{"client_msg_id":"5977bb75-bb1d-47b3-8480-624b3a07856f","type":"message","text":"2020 July","user":"U01CMBH4MQE","ts":"1611776678.049700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NGqA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"2020 July"}]}]}]},{"client_msg_id":"dd1f97e2-1f26-4987-834d-69c6f75b6424","type":"message","text":"So, I'm trying to implement a GAN using Flux. I got the code from the model_zoo, and was adapting to make it similar to what I already had programmed in Python. But it seems that my Generator is not being trained properly. The generated images are just noise, while in Python, things seems to start \"moving\" after the first epoch. Here is the code for the generator network and training:\n```function Generator(latent_dim::Int = 100) # latent_dim is the size of the vector noise. The default is 100\n    return Chain(\n            Dense(latent_dim, 256,x-&gt;leakyrelu.(x, 0.2f0)),\n            Dense(256, 512,x-&gt;leakyrelu.(x, 0.2f0)),\n            Dense(512, 1024,x-&gt;leakyrelu.(x, 0.2f0)),\n            Dense(1024,784,x-&gt;σ.(x))\n            )\nend\ngenerator_loss(fake_output) = logitbinarycrossentropy(fake_output, 1)\nfunction train_generator!(gen, dscr, x, opt_gen, hparams)\n    noise = randn!(similar(x, (hparams.latent_dim, hparams.batch_size)))\n    ps = Flux.params(gen)    \n    # pullback(ps,value) returns ps and the gradient of ps, where loss = ps, and back(value) = ∇ps(value)\n    # Taking gradient\n    loss, back = Flux.pullback(ps) do \n        generator_loss(dscr(gen(noise))) # Thithe generator_loss\n    end\n    grad = back(1f0)\n    update!(opt_gen, ps, grad)\n    return loss\nend```\nAny ideas on why this might be happening? I'm training on MNIST using the 60.000 images.","user":"U01CMBH4MQE","ts":"1611838797.057400","team":"T68168MUP","edited":{"user":"U01CMBH4MQE","ts":"1611838828.000000"},"blocks":[{"type":"rich_text","block_id":"5ZKE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So, I'm trying to implement a GAN using Flux. I got the code from the model_zoo, and was adapting to make it similar to what I already had programmed in Python. But it seems that my Generator is not being trained properly. The generated images are just noise, while in Python, things seems to start \"moving\" after the first epoch. Here is the code for the generator network and training:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function Generator(latent_dim::Int = 100) # latent_dim is the size of the vector noise. The default is 100\n    return Chain(\n            Dense(latent_dim, 256,x->leakyrelu.(x, 0.2f0)),\n            Dense(256, 512,x->leakyrelu.(x, 0.2f0)),\n            Dense(512, 1024,x->leakyrelu.(x, 0.2f0)),\n            Dense(1024,784,x->σ.(x))\n            )\nend\ngenerator_loss(fake_output) = logitbinarycrossentropy(fake_output, 1)\nfunction train_generator!(gen, dscr, x, opt_gen, hparams)\n    noise = randn!(similar(x, (hparams.latent_dim, hparams.batch_size)))\n    ps = Flux.params(gen)    \n    # pullback(ps,value) returns ps and the gradient of ps, where loss = ps, and back(value) = ∇ps(value)\n    # Taking gradient\n    loss, back = Flux.pullback(ps) do \n        generator_loss(dscr(gen(noise))) # Thithe generator_loss\n    end\n    grad = back(1f0)\n    update!(opt_gen, ps, grad)\n    return loss\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Any ideas on why this might be happening? I'm training on MNIST using the 60.000 images."}]}]}]},{"client_msg_id":"f2500347-8a9f-4849-8ee1-c146b952b1d5","type":"message","text":"Has anyone here created a GAN in Flux? I keep trying to figure out what is wrong, but haven't able to figure much out. So one of the errors was that my images were actually normalized between -1 and 1, instead of 0 and 1 (since I'm using sigmoid function). But my generator simply does not work, while the same configuration works quite well with Keras and Tensorflow :confused:","user":"U01CMBH4MQE","ts":"1611859494.060900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7QST","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Has anyone here created a GAN in Flux? I keep trying to figure out what is wrong, but haven't able to figure much out. So one of the errors was that my images were actually normalized between -1 and 1, instead of 0 and 1 (since I'm using sigmoid function). But my generator simply does not work, while the same configuration works quite well with Keras and Tensorflow "},{"type":"emoji","name":"confused"}]}]}]},{"client_msg_id":"b8683fc7-7d49-4196-894b-e9b6bbe5d69b","type":"message","text":"What's the ideal way to plot scaled versions of the images from the Flux dataset? When I just output them I see a huge mosaic of the greyscale color blocks.","user":"U01L0KU0SDV","ts":"1612134051.069800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GNk8O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What's the ideal way to plot scaled versions of the images from the Flux dataset? When I just output them I see a huge mosaic of the greyscale color blocks."}]}]}]},{"client_msg_id":"a559d794-aab7-48ff-9019-b37624d2dfe0","type":"message","text":"Figured it out, just `using Images` fixed it","user":"U01L0KU0SDV","ts":"1612135946.070100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H//j","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Figured it out, just "},{"type":"text","text":"using Images","style":{"code":true}},{"type":"text","text":" fixed it"}]}]}],"reactions":[{"name":"+1::skin-tone-5","users":["UH9KWTTD3","U0183KL21GS","U011V2YN59N"],"count":3}]},{"client_msg_id":"a6658c52-925f-4920-a927-84c5a6f2cfaa","type":"message","text":"I tried a DecisionTree example done using MLJ. Is there a way to extract the splits of the fitted tree? `fitted_params` doesn't seem to show such details.","user":"UGD4K0Z25","ts":"1612299554.072600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8FATp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I tried a DecisionTree example done using MLJ. Is there a way to extract the splits of the fitted tree? "},{"type":"text","text":"fitted_params","style":{"code":true}},{"type":"text","text":" doesn't seem to show such details."}]}]}],"thread_ts":"1612299554.072600","reply_count":2,"reply_users_count":2,"latest_reply":"1612357735.073500","reply_users":["UAZP7LJLU","UGD4K0Z25"],"subscribed":false},{"client_msg_id":"87d2413d-71c9-4934-911b-9c37cdb88a38","type":"message","text":"Hello!\nIs it just me or MLJ+Pluto(latest of both) is broken on Julia 1.6beta?","user":"U01AJUF2GEP","ts":"1612373667.076100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"N03U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello!\nIs it just me or MLJ+Pluto(latest of both) is broken on Julia 1.6beta?"}]}]}]},{"client_msg_id":"611ec36a-617f-42c2-9222-01d1ed4e2724","type":"message","text":"I can't even run `using MLJ`","user":"U01AJUF2GEP","ts":"1612373734.076500","team":"T68168MUP","edited":{"user":"U01AJUF2GEP","ts":"1612374564.000000"},"blocks":[{"type":"rich_text","block_id":"fHHsb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can't even run "},{"type":"text","text":"using MLJ","style":{"code":true}}]}]}]},{"client_msg_id":"3a51bade-dc84-496d-9b77-2e829ecfbe97","type":"message","text":"Something like this","user":"U01AJUF2GEP","ts":"1612373935.077100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nEJD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Something like this"}]}]}],"thread_ts":"1612373935.077100","reply_count":1,"reply_users_count":1,"latest_reply":"1612374547.083100","reply_users":["U01AJUF2GEP"],"subscribed":false},{"client_msg_id":"2607cb34-3df9-4f59-8082-82248db346fb","type":"message","text":"a friend of mine had a similar problem, they solved it by purging ~/.julia - it's probably cause by some dirty cache; do you use seperate environments for each project or do you dump everything into the main environment?","user":"UH24GRBLL","ts":"1612374037.078100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4A9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"a friend of mine had a similar problem, they solved it by purging ~/.julia - it's probably cause by some dirty cache; do you use seperate environments for each project or do you dump everything into the main environment?"}]}]}]},{"client_msg_id":"279925e7-2f22-4e15-9a9c-29a2a0756426","type":"message","text":"All packages are installed to the same environment:grinning:","user":"U01AJUF2GEP","ts":"1612374251.079100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wovrP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"All packages are installed to the same environment"},{"type":"emoji","name":"grinning"}]}]}]},{"client_msg_id":"5846e159-7bf7-42d6-8b5a-f1ad299fc51f","type":"message","text":"yeah... that leads to accidental downgrades because some packages don't properly update their requirements","user":"UH24GRBLL","ts":"1612374366.079600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GPI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah... that leads to accidental downgrades because some packages don't properly update their requirements"}]}]}]},{"client_msg_id":"b8054420-d4fa-49f4-96d7-f040df5e3889","type":"message","text":"or things do, but due to some transient dependencies the only compatible version is old (and apparently some are wrongly compatible)","user":"UH24GRBLL","ts":"1612374397.080300","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1612374404.000000"},"blocks":[{"type":"rich_text","block_id":"quql","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"or things do, but due to some transient dependencies the only compatible version is old (and apparently some are wrongly compatible)"}]}]}],"thread_ts":"1612374397.080300","reply_count":1,"reply_users_count":1,"latest_reply":"1612374456.081000","reply_users":["UGD4K0Z25"],"subscribed":false},{"client_msg_id":"b07a53b8-4b0d-49a9-87fa-1b4a47bacbc1","type":"message","text":"Yeah, well, making separate environments costs internet data and storage...:slightly_frowning_face:","user":"U01AJUF2GEP","ts":"1612374505.082300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"z+1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, well, making separate environments costs internet data and storage..."},{"type":"emoji","name":"slightly_frowning_face"}]}]}]},{"client_msg_id":"77ed0627-647f-42a3-82b8-5b627da05ea9","type":"message","text":"what? why do you think so?","user":"UH24GRBLL","ts":"1612374520.082900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"d4B","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what? why do you think so?"}]}]}]},{"client_msg_id":"268e59d4-ac45-4c4f-9855-fbd7924458b2","type":"message","text":"Well, that means all packages have their deps reinstalled right？","user":"U01AJUF2GEP","ts":"1612374593.084400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vQwk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Well, that means all packages have their deps reinstalled right？"}]}]}]},{"client_msg_id":"8e91b77e-f9af-4704-bfb5-243c01780878","type":"message","text":"no, they're downloaded once","user":"UH24GRBLL","ts":"1612374627.084600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OQfcC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"no, they're downloaded once"}]}]}],"reactions":[{"name":"point_up","users":["U6A936746"],"count":1}]},{"client_msg_id":"cb214518-20f0-4ce8-a9f8-83477b688a26","type":"message","text":"things are cached, you know?","user":"UH24GRBLL","ts":"1612374640.085100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4ND","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"things are cached, you know?"}]}]}]},{"client_msg_id":"cdf0efad-9daa-42a1-a5b7-e02822f9d03a","type":"message","text":"Hmmm... can you please tell me, how do I make different environments then？","user":"U01AJUF2GEP","ts":"1612374671.086100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"R5KrM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hmmm... can you please tell me, how do I make different environments then？"}]}]}]},{"client_msg_id":"3c362cd7-7ac8-4236-9148-1f513b86a1a0","type":"message","text":"I seem to have mistaken it with how conda works...","user":"U01AJUF2GEP","ts":"1612374691.086900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+tF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I seem to have mistaken it with how conda works..."}]}]}],"thread_ts":"1612374691.086900","reply_count":3,"reply_users_count":2,"latest_reply":"1612430811.093800","reply_users":["UPSSPPBFV","U01AJUF2GEP"],"subscribed":false},{"client_msg_id":"cf88ec48-9a27-499d-b693-69297c7d1d3e","type":"message","text":"<https://julialang.github.io/Pkg.jl/v1/environments/>","user":"UH24GRBLL","ts":"1612374745.087100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rJmMe","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://julialang.github.io/Pkg.jl/v1/environments/"}]}]}]},{"client_msg_id":"b0c5451a-c5d5-4a0b-9656-0b7be046a0e5","type":"message","text":"that's the basic usage - you either start julia with `julia --project=/dir/to/project` or do `]activate /dir/to/project`","user":"UH24GRBLL","ts":"1612374789.087800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3Ibe9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's the basic usage - you either start julia with "},{"type":"text","text":"julia --project=/dir/to/project","style":{"code":true}},{"type":"text","text":" or do "},{"type":"text","text":"]activate /dir/to/project","style":{"code":true}}]}]}]},{"client_msg_id":"6c5286f6-5ad0-47c4-9140-e5ebd5783511","type":"message","text":"that's very destructionist... there's not one entity creating julia packages","user":"UH24GRBLL","ts":"1612374921.090700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rMaJ+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's very destructionist... there's not one entity creating julia packages"}]}]}],"reactions":[{"name":"+1","users":["U6A936746"],"count":1}]},{"client_msg_id":"916942bb-5564-4ae3-9dc9-972e8e0534c5","type":"message","text":"If you want to know more about using Pkg, <#C67EFTEF3|pkg-usage> is the place to go - this is <#C690QRAA3|machine-learning> after all","user":"UH24GRBLL","ts":"1612374963.091200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UhkG+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you want to know more about using Pkg, "},{"type":"channel","channel_id":"C67EFTEF3"},{"type":"text","text":" is the place to go - this is "},{"type":"channel","channel_id":"C690QRAA3"},{"type":"text","text":" after all"}]}]}],"reactions":[{"name":"+1","users":["UMY1LV01G","U6A936746"],"count":2}]},{"client_msg_id":"8f615676-bf14-4dd6-9162-629ec3cbb785","type":"message","text":"Julia is particularly well placed to do this sort of stuff imo :<https://twitter.com/luislamb/status/1357132138605391872>","user":"UDGT4PM41","ts":"1612402583.092400","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1612402612.000000"},"attachments":[{"fallback":"<https://twitter.com/luislamb|@luislamb>: Neurosymbolic AI panel <https://twitter.com/RealAAAI|@RealAAAI> #AAAI2021 on Sunday Feb 7, 7:30 AM PST. <https://twitter.com/guyvdb|@guyvdb> Marta Kwiatkowska, M. Botvinick, Leslie P Kaelbling <https://twitter.com/kerstingAIML|@kerstingAIML>  <https://twitter.com/mishumausam|@mishumausam> <https://twitter.com/k_leyton_brown|@k_leyton_brown>  suggested foundational readings. <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus> <https://twitter.com/Montreal_AI|@Montreal_AI> <https://twitter.com/ceobillionaire|@ceobillionaire> <https://twitter.com/luislamb/status/1218408958781722624>","ts":1612400490,"author_name":"Luis Lamb","author_link":"https://twitter.com/luislamb/status/1357132138605391872","author_icon":"https://pbs.twimg.com/profile_images/1122684648063152129/TC1QsOE7_normal.png","author_subname":"@luislamb","text":"Neurosymbolic AI panel <https://twitter.com/RealAAAI|@RealAAAI> #AAAI2021 on Sunday Feb 7, 7:30 AM PST. <https://twitter.com/guyvdb|@guyvdb> Marta Kwiatkowska, M. Botvinick, Leslie P Kaelbling <https://twitter.com/kerstingAIML|@kerstingAIML>  <https://twitter.com/mishumausam|@mishumausam> <https://twitter.com/k_leyton_brown|@k_leyton_brown>  suggested foundational readings. <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus> <https://twitter.com/Montreal_AI|@Montreal_AI> <https://twitter.com/ceobillionaire|@ceobillionaire> <https://twitter.com/luislamb/status/1218408958781722624>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/luislamb/status/1357132138605391872","id":1,"original_url":"https://twitter.com/luislamb/status/1357132138605391872","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"},{"fallback":"<https://twitter.com/luislamb|@luislamb>: On neural-symbolic computing: suggested readings on foundations of the field - by <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus>  Barbara Hammer and colleagues <https://pbs.twimg.com/media/EOiocmdX4AEzlmA.png>","ts":1579326307,"author_name":"Luis Lamb","author_link":"https://twitter.com/luislamb/status/1218408958781722624","author_icon":"https://pbs.twimg.com/profile_images/1122684648063152129/TC1QsOE7_normal.png","author_subname":"@luislamb","text":"On neural-symbolic computing: suggested readings on foundations of the field - by <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus>  Barbara Hammer and colleagues <https://pbs.twimg.com/media/EOiocmdX4AEzlmA.png>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/luislamb/status/1218408958781722624","image_url":"https://pbs.twimg.com/media/EOiocmdX4AEzlmA.png","image_width":466,"image_height":698,"image_bytes":298839,"indent":true,"color":"32BBF3","id":2,"footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"},{"text":"<https://pbs.twimg.com/media/EOiocmgXsAIV1-6.png>","image_url":"https://pbs.twimg.com/media/EOiocmgXsAIV1-6.png","image_width":454,"image_height":688,"image_bytes":493762,"indent":true,"color":"32BBF3","id":4}],"blocks":[{"type":"rich_text","block_id":"UZT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Julia is particularly well placed to do this sort of stuff imo :"},{"type":"link","url":"https://twitter.com/luislamb/status/1357132138605391872"}]}]}]},{"client_msg_id":"d713cac6-4800-4670-a053-664e2c1211ef","type":"message","text":"<@UH24GRBLL> Thanks！It works！:open_mouth:","user":"U01AJUF2GEP","ts":"1612430778.093700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8JPi8","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UH24GRBLL"},{"type":"text","text":" Thanks！It works！"},{"type":"emoji","name":"open_mouth"}]}]}],"reactions":[{"name":"tada","users":["UH24GRBLL"],"count":1}]},{"type":"message","text":"I was looking at some ml paper (<https://arxiv.org/pdf/1206.6483.pdf> ). There they report the classification accuracy their methods.\n\nIn the paper they mentioned that they used cross-validation to select the parameters, but they never mention creating a test set (they mention a training set though) Now I was wondering, are such reported results usually just the output of crossvalidation (and the ± is just the estimated standard deviation?). Or is using a test set for reporting so common, that it does not have to be mentioned?","files":[{"id":"F01LJK6S3AB","created":1612440353,"timestamp":1612440353,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UBEF50B7C","editable":false,"size":76567,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01LJK6S3AB/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01LJK6S3AB/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_360.png","thumb_360_w":360,"thumb_360_h":137,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_480.png","thumb_480_w":480,"thumb_480_h":183,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_720.png","thumb_720_w":720,"thumb_720_h":274,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_800.png","thumb_800_w":800,"thumb_800_h":305,"original_w":888,"original_h":338,"thumb_tiny":"AwASADDSJpMn3/KlP3vwpuTigBefU/lRz6n8qTPFGTQAuT7/AJUoPPem5OaVTzQA6jFFFABRiiigAooooA//2Q==","permalink":"https://julialang.slack.com/files/UBEF50B7C/F01LJK6S3AB/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01LJK6S3AB-c3f67c00fb","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"km75/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was looking at some ml paper ("},{"type":"link","url":"https://arxiv.org/pdf/1206.6483.pdf"},{"type":"text","text":" ). There they report the classification accuracy their methods.\n\nIn the paper they mentioned that they used cross-validation to select the parameters, but they never mention creating a test set (they mention a training set though) Now I was wondering, are such reported results usually just the output of crossvalidation (and the ± is just the estimated standard deviation?). Or is using a test set for reporting so common, that it does not have to be mentioned?"}]}]}],"user":"UBEF50B7C","display_as_bot":false,"ts":"1612440716.102500","thread_ts":"1612440716.102500","reply_count":4,"reply_users_count":2,"latest_reply":"1612455756.103700","reply_users":["UMY1LV01G","UBEF50B7C"],"subscribed":false},{"client_msg_id":"1f8134b2-4e7f-4bae-ab4a-67c3b576a6d3","type":"message","text":"Anyone know about this? <https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/|https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/>","user":"UDGT4PM41","ts":"1612539182.106000","team":"T68168MUP","attachments":[{"service_name":"MarkTechPost","title":"Researchers From Google Brain Introduces Symbolic Programming And A Python Library Called PyGlove For Automated machine learning | MarkTechPost","title_link":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/","text":"Researchers From Google Brain Introduces Symbolic Programming And A Python Library Called PyGlove For Automated machine learning","fallback":"MarkTechPost: Researchers From Google Brain Introduces Symbolic Programming And A Python Library Called PyGlove For Automated machine learning | MarkTechPost","thumb_url":"https://i1.wp.com/www.marktechpost.com/wp-content/uploads/2021/02/Screen-Shot-2021-02-03-at-10.20.55-PM.png?fit=1622%2C438&ssl=1","fields":[{"title":"Written by","value":"Tanushree Shenwai","short":true},{"title":"Est. reading time","value":"3 minutes","short":true}],"ts":1612419996,"from_url":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/","thumb_width":1622,"thumb_height":438,"service_icon":"https://i0.wp.com/www.marktechpost.com/wp-content/uploads/2017/06/cropped-Untitled-design-3.png?fit=180%2C180&#038;ssl=1","id":1,"original_url":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/"}],"blocks":[{"type":"rich_text","block_id":"qVs5M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone know about this? "},{"type":"link","url":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/","text":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/"}]}]}]},{"client_msg_id":"50ff4796-f683-4dc6-b5c9-eed625278e5b","type":"message","text":"Automated？\nCan someone explain that term to me？","user":"U01AJUF2GEP","ts":"1612539673.106800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xVB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Automated？\nCan someone explain that term to me？"}]}]}]},{"client_msg_id":"72c5ff91-275c-4783-84e4-dbbad468082a","type":"message","text":"It's about learning the structure of the net as well","user":"UH24GRBLL","ts":"1612540057.107200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zLx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's about learning the structure of the net as well"}]}]}]},{"client_msg_id":"8262a133-423b-4255-a38e-339c7573ee16","type":"message","text":"in \"traditional\" machine learning you basically define some polygon by defining the structure of your approach and let the computer fit the parameters so that the curve fits the data. with this, in theory, you'd be able to learn the structure as well","user":"UH24GRBLL","ts":"1612540118.108600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7dWvN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"in \"traditional\" machine learning you basically define some polygon by defining the structure of your approach and let the computer fit the parameters so that the curve fits the data. with this, in theory, you'd be able to learn the structure as well"}]}]}]},{"client_msg_id":"d24f2b00-5e52-4c47-9481-e7e60b98c3e0","type":"message","text":"i.e., which order of polygon would be best not to over- or underfit the data","user":"UH24GRBLL","ts":"1612540142.109100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LQF0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"i.e., which order of polygon would be best not to over- or underfit the data"}]}]}]},{"client_msg_id":"1c756654-1555-4f84-a000-10cdf00e988f","type":"message","text":"(massively simplifying of course)","user":"UH24GRBLL","ts":"1612540152.109500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Eew5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(massively simplifying of course)"}]}]}]},{"client_msg_id":"516cae09-8065-41ad-8c16-86a544c18acd","type":"message","text":"the article links <https://arxiv.org/pdf/2101.08809.pdf>, for those interested","user":"UH24GRBLL","ts":"1612540197.110500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aX+y=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the article links "},{"type":"link","url":"https://arxiv.org/pdf/2101.08809.pdf"},{"type":"text","text":", for those interested"}]}]}]},{"client_msg_id":"6cf1d13e-5aa8-4d74-8735-0c53adb039b9","type":"message","text":"Which naturally call for the question: who will be the first to propose that a machine learn how to best learn the structure of a network? And if going to increasing higher order will be of any benefit","user":"U017LQ3A59U","ts":"1612540210.110800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Af3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Which naturally call for the question: who will be the first to propose that a machine learn how to best learn the structure of a network? And if going to increasing higher order will be of any benefit"}]}]}]},{"client_msg_id":"14ba0802-11ec-4e85-b007-c9da8840c342","type":"message","text":"that's exactly what this approach tries to do, Benoît","user":"UH24GRBLL","ts":"1612540248.111200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4E2RT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's exactly what this approach tries to do, Benoît"}]}]}]},{"client_msg_id":"7093abc3-f43c-46f2-ae3f-20bc781e64c5","type":"message","text":"as I understand it, from a high level, it doesn't just train one net, but multiple variations. E.g. does the network perform better with ADAM or not, does a bigger input space help, what about different stacks of layers etc","user":"UH24GRBLL","ts":"1612540315.113300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bFSV7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"as I understand it, from a high level, it doesn't just train one net, but multiple variations. E.g. does the network perform better with ADAM or not, does a bigger input space help, what about different stacks of layers etc"}]}]}]},{"client_msg_id":"2f1a8a8b-86c5-4450-a12b-469785290ea7","type":"message","text":"the problem of course is that you still have to train those subnets to find out whether any of them are any good","user":"UH24GRBLL","ts":"1612540357.114400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bER1K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the problem of course is that you still have to train those subnets to find out whether any of them are any good"}]}]}]},{"client_msg_id":"89b23846-1f5a-422a-b2bd-6903a05b74a2","type":"message","text":"That how I understand it too. What I mean is that we started to try to learn a function f(x) = y, with some method. A method to machine learn that is just a function g(x, y) = f. As I understand the paper propose to use machine learning to find this g, that then outputs optimal estimator f. In principle you could then say \"wait we use an algorithm h(x, y) = g to find the best method... we could as well apply machine learning at this level directly\"... and continue the chain of training at higher order to infinity","user":"U017LQ3A59U","ts":"1612540616.117900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qJ67T","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That how I understand it too. What I mean is that we started to try to learn a function f(x) = y, with some method. A method to machine learn that is just a function g(x, y) = f. As I understand the paper propose to use machine learning to find this g, that then outputs optimal estimator f. In principle you could then say \"wait we use an algorithm h(x, y) = g to find the best method... we could as well apply machine learning at this level directly\"... and continue the chain of training at higher order to infinity"}]}]}]},{"client_msg_id":"a7144a9c-9ccb-44a2-a96a-0ec6c9635ec3","type":"message","text":"(now that I had to write it down more clearly it sounds like a terrible idea to go beyond the second level, but there may be some well hidden benefits)","user":"U017LQ3A59U","ts":"1612540697.118900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0JK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(now that I had to write it down more clearly it sounds like a terrible idea to go beyond the second level, but there may be some well hidden benefits)"}]}]}]},{"client_msg_id":"6dfa90a5-747a-4f1f-9962-cd133fe114ba","type":"message","text":"yeah, that's the gist of it","user":"UH24GRBLL","ts":"1612541087.119100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ki2Ng","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, that's the gist of it"}]}]}]},{"client_msg_id":"332d68d8-47ef-4cbf-8714-374ad88972d0","type":"message","text":"the problem of course is that the third order in this chain is the exact same problem as the second order, so there's no benefit to going further","user":"UH24GRBLL","ts":"1612541115.119700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+Oc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the problem of course is that the third order in this chain is the exact same problem as the second order, so there's no benefit to going further"}]}]}]},{"client_msg_id":"8a2f0220-46dd-401c-8bd6-fc87396f9a3e","type":"message","text":"I could see with these huge language models the third scale could factor in things like training time and electricity costs. \"Find the type of architecture that will train the model that fits the required crossvalidation metric adjusted for the amount of compute and dollars you want to throw at it\". Although maybe that's a separate abstract problem","user":"U01724Q3PGW","ts":"1612545928.125000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2md","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I could see with these huge language models the third scale could factor in things like training time and electricity costs. \"Find the type of architecture that will train the model that fits the required crossvalidation metric adjusted for the amount of compute and dollars you want to throw at it\". Although maybe that's a separate abstract problem"}]}]}]},{"client_msg_id":"7fcdc9de-d955-4f2f-b7e9-a7c6a5a2117f","type":"message","text":"no reason not to feed that data into the second order already though","user":"UH24GRBLL","ts":"1612546050.125300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yf2uv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"no reason not to feed that data into the second order already though"}]}]}]},{"client_msg_id":"16effb5c-3479-48ab-aa9b-9030bd9d01f4","type":"message","text":"Another day, another NAS paper?","user":"UMY1LV01G","ts":"1612546299.125600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"euR0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Another day, another NAS paper?"}]}]}],"reactions":[{"name":"heavy_check_mark","users":["U01724Q3PGW"],"count":1}]},{"client_msg_id":"596d541e-9872-4865-831d-bab571f42129","type":"message","text":"What is the best way to display training/validation loss plots during training, to already see how the curves evolve from the beginning? I cannot figure out how to replace a plot in Jupyter lab (and I don't want to render tons of plots with the slightly updated curves...)","user":"UFCNUVC67","ts":"1612708834.130800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WFb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is the best way to display training/validation loss plots during training, to already see how the curves evolve from the beginning? I cannot figure out how to replace a plot in Jupyter lab (and I don't want to render tons of plots with the slightly updated curves...)"}]}]}],"thread_ts":"1612708834.130800","reply_count":3,"reply_users_count":2,"latest_reply":"1612709352.131300","reply_users":["U6A936746","UFCNUVC67"],"subscribed":false},{"client_msg_id":"2f72ebe5-e923-4a8d-ac1b-b01f85b6e146","type":"message","text":"I've been trying to figure out how to parallelize computations involving RNNs in Flux, since the hidden state needs to be kept track of separately for each parallel input of a training batch. I'd hope there's a simple built-in way of doing this.  However, I only found <https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378|a post on discourse> with the same question but no answers.. Can anyone point me in the right direction?","user":"UFCNUVC67","ts":"1612962246.135500","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Parallel feedforward computation with RNN","title_link":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378","text":"Say you have a sample of 3 observations-label as a training set for a standard fully connected NN. To parallelize the computation of the loss (and the gradient) of each label, you can feed the three observations to the NN as a matrix instead of sequentially feeding the three observation vectors. Like so: net = Chain(Dense(10,5,relu),Dense(5,1,relu)) |&gt; gpu x = cu(rand(10,3)) #each column of that matrix is one observation y = cu(rand(1,3)) #each element is one label output = net(x) loss = Flux....","fallback":"JuliaLang: Parallel feedforward computation with RNN","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1563180665,"from_url":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378"}],"blocks":[{"type":"rich_text","block_id":"7fR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've been trying to figure out how to parallelize computations involving RNNs in Flux, since the hidden state needs to be kept track of separately for each parallel input of a training batch. I'd hope there's a simple built-in way of doing this.  However, I only found "},{"type":"link","url":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378","text":"a post on discourse"},{"type":"text","text":" with the same question but no answers.. Can anyone point me in the right direction?"}]}]}]},{"client_msg_id":"e669a85f-6800-4b6f-aa16-9e074ef673b5","type":"message","text":"<https://twitter.com/srush_nlp/status/1360023284126011394?s=19|https://twitter.com/srush_nlp/status/1360023284126011394?s=19>","user":"UDGT4PM41","ts":"1613157061.137400","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/srush_nlp|@srush_nlp>: (since people keep asking) \n\nFor the record: I think einsum is bad. \n\nIt feels like programming with manual register allocation.\n\nWhat the heck are ijk...? \nWhy do I re-allocate them each line? \nWhy does it only support +, *? \n\n(it does have great branding :adult:‍🦳)","ts":1613089793,"author_name":"Sasha Rush","author_link":"https://twitter.com/srush_nlp/status/1360023284126011394","author_icon":"https://pbs.twimg.com/profile_images/1225523236873461760/tVkkzywG_normal.jpg","author_subname":"@srush_nlp","text":"(since people keep asking) \n\nFor the record: I think einsum is bad. \n\nIt feels like programming with manual register allocation.\n\nWhat the heck are ijk...? \nWhy do I re-allocate them each line? \nWhy does it only support +, *? \n\n(it does have great branding :adult:‍🦳)","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19","id":1,"original_url":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"2fcC","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19","text":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19"}]}]}]},{"client_msg_id":"640b85ab-67ce-4b81-9237-589a1b1ed182","type":"message","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer.","user":"U9RDM8ZGT","ts":"1613163846.138700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T/UL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer."}]}]}],"thread_ts":"1613163846.138700","reply_count":2,"reply_users_count":1,"latest_reply":"1613164055.139200","reply_users":["UH24GRBLL"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"<https://julialang.slack.com/archives/C680MM7D4/p1613155571397300>","user":"UH24GRBLL","ts":"1613164038.138800","thread_ts":"1613163846.138700","root":{"client_msg_id":"640b85ab-67ce-4b81-9237-589a1b1ed182","type":"message","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer.","user":"U9RDM8ZGT","ts":"1613163846.138700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T/UL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer."}]}]}],"thread_ts":"1613163846.138700","reply_count":2,"reply_users_count":1,"latest_reply":"1613164055.139200","reply_users":["UH24GRBLL"],"subscribed":false},"attachments":[{"fallback":"<https://twitter.com/texasmichelle|@texasmichelle>: As #S4TF heads into maintenance mode, it’s a bit :exploding_head: to reflect on how much I’ve learned. The community and team members built an incredible space for each other to grow :seedling: Thank you all :heart:","ts":1613152802,"author_name":"Michelle Casbon","author_link":"https://twitter.com/texasmichelle/status/1360287563898974211","author_icon":"https://pbs.twimg.com/profile_images/1007153823054376960/o7G6Yf5j_normal.jpg","author_subname":"@texasmichelle","text":"As #S4TF heads into maintenance mode, it’s a bit :exploding_head: to reflect on how much I’ve learned. The community and team members built an incredible space for each other to grow :seedling: Thank you all :heart:","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/texasmichelle/status/1360287563898974211?s=20","id":1,"original_url":"https://julialang.slack.com/archives/C680MM7D4/p1613155571397300","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"1xkJ","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://julialang.slack.com/archives/C680MM7D4/p1613155571397300"}]}]}],"client_msg_id":"5fe04641-76b8-45f2-8df2-04a87d4336e4"},{"client_msg_id":"f08fee69-1ce6-484d-8fb1-4f70e86ee0f6","type":"message","text":"Well, of the two Julia wins!","user":"U9RDM8ZGT","ts":"1613164146.139500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"khwN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Well, of the two Julia wins!"}]}]}]},{"client_msg_id":"217efef1-a8de-40bc-87d5-b689e60c68e0","type":"message","text":"Apple is still supporting Swift autodiff and ML stuff. We'll have to see where they take things","user":"UDGT4PM41","ts":"1613164175.140200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yA6u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Apple is still supporting Swift autodiff and ML stuff. We'll have to see where they take things"}]}]}]},{"client_msg_id":"224591a7-081c-4c22-94ce-e057ee11e268","type":"message","text":"That's the thing about google: they've got lots of resources to pour into projects, but they're also quite fickle.","user":"U9RDM8ZGT","ts":"1613164185.140500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yee","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's the thing about google: they've got lots of resources to pour into projects, but they're also quite fickle."}]}]}]},{"client_msg_id":"e85ee7bb-952c-423d-ac6e-e320d2147704","type":"message","text":"<https://killedbygoogle.com>  is infamous for this","user":"UH24GRBLL","ts":"1613164205.141000","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1613164223.000000"},"blocks":[{"type":"rich_text","block_id":"tHFjE","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://killedbygoogle.com"},{"type":"text","text":"  is infamous for this"}]}]}]},{"client_msg_id":"b483e542-b3a1-4b51-a24a-0dfdc8fc3e8b","type":"message","text":"But this definitely bodes well for Julia","user":"UDGT4PM41","ts":"1613164216.141300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zOz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But this definitely bodes well for Julia"}]}]}],"thread_ts":"1613164216.141300","reply_count":1,"reply_users_count":1,"latest_reply":"1613164390.141500","reply_users":["UGD4K0Z25"],"subscribed":false},{"client_msg_id":"18a8d9e3-82b8-4336-9a4b-29fb601c0785","type":"message","text":"<https://news.ycombinator.com/item?id=26117453> &lt;&lt; Lots of Julia optimism over on HN in the light of the Swift for Tensorflow canning. Interesting how much of the pessimism one saw over five years ago is slowly fading away.","user":"U677R5Q5A","ts":"1613209138.143000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dO+J","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://news.ycombinator.com/item?id=26117453"},{"type":"text","text":" << Lots of Julia optimism over on HN in the light of the Swift for Tensorflow canning. Interesting how much of the pessimism one saw over five years ago is slowly fading away."}]}]}]},{"client_msg_id":"e46afdc6-0a2c-4970-9389-9e4a69ab43d1","type":"message","text":"There's a lot of Flux love in there too :heart_eyes: :fluxml: \n\nKind of gratifying.","user":"UC4QQPG4A","ts":"1613220305.143900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZKy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's a lot of Flux love in there too "},{"type":"emoji","name":"heart_eyes"},{"type":"text","text":" "},{"type":"emoji","name":"fluxml"},{"type":"text","text":" \n\nKind of gratifying."}]}]}]},{"client_msg_id":"e7003cd6-1fa6-4d31-a7b1-5aa70295b605","type":"message","text":"Hey folks, I was hoping someone might help resolve an ambiguity in some of the Flux and Zygote documentation. So in the `Zygote` docs it says that using implicit parameters works, but is not the recommended method. By implicit parameters, the docs seem to refer to notation like this with the zero argument anonymous function\n```grads = gradient(() -&gt; sum(linear(x)), Params([W, b]))```\n But the docs say `However, implicit parameters exist mainly for compatibility with Flux's current AD; it's recommended to use the other approaches unless you need this.`\nHowever, the `Flux` tutorial uses this type of implicit parameter approach in their 60 minute blitz--provided below. And I see this type of notation popping up everywhere, including the DiffEqFlux docs. So what is the right answer--meaning if the implicit parameter approach is not recommended then it seems to get used a lot ??\n\nHere is the example from the 60 minute blitz\n```using Flux: params\n\nW = randn(3, 5)\nb = zeros(3)\nx = rand(5)\n\ny(x) = sum(W * x .+ b)\n\ngrads = gradient(()-&gt;y(x), params([W, b]))\n\ngrads[W], grads[b]```\nMaybe I am missing something or worrying about something that is not a big deal. Just figured I would check.","user":"UDDSTBX19","ts":"1613411344.151200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2QK2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey folks, I was hoping someone might help resolve an ambiguity in some of the Flux and Zygote documentation. So in the "},{"type":"text","text":"Zygote","style":{"code":true}},{"type":"text","text":" docs it says that using implicit parameters works, but is not the recommended method. By implicit parameters, the docs seem to refer to notation like this with the zero argument anonymous function\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"grads = gradient(() -> sum(linear(x)), Params([W, b]))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":" But the docs say "},{"type":"text","text":"However, implicit parameters exist mainly for compatibility with Flux's current AD; it's recommended to use the other approaches unless you need this.","style":{"code":true}},{"type":"text","text":"\nHowever, the "},{"type":"text","text":"Flux","style":{"code":true}},{"type":"text","text":" tutorial uses this type of implicit parameter approach in their 60 minute blitz--provided below. And I see this type of notation popping up everywhere, including the DiffEqFlux docs. So what is the right answer--meaning if the implicit parameter approach is not recommended then it seems to get used a lot ??\n\nHere is the example from the 60 minute blitz\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Flux: params\n\nW = randn(3, 5)\nb = zeros(3)\nx = rand(5)\n\ny(x) = sum(W * x .+ b)\n\ngrads = gradient(()->y(x), params([W, b]))\n\ngrads[W], grads[b]"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe I am missing something or worrying about something that is not a big deal. Just figured I would check."}]}]}],"thread_ts":"1613411344.151200","reply_count":4,"reply_users_count":2,"latest_reply":"1613412997.151900","reply_users":["UH9KWTTD3","UDDSTBX19"],"subscribed":false},{"client_msg_id":"7cfaffd7-328b-4a29-a8cc-45699e2c12d7","type":"message","text":"Does anyone know what the following error means when getting a gradient for a simple Flux model on Julia 1.6?\n```ERROR: LoadError: MethodError: no method matching eval(::IRTools.Inner.Undefined, ::Symbol)\nClosest candidates are:\n  eval(::Module, ::Any) at boot.jl:360\nStacktrace:\n  [1] macro expansion\n    @ ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0 [inlined]\n  [2] _pullback(::Zygote.Context, ::typeof(Core.eval), ::IRTools.Inner.Undefined, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:9\n  [3] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:76 [inlined]\n  [4] _pullback(ctx::Zygote.Context, f::typeof(Dagger.get_type), args::String)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [5] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:29 [inlined]\n  [6] _pullback\n    @ ./dict.jl:465 [inlined]\n  [7] _pullback(::Zygote.Context, ::typeof(get!), ::Dagger.var\"#89#91\", ::Dict{Symbol, Any}, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [8] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n  [9] _pullback(::Zygote.Context, ::Dagger.var\"##compute#88\", ::Nothing, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [10] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n [11] _pullback(::Zygote.Context, ::Dagger.var\"#compute##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [12] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [13] _pullback(::Zygote.Context, ::Dagger.var\"##collect#84\", ::Nothing, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [14] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [15] _pullback(::Zygote.Context, ::Base.var\"#collect##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [16] _pullback```","user":"U6A0PD8CR","ts":"1613422353.154300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YdA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know what the following error means when getting a gradient for a simple Flux model on Julia 1.6?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ERROR: LoadError: MethodError: no method matching eval(::IRTools.Inner.Undefined, ::Symbol)\nClosest candidates are:\n  eval(::Module, ::Any) at boot.jl:360\nStacktrace:\n  [1] macro expansion\n    @ ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0 [inlined]\n  [2] _pullback(::Zygote.Context, ::typeof(Core.eval), ::IRTools.Inner.Undefined, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:9\n  [3] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:76 [inlined]\n  [4] _pullback(ctx::Zygote.Context, f::typeof(Dagger.get_type), args::String)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [5] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:29 [inlined]\n  [6] _pullback\n    @ ./dict.jl:465 [inlined]\n  [7] _pullback(::Zygote.Context, ::typeof(get!), ::Dagger.var\"#89#91\", ::Dict{Symbol, Any}, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [8] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n  [9] _pullback(::Zygote.Context, ::Dagger.var\"##compute#88\", ::Nothing, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [10] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n [11] _pullback(::Zygote.Context, ::Dagger.var\"#compute##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [12] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [13] _pullback(::Zygote.Context, ::Dagger.var\"##collect#84\", ::Nothing, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [14] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [15] _pullback(::Zygote.Context, ::Base.var\"#collect##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [16] _pullback"}]}]}],"thread_ts":"1613422353.154300","reply_count":20,"reply_users_count":2,"latest_reply":"1613423819.158600","reply_users":["UM30MT6RF","U6A0PD8CR"],"subscribed":false},{"client_msg_id":"591a1946-ed3b-4ed8-be79-6cf0ad9d0c93","type":"message","text":"I'm on IRTools master and Zygote 0.6.2","user":"U6A0PD8CR","ts":"1613422382.154600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wuuA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm on IRTools master and Zygote 0.6.2"}]}]}]},{"client_msg_id":"8ba996c2-c2fa-4c73-a25d-97728585656f","type":"message","text":"Are there any benchmarks on the performance of doing ML with Julia vs doing it with pytorch on GPUs?","user":"U7PD3M3L5","ts":"1613487586.160000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hpgq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any benchmarks on the performance of doing ML with Julia vs doing it with pytorch on GPUs?"}]}]}],"thread_ts":"1613487586.160000","reply_count":1,"reply_users_count":1,"latest_reply":"1613488047.160100","reply_users":["U01C3624SGJ"],"subscribed":false},{"client_msg_id":"dc17b825-3478-4f09-b13c-577a05d98808","type":"message","text":"Hi, I'm trying to move a neural network from CPU to GPU and met with this error. Seems that the the pullback failed on GPU. Just wonder anything I should do here. I'm using Zygote 0.6.3. The lossg is just a simple MSE loss function stored on GPU.\n```  for (x,y) in trainDataG\n    train_loss, back = Zygote.pullback(() -&gt; lossg(x,y),gθ)\n    back(one(train_loss))\n  end```\n&gt; DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 0 and 81\")","user":"U01977X150R","ts":"1613527067.167000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n5/i6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I'm trying to move a neural network from CPU to GPU and met with this error. Seems that the the pullback failed on GPU. Just wonder anything I should do here. I'm using Zygote 0.6.3. The lossg is just a simple MSE loss function stored on GPU.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"  for (x,y) in trainDataG\n    train_loss, back = Zygote.pullback(() -> lossg(x,y),gθ)\n    back(one(train_loss))\n  end"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 0 and 81\")"}]}]}]},{"client_msg_id":"d83b4434-01c0-4486-8aba-df5ebab415ae","type":"message","text":"Are there any packages with ELM already implemented? There is ELM.jl but it is archived and its last commit is from 2014","user":"U01C3624SGJ","ts":"1613572969.170500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jiyxC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any packages with ELM already implemented? There is ELM.jl but it is archived and its last commit is from 2014"}]}]}]},{"client_msg_id":"1dfaeedb-97c0-49a4-a08b-dded61d31c25","type":"message","text":"```@load LinearRegressor pkg=MLJLinearModels\nmdl = LinearRegressor()```\nhas stopped working in the recent releases of MLJ\n```julia&gt; mdl = LinearRegressor()\nERROR: UndefVarError: LinearRegressor not defined\nStacktrace:\n [1] top-level scope\n   @ REPL[16]:1```","user":"U01AJUF2GEP","ts":"1613828372.000800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n/g+","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"@load LinearRegressor pkg=MLJLinearModels\nmdl = LinearRegressor()"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"has stopped working in the recent releases of MLJ\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> mdl = LinearRegressor()\nERROR: UndefVarError: LinearRegressor not defined\nStacktrace:\n [1] top-level scope\n   @ REPL[16]:1"}]}]}],"thread_ts":"1613828372.000800","reply_count":2,"reply_users_count":1,"latest_reply":"1613828856.002200","reply_users":["U7THT3TM3"],"subscribed":false},{"client_msg_id":"143b27dd-03a0-4843-a61c-5e225d9b14a0","type":"message","text":"Any idea anyone?","user":"U01AJUF2GEP","ts":"1613828381.001100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oL+vx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any idea anyone?"}]}]}]},{"client_msg_id":"f0fd6d32-17e4-49be-b39a-16adf9e7cfb4","type":"message","text":"<https://github.com/FluxML/MLJFlux.jl#loss-functions|https://github.com/FluxML/MLJFlux.jl#loss-functions> suggests that we can't use some loss functions, could someone help explain why? Are there issues with differentiating with Zygote? <@UD0SQV5LL>  thoughts?","user":"UC4QQPG4A","ts":"1614002851.010700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"su=","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/FluxML/MLJFlux.jl#loss-functions","text":"https://github.com/FluxML/MLJFlux.jl#loss-functions"},{"type":"text","text":" suggests that we can't use some loss functions, could someone help explain why? Are there issues with differentiating with Zygote? "},{"type":"user","user_id":"UD0SQV5LL"},{"type":"text","text":"  thoughts?"}]}]}]}]}