{"cursor": 1, "messages": [{"client_msg_id":"cf88ec48-9a27-499d-b693-69297c7d1d3e","type":"message","text":"<https://julialang.github.io/Pkg.jl/v1/environments/>","user":"UH24GRBLL","ts":"1612374745.087100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rJmMe","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://julialang.github.io/Pkg.jl/v1/environments/"}]}]}]},{"client_msg_id":"b0c5451a-c5d5-4a0b-9656-0b7be046a0e5","type":"message","text":"that's the basic usage - you either start julia with `julia --project=/dir/to/project` or do `]activate /dir/to/project`","user":"UH24GRBLL","ts":"1612374789.087800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3Ibe9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's the basic usage - you either start julia with "},{"type":"text","text":"julia --project=/dir/to/project","style":{"code":true}},{"type":"text","text":" or do "},{"type":"text","text":"]activate /dir/to/project","style":{"code":true}}]}]}]},{"client_msg_id":"6c5286f6-5ad0-47c4-9140-e5ebd5783511","type":"message","text":"that's very destructionist... there's not one entity creating julia packages","user":"UH24GRBLL","ts":"1612374921.090700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rMaJ+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's very destructionist... there's not one entity creating julia packages"}]}]}],"reactions":[{"name":"+1","users":["U6A936746"],"count":1}]},{"client_msg_id":"916942bb-5564-4ae3-9dc9-972e8e0534c5","type":"message","text":"If you want to know more about using Pkg, <#C67EFTEF3|pkg-usage> is the place to go - this is <#C690QRAA3|machine-learning> after all","user":"UH24GRBLL","ts":"1612374963.091200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UhkG+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you want to know more about using Pkg, "},{"type":"channel","channel_id":"C67EFTEF3"},{"type":"text","text":" is the place to go - this is "},{"type":"channel","channel_id":"C690QRAA3"},{"type":"text","text":" after all"}]}]}],"reactions":[{"name":"+1","users":["UMY1LV01G","U6A936746"],"count":2}]},{"client_msg_id":"8f615676-bf14-4dd6-9162-629ec3cbb785","type":"message","text":"Julia is particularly well placed to do this sort of stuff imo :<https://twitter.com/luislamb/status/1357132138605391872>","user":"UDGT4PM41","ts":"1612402583.092400","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1612402612.000000"},"attachments":[{"fallback":"<https://twitter.com/luislamb|@luislamb>: Neurosymbolic AI panel <https://twitter.com/RealAAAI|@RealAAAI> #AAAI2021 on Sunday Feb 7, 7:30 AM PST. <https://twitter.com/guyvdb|@guyvdb> Marta Kwiatkowska, M. Botvinick, Leslie P Kaelbling <https://twitter.com/kerstingAIML|@kerstingAIML>  <https://twitter.com/mishumausam|@mishumausam> <https://twitter.com/k_leyton_brown|@k_leyton_brown>  suggested foundational readings. <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus> <https://twitter.com/Montreal_AI|@Montreal_AI> <https://twitter.com/ceobillionaire|@ceobillionaire> <https://twitter.com/luislamb/status/1218408958781722624>","ts":1612400490,"author_name":"Luis Lamb","author_link":"https://twitter.com/luislamb/status/1357132138605391872","author_icon":"https://pbs.twimg.com/profile_images/1122684648063152129/TC1QsOE7_normal.png","author_subname":"@luislamb","text":"Neurosymbolic AI panel <https://twitter.com/RealAAAI|@RealAAAI> #AAAI2021 on Sunday Feb 7, 7:30 AM PST. <https://twitter.com/guyvdb|@guyvdb> Marta Kwiatkowska, M. Botvinick, Leslie P Kaelbling <https://twitter.com/kerstingAIML|@kerstingAIML>  <https://twitter.com/mishumausam|@mishumausam> <https://twitter.com/k_leyton_brown|@k_leyton_brown>  suggested foundational readings. <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus> <https://twitter.com/Montreal_AI|@Montreal_AI> <https://twitter.com/ceobillionaire|@ceobillionaire> <https://twitter.com/luislamb/status/1218408958781722624>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/luislamb/status/1357132138605391872","id":1,"original_url":"https://twitter.com/luislamb/status/1357132138605391872","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"},{"fallback":"<https://twitter.com/luislamb|@luislamb>: On neural-symbolic computing: suggested readings on foundations of the field - by <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus>  Barbara Hammer and colleagues <https://pbs.twimg.com/media/EOiocmdX4AEzlmA.png>","ts":1579326307,"author_name":"Luis Lamb","author_link":"https://twitter.com/luislamb/status/1218408958781722624","author_icon":"https://pbs.twimg.com/profile_images/1122684648063152129/TC1QsOE7_normal.png","author_subname":"@luislamb","text":"On neural-symbolic computing: suggested readings on foundations of the field - by <https://twitter.com/AvilaGarcez|@AvilaGarcez> <https://twitter.com/pascalhitzler|@pascalhitzler> <https://twitter.com/GaryMarcus|@GaryMarcus>  Barbara Hammer and colleagues <https://pbs.twimg.com/media/EOiocmdX4AEzlmA.png>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/luislamb/status/1218408958781722624","image_url":"https://pbs.twimg.com/media/EOiocmdX4AEzlmA.png","image_width":466,"image_height":698,"image_bytes":298839,"indent":true,"color":"32BBF3","id":2,"footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"},{"text":"<https://pbs.twimg.com/media/EOiocmgXsAIV1-6.png>","image_url":"https://pbs.twimg.com/media/EOiocmgXsAIV1-6.png","image_width":454,"image_height":688,"image_bytes":493762,"indent":true,"color":"32BBF3","id":4}],"blocks":[{"type":"rich_text","block_id":"UZT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Julia is particularly well placed to do this sort of stuff imo :"},{"type":"link","url":"https://twitter.com/luislamb/status/1357132138605391872"}]}]}]},{"client_msg_id":"d713cac6-4800-4670-a053-664e2c1211ef","type":"message","text":"<@UH24GRBLL> Thanks！It works！:open_mouth:","user":"U01AJUF2GEP","ts":"1612430778.093700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8JPi8","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UH24GRBLL"},{"type":"text","text":" Thanks！It works！"},{"type":"emoji","name":"open_mouth"}]}]}],"reactions":[{"name":"tada","users":["UH24GRBLL"],"count":1}]},{"type":"message","text":"I was looking at some ml paper (<https://arxiv.org/pdf/1206.6483.pdf> ). There they report the classification accuracy their methods.\n\nIn the paper they mentioned that they used cross-validation to select the parameters, but they never mention creating a test set (they mention a training set though) Now I was wondering, are such reported results usually just the output of crossvalidation (and the ± is just the estimated standard deviation?). Or is using a test set for reporting so common, that it does not have to be mentioned?","files":[{"id":"F01LJK6S3AB","created":1612440353,"timestamp":1612440353,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UBEF50B7C","editable":false,"size":76567,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01LJK6S3AB/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01LJK6S3AB/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_360.png","thumb_360_w":360,"thumb_360_h":137,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_480.png","thumb_480_w":480,"thumb_480_h":183,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_720.png","thumb_720_w":720,"thumb_720_h":274,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_800.png","thumb_800_w":800,"thumb_800_h":305,"original_w":888,"original_h":338,"thumb_tiny":"AwASADDSJpMn3/KlP3vwpuTigBefU/lRz6n8qTPFGTQAuT7/AJUoPPem5OaVTzQA6jFFFABRiiigAooooA//2Q==","permalink":"https://julialang.slack.com/files/UBEF50B7C/F01LJK6S3AB/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01LJK6S3AB-c3f67c00fb","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"km75/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was looking at some ml paper ("},{"type":"link","url":"https://arxiv.org/pdf/1206.6483.pdf"},{"type":"text","text":" ). There they report the classification accuracy their methods.\n\nIn the paper they mentioned that they used cross-validation to select the parameters, but they never mention creating a test set (they mention a training set though) Now I was wondering, are such reported results usually just the output of crossvalidation (and the ± is just the estimated standard deviation?). Or is using a test set for reporting so common, that it does not have to be mentioned?"}]}]}],"user":"UBEF50B7C","display_as_bot":false,"ts":"1612440716.102500","thread_ts":"1612440716.102500","reply_count":4,"reply_users_count":2,"latest_reply":"1612455756.103700","reply_users":["UMY1LV01G","UBEF50B7C"],"subscribed":false},{"client_msg_id":"1f8134b2-4e7f-4bae-ab4a-67c3b576a6d3","type":"message","text":"Anyone know about this? <https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/|https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/>","user":"UDGT4PM41","ts":"1612539182.106000","team":"T68168MUP","attachments":[{"service_name":"MarkTechPost","title":"Researchers From Google Brain Introduces Symbolic Programming And A Python Library Called PyGlove For Automated machine learning | MarkTechPost","title_link":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/","text":"Researchers From Google Brain Introduces Symbolic Programming And A Python Library Called PyGlove For Automated machine learning","fallback":"MarkTechPost: Researchers From Google Brain Introduces Symbolic Programming And A Python Library Called PyGlove For Automated machine learning | MarkTechPost","thumb_url":"https://i1.wp.com/www.marktechpost.com/wp-content/uploads/2021/02/Screen-Shot-2021-02-03-at-10.20.55-PM.png?fit=1622%2C438&ssl=1","fields":[{"title":"Written by","value":"Tanushree Shenwai","short":true},{"title":"Est. reading time","value":"3 minutes","short":true}],"ts":1612419996,"from_url":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/","thumb_width":1622,"thumb_height":438,"service_icon":"https://i0.wp.com/www.marktechpost.com/wp-content/uploads/2017/06/cropped-Untitled-design-3.png?fit=180%2C180&#038;ssl=1","id":1,"original_url":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/"}],"blocks":[{"type":"rich_text","block_id":"qVs5M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone know about this? "},{"type":"link","url":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/","text":"https://www.marktechpost.com/2021/02/03/researchers-from-google-brain-introduces-symbolic-programming-and-a-python-library-called-pyglove-for-automated-machine-learning/"}]}]}]},{"client_msg_id":"50ff4796-f683-4dc6-b5c9-eed625278e5b","type":"message","text":"Automated？\nCan someone explain that term to me？","user":"U01AJUF2GEP","ts":"1612539673.106800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xVB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Automated？\nCan someone explain that term to me？"}]}]}]},{"client_msg_id":"72c5ff91-275c-4783-84e4-dbbad468082a","type":"message","text":"It's about learning the structure of the net as well","user":"UH24GRBLL","ts":"1612540057.107200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zLx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's about learning the structure of the net as well"}]}]}]},{"client_msg_id":"8262a133-423b-4255-a38e-339c7573ee16","type":"message","text":"in \"traditional\" machine learning you basically define some polygon by defining the structure of your approach and let the computer fit the parameters so that the curve fits the data. with this, in theory, you'd be able to learn the structure as well","user":"UH24GRBLL","ts":"1612540118.108600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7dWvN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"in \"traditional\" machine learning you basically define some polygon by defining the structure of your approach and let the computer fit the parameters so that the curve fits the data. with this, in theory, you'd be able to learn the structure as well"}]}]}]},{"client_msg_id":"d24f2b00-5e52-4c47-9481-e7e60b98c3e0","type":"message","text":"i.e., which order of polygon would be best not to over- or underfit the data","user":"UH24GRBLL","ts":"1612540142.109100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LQF0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"i.e., which order of polygon would be best not to over- or underfit the data"}]}]}]},{"client_msg_id":"1c756654-1555-4f84-a000-10cdf00e988f","type":"message","text":"(massively simplifying of course)","user":"UH24GRBLL","ts":"1612540152.109500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Eew5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(massively simplifying of course)"}]}]}]},{"client_msg_id":"516cae09-8065-41ad-8c16-86a544c18acd","type":"message","text":"the article links <https://arxiv.org/pdf/2101.08809.pdf>, for those interested","user":"UH24GRBLL","ts":"1612540197.110500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aX+y=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the article links "},{"type":"link","url":"https://arxiv.org/pdf/2101.08809.pdf"},{"type":"text","text":", for those interested"}]}]}]},{"client_msg_id":"6cf1d13e-5aa8-4d74-8735-0c53adb039b9","type":"message","text":"Which naturally call for the question: who will be the first to propose that a machine learn how to best learn the structure of a network? And if going to increasing higher order will be of any benefit","user":"U017LQ3A59U","ts":"1612540210.110800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Af3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Which naturally call for the question: who will be the first to propose that a machine learn how to best learn the structure of a network? And if going to increasing higher order will be of any benefit"}]}]}]},{"client_msg_id":"14ba0802-11ec-4e85-b007-c9da8840c342","type":"message","text":"that's exactly what this approach tries to do, Benoît","user":"UH24GRBLL","ts":"1612540248.111200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4E2RT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's exactly what this approach tries to do, Benoît"}]}]}]},{"client_msg_id":"7093abc3-f43c-46f2-ae3f-20bc781e64c5","type":"message","text":"as I understand it, from a high level, it doesn't just train one net, but multiple variations. E.g. does the network perform better with ADAM or not, does a bigger input space help, what about different stacks of layers etc","user":"UH24GRBLL","ts":"1612540315.113300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bFSV7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"as I understand it, from a high level, it doesn't just train one net, but multiple variations. E.g. does the network perform better with ADAM or not, does a bigger input space help, what about different stacks of layers etc"}]}]}]},{"client_msg_id":"2f1a8a8b-86c5-4450-a12b-469785290ea7","type":"message","text":"the problem of course is that you still have to train those subnets to find out whether any of them are any good","user":"UH24GRBLL","ts":"1612540357.114400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bER1K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the problem of course is that you still have to train those subnets to find out whether any of them are any good"}]}]}]},{"client_msg_id":"89b23846-1f5a-422a-b2bd-6903a05b74a2","type":"message","text":"That how I understand it too. What I mean is that we started to try to learn a function f(x) = y, with some method. A method to machine learn that is just a function g(x, y) = f. As I understand the paper propose to use machine learning to find this g, that then outputs optimal estimator f. In principle you could then say \"wait we use an algorithm h(x, y) = g to find the best method... we could as well apply machine learning at this level directly\"... and continue the chain of training at higher order to infinity","user":"U017LQ3A59U","ts":"1612540616.117900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qJ67T","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That how I understand it too. What I mean is that we started to try to learn a function f(x) = y, with some method. A method to machine learn that is just a function g(x, y) = f. As I understand the paper propose to use machine learning to find this g, that then outputs optimal estimator f. In principle you could then say \"wait we use an algorithm h(x, y) = g to find the best method... we could as well apply machine learning at this level directly\"... and continue the chain of training at higher order to infinity"}]}]}]},{"client_msg_id":"a7144a9c-9ccb-44a2-a96a-0ec6c9635ec3","type":"message","text":"(now that I had to write it down more clearly it sounds like a terrible idea to go beyond the second level, but there may be some well hidden benefits)","user":"U017LQ3A59U","ts":"1612540697.118900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0JK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(now that I had to write it down more clearly it sounds like a terrible idea to go beyond the second level, but there may be some well hidden benefits)"}]}]}]},{"client_msg_id":"6dfa90a5-747a-4f1f-9962-cd133fe114ba","type":"message","text":"yeah, that's the gist of it","user":"UH24GRBLL","ts":"1612541087.119100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ki2Ng","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, that's the gist of it"}]}]}]},{"client_msg_id":"332d68d8-47ef-4cbf-8714-374ad88972d0","type":"message","text":"the problem of course is that the third order in this chain is the exact same problem as the second order, so there's no benefit to going further","user":"UH24GRBLL","ts":"1612541115.119700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+Oc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the problem of course is that the third order in this chain is the exact same problem as the second order, so there's no benefit to going further"}]}]}]},{"client_msg_id":"8a2f0220-46dd-401c-8bd6-fc87396f9a3e","type":"message","text":"I could see with these huge language models the third scale could factor in things like training time and electricity costs. \"Find the type of architecture that will train the model that fits the required crossvalidation metric adjusted for the amount of compute and dollars you want to throw at it\". Although maybe that's a separate abstract problem","user":"U01724Q3PGW","ts":"1612545928.125000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2md","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I could see with these huge language models the third scale could factor in things like training time and electricity costs. \"Find the type of architecture that will train the model that fits the required crossvalidation metric adjusted for the amount of compute and dollars you want to throw at it\". Although maybe that's a separate abstract problem"}]}]}]},{"client_msg_id":"7fcdc9de-d955-4f2f-b7e9-a7c6a5a2117f","type":"message","text":"no reason not to feed that data into the second order already though","user":"UH24GRBLL","ts":"1612546050.125300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yf2uv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"no reason not to feed that data into the second order already though"}]}]}]},{"client_msg_id":"16effb5c-3479-48ab-aa9b-9030bd9d01f4","type":"message","text":"Another day, another NAS paper?","user":"UMY1LV01G","ts":"1612546299.125600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"euR0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Another day, another NAS paper?"}]}]}],"reactions":[{"name":"heavy_check_mark","users":["U01724Q3PGW"],"count":1}]},{"client_msg_id":"596d541e-9872-4865-831d-bab571f42129","type":"message","text":"What is the best way to display training/validation loss plots during training, to already see how the curves evolve from the beginning? I cannot figure out how to replace a plot in Jupyter lab (and I don't want to render tons of plots with the slightly updated curves...)","user":"UFCNUVC67","ts":"1612708834.130800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WFb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is the best way to display training/validation loss plots during training, to already see how the curves evolve from the beginning? I cannot figure out how to replace a plot in Jupyter lab (and I don't want to render tons of plots with the slightly updated curves...)"}]}]}],"thread_ts":"1612708834.130800","reply_count":3,"reply_users_count":2,"latest_reply":"1612709352.131300","reply_users":["U6A936746","UFCNUVC67"],"subscribed":false},{"client_msg_id":"2f72ebe5-e923-4a8d-ac1b-b01f85b6e146","type":"message","text":"I've been trying to figure out how to parallelize computations involving RNNs in Flux, since the hidden state needs to be kept track of separately for each parallel input of a training batch. I'd hope there's a simple built-in way of doing this.  However, I only found <https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378|a post on discourse> with the same question but no answers.. Can anyone point me in the right direction?","user":"UFCNUVC67","ts":"1612962246.135500","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Parallel feedforward computation with RNN","title_link":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378","text":"Say you have a sample of 3 observations-label as a training set for a standard fully connected NN. To parallelize the computation of the loss (and the gradient) of each label, you can feed the three observations to the NN as a matrix instead of sequentially feeding the three observation vectors. Like so: net = Chain(Dense(10,5,relu),Dense(5,1,relu)) |&gt; gpu x = cu(rand(10,3)) #each column of that matrix is one observation y = cu(rand(1,3)) #each element is one label output = net(x) loss = Flux....","fallback":"JuliaLang: Parallel feedforward computation with RNN","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1563180665,"from_url":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378"}],"blocks":[{"type":"rich_text","block_id":"7fR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've been trying to figure out how to parallelize computations involving RNNs in Flux, since the hidden state needs to be kept track of separately for each parallel input of a training batch. I'd hope there's a simple built-in way of doing this.  However, I only found "},{"type":"link","url":"https://discourse.julialang.org/t/parallel-feedforward-computation-with-rnn/26378","text":"a post on discourse"},{"type":"text","text":" with the same question but no answers.. Can anyone point me in the right direction?"}]}]}]},{"client_msg_id":"e669a85f-6800-4b6f-aa16-9e074ef673b5","type":"message","text":"<https://twitter.com/srush_nlp/status/1360023284126011394?s=19|https://twitter.com/srush_nlp/status/1360023284126011394?s=19>","user":"UDGT4PM41","ts":"1613157061.137400","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/srush_nlp|@srush_nlp>: (since people keep asking) \n\nFor the record: I think einsum is bad. \n\nIt feels like programming with manual register allocation.\n\nWhat the heck are ijk...? \nWhy do I re-allocate them each line? \nWhy does it only support +, *? \n\n(it does have great branding :adult:‍🦳)","ts":1613089793,"author_name":"Sasha Rush","author_link":"https://twitter.com/srush_nlp/status/1360023284126011394","author_icon":"https://pbs.twimg.com/profile_images/1225523236873461760/tVkkzywG_normal.jpg","author_subname":"@srush_nlp","text":"(since people keep asking) \n\nFor the record: I think einsum is bad. \n\nIt feels like programming with manual register allocation.\n\nWhat the heck are ijk...? \nWhy do I re-allocate them each line? \nWhy does it only support +, *? \n\n(it does have great branding :adult:‍🦳)","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19","id":1,"original_url":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"2fcC","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19","text":"https://twitter.com/srush_nlp/status/1360023284126011394?s=19"}]}]}]},{"client_msg_id":"640b85ab-67ce-4b81-9237-589a1b1ed182","type":"message","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer.","user":"U9RDM8ZGT","ts":"1613163846.138700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T/UL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer."}]}]}],"thread_ts":"1613163846.138700","reply_count":2,"reply_users_count":1,"latest_reply":"1613164055.139200","reply_users":["UH24GRBLL"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"<https://julialang.slack.com/archives/C680MM7D4/p1613155571397300>","user":"UH24GRBLL","ts":"1613164038.138800","thread_ts":"1613163846.138700","root":{"client_msg_id":"640b85ab-67ce-4b81-9237-589a1b1ed182","type":"message","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer.","user":"U9RDM8ZGT","ts":"1613163846.138700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T/UL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Word on the street is that Swift for Tensorflow has been shut down. I take that to mean that Google isn't supporting with it with resources any longer."}]}]}],"thread_ts":"1613163846.138700","reply_count":2,"reply_users_count":1,"latest_reply":"1613164055.139200","reply_users":["UH24GRBLL"],"subscribed":false},"attachments":[{"fallback":"<https://twitter.com/texasmichelle|@texasmichelle>: As #S4TF heads into maintenance mode, it’s a bit :exploding_head: to reflect on how much I’ve learned. The community and team members built an incredible space for each other to grow :seedling: Thank you all :heart:","ts":1613152802,"author_name":"Michelle Casbon","author_link":"https://twitter.com/texasmichelle/status/1360287563898974211","author_icon":"https://pbs.twimg.com/profile_images/1007153823054376960/o7G6Yf5j_normal.jpg","author_subname":"@texasmichelle","text":"As #S4TF heads into maintenance mode, it’s a bit :exploding_head: to reflect on how much I’ve learned. The community and team members built an incredible space for each other to grow :seedling: Thank you all :heart:","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/texasmichelle/status/1360287563898974211?s=20","id":1,"original_url":"https://julialang.slack.com/archives/C680MM7D4/p1613155571397300","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"1xkJ","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://julialang.slack.com/archives/C680MM7D4/p1613155571397300"}]}]}],"client_msg_id":"5fe04641-76b8-45f2-8df2-04a87d4336e4"},{"client_msg_id":"f08fee69-1ce6-484d-8fb1-4f70e86ee0f6","type":"message","text":"Well, of the two Julia wins!","user":"U9RDM8ZGT","ts":"1613164146.139500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"khwN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Well, of the two Julia wins!"}]}]}]},{"client_msg_id":"217efef1-a8de-40bc-87d5-b689e60c68e0","type":"message","text":"Apple is still supporting Swift autodiff and ML stuff. We'll have to see where they take things","user":"UDGT4PM41","ts":"1613164175.140200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yA6u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Apple is still supporting Swift autodiff and ML stuff. We'll have to see where they take things"}]}]}]},{"client_msg_id":"224591a7-081c-4c22-94ce-e057ee11e268","type":"message","text":"That's the thing about google: they've got lots of resources to pour into projects, but they're also quite fickle.","user":"U9RDM8ZGT","ts":"1613164185.140500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yee","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's the thing about google: they've got lots of resources to pour into projects, but they're also quite fickle."}]}]}]},{"client_msg_id":"e85ee7bb-952c-423d-ac6e-e320d2147704","type":"message","text":"<https://killedbygoogle.com>  is infamous for this","user":"UH24GRBLL","ts":"1613164205.141000","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1613164223.000000"},"blocks":[{"type":"rich_text","block_id":"tHFjE","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://killedbygoogle.com"},{"type":"text","text":"  is infamous for this"}]}]}]},{"client_msg_id":"b483e542-b3a1-4b51-a24a-0dfdc8fc3e8b","type":"message","text":"But this definitely bodes well for Julia","user":"UDGT4PM41","ts":"1613164216.141300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zOz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But this definitely bodes well for Julia"}]}]}],"thread_ts":"1613164216.141300","reply_count":1,"reply_users_count":1,"latest_reply":"1613164390.141500","reply_users":["UGD4K0Z25"],"subscribed":false},{"client_msg_id":"18a8d9e3-82b8-4336-9a4b-29fb601c0785","type":"message","text":"<https://news.ycombinator.com/item?id=26117453> &lt;&lt; Lots of Julia optimism over on HN in the light of the Swift for Tensorflow canning. Interesting how much of the pessimism one saw over five years ago is slowly fading away.","user":"U677R5Q5A","ts":"1613209138.143000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dO+J","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://news.ycombinator.com/item?id=26117453"},{"type":"text","text":" << Lots of Julia optimism over on HN in the light of the Swift for Tensorflow canning. Interesting how much of the pessimism one saw over five years ago is slowly fading away."}]}]}]},{"client_msg_id":"e46afdc6-0a2c-4970-9389-9e4a69ab43d1","type":"message","text":"There's a lot of Flux love in there too :heart_eyes: :fluxml: \n\nKind of gratifying.","user":"UC4QQPG4A","ts":"1613220305.143900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZKy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's a lot of Flux love in there too "},{"type":"emoji","name":"heart_eyes"},{"type":"text","text":" "},{"type":"emoji","name":"fluxml"},{"type":"text","text":" \n\nKind of gratifying."}]}]}]},{"client_msg_id":"e7003cd6-1fa6-4d31-a7b1-5aa70295b605","type":"message","text":"Hey folks, I was hoping someone might help resolve an ambiguity in some of the Flux and Zygote documentation. So in the `Zygote` docs it says that using implicit parameters works, but is not the recommended method. By implicit parameters, the docs seem to refer to notation like this with the zero argument anonymous function\n```grads = gradient(() -&gt; sum(linear(x)), Params([W, b]))```\n But the docs say `However, implicit parameters exist mainly for compatibility with Flux's current AD; it's recommended to use the other approaches unless you need this.`\nHowever, the `Flux` tutorial uses this type of implicit parameter approach in their 60 minute blitz--provided below. And I see this type of notation popping up everywhere, including the DiffEqFlux docs. So what is the right answer--meaning if the implicit parameter approach is not recommended then it seems to get used a lot ??\n\nHere is the example from the 60 minute blitz\n```using Flux: params\n\nW = randn(3, 5)\nb = zeros(3)\nx = rand(5)\n\ny(x) = sum(W * x .+ b)\n\ngrads = gradient(()-&gt;y(x), params([W, b]))\n\ngrads[W], grads[b]```\nMaybe I am missing something or worrying about something that is not a big deal. Just figured I would check.","user":"UDDSTBX19","ts":"1613411344.151200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2QK2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey folks, I was hoping someone might help resolve an ambiguity in some of the Flux and Zygote documentation. So in the "},{"type":"text","text":"Zygote","style":{"code":true}},{"type":"text","text":" docs it says that using implicit parameters works, but is not the recommended method. By implicit parameters, the docs seem to refer to notation like this with the zero argument anonymous function\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"grads = gradient(() -> sum(linear(x)), Params([W, b]))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":" But the docs say "},{"type":"text","text":"However, implicit parameters exist mainly for compatibility with Flux's current AD; it's recommended to use the other approaches unless you need this.","style":{"code":true}},{"type":"text","text":"\nHowever, the "},{"type":"text","text":"Flux","style":{"code":true}},{"type":"text","text":" tutorial uses this type of implicit parameter approach in their 60 minute blitz--provided below. And I see this type of notation popping up everywhere, including the DiffEqFlux docs. So what is the right answer--meaning if the implicit parameter approach is not recommended then it seems to get used a lot ??\n\nHere is the example from the 60 minute blitz\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Flux: params\n\nW = randn(3, 5)\nb = zeros(3)\nx = rand(5)\n\ny(x) = sum(W * x .+ b)\n\ngrads = gradient(()->y(x), params([W, b]))\n\ngrads[W], grads[b]"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe I am missing something or worrying about something that is not a big deal. Just figured I would check."}]}]}],"thread_ts":"1613411344.151200","reply_count":4,"reply_users_count":2,"latest_reply":"1613412997.151900","reply_users":["UH9KWTTD3","UDDSTBX19"],"subscribed":false},{"client_msg_id":"7cfaffd7-328b-4a29-a8cc-45699e2c12d7","type":"message","text":"Does anyone know what the following error means when getting a gradient for a simple Flux model on Julia 1.6?\n```ERROR: LoadError: MethodError: no method matching eval(::IRTools.Inner.Undefined, ::Symbol)\nClosest candidates are:\n  eval(::Module, ::Any) at boot.jl:360\nStacktrace:\n  [1] macro expansion\n    @ ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0 [inlined]\n  [2] _pullback(::Zygote.Context, ::typeof(Core.eval), ::IRTools.Inner.Undefined, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:9\n  [3] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:76 [inlined]\n  [4] _pullback(ctx::Zygote.Context, f::typeof(Dagger.get_type), args::String)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [5] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:29 [inlined]\n  [6] _pullback\n    @ ./dict.jl:465 [inlined]\n  [7] _pullback(::Zygote.Context, ::typeof(get!), ::Dagger.var\"#89#91\", ::Dict{Symbol, Any}, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [8] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n  [9] _pullback(::Zygote.Context, ::Dagger.var\"##compute#88\", ::Nothing, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [10] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n [11] _pullback(::Zygote.Context, ::Dagger.var\"#compute##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [12] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [13] _pullback(::Zygote.Context, ::Dagger.var\"##collect#84\", ::Nothing, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [14] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [15] _pullback(::Zygote.Context, ::Base.var\"#collect##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [16] _pullback```","user":"U6A0PD8CR","ts":"1613422353.154300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YdA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know what the following error means when getting a gradient for a simple Flux model on Julia 1.6?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ERROR: LoadError: MethodError: no method matching eval(::IRTools.Inner.Undefined, ::Symbol)\nClosest candidates are:\n  eval(::Module, ::Any) at boot.jl:360\nStacktrace:\n  [1] macro expansion\n    @ ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0 [inlined]\n  [2] _pullback(::Zygote.Context, ::typeof(Core.eval), ::IRTools.Inner.Undefined, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:9\n  [3] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:76 [inlined]\n  [4] _pullback(ctx::Zygote.Context, f::typeof(Dagger.get_type), args::String)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [5] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:29 [inlined]\n  [6] _pullback\n    @ ./dict.jl:465 [inlined]\n  [7] _pullback(::Zygote.Context, ::typeof(get!), ::Dagger.var\"#89#91\", ::Dict{Symbol, Any}, ::Symbol)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n  [8] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n  [9] _pullback(::Zygote.Context, ::Dagger.var\"##compute#88\", ::Nothing, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [10] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:28 [inlined]\n [11] _pullback(::Zygote.Context, ::Dagger.var\"#compute##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(compute), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [12] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [13] _pullback(::Zygote.Context, ::Dagger.var\"##collect#84\", ::Nothing, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [14] _pullback\n    @ ~/.julia/dev/Dagger/src/compute.jl:8 [inlined]\n [15] _pullback(::Zygote.Context, ::Base.var\"#collect##kw\", ::NamedTuple{(:options,), Tuple{Nothing}}, ::typeof(collect), ::Context, ::Thunk)\n    @ Zygote ~/.julia/packages/Zygote/Iz3wR/src/compiler/interface2.jl:0\n [16] _pullback"}]}]}],"thread_ts":"1613422353.154300","reply_count":20,"reply_users_count":2,"latest_reply":"1613423819.158600","reply_users":["UM30MT6RF","U6A0PD8CR"],"subscribed":false},{"client_msg_id":"591a1946-ed3b-4ed8-be79-6cf0ad9d0c93","type":"message","text":"I'm on IRTools master and Zygote 0.6.2","user":"U6A0PD8CR","ts":"1613422382.154600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wuuA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm on IRTools master and Zygote 0.6.2"}]}]}]},{"client_msg_id":"8ba996c2-c2fa-4c73-a25d-97728585656f","type":"message","text":"Are there any benchmarks on the performance of doing ML with Julia vs doing it with pytorch on GPUs?","user":"U7PD3M3L5","ts":"1613487586.160000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hpgq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any benchmarks on the performance of doing ML with Julia vs doing it with pytorch on GPUs?"}]}]}],"thread_ts":"1613487586.160000","reply_count":1,"reply_users_count":1,"latest_reply":"1613488047.160100","reply_users":["U01C3624SGJ"],"subscribed":false},{"client_msg_id":"dc17b825-3478-4f09-b13c-577a05d98808","type":"message","text":"Hi, I'm trying to move a neural network from CPU to GPU and met with this error. Seems that the the pullback failed on GPU. Just wonder anything I should do here. I'm using Zygote 0.6.3. The lossg is just a simple MSE loss function stored on GPU.\n```  for (x,y) in trainDataG\n    train_loss, back = Zygote.pullback(() -&gt; lossg(x,y),gθ)\n    back(one(train_loss))\n  end```\n&gt; DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 0 and 81\")","user":"U01977X150R","ts":"1613527067.167000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n5/i6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I'm trying to move a neural network from CPU to GPU and met with this error. Seems that the the pullback failed on GPU. Just wonder anything I should do here. I'm using Zygote 0.6.3. The lossg is just a simple MSE loss function stored on GPU.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"  for (x,y) in trainDataG\n    train_loss, back = Zygote.pullback(() -> lossg(x,y),gθ)\n    back(one(train_loss))\n  end"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 0 and 81\")"}]}]}]},{"client_msg_id":"d83b4434-01c0-4486-8aba-df5ebab415ae","type":"message","text":"Are there any packages with ELM already implemented? There is ELM.jl but it is archived and its last commit is from 2014","user":"U01C3624SGJ","ts":"1613572969.170500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jiyxC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any packages with ELM already implemented? There is ELM.jl but it is archived and its last commit is from 2014"}]}]}]},{"client_msg_id":"1dfaeedb-97c0-49a4-a08b-dded61d31c25","type":"message","text":"```@load LinearRegressor pkg=MLJLinearModels\nmdl = LinearRegressor()```\nhas stopped working in the recent releases of MLJ\n```julia&gt; mdl = LinearRegressor()\nERROR: UndefVarError: LinearRegressor not defined\nStacktrace:\n [1] top-level scope\n   @ REPL[16]:1```","user":"U01AJUF2GEP","ts":"1613828372.000800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n/g+","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"@load LinearRegressor pkg=MLJLinearModels\nmdl = LinearRegressor()"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"has stopped working in the recent releases of MLJ\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> mdl = LinearRegressor()\nERROR: UndefVarError: LinearRegressor not defined\nStacktrace:\n [1] top-level scope\n   @ REPL[16]:1"}]}]}],"thread_ts":"1613828372.000800","reply_count":2,"reply_users_count":1,"latest_reply":"1613828856.002200","reply_users":["U7THT3TM3"],"subscribed":false},{"client_msg_id":"143b27dd-03a0-4843-a61c-5e225d9b14a0","type":"message","text":"Any idea anyone?","user":"U01AJUF2GEP","ts":"1613828381.001100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oL+vx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any idea anyone?"}]}]}]},{"client_msg_id":"f0fd6d32-17e4-49be-b39a-16adf9e7cfb4","type":"message","text":"<https://github.com/FluxML/MLJFlux.jl#loss-functions|https://github.com/FluxML/MLJFlux.jl#loss-functions> suggests that we can't use some loss functions, could someone help explain why? Are there issues with differentiating with Zygote? <@UD0SQV5LL>  thoughts?","user":"UC4QQPG4A","ts":"1614002851.010700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"su=","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/FluxML/MLJFlux.jl#loss-functions","text":"https://github.com/FluxML/MLJFlux.jl#loss-functions"},{"type":"text","text":" suggests that we can't use some loss functions, could someone help explain why? Are there issues with differentiating with Zygote? "},{"type":"user","user_id":"UD0SQV5LL"},{"type":"text","text":"  thoughts?"}]}]}]},{"client_msg_id":"b6cfbdda-6308-4cf2-873a-f2d0e27e90ab","type":"message","text":"Is there a quickstart on how to convert a tensorflow/python notebook to Flux? (I know almost nothing of Flux.)","user":"U01CQTKB86N","ts":"1614004830.011500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Y5Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a quickstart on how to convert a tensorflow/python notebook to Flux? (I know almost nothing of Flux.)"}]}]}],"thread_ts":"1614004830.011500","reply_count":6,"reply_users_count":2,"latest_reply":"1614006515.012600","reply_users":["U01CQTKB86N","UH9KWTTD3"],"subscribed":false},{"client_msg_id":"619299b6-793d-4f06-807b-de624bd64564","type":"message","text":"Say, I was searching for any libraries for relation-extraction or named entity recognition from text in Julia. This would probably fall under NLP. I could not find anything, so I was wondering if anyone knew of any julia implementations?","user":"UDDSTBX19","ts":"1614007366.014200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1scl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Say, I was searching for any libraries for relation-extraction or named entity recognition from text in Julia. This would probably fall under NLP. I could not find anything, so I was wondering if anyone knew of any julia implementations?"}]}]}]},{"client_msg_id":"5d0ac6e8-48b5-4e93-9b63-dcaba7eac686","type":"message","text":"Are there any tutorials for using LDA (Linear Discriminant Analysis) as a dimensionality reduction on julia?","user":"U01C3624SGJ","ts":"1614088537.016300","team":"T68168MUP","edited":{"user":"U01C3624SGJ","ts":"1614088993.000000"},"blocks":[{"type":"rich_text","block_id":"CVCEx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any tutorials for using LDA (Linear Discriminant Analysis) as a dimensionality reduction on julia?"}]}]}],"thread_ts":"1614088537.016300","reply_count":5,"reply_users_count":2,"latest_reply":"1614088972.017400","reply_users":["UJ7DVTVQ8","U01C3624SGJ"],"subscribed":false},{"client_msg_id":"dfef5759-0244-48af-9042-3dbfd58a8e2a","type":"message","text":"Hi <@U8MPCDJAY> how would you characterize the difference between ObjectDetector.jl and YOLO.jl ?","user":"U679VPJ8L","ts":"1614092145.018800","team":"T68168MUP","edited":{"user":"U679VPJ8L","ts":"1614092167.000000"},"blocks":[{"type":"rich_text","block_id":"BxiY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi "},{"type":"user","user_id":"U8MPCDJAY"},{"type":"text","text":" how would you characterize the difference between ObjectDetector.jl and YOLO.jl ?"}]}]}],"thread_ts":"1614092145.018800","reply_count":5,"reply_users_count":1,"latest_reply":"1614092553.023100","reply_users":["U8MPCDJAY"],"subscribed":false},{"client_msg_id":"cc266ff9-240c-4547-b696-0a0973936a96","type":"message","text":"<https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/>","user":"U67BJLYCS","ts":"1614221247.027400","team":"T68168MUP","attachments":[{"service_name":"Bart Wronski","service_url":"http://bartwronski.com","title":"Bilinear down/upsampling, aligning pixel grids, and that infamous GPU half pixel offset","title_link":"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/","author_name":"bartwronski","author_link":"https://bartwronski.com/author/bartwronski/","thumb_url":"https://bartwronski.files.wordpress.com/2021/02/box_then_even_odd-6.gif?fit=200%2C150","thumb_width":150,"thumb_height":150,"text":"See this ugly pixel shift when upsampling a downsampled image? My post describes where it can come from and how to avoid those! \n\n\n\nIt&rsquo;s been more than two decades of me using bilinear texture filtering, a few months since I&rsquo;ve written about bilinear resampling, but only two days since I discovered a bug of mine related to it. &#128517; Similarly, just last week a colleague asked for a very fast implementation of bilinear on a CPU and it caused a series of questions &ldquo;which kind of bilinear?&rdquo;.\n\n\n\nSo I figured it&rsquo;s an opportunity for another short blog post &ndash; on bilinear filtering, but in context of down/upsampling. We will touch here on GPU half pixel offsets, aligning pixel grids, a bug / confusion in Tensorflow, deeper signal processing analysis of what&rsquo;s going on during bilinear operations, and analysis of the magic of the famous &ldquo;magic kernel&rdquo;.\n\n\n\nI highly recommend my previous post as a primer on the topic, as I&rsquo;ll use some of the tools and terminology from there, but it&rsquo;s not strictly required. Let&rsquo;s go!\n\n\n\nBilinear confusion\n\n\n\nThe term bilinear upsampling and downsampling is used a lot, but what does it mean?&nbsp;\n\n\n\nOne of the few ideas I&rsquo;d like to convey in this post is that bilinear upsampling / downsampling doesn&rsquo;t have a single meaning or a consensus around this term use. Which is kind of surprising for a bread and butter type of image processing operation that is used all the time!\n\n\n\nIt&rsquo;s also surprisingly hard to get it right even by image processing professionals, and a source of long standing bugs and confusion in top libraries (and I know of some actual production bugs caused by this Tensorflow inconsistency)!\n\n\n\nEdit: there&rsquo;s a blog post titled &ldquo;How Tensorflow&rsquo;s tf.image.resize stole 60 days of my life&rdquo; and it&rsquo;s describing same issue. I know of some of my colleagues that spent months on fixing it in Tensorflow 2 &ndash; imagine effort of fixing incorrect uses and &ldquo;fixing&rdquo; already trained models that were trained around this bug&hellip; \n\n\n\nImage credit/source: Oleksandr Savsunenko\n\n\n\nSome parts of it like phase shifting are so tricky that a famous blog post of &ldquo;magic kernel&rdquo; comes up every few years and again, experts re(read) it a few times to figure out what&rsquo;s going on there, while the author simply rediscovered the bilinear! (Important note: I don&rsquo;t want to pick on the author, far from it, as he is a super smart and knowledgeable person, and willingness to share insights is always respect worthy. &ldquo;Magic kernel&rdquo; is just an example of why it&rsquo;s so hard and confusing to talk about &ldquo;bilinear&rdquo;. I also respect how he amended and improved the post multiple times. But there is no &ldquo;magic kernel&rdquo;.)\n\n\n\nSo let&rsquo;s have a look at what&rsquo;s the problem. I will focus here exclusively on 2x up/downsampling and hope that some thought framework I propose and use here will be beneficial for you to also look at and analyze different (and non-integer factors).\n\n\n\nBecause of bilinear separability, I will again abuse the notation and call &ldquo;bilinear&rdquo; a filter when applied to 1D signals and generally a lot of my analysis will be in 1D.\n\n\n\nBilinear downsampling and upsampling\n\n\n\nWhat do we mean by bilinear upsampling?\n\n\n\nLet&rsquo;s start with the most simple explanation, without the nitty gritty: it is creating a larger resolution image where every sample is created from bilinear filtering of a smaller resolution image.\n\n\n\nFor the bilinear downsampling, things get a bit muddy. It is using a bilinear filter to prevent signal aliasing when decimating the input image &ndash; ugh, lots of technical terms. I will circle back to it, but first address the first common confusion.\n\n\n\nIs this box or bilinear downsampling? Two ways of addressing it\n\n\n\nWhen downsampling images by 2, we every often use terms box filter and bilinear filter interchangeably. And both can be correct. How so?\n\n\n\nLet&rsquo;s have a look at the following diagram:&nbsp;\n\n\n\n(Bi)linear vs box downsampling give us the same effective weights. Black dots represent pixel centers, upper row is the target/low resolution texture, and the bottom row the source, higher resolution one. Blue lines represents discretized weights of the kernel. \n\n\n\nWe can see that a 2 tap box filter is the same as a 2 tap bilinear filter. The reason for it is that in this case, both filters are centered between the pixels. After discretizing them (evaluating filter weights at sample points), there is no difference, as we no longer know what was the formula to generate them, and how the filter kernel looked outside of the evaluation points.\n\n\n\nThe most typical way of doing bilinear downsampling is the same as box downsampling. Using those two names for 2x downsampling interchangeably is both correct! (Side note: Things diverge when taking about more than 2x downsampling. This might be a good topic for another blog post.) For 1D signals it means averaging every two elements together, for 2D images averaging 4 elements to produce a single one.\n\n\n\nYou might have noticed something that I implicitly assumed there &ndash; pixel centers there were shifted by half a pixel, and the edges/corners were aligned.\n\n\n\nThere is &ldquo;another way&rdquo; of doing bilinear downsampling, like this:\n\n\n\nA second take on bilinear downsampling &ndash; this time with pixel centers (black dots) aligned. Again the source image / signal is on the bottom, target signal on the top.\n\n\n\nThis one definitely and clearly is also a linear tent, and it doesn&rsquo;t shift pixel centers. The resulting filter weights of [0.25 0.5 0.25] are also called a [1 2 1] filter, or the simplest case of a binomial filter, a very reasonable approximation to a Gaussian filter. (To understand why, see what happens to the binomial distribution as the trial count goes to infinity!). It&rsquo;s probably the filter I use the most in my work, but I digress. &#128578;\n\n\n\nWhy this second method is not used that much? This is by design and a reason for half texel shifts in GPU coordinates / samplers, and you might have noticed the problem &ndash; the last texel of high resolution array gets discarded. But let&rsquo;s not get ahead of ourselves, first we can have a look at the relationship with upsampling.\n\n\n\nTwo ways of bilinear upsampling &ndash; which one is &ldquo;proper&rdquo;?\n\n\n\nIf you were to design a bilinear upsampling algorithm, there are a few ways to address it.\n\n\n\nLet me start with a &ldquo;naive&rdquo; one that can have problems. We can take every original pixel, and between them just place averages of the other ones.\n\n\n\nNaive bilinear upsampling when pixel centers are aligned. Some pixels receive a copy of the source (green line), the other ones (alternating) a blend between two neighbors.\n\n\n\nIs it bilinear / tent? Yes, it&rsquo;s a tent filter on zero-inserted image (more on it later). It has an unusual property; some pixels get blurred, some pixels stay &ldquo;sharp&rdquo; (original copied).\n\n\n\nBut more importantly, if you do box/bilinear downsampling as described above, and then upsample an image, it will be shifted:\n\n\n\nUsing box downsampling, and then copy / interpolate upsampling shifts the image by half a pixel. This is a wrong way to do it! \n\n\n\nOr rather &ndash; it will not correct for the half pixel shift created by downsampling.\n\n\n\nIt will work however with downsampling using the second method. The second method interpolates every single output pixel; all are interpolated:\n\n\n\nWhen done properly, bilinear down/upsample doesn&rsquo;t shift the image.\n\n\n\nThis another way of doing bilinear upsampling that might first feel initially unintuitive: every pixel is 0.75 of one pixel, and 0.25 of another one, alternating &ldquo;to the left&rdquo; and &ldquo;to the right&rdquo;. This is exactly what a GPU does when you upsample a texture by 2x:\n\n\n\n\n\n\n\nThe…","fallback":"Bart Wronski Link: Bilinear down/upsampling, aligning pixel grids, and that infamous GPU half pixel&nbsp;offset","from_url":"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/","service_icon":"https://s2.wp.com/i/webclip.png","id":1,"original_url":"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/"}],"blocks":[{"type":"rich_text","block_id":"V2pej","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/"}]}]}]},{"client_msg_id":"acb186dc-1365-4c17-834a-8ca2fe6e8c09","type":"message","text":"Hi, I'm trying to use Neural ODE with DiFEqFlux. My equation is :\n```function true_ode(du,u,p,t)\n    true_A, true_B = p\n    if t &lt; tc\n        du[1] =true_A*0.041 - true_B*u[1]\n    else\n         du[1] = - true_B*u[1]\n    end\nend```\nAnd I want to put her in the neural network :\n```dudt = FastChain((u,p) -&gt; true_ode(u),\n        FastDense(1, 50, tanh),\n        FastDense(50, 1))```\nDo you think it's possible in spite the \"if\" temporal condition ?","user":"U01NRTNRCDV","ts":"1614269275.030400","team":"T68168MUP","edited":{"user":"U01NRTNRCDV","ts":"1614269321.000000"},"blocks":[{"type":"rich_text","block_id":"Nopxw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I'm trying to use Neural ODE with DiFEqFlux. My equation is :\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function true_ode(du,u,p,t)\n    true_A, true_B = p\n    if t < tc\n        du[1] =true_A*0.041 - true_B*u[1]\n    else\n         du[1] = - true_B*u[1]\n    end\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"And I want to put her in the neural network :\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"dudt = FastChain((u,p) -> true_ode(u),\n        FastDense(1, 50, tanh),\n        FastDense(50, 1))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Do you think it's possible in spite the \"if\" temporal condition ?"}]}]}]},{"client_msg_id":"fc11b06e-2844-42d5-9f5e-afd835e3cf06","type":"message","text":"Anyone here tackled outlier detection on images in Julia? Any learnings to share? Models used, results, does and don'ts? Thanks!","user":"USFR23ZHQ","ts":"1614282157.032600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HEKB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone here tackled outlier detection on images in Julia? Any learnings to share? Models used, results, does and don'ts? Thanks!"}]}]}]},{"client_msg_id":"d806afc7-fe0d-493f-9d1c-cba298ef8d24","type":"message","text":"Is it possible to set part of a large matrix to not be trainable? It seems the Flux.Zeros method relies on setting an entire parameter to non-trainable.","user":"U01L0KU0SDV","ts":"1614311246.033900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gUa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it possible to set part of a large matrix to not be trainable? It seems the Flux.Zeros method relies on setting an entire parameter to non-trainable."}]}]}]},{"client_msg_id":"68b17398-12de-428e-ae3a-438ea035a471","type":"message","text":"Reason being, I'm creating a new type of convolution, where it is hollow in the middle, essentially a \"perimeter convolution.\" And I'd like to piggyback on the existing convolutional layers, and simply just zero out the innards, and also make them not part of the Flux.params or Flux.trainable properties.","user":"U01L0KU0SDV","ts":"1614311323.035400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xLh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Reason being, I'm creating a new type of convolution, where it is hollow in the middle, essentially a \"perimeter convolution.\" And I'd like to piggyback on the existing convolutional layers, and simply just zero out the innards, and also make them not part of the Flux.params or Flux.trainable properties."}]}]}]},{"client_msg_id":"31c7f33a-0e86-4586-a620-a4d104335b53","type":"message","text":"This doesn't seem to be answered: <https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197> :disappointed:","user":"U01L0KU0SDV","ts":"1614311537.035600","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"How to enforce weight matrix to be of a certain form (train a subset) in Flux?","title_link":"https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197","text":"For example, I want a layer specified by a symmetric or a tridiagonal matrix. Obviously, train! does not know about it, and an error is raised: ArgumentError: cannot set entry (3, 1) off the tridiagonal band to a nonzero value (0.03524077074068107). How to tell Flux to train only a certain subset of parameters (diagonals/upper half, etc)?","fallback":"JuliaLang: How to enforce weight matrix to be of a certain form (train a subset) in Flux?","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1578667877,"from_url":"https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197"}],"blocks":[{"type":"rich_text","block_id":"2ZMr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This doesn't seem to be answered: "},{"type":"link","url":"https://discourse.julialang.org/t/how-to-enforce-weight-matrix-to-be-of-a-certain-form-train-a-subset-in-flux/33197"},{"type":"text","text":" "},{"type":"emoji","name":"disappointed"}]}]}]},{"client_msg_id":"660155a6-aaa3-4225-876d-184fd66b90d1","type":"message","text":"Was thinking maybe I could use this? <https://github.com/ahwillia/CatViews.jl>","user":"U01L0KU0SDV","ts":"1614312440.035900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FL4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Was thinking maybe I could use this? "},{"type":"link","url":"https://github.com/ahwillia/CatViews.jl"}]}]}]},{"client_msg_id":"a915bce4-c46c-4414-98c0-435ad9de4ea0","type":"message","text":"<@U6A936746> I am considering DataDeps.jl for managing pre-trained model weights. They are hosted in a separate repo from the package w/ git lfs. Came across this line “DataDeps.jl does not provide for versioning of data – you can’t force users to download new copies of your data using DataDeps.”","user":"UH9KWTTD3","ts":"1614360740.042000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n36/w","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U6A936746"},{"type":"text","text":" I am considering DataDeps.jl for managing pre-trained model weights. They are hosted in a separate repo from the package w/ git lfs. Came across this line “DataDeps.jl does not provide for versioning of data – you can’t force users to download new copies of your data using DataDeps.”"}]}]}]},{"client_msg_id":"cbd87050-9576-43cf-86e6-3ea4342a8c6c","type":"message","text":"Sounds to me like Pkg artifacts will be a better choice for what I need. Just wanted to double check there wasn’t something I’m missing since DataDeps.jl was suggested to me.","user":"UH9KWTTD3","ts":"1614360781.042900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5r8G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sounds to me like Pkg artifacts will be a better choice for what I need. Just wanted to double check there wasn’t something I’m missing since DataDeps.jl was suggested to me."}]}]}]},{"client_msg_id":"79838b35-f1c9-4b7b-b2c8-ee2b9e6c3406","type":"message","text":"I think data artifacts are a much better long term idea, since we can version and distribute them fairly cheaply and reliably","user":"UC4QQPG4A","ts":"1614363227.044300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V0+jS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think data artifacts are a much better long term idea, since we can version and distribute them fairly cheaply and reliably"}]}]}],"thread_ts":"1614363227.044300","reply_count":3,"reply_users_count":2,"latest_reply":"1614363555.044800","reply_users":["UH9KWTTD3","UC4QQPG4A"],"subscribed":false},{"client_msg_id":"a36e0c4c-4928-49ab-8a57-5a15f7e64567","type":"message","text":"is there a natural gradient implemented in Julia somewhere?","user":"UC6SUUPRC","ts":"1614368026.045300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gny14","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a natural gradient implemented in Julia somewhere?"}]}]}],"thread_ts":"1614368026.045300","reply_count":1,"reply_users_count":1,"latest_reply":"1614368514.046500","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"04b27987-d790-406b-b470-640d1591fd59","type":"message","text":"I find there are fisher info matrix defined in StatsBase, but it seems not for gradients","user":"UC6SUUPRC","ts":"1614368040.045700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gXt2a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I find there are fisher info matrix defined in StatsBase, but it seems not for gradients"}]}]}]},{"client_msg_id":"95393e2b-209b-4f74-9151-bcb7e842ae9f","type":"message","text":"New papers from the s4tf project: <https://twitter.com/bsaeta/status/1366271405285801984?s=19|https://twitter.com/bsaeta/status/1366271405285801984?s=19> interesting take on  optimizer and model interface","user":"UDGT4PM41","ts":"1614607367.053000","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1614607464.000000"},"attachments":[{"fallback":"<https://twitter.com/bsaeta|@bsaeta>: As promised ~2 weeks ago, some academic papers about #S4TF are now available! First up is “the overview paper\" (<https://arxiv.org/abs/2102.13243>); highlights include: (1) a discussion on how mutable value semantics is incredibly powerful (especially for autodiff &amp; hw acclrs), and …","ts":1614579461,"author_name":"Brennan Saeta","author_link":"https://twitter.com/bsaeta/status/1366271405285801984","author_icon":"https://pbs.twimg.com/profile_images/314609740/DJKarat_normal.png","author_subname":"@bsaeta","text":"As promised ~2 weeks ago, some academic papers about #S4TF are now available! First up is “the overview paper\" (<https://arxiv.org/abs/2102.13243>); highlights include: (1) a discussion on how mutable value semantics is incredibly powerful (especially for autodiff &amp; hw acclrs), and …","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/bsaeta/status/1366271405285801984?s=19","id":1,"original_url":"https://twitter.com/bsaeta/status/1366271405285801984?s=19","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"ZYlQX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"New papers from the s4tf project: "},{"type":"link","url":"https://twitter.com/bsaeta/status/1366271405285801984?s=19","text":"https://twitter.com/bsaeta/status/1366271405285801984?s=19"},{"type":"text","text":" interesting take on  optimizer and model interface"}]}]}]},{"client_msg_id":"de7c3ec8-fee1-4fea-ae8b-a49908d30b66","type":"message","text":"<https://twitter.com/bsaeta/status/1366271591852642306?s=19|https://twitter.com/bsaeta/status/1366271591852642306?s=19>","user":"UDGT4PM41","ts":"1614607496.055200","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/bsaeta|@bsaeta>: … And finally, we have <https://twitter.com/apaszke|@apaszke> ‘s intern paper on static shape analysis for ML programs called “Tensors Fitting Perfectly”: <https://arxiv.org/abs/2102.13254> . While I’m sad #S4TF is now in archive mode, the team did awesome work, and I’m glad we’ve been able to share some lessons …","ts":1614579506,"author_name":"Brennan Saeta","author_link":"https://twitter.com/bsaeta/status/1366271591852642306","author_icon":"https://pbs.twimg.com/profile_images/314609740/DJKarat_normal.png","author_subname":"@bsaeta","text":"… And finally, we have <https://twitter.com/apaszke|@apaszke> ‘s intern paper on static shape analysis for ML programs called “Tensors Fitting Perfectly”: <https://arxiv.org/abs/2102.13254> . While I’m sad #S4TF is now in archive mode, the team did awesome work, and I’m glad we’ve been able to share some lessons …","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/bsaeta/status/1366271591852642306?s=19","id":1,"original_url":"https://twitter.com/bsaeta/status/1366271591852642306?s=19","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"uzKkZ","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/bsaeta/status/1366271591852642306?s=19","text":"https://twitter.com/bsaeta/status/1366271591852642306?s=19"}]}]}]},{"client_msg_id":"d8cd6129-63d2-4ce1-875d-ee4b550069a0","type":"message","text":"<@U674T3KB3>  and <@U01K2JB9GPJ>  might be interested in that one","user":"UDGT4PM41","ts":"1614607520.055900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hmL","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U674T3KB3"},{"type":"text","text":"  and "},{"type":"user","user_id":"U01K2JB9GPJ"},{"type":"text","text":"  might be interested in that one"}]}]}]},{"type":"message","subtype":"channel_join","ts":"1614607525.056100","user":"U01K2JB9GPJ","text":"<@U01K2JB9GPJ> has joined the channel","inviter":"UDGT4PM41"},{"client_msg_id":"6ea5044a-c86e-4eed-857a-0baa38326b2d","type":"message","text":"<https://julialang.slack.com/archives/C680MM7D4/p1614965145034100>","user":"UDGT4PM41","ts":"1614965313.000400","team":"T68168MUP","attachments":[{"from_url":"https://julialang.slack.com/archives/C680MM7D4/p1614965145034100","fallback":"[March 5th, 2021 9:25 AM] arikatzpro: PyTorch is getting JAX like code transforms: <https://twitter.com/cHHillee/status/1367621541693857794>","ts":"1614965145.034100","author_id":"UDGT4PM41","author_subname":"Ari Katz","channel_id":"C680MM7D4","channel_name":"random","is_msg_unfurl":true,"text":"PyTorch is getting JAX like code transforms: <https://twitter.com/cHHillee/status/1367621541693857794>","author_name":"Ari Katz","author_link":"https://julialang.slack.com/team/UDGT4PM41","author_icon":"https://secure.gravatar.com/avatar/a9e84ba6e7b9db667ae3371c11a07dfe.jpg?s=48&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-48.png","mrkdwn_in":["text"],"id":1,"original_url":"https://julialang.slack.com/archives/C680MM7D4/p1614965145034100","footer":"Posted in #random"}],"blocks":[{"type":"rich_text","block_id":"943SV","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://julialang.slack.com/archives/C680MM7D4/p1614965145034100"}]}]}]},{"client_msg_id":"b6ee217c-69ec-436f-ba77-a5bc8a6ecf30","type":"message","text":"Hi. How can we get a loop output like Tensorflow when training a model in Flux?\nIt would print how many epochs are left and how many seconds are left for each epoch.","user":"U01PP5BA1C4","ts":"1615050487.001900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vUD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi. How can we get a loop output like Tensorflow when training a model in Flux?\nIt would print how many epochs are left and how many seconds are left for each epoch."}]}]}],"reactions":[{"name":"eyes","users":["U01CQTKB86N"],"count":1}]},{"client_msg_id":"f292845c-8ed0-417e-bd9d-cc949d87dc52","type":"message","text":"Hi everyone,\nI have a question for my neural ODE which is :\n```\nfunction dudt2(u,p,t)\n  FastChain(\n        (u,p) -&gt; ifelse(t &lt;= tc, c_int , 0) .- u,\n            FastDense(1, 2, tanh),\n        FastDense(2, 1))\nend\n\n\nfunction neural_ode_f(u,p,t)\n  FastChain((u,p) -&gt; ifelse(t &lt;= tc,c_int , 0) .- u,\n        FastDense(1, 2, tanh),\n        FastDense(2, 1))(u,p)\nend\n\npinit = initial_params(dudt2(u0,p_start,tbegin))\nprob = ODEProblem(neural_ode_f, u0, tspan, pinit)```\n\nDo you think that it understand the parameters p to learn ? Like this ODE \n```\nfunction odeTK(du, u, p,t)\n    if t &lt;= tc\n        du[1] = p[1]*c_int - p[2]u[1]\n    else t &gt; tc\n        du[1] = -p[2]*(u[1])\n    end\nend```\nAnd I’m not sure that it understand the if condition, because the result as the same when I only use\n\n```\nfunction dudt2(u,p,t)\n  FastChain(\n        (u,p) -&gt; c_int .- u,\n            FastDense(1, 2, tanh),\n        FastDense(2, 1))\nend\n\n\nfunction neural_ode_f(u,p,t)\n  FastChain((u,p) -&gt; c_int .- u,\n        FastDense(1, 2, tanh),\n        FastDense(2, 1))(u,p)\nend\n\npinit = initial_params(dudt2(u0,p_start,tbegin))\nprob = ODEProblem(neural_ode_f, u0, tspan, pinit)```\nThank you for your help :smile:","user":"U01NRTNRCDV","ts":"1615201820.003600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KI2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi everyone,\nI have a question for my neural ODE which is :\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"\nfunction dudt2(u,p,t)\n  FastChain(\n        (u,p) -> ifelse(t <= tc, c_int , 0) .- u,\n            FastDense(1, 2, tanh),\n        FastDense(2, 1))\nend\n\n\nfunction neural_ode_f(u,p,t)\n  FastChain((u,p) -> ifelse(t <= tc,c_int , 0) .- u,\n        FastDense(1, 2, tanh),\n        FastDense(2, 1))(u,p)\nend\n\npinit = initial_params(dudt2(u0,p_start,tbegin))\nprob = ODEProblem(neural_ode_f, u0, tspan, pinit)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n\nDo you think that it understand the parameters p to learn ? Like this ODE \n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"\nfunction odeTK(du, u, p,t)\n    if t <= tc\n        du[1] = p[1]*c_int - p[2]u[1]\n    else t > tc\n        du[1] = -p[2]*(u[1])\n    end\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nAnd I’m not sure that it understand the if condition, because the result as the same when I only use\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"\nfunction dudt2(u,p,t)\n  FastChain(\n        (u,p) -> c_int .- u,\n            FastDense(1, 2, tanh),\n        FastDense(2, 1))\nend\n\n\nfunction neural_ode_f(u,p,t)\n  FastChain((u,p) -> c_int .- u,\n        FastDense(1, 2, tanh),\n        FastDense(2, 1))(u,p)\nend\n\npinit = initial_params(dudt2(u0,p_start,tbegin))\nprob = ODEProblem(neural_ode_f, u0, tspan, pinit)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you for your help "},{"type":"emoji","name":"smile"}]}]}]},{"client_msg_id":"9b46e8ac-034c-42ca-bf7e-3e1f8c169e13","type":"message","text":"Has anyone used Catboost on julia?","user":"U01C3624SGJ","ts":"1615208154.004200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Euo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Has anyone used Catboost on julia?"}]}]}]},{"client_msg_id":"87105fab-cf26-4386-b596-bd0385e866b0","type":"message","text":"Hi all. Conceptual question; In <#C690QRAA3|machine-learning>, whenever we refer to learning rate (η) we consider this to be the step-size of the sum of changes that we apply to the current weight-change. However, we are never consistent with math. Not even Hinton himself was: <https://www.nature.com/articles/323533a0.pdf> he included the term ϵ  (=η) out-of-nowhere realizing that the gradient descent should be a slow change of an amount proportional to the accumulated: η*dE/dw. In reality, what I think its happening, is that η = dw = step-size of the update in the numerical simulation. In physical units, we need to consider that if the weights had units, we can't just do Δw = -η*dE/dw and hope it makes physical sense (most of our models can spare of this but lack mathematical consistency)... in fact, if you look at the way Hinton establishes his cost function (total error), the actual units of the cost function are the same as the weights. Therefore, to be consistent with math, should he just say that \"for numerical simulations, we tune the derivative step to achieve convergence such that Δw = -η*dE. What are your thoughts?","user":"ULKN4RKAR","ts":"1615361914.020100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kFJC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all. Conceptual question; In "},{"type":"channel","channel_id":"C690QRAA3"},{"type":"text","text":", whenever we refer to learning rate (η) we consider this to be the step-size of the sum of changes that we apply to the current weight-change. However, we are never consistent with math. Not even Hinton himself was: "},{"type":"link","url":"https://www.nature.com/articles/323533a0.pdf"},{"type":"text","text":" he included the term ϵ  (=η) out-of-nowhere realizing that the gradient descent should be a slow change of an amount proportional to the accumulated: η*dE/dw. In reality, what I think its happening, is that η = dw = step-size of the update in the numerical simulation. In physical units, we need to consider that if the weights had units, we can't just do Δw = -η*dE/dw and hope it makes physical sense (most of our models can spare of this but lack mathematical consistency)... in fact, if you look at the way Hinton establishes his cost function (total error), the actual units of the cost function are the same as the weights. Therefore, to be consistent with math, should he just say that \"for numerical simulations, we tune the derivative step to achieve convergence such that Δw = -η*dE. What are your thoughts?"}]}]}],"thread_ts":"1615361914.020100","reply_count":1,"reply_users_count":1,"latest_reply":"1615362532.020200","reply_users":["ULKN4RKAR"],"subscribed":false},{"client_msg_id":"87708FE8-6D70-42DC-B232-79A8F7C620ED","type":"message","text":"Is there a plot recipe for Flux.Chain? I started to write one, that already works for Dense and RNN layers (the easy ones), but I would like to know whether there's one already or not.","user":"U01CR62LAAD","ts":"1615469643.027000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zA5P","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a plot recipe for Flux.Chain? I started to write one, that already works for Dense and RNN layers (the easy ones), but I would like to know whether there's one already or not."}]}]}],"thread_ts":"1615469643.027000","reply_count":1,"reply_users_count":1,"latest_reply":"1615471513.027300","reply_users":["UH9KWTTD3"],"subscribed":false},{"client_msg_id":"72e7a6c2-71b6-4653-af52-09ca79c0501f","type":"message","text":"<https://venturebeat.com/2021/03/11/hugging-face-triples-investment-in-open-source-machine-learning-models/|https://venturebeat.com/2021/03/11/hugging-face-triples-investment-in-open-source-machine-learning-models/>","user":"UDGT4PM41","ts":"1615498886.028900","team":"T68168MUP","attachments":[{"service_name":"VentureBeat","title":"Hugging Face triples investment in open source machine learning models","title_link":"https://venturebeat.com/2021/03/11/hugging-face-triples-investment-in-open-source-machine-learning-models/","text":"Hugging Face is going to triple efforts to build an open source community for AI with the close of a $40 million series B round today.","fallback":"VentureBeat: Hugging Face triples investment in open source machine learning models","image_url":"https://venturebeat.com/wp-content/uploads/2019/12/hugging-face.png?w=1200&strip=all","image_width":500,"image_height":250,"ts":1615474846,"from_url":"https://venturebeat.com/2021/03/11/hugging-face-triples-investment-in-open-source-machine-learning-models/","image_bytes":48675,"service_icon":"https://venturebeat.com/wp-content/themes/vb-news/img/favicon.ico","id":1,"original_url":"https://venturebeat.com/2021/03/11/hugging-face-triples-investment-in-open-source-machine-learning-models/"}],"blocks":[{"type":"rich_text","block_id":"SrP","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://venturebeat.com/2021/03/11/hugging-face-triples-investment-in-open-source-machine-learning-models/","text":"https://venturebeat.com/2021/03/11/hugging-face-triples-investment-in-open-source-machine-learning-models/"}]}]}]},{"client_msg_id":"5f043de7-407f-4c59-a740-5444e37872b9","type":"message","text":"<https://arxiv.org/pdf/2011.01383.pdf>","user":"UDGT4PM41","ts":"1615502747.029200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"j6z","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://arxiv.org/pdf/2011.01383.pdf"}]}]}]},{"client_msg_id":"d0ea42ed-ac72-404e-9de8-87bb0422b744","type":"message","text":"\"CORTEX: A COMPILER FOR RECURSIVE DEEP LEARNING MODELS\"","user":"UDGT4PM41","ts":"1615502760.029400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fqW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"\"CORTEX: A COMPILER FOR RECURSIVE DEEP LEARNING MODELS\""}]}]}]},{"client_msg_id":"4345f3c9-e113-413c-acdc-75eade133e05","type":"message","text":"From this group at CMU: <https://catalyst.cs.cmu.edu/>","user":"UDGT4PM41","ts":"1615502768.029700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wEp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"From this group at CMU: "},{"type":"link","url":"https://catalyst.cs.cmu.edu/"}]}]}]},{"client_msg_id":"62ad00f2-896f-4d3a-b033-46620cefd9ae","type":"message","text":"<https://catalyst.cs.cmu.edu/projects/taso.html>","user":"UDGT4PM41","ts":"1615502798.029900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FhB","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://catalyst.cs.cmu.edu/projects/taso.html"}]}]}]},{"client_msg_id":"17548b25-51fc-4286-b833-58628c90a3c2","type":"message","text":"\"The Tensor Algebra SuperOptimizer for Deep Learning\"","user":"UDGT4PM41","ts":"1615502816.030100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0Y/XA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"\"The Tensor Algebra SuperOptimizer for Deep Learning\""}]}]}]},{"client_msg_id":"2FCCB376-F590-4298-98E3-7F39462A4291","type":"message","text":"Hi, all. As I build the plot recipe for Chain, I have two questions, if I may. \n\n1) Given a layer of the Chain, is there a method, independent of the type of layer, that sets all the parameters of that layer to random numbers? I would like to see each neurons on the next layer are affected by each layer in current layer. I will do by applying the layer to the basis in the input space (for a pool of random parameters) and see which neurons on the next layer are different from zero, so I need to avoid getting zeros by chance. \n\n2) if I have a function `f(x, a)` and I want to use `x-&gt; f(x, a)` in a certain layer and set `a` as a train able parameter, is that possible? How?","user":"U01CR62LAAD","ts":"1615676180.045500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4oHV4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, all. As I build the plot recipe for Chain, I have two questions, if I may. \n\n"},{"type":"text","text":"1) Given a layer of the Chain, is there a method, independent of the type of layer, that sets all the parameters of that layer to random numbers? I would like to see each neurons on the next layer are affected by each layer in current layer. I will do by applying the layer to the basis in the input space (for a pool of random parameters) and see which neurons on the next layer are different from zero, so I need to avoid getting zeros by chance. \n\n2) if I have a function "},{"type":"text","text":"f(x, a)","style":{"code":true}},{"type":"text","text":" and I want to use "},{"type":"text","text":"x-> f(x, a)","style":{"code":true}},{"type":"text","text":" in a certain layer and set "},{"type":"text","text":"a","style":{"code":true}},{"type":"text","text":" as a train able parameter, is that possible? How?"}]}]}],"thread_ts":"1615676180.045500","reply_count":3,"reply_users_count":1,"latest_reply":"1615677437.046000","reply_users":["UH9KWTTD3"],"subscribed":false},{"client_msg_id":"91050585-de90-4739-a099-5d4f72dc3710","type":"message","text":"Interesting opportunity for someone itching for a project\n<https://techcrunch.com/2021/01/25/facebooks-ad-library-targeting-political-ad-election-data/>","user":"UPUBAM63X","ts":"1615847202.053200","team":"T68168MUP","edited":{"user":"UPUBAM63X","ts":"1615847210.000000"},"blocks":[{"type":"rich_text","block_id":"JyS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Interesting opportunity for someone itching for a project\n"},{"type":"link","url":"https://techcrunch.com/2021/01/25/facebooks-ad-library-targeting-political-ad-election-data/"}]}]}]},{"client_msg_id":"fc5808f5-f1bd-4ac4-b5f7-c37d5fdf0c43","type":"message","text":"FastAI.jl and ML community meeting happening now","user":"UDGT4PM41","ts":"1615911187.000600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MW2y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"FastAI.jl and ML community meeting happening now"}]}]}]},{"client_msg_id":"222cfff8-8baf-41c7-b324-645ac3016de3","type":"message","text":"<https://uwmadison.zoom.us/j/97409965147>","user":"UDGT4PM41","ts":"1615911216.000800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m6KD","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://uwmadison.zoom.us/j/97409965147"}]}]}]},{"client_msg_id":"0d806891-8e69-4eb8-a418-8231b2ec106b","type":"message","text":"hello! (new to flux). for flux when trying to pass different parts of an input to different cells, does it need to be wrapped as a single chained model? (as opposed to being encoded during loss calculation) i currently get a dimension mismatch error (`ERROR: LoadError: DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 12 and 16\")`) when trying to combine gru with dense layers. i have 2 grus (processing part of the input) + an unprocessed input being fed into a dense layer. loss calculation works fine, so i'm a little confused as to where this mismatch is coming from. i've tried to put something close to a minimum working example in the reply thread below.","user":"UPKKW4H7B","ts":"1615929368.006800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"A45s","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hello! (new to flux). for flux when trying to pass different parts of an input to different cells, does it need to be wrapped as a single chained model? (as opposed to being encoded during loss calculation) i currently get a dimension mismatch error ("},{"type":"text","text":"ERROR: LoadError: DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 12 and 16\")","style":{"code":true}},{"type":"text","text":") when trying to combine gru with dense layers. i have 2 grus (processing part of the input) + an unprocessed input being fed into a dense layer. loss calculation works fine, so i'm a little confused as to where this mismatch is coming from. i've tried to put something close to a minimum working example in the reply thread below."}]}]}],"thread_ts":"1615929368.006800","reply_count":1,"reply_users_count":1,"latest_reply":"1615929381.006900","reply_users":["UPKKW4H7B"],"subscribed":false},{"client_msg_id":"c9294168-6f60-4208-8638-ddc7deec0f89","type":"message","text":"Hi guysm I am building a classifier and saving it as pickle file to put in the production environment. I am wondering what is the best practice to record the features set selected by feature selection during model building?\n\nAn alternative that I can think about is maintaining a text file containing a feature set, e.g.\n\n_selected_features.txt_\n```feature1\nfeature3\nfeature9```\nAnd then, the script (that runs the classifier), read that file and slice incoming data only on those features.\n\nIs there any better alternatives rather than maintaining the text file? I can see the issue arises due to manual update of text file when updating the classifier, since the updated version could probably use different set of features.","user":"UUT4VGTE2","ts":"1615944855.000300","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1615944897.000000"},"blocks":[{"type":"rich_text","block_id":"tP0G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guysm I am building a classifier and saving it as pickle file to put in the production environment. I am wondering what is the best practice to record the features set selected by feature selection during model building?\n\nAn alternative that I can think about is maintaining a text file containing a feature set, e.g.\n\n"},{"type":"text","text":"selected_features.txt","style":{"italic":true}},{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"feature1\nfeature3\nfeature9"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nAnd then, the script (that runs the classifier), read that file and slice incoming data only on those features.\n\nIs there any better alternatives rather than maintaining the text file? I can see the issue arises due to manual update of text file when updating the classifier, since the updated version could probably use different set of features."}]}]}]},{"client_msg_id":"2075c8f1-8e5a-4300-b08b-c04f7d7d8451","type":"message","text":"<https://newatlas.com/computers/computer-tool-deepfakes-94-percent-accuracy/>","user":"UH24GRBLL","ts":"1615977418.001100","team":"T68168MUP","attachments":[{"service_name":"New Atlas","title":"Computer tool spots deepfakes via tiny reflections in the eyes","title_link":"https://newatlas.com/computers/computer-tool-deepfakes-94-percent-accuracy/","text":"Driven by advances in artificial intelligence, doctored video content known as deepfakes present a serious and growing danger when it comes to the spread of misinformation. As these altered clips become more and more convincing, there is a pressing need for tools that can help distinguish them from…","fallback":"New Atlas: Computer tool spots deepfakes via tiny reflections in the eyes","image_url":"https://assets.newatlas.com/dims4/default/85c58f0/2147483647/strip/true/crop/894x469+0+129/resize/1200x630!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F3c%2F44%2Fd06fd4e7471484af83763327f4a6%2F1615389259159.jpg","image_width":476,"image_height":250,"ts":1615899117,"from_url":"https://newatlas.com/computers/computer-tool-deepfakes-94-percent-accuracy/","image_bytes":69531,"service_icon":"https://newatlas.com/apple-touch-icon.png","id":1,"original_url":"https://newatlas.com/computers/computer-tool-deepfakes-94-percent-accuracy/"}],"blocks":[{"type":"rich_text","block_id":"41Au","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://newatlas.com/computers/computer-tool-deepfakes-94-percent-accuracy/"}]}]}],"thread_ts":"1615977418.001100","reply_count":10,"reply_users_count":5,"latest_reply":"1615979847.003600","reply_users":["UGD4K0Z25","UH24GRBLL","UBVE598BC","U67D54KS8","U6N6VQE30"],"subscribed":false},{"client_msg_id":"7b96581f-c897-4c1d-b4f3-cf7d9de757f5","type":"message","text":"<https://arxiv.org/pdf/2103.07579.pdf>","user":"UPUBAM63X","ts":"1615979299.003500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H/hYu","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://arxiv.org/pdf/2103.07579.pdf"}]}]}]},{"type":"message","text":"Question regarding Zygote.jl.  Any help is appreciated.\n\nHow do we handle sparse data when calculating the gradients? I get the following error:","files":[{"id":"F01RT1AB3GA","created":1616117418,"timestamp":1616117418,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U0158N77PFT","editable":false,"size":44225,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01RT1AB3GA/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01RT1AB3GA/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01RT1AB3GA-bfd395b484/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01RT1AB3GA-bfd395b484/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01RT1AB3GA-bfd395b484/image_360.png","thumb_360_w":360,"thumb_360_h":55,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01RT1AB3GA-bfd395b484/image_480.png","thumb_480_w":480,"thumb_480_h":74,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01RT1AB3GA-bfd395b484/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01RT1AB3GA-bfd395b484/image_720.png","thumb_720_w":720,"thumb_720_h":111,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01RT1AB3GA-bfd395b484/image_800.png","thumb_800_w":800,"thumb_800_h":123,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01RT1AB3GA-bfd395b484/image_960.png","thumb_960_w":960,"thumb_960_h":148,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01RT1AB3GA-bfd395b484/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":158,"original_w":1091,"original_h":168,"thumb_tiny":"AwAHADCrkYpOKSimAvHr+lB20lFABx70ce9JRQB//9k=","permalink":"https://julialang.slack.com/files/U0158N77PFT/F01RT1AB3GA/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01RT1AB3GA-67a083f35b","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"NMm/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Question regarding Zygote.jl.  Any help is appreciated.\n\nHow do we handle sparse data when calculating the gradients? I get the following error:"}]}]}],"user":"U0158N77PFT","display_as_bot":false,"ts":"1616117422.010200","edited":{"user":"U0158N77PFT","ts":"1616117456.000000"}},{"client_msg_id":"59a92e4e-56c4-40f2-9425-cafc36fa1384","type":"message","text":"hello! i think i'm missing something at a fundamental level for recurrent layers in flux. i have the following working example with a custom layer using a dense layer (6,2). when i change from dense to something like rnn or gru, i get a dimension mismatch with the batch size and i'd like to check while i try to understand this better.\n\n```struct CustomLayer\n    network_1\nend\n(m::CustomLayer)(x) = [m.network_1(x[1:end-1,:]);\n                       permutedims(x[end,:])]\nfunction mwe()\n    model = Flux.Chain(CustomLayer(Flux.Dense(6, 2)),\n                       Flux.Dense(3, 1, Flux.sigmoid))\n    function loss(x, y)\n        return Flux.Losses.binarycrossentropy(model(x)[1,:], y)\n    end\n    batch_size = 32\n    number_of_epochs = 10\n    optimizer = Flux.ADAGrad()\n    train_data_x = rand(7,1000)\n    train_data_y = rand((0,1), 1000)\n    _train_data = Flux.Data.DataLoader((train_data_x, train_data_y), batchsize=batch_size)\n    Flux.@epochs number_of_epochs Flux.train!(loss,\n                                              Flux.params(model),\n                                              _train_data,\n                                              optimizer)\nend\nmwe()```\nerror:\n```[ Info: Epoch 1\nERROR: LoadError: DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 8 and 32\")\nStacktrace:\n [1] _bcs1 at ./broadcast.jl:490 [inlined]\n [2] _bcs at ./broadcast.jl:484 [inlined] (repeats 2 times)\n [3] broadcast_shape at ./broadcast.jl:478 [inlined]\n [4] combine_axes at ./broadcast.jl:473 [inlined]\n [5] instantiate at ./broadcast.jl:256 [inlined]\n [6] materialize at ./broadcast.jl:819 [inlined]\n [7] broadcast(::typeof(+), ::Array{Float64,2}, ::Array{Float64,2}) at ./broadcast.jl:757```","user":"UPKKW4H7B","ts":"1616335744.019900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mim","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hello! i think i'm missing something at a fundamental level for recurrent layers in flux. i have the following working example with a custom layer using a dense layer (6,2). when i change from dense to something like rnn or gru, i get a dimension mismatch with the batch size and i'd like to check while i try to understand this better.\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"struct CustomLayer\n    network_1\nend\n(m::CustomLayer)(x) = [m.network_1(x[1:end-1,:]);\n                       permutedims(x[end,:])]\nfunction mwe()\n    model = Flux.Chain(CustomLayer(Flux.Dense(6, 2)),\n                       Flux.Dense(3, 1, Flux.sigmoid))\n    function loss(x, y)\n        return Flux.Losses.binarycrossentropy(model(x)[1,:], y)\n    end\n    batch_size = 32\n    number_of_epochs = 10\n    optimizer = Flux.ADAGrad()\n    train_data_x = rand(7,1000)\n    train_data_y = rand((0,1), 1000)\n    _train_data = Flux.Data.DataLoader((train_data_x, train_data_y), batchsize=batch_size)\n    Flux.@epochs number_of_epochs Flux.train!(loss,\n                                              Flux.params(model),\n                                              _train_data,\n                                              optimizer)\nend\nmwe()"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nerror:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"[ Info: Epoch 1\nERROR: LoadError: DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 8 and 32\")\nStacktrace:\n [1] _bcs1 at ./broadcast.jl:490 [inlined]\n [2] _bcs at ./broadcast.jl:484 [inlined] (repeats 2 times)\n [3] broadcast_shape at ./broadcast.jl:478 [inlined]\n [4] combine_axes at ./broadcast.jl:473 [inlined]\n [5] instantiate at ./broadcast.jl:256 [inlined]\n [6] materialize at ./broadcast.jl:819 [inlined]\n [7] broadcast(::typeof(+), ::Array{Float64,2}, ::Array{Float64,2}) at ./broadcast.jl:757"}]}]}]},{"client_msg_id":"2460ffa1-9563-419f-9ba0-8b9792d12a9f","type":"message","text":"Anyone knows if julia has some package similar to R \"Stream\" or MOA (massive online data) for stream data analysis?","user":"U01PZNQ9LAD","ts":"1616507234.022300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"r6vz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone knows if julia has some package similar to R \"Stream\" or MOA (massive online data) for stream data analysis?"}]}]}],"thread_ts":"1616507234.022300","reply_count":3,"reply_users_count":2,"latest_reply":"1616508530.023100","reply_users":["U679VPJ8L","U01PZNQ9LAD"],"subscribed":false},{"client_msg_id":"d0c92d14-cb6f-4d89-b36a-2965bb4ed2f8","type":"message","text":"<https://www.reddit.com/r/MachineLearning/comments/mbhewa/d_advanced_takeaways_from_fastai_book/>","user":"UDGT4PM41","ts":"1616531207.023600","team":"T68168MUP","attachments":[{"service_name":"reddit","title":"[D] Advanced Takeaways from fast.ai book","title_link":"https://www.reddit.com/r/MachineLearning/comments/mbhewa/d_advanced_takeaways_from_fastai_book/","text":"I recently read the Fast AI deep learning [book](<https://www.goodreads.com/book/show/50204643-deep-learning-for-coders-with-fastai-and-pytorch>)...","fallback":"reddit: [D] Advanced Takeaways from fast.ai book","thumb_url":"https://external-preview.redd.it/uJR4F6Cw7OxqnzuKGka9jN6NKa7maYoVlBXb0TK602U.jpg?width=305&height=159.685863874&auto=webp&crop=305:159.685863874,smart&s=847fa3f2b1398839343647a8da4481cd3b18ece2","from_url":"https://www.reddit.com/r/MachineLearning/comments/mbhewa/d_advanced_takeaways_from_fastai_book/","thumb_width":305,"thumb_height":160,"service_icon":"http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png","id":1,"original_url":"https://www.reddit.com/r/MachineLearning/comments/mbhewa/d_advanced_takeaways_from_fastai_book/"}],"blocks":[{"type":"rich_text","block_id":"luH","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://www.reddit.com/r/MachineLearning/comments/mbhewa/d_advanced_takeaways_from_fastai_book/"}]}]}],"thread_ts":"1616531207.023600","reply_count":1,"reply_users_count":1,"latest_reply":"1616533521.023800","reply_users":["UGD4K0Z25"],"subscribed":false},{"client_msg_id":"89749974-5d93-4ac8-858d-6fbb87803f53","type":"message","text":"This question is more \"conventional machine learning applied to quantum\" related.  ANY constructive feedback is more than appreciated.\n\nI've been investigating the possibility of using ML to accelerate quantum optics simulations in cases where the quantum related math is computationally expensive.\n\nI think I've come to the conclusion that that since quantum state transformations are performed using unitary operators, linear algebra, it's very unlikely that any ML solution will be faster than a physics first principles quantum solution.\n\nDoes anyone disagree or have a counter example?","user":"U0158N77PFT","ts":"1616535740.024400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"t5N","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This question is more \"conventional machine learning applied to quantum\" related.  ANY constructive feedback is more than appreciated.\n\nI've been investigating the possibility of using ML to accelerate quantum optics simulations in cases where the quantum related math is computationally expensive.\n\nI think I've come to the conclusion that that since quantum state transformations are performed using unitary operators, linear algebra, it's very unlikely that any ML solution will be faster than a physics first principles quantum solution.\n\nDoes anyone disagree or have a counter example?"}]}]}]},{"client_msg_id":"1d8716f1-c8b9-4328-b384-6de71cdbb347","type":"message","text":"&gt; since quantum state transformations are performed using unitary operators\nThat is true for closed quantum systems (note that there is research on non-hermitian quantum mechanics.. <https://en.wikipedia.org/wiki/Non-Hermitian_quantum_mechanics>).\nHowever, if you go to an open system description with a measurement, you’ll get non-linear terms. In our paper <https://arxiv.org/abs/2101.01190> one (for example) has to include a term &lt;\\sigma^\\dagger+sigma&gt; for the quadrature measurement if a homodyne detection is considered.\nI am not an expert on accelerating the differential equation solution by ML but I guess it could be worth to look into surrogates <https://surrogates.sciml.ai/latest/>  or reservoir computing <https://reservoir.sciml.ai/dev/> .","user":"UR75SQMCZ","ts":"1616537037.031700","team":"T68168MUP","attachments":[{"title":"Non-Hermitian quantum mechanics","title_link":"https://en.wikipedia.org/wiki/Non-Hermitian_quantum_mechanics","from_url":"https://en.wikipedia.org/wiki/Non-Hermitian_quantum_mechanics","author_name":"Wikipedia","author_link":"https://en.wikipedia.org/","text":"Non-Hermitian quantum mechanics is the study of quantum-mechanical Hamiltonians that are not Hermitian. Notably, they appear in the study of dissipative systems. Also, non-Hermitian Hamiltonians with unbroken parity-time (PT) symmetry have all real eigenvalues.","fallback":"wikipedia: Non-Hermitian quantum mechanics","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/wikipedia.png","id":1,"original_url":"https://en.wikipedia.org/wiki/Non-Hermitian_quantum_mechanics"},{"service_name":"arXiv.org","title":"Control of Stochastic Quantum Dynamics with Differentiable Programming","title_link":"https://arxiv.org/abs/2101.01190","text":"Controlling stochastic dynamics of a quantum system is an indispensable task in fields such as quantum information processing and metrology. Yet, there is no general ready-made approach to design...","fallback":"arXiv.org: Control of Stochastic Quantum Dynamics with Differentiable Programming","from_url":"https://arxiv.org/abs/2101.01190","service_icon":"https://static.arxiv.org/static/browse/0.3.2.6/images/icons/favicon.ico","id":2,"original_url":"https://arxiv.org/abs/2101.01190"}],"blocks":[{"type":"rich_text","block_id":"0494y","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"since quantum state transformations are performed using unitary operators"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"That is true for closed quantum systems (note that there is research on non-hermitian quantum mechanics.. "},{"type":"link","url":"https://en.wikipedia.org/wiki/Non-Hermitian_quantum_mechanics"},{"type":"text","text":").\nHowever, if you go to an open system description with a measurement, you’ll get non-linear terms. In our paper "},{"type":"link","url":"https://arxiv.org/abs/2101.01190"},{"type":"text","text":" one (for example) has to include a term <\\sigma^\\dagger+sigma> for the quadrature measurement if a homodyne detection is considered.\nI am not an expert on accelerating the differential equation solution by ML but I guess it could be worth to look into surrogates "},{"type":"link","url":"https://surrogates.sciml.ai/latest/"},{"type":"text","text":"  or reservoir computing "},{"type":"link","url":"https://reservoir.sciml.ai/dev/"},{"type":"text","text":" ."}]}]}]},{"client_msg_id":"344e71c4-b059-4c05-a36d-1cf823f0cd15","type":"message","text":"<@UR75SQMCZ> - Thank you for the quick reply and potential research tip.\n\nI was neglecting open quantum systems simply because I haven't yet developed a simulation which demonstrates such a scenario which has been shown to be mathematically correct.\n\nI'll take a look at the links you offered and see if I can mature my thinking and modeling of open quantum systems to exploit surrogates.\n\nThanks again!","user":"U0158N77PFT","ts":"1616540242.036100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WDamH","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UR75SQMCZ"},{"type":"text","text":" - Thank you for the quick reply and potential research tip.\n\nI was neglecting open quantum systems simply because I haven't yet developed a simulation which demonstrates such a scenario which has been shown to be mathematically correct.\n\nI'll take a look at the links you offered and see if I can mature my thinking and modeling of open quantum systems to exploit surrogates.\n\nThanks again!"}]}]}]},{"client_msg_id":"2388cc9e-67ba-418a-953e-d14ca9dff354","type":"message","text":"What would be the best package to use for multivariate time series forecasting?","user":"U01EZ6VN118","ts":"1616631331.040500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"c/v/a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What would be the best package to use for multivariate time series forecasting?"}]}]}],"thread_ts":"1616631331.040500","reply_count":3,"reply_users_count":2,"latest_reply":"1616633209.041100","reply_users":["UMY1LV01G","U01724Q3PGW"],"is_locked":false,"subscribed":false},{"client_msg_id":"f6e76907-03f1-4013-b3e8-10b98fceca16","type":"message","text":"Does the pretrained VGG19 in Metalhead take BGR or RGB inputs? In Keras it takes BGR input","user":"U01PP5BA1C4","ts":"1616651712.041900","team":"T68168MUP","edited":{"user":"U01PP5BA1C4","ts":"1616651902.000000"},"blocks":[{"type":"rich_text","block_id":"T2l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does the pretrained VGG19 in Metalhead take BGR or RGB inputs? In Keras it takes BGR input"}]}]}]},{"client_msg_id":"d849e03a-e13c-47e0-badb-579ff4d073d5","type":"message","text":"Hey folks, what is the best library for computing Dependency Parse Trees for NLP in Julia? I found `DependencyTrees.jl` , but I was not sure if that is the best one to use right now, or if anyone has better recommendations.","user":"UDDSTBX19","ts":"1616684385.044400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"A3Y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey folks, what is the best library for computing Dependency Parse Trees for NLP in Julia? I found "},{"type":"text","text":"DependencyTrees.jl","style":{"code":true}},{"type":"text","text":" , but I was not sure if that is the best one to use right now, or if anyone has better recommendations."}]}]}]},{"client_msg_id":"3c9b6535-4ed0-4189-b674-51bb43ad1465","type":"message","text":"It seems automated feature engineering is a thing. Is <https://www.featuretools.com> a good tool? Does Julia have something for that?","user":"U01CQTKB86N","ts":"1616698048.045100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OWe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It seems automated feature engineering is a thing. Is "},{"type":"link","url":"https://www.featuretools.com"},{"type":"text","text":" a good tool? Does Julia have something for that?"}]}]}]},{"client_msg_id":"0895e0dc-7cef-43f0-866f-66cd6bd4a000","type":"message","text":"<@U6DKQSV7Z> Hi yueh, I have added to <https://github.com/CTUAvastLab/Mill.jl> a rudimentary support for representing graphs in branch <https://github.com/CTUAvastLab/Mill.jl/tree/graphsupport>. The idea behind Mill.jl is to facilitate machine learning over complex structure by adopting an invariant that each data type (Vector, set of vectors, tuple of vectors and now graphs) can be projected to a vector. This design decision allows you to “stack” building blocks to represent complicated structures, like for example graphs with complex description on vertices and edges. At the moment, I have added a rudimentary support for graph neural networks, effectively supporting just message passing approaches (in <https://github.com/CTUAvastLab/Mill.jl/blob/graphsupport/src/modelnodes/graphmodel.jl>). I would like to ask, if you would be willing to help me in adding support for using models of GeometricFlux. It might be quite a nice addition to the ecosystem and in line with automated feature engineering <@U01CQTKB86N> has mentioned above.","user":"U6YRZ18GZ","ts":"1616746090.052000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hV2","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U6DKQSV7Z"},{"type":"text","text":" Hi yueh, I have added to "},{"type":"link","url":"https://github.com/CTUAvastLab/Mill.jl"},{"type":"text","text":" a rudimentary support for representing graphs in branch "},{"type":"link","url":"https://github.com/CTUAvastLab/Mill.jl/tree/graphsupport"},{"type":"text","text":". The idea behind Mill.jl is to facilitate machine learning over complex structure by adopting an invariant that each data type (Vector, set of vectors, tuple of vectors and now graphs) can be projected to a vector. This design decision allows you to “stack” building blocks to represent complicated structures, like for example graphs with complex description on vertices and edges. At the moment, I have added a rudimentary support for graph neural networks, effectively supporting just message passing approaches (in "},{"type":"link","url":"https://github.com/CTUAvastLab/Mill.jl/blob/graphsupport/src/modelnodes/graphmodel.jl"},{"type":"text","text":"). I would like to ask, if you would be willing to help me in adding support for using models of GeometricFlux. It might be quite a nice addition to the ecosystem and in line with automated feature engineering "},{"type":"user","user_id":"U01CQTKB86N"},{"type":"text","text":" has mentioned above."}]}]}]},{"client_msg_id":"703c8aff-0405-4acd-a9eb-eb61029da17f","type":"message","text":"Hi. What are the best practices to do deep learning with Flux? Many model zoo examples are using Parameters.jl but in an issue discussion I saw someone saying that you should not use Parameters.jl.. which one is correct?\nAnd why are the models not sent as a parameter to the loss function? The model is being called from the global scope, so that will result in slow code right? I am quite confused.. It would be great if you compiled some best practices. The current docs are nice but it could be better and I'd love to write them after learning the best practices.. Please share some in the replies of this message and I will compile them together with explanations","user":"U01PP5BA1C4","ts":"1616845378.061500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ngy=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi. What are the best practices to do deep learning with Flux? Many model zoo examples are using Parameters.jl but in an issue discussion I saw someone saying that you should not use Parameters.jl.. which one is correct?\nAnd why are the models not sent as a parameter to the loss function? The model is being called from the global scope, so that will result in slow code right? I am quite confused.. It would be great if you compiled some best practices. The current docs are nice but it could be better and I'd love to write them after learning the best practices.. Please share some in the replies of this message and I will compile them together with explanations"}]}]}]},{"client_msg_id":"cf9c92f9-83f0-4399-8c0b-3e876b6c95cc","type":"message","text":"Typically the cost of running the model is much much higher than the lookup. You could pass the model in to the function as well. Typically, since it's a callable struct, the cost of a dynamic lookup is tiny.\n\nI think parameters.jl is a general purpose utility but not strictly a great design pattern as shown in the zoo.","user":"UC4QQPG4A","ts":"1616855494.065000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"66E","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Typically the cost of running the model is much much higher than the lookup. You could pass the model in to the function as well. Typically, since it's a callable struct, the cost of a dynamic lookup is tiny.\n\nI think parameters.jl is a general purpose utility but not strictly a great design pattern as shown in the zoo."}]}]}]},{"client_msg_id":"ba761d5f-2bf2-454c-ae76-a7eda35db169","type":"message","text":"You can pass the model to the loss function (e.g. `loss(x, y, m) = Flux.Losses.logitcrossentropy(m(x), y)`). Like <@UC4QQPG4A> said, even though this is technically faster since the model isn’t in global scope when called, the performance difference is negligible compared to the cost of actually running `m(x)`. I would say that if you are doing a short training script, then do whatever one you like. For more complex scripts, I always pass the model as a third argument, because I want to be able to call the loss function on different models. Closing over the model like `loss(x, y) = Flux.Losses.logitcrossentropy(model(x), y)` means you will only be able to use the global variable `model` in your loss evaluation.","user":"UH9KWTTD3","ts":"1616861671.069700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/KEmt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can pass the model to the loss function (e.g. "},{"type":"text","text":"loss(x, y, m) = Flux.Losses.logitcrossentropy(m(x), y)","style":{"code":true}},{"type":"text","text":"). Like "},{"type":"user","user_id":"UC4QQPG4A"},{"type":"text","text":" said, even though this is technically faster since the model isn’t in global scope when called, the performance difference is negligible compared to the cost of actually running "},{"type":"text","text":"m(x)","style":{"code":true}},{"type":"text","text":". I would say that if you are doing a short training script, then do whatever one you like. For more complex scripts, I always pass the model as a third argument, because I want to be able to call the loss function on different models. Closing over the model like "},{"type":"text","text":"loss(x, y) = Flux.Losses.logitcrossentropy(model(x), y)","style":{"code":true}},{"type":"text","text":" means you will only be able to use the global variable "},{"type":"text","text":"model","style":{"code":true}},{"type":"text","text":" in your loss evaluation."}]}]}],"reactions":[{"name":"today-i-learned","users":["U0138UTB7A4"],"count":1}]},{"client_msg_id":"b5895c5f-dfb3-4b2a-a632-8ba3d6a7ca1d","type":"message","text":"Re: Parameters.jl, I only see the `@with_kw` macro being used to define an args struct to collect all the training parameters like number of epochs, batch size, etc. The purpose is just a syntactic choice so that you can write `args = Args(batch_size = 32, nepochs = 100, ...)` at the start of the script then do `args.batch_size` to refer to the batch size. There is nothing bad about doing this, and it follows a common pattern in a lot ML scripts in many languages.\n\nI am not sure which issues you are referring to about Parameters.jl, but I can guess. Those issues aren’t saying there is anything wrong with using Parameters.jl. Just that the Parameters.jl package was created a while ago, and Base Julia has several new features that make its use in the model zoo tutorials unnecessary. For example, `@with_kw` is used to provide a default keyword based constructor for `Args`, but Base added `Base.@kwdef` which does the same thing. Additionally, Julia now has `NamedTuple` s which mean that it is probably more sensible to just write `args = (batch_size = 32, nepochs = 100)` at the start of the file instead of defining a struct to collect together named training paramters.","user":"UH9KWTTD3","ts":"1616862063.076000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yD+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Re: Parameters.jl, I only see the "},{"type":"text","text":"@with_kw","style":{"code":true}},{"type":"text","text":" macro being used to define an args struct to collect all the training parameters like number of epochs, batch size, etc. The purpose is just a syntactic choice so that you can write "},{"type":"text","text":"args = Args(batch_size = 32, nepochs = 100, ...)","style":{"code":true}},{"type":"text","text":" at the start of the script then do "},{"type":"text","text":"args.batch_size","style":{"code":true}},{"type":"text","text":" to refer to the batch size. There is nothing bad about doing this, and it follows a common pattern in a lot ML scripts in many languages.\n\nI am not sure which issues you are referring to about Parameters.jl, but I can guess. Those issues aren’t saying there is anything wrong with using Parameters.jl. Just that the Parameters.jl package was created a while ago, and Base Julia has several new features that make its use in the model zoo tutorials unnecessary. For example, "},{"type":"text","text":"@with_kw","style":{"code":true}},{"type":"text","text":" is used to provide a default keyword based constructor for "},{"type":"text","text":"Args","style":{"code":true}},{"type":"text","text":", but Base added "},{"type":"text","text":"Base.@kwdef","style":{"code":true}},{"type":"text","text":" which does the same thing. Additionally, Julia now has "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" s which mean that it is probably more sensible to just write "},{"type":"text","text":"args = (batch_size = 32, nepochs = 100)","style":{"code":true}},{"type":"text","text":" at the start of the file instead of defining a struct to collect together named training paramters."}]}]}]},{"client_msg_id":"E4F08A24-660E-4AB7-82F0-2FD28FCFDF97","type":"message","text":"Correct me if I’m wrong. The performance will also be affected w.r.t whether softmax layer is added in the model or not because it is a relatively costly computation. So another best practice might be to use `Flux.Losses.logitcrossentropy` in multi class setting instead of doing it by yourself and then doing `Flux.Losses.crossentropy` as it will cover numerically unstable corner cases as well. Is this correct?","user":"U01HPCV8GTW","ts":"1616868810.082800","team":"T68168MUP","edited":{"user":"U01HPCV8GTW","ts":"1616868861.000000"},"blocks":[{"type":"rich_text","block_id":"cFk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Correct me if I’m wrong. The performance will also be affected w.r.t whether softmax layer is added in the model or not because it is a relatively costly computation. So another best practice might be to use "},{"type":"text","text":"Flux.Losses.logitcrossentropy ","style":{"code":true}},{"type":"text","text":"in multi class setting instead of doing it by yourself and then doing "},{"type":"text","text":"Flux.Losses.crossentropy ","style":{"code":true}},{"type":"text","text":"as it will cover numerically unstable corner cases as well. Is this correct?"}]}]}]},{"client_msg_id":"585951ee-395c-4d93-9e36-eb0ad2332432","type":"message","text":"Yes","user":"UC4QQPG4A","ts":"1616912129.083500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n1Y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes"}]}]}]},{"client_msg_id":"a58e282a-2d2c-4e7c-905f-ef21c55efb97","type":"message","text":"are there any julia bindings for mlflow? or perhaps a similar experimentation tracking framework? I've looked at `DrWatson` and it's not quite what I'm looking for at this stage - I'd rather have experiment metadata persisted in a database.","user":"U8WEJ293L","ts":"1617023069.085200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5bro","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"are there any julia bindings for mlflow? or perhaps a similar experimentation tracking framework? I've looked at "},{"type":"text","text":"DrWatson","style":{"code":true}},{"type":"text","text":" and it's not quite what I'm looking for at this stage - I'd rather have experiment metadata persisted in a database."}]}]}]},{"client_msg_id":"dae98458-45c3-4632-934d-485b1b0acaab","type":"message","text":"<https://twitter.com/maxjaderberg/status/1376886882995425285>","user":"UDGT4PM41","ts":"1617129554.089300","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/maxjaderberg|@maxjaderberg>: Super cool: self-supervised learning on images with a Quantum Neural Network. The quantum net learns better representations than the equivalent classical nets for use on downstream tasks. And is actually evaluated on a real quantum computer! <https://arxiv.org/abs/2103.14653> <https://twitter.com/benjaderberg|@benjaderberg> <https://pbs.twimg.com/media/ExuuillXMAE4V28.jpg>","ts":1617110388,"author_name":"Max Jaderberg","author_link":"https://twitter.com/maxjaderberg/status/1376886882995425285","author_icon":"https://pbs.twimg.com/profile_images/1139603010441678848/erPXyBvf_normal.jpg","author_subname":"@maxjaderberg","text":"Super cool: self-supervised learning on images with a Quantum Neural Network. The quantum net learns better representations than the equivalent classical nets for use on downstream tasks. And is actually evaluated on a real quantum computer! <https://arxiv.org/abs/2103.14653> <https://twitter.com/benjaderberg|@benjaderberg> <https://pbs.twimg.com/media/ExuuillXMAE4V28.jpg>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/maxjaderberg/status/1376886882995425285","image_url":"https://pbs.twimg.com/media/ExuuillXMAE4V28.jpg","image_width":1073,"image_height":761,"image_bytes":77447,"id":1,"original_url":"https://twitter.com/maxjaderberg/status/1376886882995425285","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"esM6V","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/maxjaderberg/status/1376886882995425285"}]}]}]},{"client_msg_id":"29e4038e-bfdf-4b84-9fe3-43400bccb7c9","type":"message","text":"I am experimenting a bit with Zygote, and this is an error I am getting while checking for this convolving kernels differentiability-\n```julia&gt; jacobian((a,b)-&gt;imfilter(a,b),randn(50,50),Kernel.gaussian(1))```\nThis is the error message-\n```ERROR: Compiling Tuple{typeof(imfilter!), Matrix{Float64}, Matrix{Float64}, Tuple{OffsetArrays.OffsetMatrix{Float64, Matrix{Float64}}, OffsetArrays.OffsetMatrix{Float64, Matrix{Float64}}}, Pad{0}, ImageFiltering.Algorithm.FIRTiled{2}}: try/catch is not supported.```\nI don't understand what should I do now?","user":"UTDSTSANP","ts":"1617220126.091600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pECa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am experimenting a bit with Zygote, and this is an error I am getting while checking for this convolving kernels differentiability-\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> jacobian((a,b)->imfilter(a,b),randn(50,50),Kernel.gaussian(1))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"This is the error message-\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ERROR: Compiling Tuple{typeof(imfilter!), Matrix{Float64}, Matrix{Float64}, Tuple{OffsetArrays.OffsetMatrix{Float64, Matrix{Float64}}, OffsetArrays.OffsetMatrix{Float64, Matrix{Float64}}}, Pad{0}, ImageFiltering.Algorithm.FIRTiled{2}}: try/catch is not supported."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I don't understand what should I do now?"}]}]}],"thread_ts":"1617220126.091600","reply_count":1,"reply_users_count":1,"latest_reply":"1617220191.091700","reply_users":["UTDSTSANP"],"is_locked":false,"subscribed":false},{"client_msg_id":"b59aaf23-528e-4dce-ad00-e02e9f81cd93","type":"message","text":"Hi, everyone! I upgraded to 1.6.0 and Flux to 0.12.1. But I started to get some silly errors.\n```julia&gt; m = Chain(Dense(2,3))\nChain(Dense(2, 3))\n\njulia&gt; m(rand(2))\n3-element Vector{Float64}:\n -0.7720298389165985\n -0.975560769181443\n -0.11426826961898628\n\njulia&gt; m = Chain(RNN(2,3))\nChain(Recur(RNNCell(2, 3, tanh)))\n\njulia&gt; m(rand(2))\nERROR: MethodError: no method matching (::Flux.RNNCell{typeof(tanh), Matrix{Float32}, Vector{Float32}, Matrix{Float32}})(::Matrix{Float32}, ::Vector{Float64})\nClosest candidates are:\n  (::Flux.RNNCell{F, A, V, var\"#s263\"} where var\"#s263\"&lt;:AbstractMatrix{T})(::Any, ::Union{AbstractVector{T}, AbstractMatrix{T}, Flux.OneHotArray}) where {F, A, V, T} at /Users/rrosa/.julia/packages/Flux/qp1gc/src/layers/recurrent.jl:83\nStacktrace:\n [1] (::Flux.Recur{Flux.RNNCell{typeof(tanh), Matrix{Float32}, Vector{Float32}, Matrix{Float32}}, Matrix{Float32}})(x::Vector{Float64})\n   @ Flux ~/.julia/packages/Flux/qp1gc/src/layers/recurrent.jl:34\n [2] applychain(fs::Tuple{Flux.Recur{Flux.RNNCell{typeof(tanh), Matrix{Float32}, Vector{Float32}, Matrix{Float32}}, Matrix{Float32}}}, x::Vector{Float64})\n   @ Flux ~/.julia/packages/Flux/qp1gc/src/layers/basic.jl:36\n [3] (::Chain{Tuple{Flux.Recur{Flux.RNNCell{typeof(tanh), Matrix{Float32}, Vector{Float32}, Matrix{Float32}}, Matrix{Float32}}}})(x::Vector{Float64})\n   @ Flux ~/.julia/packages/Flux/qp1gc/src/layers/basic.jl:38\n [4] top-level scope\n   @ REPL[27]:1```\nOther types of layers give similar erros. Only Dense works fine. What is going on? What am I missing. There is only `Flux v0.12.1` in this project, in an attempt to isolate the problem.","user":"U01CR62LAAD","ts":"1617539205.097700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BXAKG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, everyone! I upgraded to 1.6.0 and Flux to 0.12.1. But I started to get some silly errors.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> m = Chain(Dense(2,3))\nChain(Dense(2, 3))\n\njulia> m(rand(2))\n3-element Vector{Float64}:\n -0.7720298389165985\n -0.975560769181443\n -0.11426826961898628\n\njulia> m = Chain(RNN(2,3))\nChain(Recur(RNNCell(2, 3, tanh)))\n\njulia> m(rand(2))\nERROR: MethodError: no method matching (::Flux.RNNCell{typeof(tanh), Matrix{Float32}, Vector{Float32}, Matrix{Float32}})(::Matrix{Float32}, ::Vector{Float64})\nClosest candidates are:\n  (::Flux.RNNCell{F, A, V, var\"#s263\"} where var\"#s263\"<:AbstractMatrix{T})(::Any, ::Union{AbstractVector{T}, AbstractMatrix{T}, Flux.OneHotArray}) where {F, A, V, T} at /Users/rrosa/.julia/packages/Flux/qp1gc/src/layers/recurrent.jl:83\nStacktrace:\n [1] (::Flux.Recur{Flux.RNNCell{typeof(tanh), Matrix{Float32}, Vector{Float32}, Matrix{Float32}}, Matrix{Float32}})(x::Vector{Float64})\n   @ Flux ~/.julia/packages/Flux/qp1gc/src/layers/recurrent.jl:34\n [2] applychain(fs::Tuple{Flux.Recur{Flux.RNNCell{typeof(tanh), Matrix{Float32}, Vector{Float32}, Matrix{Float32}}, Matrix{Float32}}}, x::Vector{Float64})\n   @ Flux ~/.julia/packages/Flux/qp1gc/src/layers/basic.jl:36\n [3] (::Chain{Tuple{Flux.Recur{Flux.RNNCell{typeof(tanh), Matrix{Float32}, Vector{Float32}, Matrix{Float32}}, Matrix{Float32}}}})(x::Vector{Float64})\n   @ Flux ~/.julia/packages/Flux/qp1gc/src/layers/basic.jl:38\n [4] top-level scope\n   @ REPL[27]:1"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Other types of layers give similar erros. Only Dense works fine. What is going on? What am I missing. There is only "},{"type":"text","text":"Flux v0.12.1","style":{"code":true}},{"type":"text","text":" in this project, in an attempt to isolate the problem."}]}]}]},{"client_msg_id":"4a9d097b-7937-4785-84f7-7b1a64042600","type":"message","text":"Hi All, I am making a Medium publication for Julia and Machine Learning and looking if anyone wants to contribute and/or if any one has any advice ? (Also I am not sure if this goes to general or random, pleae let me know and I move the post)\n <https://medium.com/mljulia|https://medium.com/mljulia>","user":"U01T8MZ8Q1Z","ts":"1617557667.101300","team":"T68168MUP","attachments":[{"title":"MLJulia","title_link":"https://medium.com/mljulia","text":"Julia Programming Language and its usage mostly focused on Machine learning","fallback":"MLJulia","image_url":"https://miro.medium.com/max/999/1*l08U9tCcyNGhYaf-SBt29w.png","from_url":"https://medium.com/mljulia","image_width":250,"image_height":250,"image_bytes":50999,"service_icon":"https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png","service_name":"medium.com","id":1,"original_url":"https://medium.com/mljulia"}],"blocks":[{"type":"rich_text","block_id":"G1//p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi All, I am making a Medium publication for Julia and Machine Learning and looking if anyone wants to contribute and/or if any one has any advice ? (Also I am not sure if this goes to general or random, pleae let me know and I move the post)\n "},{"type":"link","url":"https://medium.com/mljulia","text":"https://medium.com/mljulia"}]}]}],"thread_ts":"1617557667.101300","reply_count":2,"reply_users_count":1,"latest_reply":"1617558084.102100","reply_users":["UJ7DVTVQ8"],"is_locked":false,"subscribed":false},{"client_msg_id":"D01307C2-AF8F-4349-B257-D83B4AD51D16","type":"message","text":"I am looking at Flux.outputsize. I don't quite understand it yet, but before I dig deeper into it, does anybody know whether it is possible to adapt it to find out which neurons (or índices in the output array) on the next layer are activated by a specific neuron in the current layer?","user":"U01CR62LAAD","ts":"1617558348.107600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vIPJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am looking at Flux.outputsize. I don't quite understand it yet, but before I dig deeper into it, does anybody know whether it is possible to adapt it to find out which neurons (or índices in the output array) on the next layer are activated by a specific neuron in the current layer?"}]}]}]}]}