{"cursor": 0, "messages": [{"type":"message","subtype":"channel_join","ts":"1612997896.000200","user":"ULL3KSGBS","text":"<@ULL3KSGBS> has joined the channel"},{"type":"message","subtype":"channel_purpose","ts":"1612997896.000300","user":"ULL3KSGBS","text":"<@ULL3KSGBS> set the channel purpose: ECP project ExaSGD","purpose":"ECP project ExaSGD"},{"type":"message","subtype":"channel_join","ts":"1612997915.000500","user":"UN2U72Q3F","text":"<@UN2U72Q3F> has joined the channel","inviter":"ULL3KSGBS"},{"type":"message","subtype":"channel_join","ts":"1612997915.000700","user":"U67BJLYCS","text":"<@U67BJLYCS> has joined the channel","inviter":"ULL3KSGBS"},{"type":"message","subtype":"channel_join","ts":"1612997916.000900","user":"U6A0PD8CR","text":"<@U6A0PD8CR> has joined the channel","inviter":"ULL3KSGBS"},{"client_msg_id":"2c29382a-ec89-489c-8023-efae5a7228da","type":"message","text":"Hi <@U67BJLYCS>! We have two construction sites at the moment. 1) Porting to AMDGPU.jl and 2) Moving to second-order Hessians. We use KernelAbstractions in ExaPF together with ForwardDiff and moved to Hessians using AD now. What we observe is that a small test case uses a lot of compile time with KA:\n `julia --project --optimize=0 --check-bounds=no test/Polar/hessian.jl  157.00s user 3.38s system 101% cpu 2:38.77 total`\nvs\n `julia --project --optimize=0 --check-bounds=no test/Polar/hessian.jl  57.49s user 3.22s system 102% cpu 59.058 total`\nwithout KA on the CPU. The difference is all only compile time. The actual kernel is computationally extremely small. A quick `@profile` shows a scary number of Cassette potholes. Francois was spending quite some time on making our code less inference heavy. So we are aware that we may just be doing something wrong. Do you have any idea? Basically what makes it blow up is that we are using a float type of\n`t1s{N,V} = ForwardDiff.Dual{Nothing,V, N} where {N,V}` and go second order with `t2s{M,N,V} =  ForwardDiff.Dual{Nothing,t1s{N,V}, M} where {M,N,V}` . `M` and `N` grow with larger problems. I fear that some expressions may just explode in size.","user":"ULL3KSGBS","ts":"1612998631.007900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"L2l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi "},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":"! We have two construction sites at the moment. 1) Porting to AMDGPU.jl and 2) Moving to second-order Hessians. We use KernelAbstractions in ExaPF together with ForwardDiff and moved to Hessians using AD now. What we observe is that a small test case uses a lot of compile time with KA:\n "},{"type":"text","text":"julia --project --optimize=0 --check-bounds=no test/Polar/hessian.jl  157.00s user 3.38s system 101% cpu 2:38.77 total","style":{"code":true}},{"type":"text","text":"\nvs\n "},{"type":"text","text":"julia --project --optimize=0 --check-bounds=no test/Polar/hessian.jl  57.49s user 3.22s system 102% cpu 59.058 total","style":{"code":true}},{"type":"text","text":"\nwithout KA on the CPU. The difference is all only compile time. The actual kernel is computationally extremely small. A quick "},{"type":"text","text":"@profile","style":{"code":true}},{"type":"text","text":" shows a scary number of Cassette potholes. Francois was spending quite some time on making our code less inference heavy. So we are aware that we may just be doing something wrong. Do you have any idea? Basically what makes it blow up is that we are using a float type of\n"},{"type":"text","text":"t1s{N,V} = ForwardDiff.Dual{Nothing,V, N} where {N,V}","style":{"code":true}},{"type":"text","text":" and go second order with "},{"type":"text","text":"t2s{M,N,V} =  ForwardDiff.Dual{Nothing,t1s{N,V}, M} where {M,N,V}","style":{"code":true}},{"type":"text","text":" . "},{"type":"text","text":"M","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"N","style":{"code":true}},{"type":"text","text":" grow with larger problems. I fear that some expressions may just explode in size."}]}]}]},{"client_msg_id":"41f28b9d-73f4-45e3-aaf2-913a7b7c4b12","type":"message","text":"Hi!","user":"U67BJLYCS","ts":"1613000665.008100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wg4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi!"}]}]}]},{"client_msg_id":"add8c510-e387-4672-9dc9-c339cfeb31cf","type":"message","text":"I can't say that I am surprised","user":"U67BJLYCS","ts":"1613000721.008400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nEvJi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can't say that I am surprised"}]}]}]},{"client_msg_id":"7ea3d9a7-2497-45db-b927-01b49e79c812","type":"message","text":"using Cassette means that we hit an empty inference cache for everything","user":"U67BJLYCS","ts":"1613000747.009000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"esz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"using Cassette means that we hit an empty inference cache for everything"}]}]}]},{"client_msg_id":"49ec9328-75a0-4bc2-9378-6f2ad113f5f3","type":"message","text":"Can you remind me where the code lives?","user":"U67BJLYCS","ts":"1613000777.009400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QHJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can you remind me where the code lives?"}]}]}]},{"client_msg_id":"627653f3-fe43-4e80-b595-ece08115a230","type":"message","text":"This is the full code. Though, we should try to build a MWE. Let me know if you'd be interested in that. It's the main power flow kernel:\n <https://github.com/exanauts/ExaPF.jl/blob/ab577acb9ddbb470b3d9fe606423a168028df6a2/src/polar/kernels.jl#L65-L96>\n\nAnd it's called from here with second-order types:\n<https://github.com/exanauts/ExaPF.jl/blob/ab577acb9ddbb470b3d9fe606423a168028df6a2/src/autodiff.jl#L583-L590>\n\nThere's a bit reordering going on due the application background before calling the kernel. This is implemented through views. Again, once compiled, the code flies. So that's good. If you think there's a way to fix it we'll invest some time in a MWE and try to isolate it there.","user":"ULL3KSGBS","ts":"1613056192.002500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jQn=d","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This is the full code. Though, we should try to build a MWE. Let me know if you'd be interested in that. It's the main power flow kernel:\n "},{"type":"link","url":"https://github.com/exanauts/ExaPF.jl/blob/ab577acb9ddbb470b3d9fe606423a168028df6a2/src/polar/kernels.jl#L65-L96"},{"type":"text","text":"\n\nAnd it's called from here with second-order types:\n"},{"type":"link","url":"https://github.com/exanauts/ExaPF.jl/blob/ab577acb9ddbb470b3d9fe606423a168028df6a2/src/autodiff.jl#L583-L590"},{"type":"text","text":"\n\nThere's a bit reordering going on due the application background before calling the kernel. This is implemented through views. Again, once compiled, the code flies. So that's good. If you think there's a way to fix it we'll invest some time in a MWE and try to isolate it there."}]}]}]},{"client_msg_id":"2c08bae1-f5af-4da9-af4b-e225abdf60d4","type":"message","text":"<@U67BJLYCS> Sorry I missed your message here in the Julia slack. I have still to organize my notifications here.","user":"ULL3KSGBS","ts":"1613056947.003200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+cmSS","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":" Sorry I missed your message here in the Julia slack. I have still to organize my notifications here."}]}]}]},{"client_msg_id":"ef1d07dd-c39a-4431-8ff2-998f43835c0d","type":"message","text":"Valentin, forget about it. I've just today wrote a handwritten adjoint and we are doing forward over reverse now. It's fast, and once Enzyme digests GPU code, we can just flip the switch.","user":"ULL3KSGBS","ts":"1613102362.004100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8sbJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Valentin, forget about it. I've just today wrote a handwritten adjoint and we are doing forward over reverse now. It's fast, and once Enzyme digests GPU code, we can just flip the switch."}]}]}]},{"client_msg_id":"7215f0fb-f942-4c70-951b-9160d354be98","type":"message","text":"haha okay","user":"U67BJLYCS","ts":"1613107628.005500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"i+Oq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"haha okay"}]}]}]},{"client_msg_id":"a4fad8c3-102a-45cf-a3ca-54b201f29eab","type":"message","text":"well if you do have an MWE","user":"U67BJLYCS","ts":"1613107637.005800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gyLi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"well if you do have an MWE"}]}]}]},{"client_msg_id":"82d12a52-2e0c-4ef6-838c-3edc2481cfa8","type":"message","text":"I can look at the compilation times","user":"U67BJLYCS","ts":"1613107643.006000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HrOM6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can look at the compilation times"}]}]}]},{"client_msg_id":"58a20365-5cf1-4446-b0db-8ffc8139f785","type":"message","text":"So Enzyme supporting GPU is more important?","user":"U67BJLYCS","ts":"1613107659.006300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AeQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So Enzyme supporting GPU is more important?"}]}]}]},{"client_msg_id":"ebdb8574-d22b-4c5b-ae42-2c37d89e6cf9","type":"message","text":"Gotcha","user":"U67BJLYCS","ts":"1613107661.006500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+7NN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Gotcha"}]}]}]},{"client_msg_id":"0b67f70c-f474-493f-a346-61964a5cea12","type":"message","text":"Lol. Yes I can confirm now. So KA + ForwardDiff + adjoint is still our way to go.","user":"ULL3KSGBS","ts":"1613575646.001500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AxxqX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Lol. Yes I can confirm now. So KA + ForwardDiff + adjoint is still our way to go."}]}]}]},{"client_msg_id":"6a94f382-99f0-4fa2-80e9-2e2d44fa1f2e","type":"message","text":"+1","user":"U67BJLYCS","ts":"1613576570.001700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nZhK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"+1"}]}]}]},{"client_msg_id":"757366e4-ad41-40ce-a89f-41cd87ea69be","type":"message","text":"Julian has been working on AMD support for KA","user":"U67BJLYCS","ts":"1613576589.002200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Rr4n","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Julian has been working on AMD support for KA"}]}]}]},{"client_msg_id":"983a8df7-c973-4c63-afab-2285fb5f66ab","type":"message","text":"So that should materialize soon (tm)","user":"U67BJLYCS","ts":"1613576601.002700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sqyL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So that should materialize soon (tm)"}]}]}]},{"client_msg_id":"c5df731c-7c08-4285-9266-1f855473a242","type":"message","text":"That's great. I also aligned our deadline with respect to AMD to June.","user":"ULL3KSGBS","ts":"1613576630.003300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xU5Ax","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's great. I also aligned our deadline with respect to AMD to June."}]}]}]},{"client_msg_id":"dec3bced-fd9d-4fd1-b129-1affd0b84e55","type":"message","text":"Post March 1st I hopefully find the time to do Enzyme +KA integration","user":"U67BJLYCS","ts":"1613576684.004100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"h2y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Post March 1st I hopefully find the time to do Enzyme +KA integration"}]}]}]},{"type":"message","text":"@channel We have ExaPF successfully running on Summit on the NVIDIA GPU, and all with KA with a reduced Hessian falling out of it at the end. That was an important goal. There will be a bit more testing and we'll have a review on March 30. After that, we will pester you probably a bit :slightly_smiling_face: .","files":[{"id":"F01QRRFPL7K","created":1614979946,"timestamp":1614979946,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"ULL3KSGBS","editable":false,"size":4052,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01QRRFPL7K/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01QRRFPL7K/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01QRRFPL7K-6202752507/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01QRRFPL7K-6202752507/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01QRRFPL7K-6202752507/image_360.png","thumb_360_w":343,"thumb_360_h":42,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01QRRFPL7K-6202752507/image_160.png","original_w":343,"original_h":42,"thumb_tiny":"AwAFADCnv+tG8nr/AEptFAg49D+dLwOlJRQAZOMGl3HGDTaKBn//2Q==","permalink":"https://julialang.slack.com/files/ULL3KSGBS/F01QRRFPL7K/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01QRRFPL7K-bccc291422","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"hxA7E","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"@channel We have ExaPF successfully running on Summit on the NVIDIA GPU, and all with KA with a reduced Hessian falling out of it at the end. That was an important goal. There will be a bit more testing and we'll have a review on March 30. After that, we will pester you probably a bit "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" ."}]}]}],"user":"ULL3KSGBS","display_as_bot":false,"ts":"1614979949.002000"},{"client_msg_id":"30e54212-371f-4abd-a1ff-337e9c2c040f","type":"message","text":"Awesome work! I'm working on getting ROCKernels+AMDGPU passing the KA tests, so hopefully we'll be ready for you all :slightly_smiling_face:","user":"U6A0PD8CR","ts":"1614981031.002900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6W0K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Awesome work! I'm working on getting ROCKernels+AMDGPU passing the KA tests, so hopefully we'll be ready for you all "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"7c4d06de-b44c-428e-9657-20621f6e229e","type":"message","text":"Nice, can't wait seeing it all work in harmony :slightly_smiling_face: .","user":"ULL3KSGBS","ts":"1614981089.003700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6LZJo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Nice, can't wait seeing it all work in harmony "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" ."}]}]}]},{"client_msg_id":"beda5c5b-bfd6-4952-b197-c5847eb5c08a","type":"message","text":"@channel Hi guys. The following kernel sometimes returns non-deterministic results. That sometimes is like 1 in 60 full program executions. It can though be consistently triggered by running with multiple ExaPF instances on a single node. Do you have any such past war story that you can share? When we try to put that part of the code in a `try` `catch` loop and just repeat the calculation, it often times recovers after a few retries.\n<https://github.com/exanauts/ExaPF.jl/blob/dbe5d3987b8d434d37cb4a2c838630347e20e685/src/Polar/kernels.jl#L13-L46>\n\nIt has been there for a while, but we always had other stuff to focus on. Now with a few hundred instances on Summit it gets harder to ignore :confused: .","user":"ULL3KSGBS","ts":"1615855896.003900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yyt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"@channel Hi guys. The following kernel sometimes returns non-deterministic results. That sometimes is like 1 in 60 full program executions. It can though be consistently triggered by running with multiple ExaPF instances on a single node. Do you have any such past war story that you can share? When we try to put that part of the code in a "},{"type":"text","text":"try","style":{"code":true}},{"type":"text","text":" "},{"type":"text","text":"catch","style":{"code":true}},{"type":"text","text":" loop and just repeat the calculation, it often times recovers after a few retries.\n"},{"type":"link","url":"https://github.com/exanauts/ExaPF.jl/blob/dbe5d3987b8d434d37cb4a2c838630347e20e685/src/Polar/kernels.jl#L13-L46"},{"type":"text","text":"\n\nIt has been there for a while, but we always had other stuff to focus on. Now with a few hundred instances on Summit it gets harder to ignore "},{"type":"emoji","name":"confused"},{"type":"text","text":" ."}]}]}]},{"client_msg_id":"d1ea272b-444b-4a03-a28d-b5f8cd7308e2","type":"message","text":"is this CPU or GPU?","user":"U67BJLYCS","ts":"1615857064.000200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3e7b0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is this CPU or GPU?"}]}]}]},{"client_msg_id":"9efccd7b-8e2c-4466-b5f2-385a9e17bf30","type":"message","text":"oh only GPU. On the CPU it's doing fine.","user":"ULL3KSGBS","ts":"1615857077.000500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BAd/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oh only GPU. On the CPU it's doing fine."}]}]}]},{"client_msg_id":"081ff0e9-3701-4cbf-828a-0b9ffbd0fcf2","type":"message","text":"But I think it's also only using one thread there :slightly_smiling_face:","user":"ULL3KSGBS","ts":"1615857098.000900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"E8CX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But I think it's also only using one thread there "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"5029709e-2ff2-4fc7-a18a-accde34e22c7","type":"message","text":"I am wondering if we have an out of bounds execution here","user":"U67BJLYCS","ts":"1615857144.001200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Q8y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am wondering if we have an out of bounds execution here"}]}]}]},{"client_msg_id":"b18edfd3-c43f-4d7c-bb4d-2996415d3342","type":"message","text":"Accessing `F[npq + i]` should be okay. Every element is only accessed once by each thread.","user":"ULL3KSGBS","ts":"1615857186.002100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"429","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Accessing "},{"type":"text","text":"F[npq + i]","style":{"code":true}},{"type":"text","text":" should be okay. Every element is only accessed once by each thread."}]}]}]},{"client_msg_id":"de478dec-16e9-47c5-a3fc-59e3afaae4e7","type":"message","text":"ah the range is `npv + npq`","user":"U67BJLYCS","ts":"1615857208.002700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qHZs1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ah the range is "},{"type":"text","text":"npv + npq","style":{"code":true}}]}]}]},{"client_msg_id":"b8e0b9d0-b7dc-472c-8258-027c243c8119","type":"message","text":"F is of size `npv + 2*npq` . Yes.","user":"ULL3KSGBS","ts":"1615857219.002900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"edlN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"F is of size "},{"type":"text","text":"npv + 2*npq","style":{"code":true}},{"type":"text","text":" . Yes."}]}]}]},{"client_msg_id":"123561c9-94a3-4c8e-92a6-a715eddfdf35","type":"message","text":"I am seeing nothing fishy","user":"U67BJLYCS","ts":"1615857360.003100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gwF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am seeing nothing fishy"}]}]}]},{"client_msg_id":"36eb112f-1643-4c65-a0e3-9eb0e44b40f2","type":"message","text":"is `npv + 2*npq` divisible by 32?","user":"U67BJLYCS","ts":"1615857378.003600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jtQP5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is "},{"type":"text","text":"npv + 2*npq","style":{"code":true}},{"type":"text","text":" divisible by 32?"}]}]}]},{"client_msg_id":"896cbd14-fe74-4211-bd83-414fefd3e8c8","type":"message","text":"ok. that's good. or bad :slightly_smiling_face: . no it's not.","user":"ULL3KSGBS","ts":"1615857389.003900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5PS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ok. that's good. or bad "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" . no it's not."}]}]}]},{"client_msg_id":"6a83da1b-5764-4f27-a2ca-b5f1d534ac36","type":"message","text":"or if so it'd be coincidence.","user":"ULL3KSGBS","ts":"1615857460.004200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gsyz4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"or if so it'd be coincidence."}]}]}]},{"client_msg_id":"66602d14-48a2-4fb8-9d1b-b20480d1919b","type":"message","text":"that should not be a problem","user":"U67BJLYCS","ts":"1615858773.004500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"j4MP5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that should not be a problem"}]}]}]},{"client_msg_id":"aeef8565-a544-4db2-a013-347d4ea997cf","type":"message","text":"but I am suspicous of everything","user":"U67BJLYCS","ts":"1615858784.004800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"591B","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but I am suspicous of everything"}]}]}]},{"client_msg_id":"82fd8e3f-f2a4-484e-818d-44a97a34809b","type":"message","text":"Hi guys. We have completed a reduced space Hessian implementation that heavily relies on KA and Krylov.jl. We are going to present this at our internal ECP review and we are also planning to submit this to SC21. Would you be interested to join in? Here's the overleaf with just a very crude structure at the moment:  <https://www.overleaf.com/4777113315drztcmmzpyvc> . We would do the heavily lifting, but would be glad to have you onboard for some input. That's basically the implementation that we plan on porting to AMD in the upcoming quarter.","user":"ULL3KSGBS","ts":"1616605123.002400","team":"T68168MUP","attachments":[{"title":"Overleaf, Online LaTeX Editor","title_link":"https://www.overleaf.com/4777113315drztcmmzpyvc","text":"An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.","fallback":"Overleaf, Online LaTeX Editor","thumb_url":"https://cdn.overleaf.com/img/ol-brand/overleaf_og_logo.png","from_url":"https://www.overleaf.com/4777113315drztcmmzpyvc","thumb_width":256,"thumb_height":256,"service_icon":"https://www.overleaf.com/apple-touch-icon-precomposed.png","service_name":"overleaf.com","id":1,"original_url":"https://www.overleaf.com/4777113315drztcmmzpyvc"}],"blocks":[{"type":"rich_text","block_id":"/QV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys. We have completed a reduced space Hessian implementation that heavily relies on KA and Krylov.jl. We are going to present this at our internal ECP review and we are also planning to submit this to SC21. Would you be interested to join in? Here's the overleaf with just a very crude structure at the moment:  "},{"type":"link","url":"https://www.overleaf.com/4777113315drztcmmzpyvc"},{"type":"text","text":" . We would do the heavily lifting, but would be glad to have you onboard for some input. That's basically the implementation that we plan on porting to AMD in the upcoming quarter."}]}]}]},{"client_msg_id":"d2d63d1f-4998-4f2d-8c61-b5ebd70f25d4","type":"message","text":"Definitely up for it","user":"U67BJLYCS","ts":"1616605500.002800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"izmKi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Definitely up for it"}]}]}]},{"client_msg_id":"e8b0bec3-e05b-4c02-8716-9a5c7d3d3e64","type":"message","text":"<https://join.slack.com/share/zt-ohffo0yo-n8ofldExWqx9Vx58DBZs0A> Here's a link to our SC21 channel if you want to join.","user":"ULL3KSGBS","ts":"1616605630.003200","team":"T68168MUP","attachments":[{"service_name":"Slack","title":"Let’s work together with Slack Connect","title_link":"https://join.slack.com/share/zt-ohffo0yo-n8ofldExWqx9Vx58DBZs0A","text":"Accept this invitation and our teams will be able to send messages, share files, and work together right in Slack. Depending on your settings, your admins may need to approve your request first.","fallback":"Slack: Let’s work together with Slack Connect","from_url":"https://join.slack.com/share/zt-ohffo0yo-n8ofldExWqx9Vx58DBZs0A","thumb_url":"https://a.slack-edge.com/2c67fd/img/shared_channels/share_illustration_transparent@1x.png","thumb_width":140,"thumb_height":140,"service_icon":"https://a.slack-edge.com/80588/marketing/img/meta/favicon-32.png","id":1,"original_url":"https://join.slack.com/share/zt-ohffo0yo-n8ofldExWqx9Vx58DBZs0A"}],"blocks":[{"type":"rich_text","block_id":"it8","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://join.slack.com/share/zt-ohffo0yo-n8ofldExWqx9Vx58DBZs0A"},{"type":"text","text":" Here's a link to our SC21 channel if you want to join."}]}]}]},{"client_msg_id":"93b572ad-d46a-4879-8645-531dcb57f644","type":"message","text":"KernelAbstractions 0.6 was released :slightly_smiling_face:. Should we try to switch?","user":"ULL3KSGBS","ts":"1617301494.000600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hra+D","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"KernelAbstractions 0.6 was released "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":". Should we try to switch?"}]}]}]},{"client_msg_id":"6ac199c4-ef5c-4019-a384-8907bb7a39ea","type":"message","text":"Yeah","user":"U67BJLYCS","ts":"1617301854.000700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wZXw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah"}]}]}]},{"client_msg_id":"16aa473c-da2d-445a-91e9-ddab6c452fab","type":"message","text":"You will need to add `CUDAKernels`","user":"U67BJLYCS","ts":"1617301867.000800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ky4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You will need to add "},{"type":"text","text":"CUDAKernels","style":{"code":true}}]}]}]},{"client_msg_id":"ac991748-fd8a-4145-a32b-df4e07c040a8","type":"message","text":"And we still have to figure out how to elegantly switch backends","user":"U67BJLYCS","ts":"1617301882.001000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"N96Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And we still have to figure out how to elegantly switch backends"}]}]}]},{"client_msg_id":"b5f31eea-5ac1-4366-bcfe-5876b59cfc6e","type":"message","text":":guitar:","user":"ULL3KSGBS","ts":"1617301882.001100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"q4d","elements":[{"type":"rich_text_section","elements":[{"type":"emoji","name":"guitar"}]}]}]},{"client_msg_id":"97b5ac2d-fd5b-4387-ac17-fe2a53c5bcac","type":"message","text":"nice. we'll try it out.","user":"ULL3KSGBS","ts":"1617301893.001300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"L9thD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"nice. we'll try it out."}]}]}]},{"client_msg_id":"439df2cc-be61-4715-b560-026d58edc6f9","type":"message","text":"But you could also choose `ROCKernels`","user":"U67BJLYCS","ts":"1617301899.001400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CgqR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But you could also choose "},{"type":"text","text":"ROCKernels","style":{"code":true}}]}]}]},{"client_msg_id":"45c84088-a717-4a4c-a420-27cc5174cffe","type":"message","text":"For the AMD support","user":"U67BJLYCS","ts":"1617301907.001500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6EpC4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For the AMD support"}]}]}]},{"client_msg_id":"74261f10-4354-4455-8b35-df448ed6e879","type":"message","text":"But that is decidedly early access","user":"U67BJLYCS","ts":"1617301924.001600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TDx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But that is decidedly early access"}]}]}]},{"client_msg_id":"82fa0489-6653-4a3d-b22e-395c6f7c4218","type":"message","text":"We should probably document that ROCKernels is experimental","user":"U6A0PD8CR","ts":"1617305614.002100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"e+x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We should probably document that ROCKernels is experimental"}]}]}]},{"client_msg_id":"326148b6-1304-48f8-92fa-ae2823f56d48","type":"message","text":"Guys, we are still chasing the Heisenbug. And at least now we seem to have an MWE that crashes hard, only when running multiple Julia instances on a GPU. So we want to polish it more. This made us curious about the general behavior of synchronization in CUDA.jl (and AMDGPU.jl). It is not clear to us when an implicit synchronization takes place like for `.=` or `copyto!`.","user":"ULL3KSGBS","ts":"1617307191.004300","team":"T68168MUP","edited":{"user":"ULL3KSGBS","ts":"1617307263.000000"},"blocks":[{"type":"rich_text","block_id":"ph4t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Guys, we are still chasing the Heisenbug. And at least now we seem to have an MWE that crashes hard, only when running multiple Julia instances on a GPU. So we want to polish it more. This made us curious about the general behavior of synchronization in CUDA.jl (and AMDGPU.jl). It is not clear to us when an implicit synchronization takes place like for "},{"type":"text","text":".=","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"copyto!","style":{"code":true}},{"type":"text","text":"."}]}]}]},{"client_msg_id":"9651521c-800a-477b-a142-5cedef10d893","type":"message","text":"We assumed so far there's an implicit synchronization when using `GPUArrays.jl` . Maybe there isn't?","user":"ULL3KSGBS","ts":"1617307231.004900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TQ1XH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We assumed so far there's an implicit synchronization when using "},{"type":"text","text":"GPUArrays.jl","style":{"code":true}},{"type":"text","text":" . Maybe there isn't?"}]}]}]},{"client_msg_id":"612b6c5d-7d38-41e4-82ad-8aef8562df0d","type":"message","text":"For CUDA, it uses the task-default stream, so all GPUArrays operations on the same Julia task serialize with each other","user":"U6A0PD8CR","ts":"1617309262.006400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"47Rc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For CUDA, it uses the task-default stream, so all GPUArrays operations on the same Julia task serialize with each other"}]}]}]},{"client_msg_id":"4a023d65-6be4-47b6-9fb4-c9ffc24eab70","type":"message","text":"But if you do things on multiple tasks, they need to explicitly sync with each other","user":"U6A0PD8CR","ts":"1617309283.006900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4ce","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But if you do things on multiple tasks, they need to explicitly sync with each other"}]}]}]},{"client_msg_id":"03aee8e4-f299-4c4d-8b72-0fb751cb31f2","type":"message","text":"oh. And if we use GPUArrays and KA?","user":"ULL3KSGBS","ts":"1617309315.007400","team":"T68168MUP","edited":{"user":"ULL3KSGBS","ts":"1617309418.000000"},"blocks":[{"type":"rich_text","block_id":"mL3g","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oh. And if we use GPUArrays and KA?"}]}]}]},{"client_msg_id":"00706377-0077-4262-a22e-45f5fde2816c","type":"message","text":"Should we synchronize when going from one to the other?","user":"ULL3KSGBS","ts":"1617309333.007800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Vh3KI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Should we synchronize when going from one to the other?"}]}]}]},{"client_msg_id":"7e63ebf8-4523-4468-9d01-c6046eb1b207","type":"message","text":"So, you need to do `wait(CudaEvent())` or something like that to sync with a non-KA stream. I *think* it will sync with just the task-local stream. <@U67BJLYCS>?","user":"U6A0PD8CR","ts":"1617309417.008900","team":"T68168MUP","edited":{"user":"U6A0PD8CR","ts":"1617309523.000000"},"blocks":[{"type":"rich_text","block_id":"cbqKa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So, you need to do "},{"type":"text","text":"wait(CudaEvent())","style":{"code":true}},{"type":"text","text":" or something like that to sync with a non-KA stream. I "},{"type":"text","text":"think","style":{"bold":true}},{"type":"text","text":" it will sync with just the task-local stream. "},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"a2fdf7d9-f120-4401-8919-9d9a26422ae3","type":"message","text":"(Or pass that event as a dependency)","user":"U6A0PD8CR","ts":"1617309436.009400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WSND","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(Or pass that event as a dependency)"}]}]}]},{"client_msg_id":"c3c7ef7b-9f6b-4f76-a431-ba9660baa890","type":"message","text":"Also, this is for CUDA master, where the task-local streams exist","user":"U6A0PD8CR","ts":"1617309460.009900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xIx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also, this is for CUDA master, where the task-local streams exist"}]}]}]},{"client_msg_id":"9b3d364e-8838-4705-a10b-329f95fa1d59","type":"message","text":"CUDA.jl 3.0 will have that when it's released","user":"U6A0PD8CR","ts":"1617309470.010200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HIQiE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"CUDA.jl 3.0 will have that when it's released"}]}]}]},{"client_msg_id":"6075f09d-766c-4808-9327-7c0d5f6dc7cd","type":"message","text":"I think I have to better understand the interaction with streams :confused: . We did not take special care of that. We use GPUArrays, and then do some KA kernel followed by a wait. That's it.","user":"ULL3KSGBS","ts":"1617309567.011500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QeDl6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think I have to better understand the interaction with streams "},{"type":"emoji","name":"confused"},{"type":"text","text":" . We did not take special care of that. We use GPUArrays, and then do some KA kernel followed by a wait. That's it."}]}]}]},{"client_msg_id":"8cf0c063-0f91-45d1-878d-8b0a3c6e8abe","type":"message","text":"And we don't use master. I think 2.6 it is.","user":"ULL3KSGBS","ts":"1617309576.011800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3Tf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And we don't use master. I think 2.6 it is."}]}]}]},{"client_msg_id":"62a42ea1-79f2-4575-9fed-611d33bcda53","type":"message","text":"&gt; We use GPUArrays, and then do some KA kernel followed by a wait. That's it.\nYeah that's probably where the bug comes from","user":"U6A0PD8CR","ts":"1617309600.012300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VhVhs","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"We use GPUArrays, and then do some KA kernel followed by a wait. That's it."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nYeah that's probably where the bug comes from"}]}]}]},{"client_msg_id":"a60672b3-ad77-4e32-85d6-0367b474d805","type":"message","text":"Wait, let me double-check","user":"U6A0PD8CR","ts":"1617309609.012600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bifr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Wait, let me double-check"}]}]}],"thread_ts":"1617309609.012600","reply_count":4,"reply_users_count":2,"latest_reply":"1617309697.013800","reply_users":["U6A0PD8CR","ULL3KSGBS"],"is_locked":false,"subscribed":false},{"client_msg_id":"2a6fb0f3-21b3-4bcd-99d7-4f3add2e8b70","type":"message","text":"so other than this wait we don't sync","user":"ULL3KSGBS","ts":"1617309611.012700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4Ug","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so other than this wait we don't sync"}]}]}]},{"client_msg_id":"5dd89c98-8e08-471c-aa5a-05910bfefe62","type":"message","text":"Ok thanks a lot! We'll do our homework then.","user":"ULL3KSGBS","ts":"1617309693.013700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uRwk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok thanks a lot! We'll do our homework then."}]}]}]},{"client_msg_id":"e7de7efb-a224-4f16-b9b1-768c00fbe622","type":"message","text":":+1:","user":"U6A0PD8CR","ts":"1617309727.014500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UdN","elements":[{"type":"rich_text_section","elements":[{"type":"emoji","name":"+1"}]}]}]},{"client_msg_id":"461f8948-54c7-4784-a50c-da46251d969f","type":"message","text":"This will also be relevant to AMDGPU, since our queues (== streams) are non-blocking, so you need to be explicit about synchronization","user":"U6A0PD8CR","ts":"1617309758.015200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F/c","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This will also be relevant to AMDGPU, since our queues (== streams) are non-blocking, so you need to be explicit about synchronization"}]}]}]},{"client_msg_id":"4e88320b-b831-44c1-90ff-b17d44471d58","type":"message","text":"alright. makes total sense. ignorance was a bliss so far.","user":"ULL3KSGBS","ts":"1617309815.015600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xr/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"alright. makes total sense. ignorance was a bliss so far."}]}]}]},{"client_msg_id":"442531ef-0c4d-4eeb-bce7-4016e07f905e","type":"message","text":"until it isn't","user":"ULL3KSGBS","ts":"1617309824.015800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ftT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"until it isn't"}]}]}]},{"client_msg_id":"724263fb-c312-4a30-8b9f-dc0f78382213","type":"message","text":"<@U6A0PD8CR> you solved it! Adding  `dependencies=Event(CUDADevice())` fixed it!!! Awesome... we should have looked earlier at `Oceananigans.jl`","user":"ULL3KSGBS","ts":"1617313735.017100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zYJa","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U6A0PD8CR"},{"type":"text","text":" you solved it! Adding  "},{"type":"text","text":"dependencies=Event(CUDADevice())","style":{"code":true}},{"type":"text","text":" fixed it!!! Awesome... we should have looked earlier at "},{"type":"text","text":"Oceananigans.jl","style":{"code":true}}]}]}]},{"client_msg_id":"6337304d-c5bc-448f-b0e4-d0a1b2c5caee","type":"message","text":"I think I explained it in my JuliaCon talk but never in the docs properly","user":"U67BJLYCS","ts":"1617323059.017400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rZSRH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think I explained it in my JuliaCon talk but never in the docs properly"}]}]}]},{"client_msg_id":"220364bf-ffcc-4ecb-bdd6-b3943b330be0","type":"message","text":"Yea, if you want we can create a small example to put in the quickstart guide. I think GPU novices like me really trip over this, since I guess KA is often used in conjunction with GPUArrays. Though, novices like me should also have read up a bit about GPUs :slightly_smiling_face: . The silent corruption is sneaky.","user":"ULL3KSGBS","ts":"1617341185.019200","team":"T68168MUP","edited":{"user":"ULL3KSGBS","ts":"1617341419.000000"},"blocks":[{"type":"rich_text","block_id":"YjUG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yea, if you want we can create a small example to put in the quickstart guide. I think GPU novices like me really trip over this, since I guess KA is often used in conjunction with GPUArrays. Though, novices like me should also have read up a bit about GPUs "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" . The silent corruption is sneaky."}]}]}]},{"client_msg_id":"a0153285-e73c-48f9-a6a6-73e8e3ba6023","type":"message","text":"That would be fantastic","user":"U67BJLYCS","ts":"1617371141.019700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5Q4d","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That would be fantastic"}]}]}]},{"client_msg_id":"f0d99f4f-5be4-4119-bfbb-232ad42a3565","type":"message","text":"@channel Hi friends! We hit another minor wall. First of all, Francois has made excellent progress and we are indeed showing the results that we eventually hoped for with the GPU code being faster than on CPU. However:\n• On larger cases, the code crashes. Larger means values of indices that go beyond the core count (~9000)\n• We implemented a batched version of the algorithm where essentially the kernel now has Cartesian indices with `batch size * problem size`. There the issue of the crashes is very prominent.\n• We use KA 0.4.6. There we have no crashes up to very large kernels. With 0.5.5 we get crashes on much smaller kernels (as in batch size and problem size, not code size, it's the same kernel).\nWe have the suspicion that it is related to going beyond the GPU core count. The CPU instantiated kernels are correct. Also if the GPU kernel returns, it's also correct.","user":"ULL3KSGBS","ts":"1617655449.004400","team":"T68168MUP","edited":{"user":"ULL3KSGBS","ts":"1617655835.000000"},"blocks":[{"type":"rich_text","block_id":"1QZXp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"@channel Hi friends! We hit another minor wall. First of all, Francois has made excellent progress and we are indeed showing the results that we eventually hoped for with the GPU code being faster than on CPU. However:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"On larger cases, the code crashes. Larger means values of indices that go beyond the core count (~9000)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"We implemented a batched version of the algorithm where essentially the kernel now has Cartesian indices with "},{"type":"text","text":"batch size * problem size","style":{"code":true}},{"type":"text","text":". There the issue of the crashes is very prominent."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"We use KA 0.4.6. There we have no crashes up to very large kernels. With 0.5.5 we get crashes on much smaller kernels (as in batch size and problem size, not code size, it's the same kernel)."}]}],"style":"bullet","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"We have the suspicion that it is related to going beyond the GPU core count. The CPU instantiated kernels are correct. Also if the GPU kernel returns, it's also correct."}]}]}]},{"client_msg_id":"3c14e958-eeff-40fe-8c13-0a1cc5d56ebd","type":"message","text":"Also, on a general note. Is it good to do the batching by increasing the size of the kernels or should we launch `batch_size` kernels? That might also avoid this issue we have.","user":"ULL3KSGBS","ts":"1617655630.005300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NPyh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also, on a general note. Is it good to do the batching by increasing the size of the kernels or should we launch "},{"type":"text","text":"batch_size","style":{"code":true}},{"type":"text","text":" kernels? That might also avoid this issue we have."}]}]}]},{"client_msg_id":"f56f1401-23df-4fa1-9968-466f0cde5be1","type":"message","text":"&gt; On larger cases, the code crashes. Larger means values of indices that go beyond the core count (~9000)\nHow does this crash manifest?","user":"U67BJLYCS","ts":"1617657874.006000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jJSY","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"On larger cases, the code crashes. Larger means values of indices that go beyond the core count (~9000)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nHow does this crash manifest?"}]}]}]},{"client_msg_id":"1695eb49-7868-422a-8984-e415abced6cd","type":"message","text":"```Device CUDADevice(): Error During Test at /scratch/mschanen/git/ExaPF.jl/test/Polar/batch_hessian.jl:26\n  Got exception outside of a @test\n  KernelException: exception thrown during kernel execution on device Quadro GV100\n  Stacktrace:\n    [1] check_exceptions()\n      @ CUDA /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/src/compiler/exceptions.jl:37\n    [2] prepare_cuda_call()\n      @ CUDA /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/src/state.jl:85\n    [3] initialize_api()\n      @ CUDA /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/lib/cudadrv/error.jl:92\n    [4] unsafe_cuEventQuery\n      @ /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/lib/cudadrv/libcuda.jl:1080 [inlined]\n    [5] query\n      @ /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/lib/cudadrv/events.jl:61 [inlined]\n    [6] isdone\n      @ /scratch/mschanen/julia_depot/packages/KernelAbstractions/X5hOr/src/backends/cuda.jl:52 [inlined]\n    [7] wait(::CPU, ev::KernelAbstractions.CudaEvent, progress::typeof(yield))\n      @ KernelAbstractions /scratch/mschanen/julia_depot/packages/KernelAbstractions/X5hOr/src/backends/cuda.jl:67\n    [8] wait (repeats 2 times)\n      @ /scratch/mschanen/julia_depot/packages/KernelAbstractions/X5hOr/src/backends/cuda.jl:61 [inlined]\n    [9] batch_adj_residual_polar!(F::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, adj_F::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 1}, vm::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, adj_vm::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, va::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, adj_va::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, ybus_re::ExaPF.Spmat{CuArray{Int64, 1}, CuArray{Float64, 1}}, ybus_im::ExaPF.Spmat{CuArray{Int64, 1}, CuArray{Float64, 1}}, transpose_perm::CuArray{Int64, 1}, pinj::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, adj_pinj::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, qinj::CuArray{Float64, 1}, edge_vm_from::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, edge_vm_to::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, edge_va_from::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, edge_va_to::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, pv::CuArray{Int64, 1}, pq::CuArray{Int64, 1}, nbus::Int64)\n      @ ExaPF /scratch/mschanen/git/ExaPF.jl/src/Polar/batch_kernel.jl:124```","user":"ULL3KSGBS","ts":"1617657907.006300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YxT","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Device CUDADevice(): Error During Test at /scratch/mschanen/git/ExaPF.jl/test/Polar/batch_hessian.jl:26\n  Got exception outside of a @test\n  KernelException: exception thrown during kernel execution on device Quadro GV100\n  Stacktrace:\n    [1] check_exceptions()\n      @ CUDA /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/src/compiler/exceptions.jl:37\n    [2] prepare_cuda_call()\n      @ CUDA /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/src/state.jl:85\n    [3] initialize_api()\n      @ CUDA /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/lib/cudadrv/error.jl:92\n    [4] unsafe_cuEventQuery\n      @ /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/lib/cudadrv/libcuda.jl:1080 [inlined]\n    [5] query\n      @ /scratch/mschanen/julia_depot/packages/CUDA/qEV3Y/lib/cudadrv/events.jl:61 [inlined]\n    [6] isdone\n      @ /scratch/mschanen/julia_depot/packages/KernelAbstractions/X5hOr/src/backends/cuda.jl:52 [inlined]\n    [7] wait(::CPU, ev::KernelAbstractions.CudaEvent, progress::typeof(yield))\n      @ KernelAbstractions /scratch/mschanen/julia_depot/packages/KernelAbstractions/X5hOr/src/backends/cuda.jl:67\n    [8] wait (repeats 2 times)\n      @ /scratch/mschanen/julia_depot/packages/KernelAbstractions/X5hOr/src/backends/cuda.jl:61 [inlined]\n    [9] batch_adj_residual_polar!(F::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, adj_F::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 1}, vm::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, adj_vm::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, va::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, adj_va::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, ybus_re::ExaPF.Spmat{CuArray{Int64, 1}, CuArray{Float64, 1}}, ybus_im::ExaPF.Spmat{CuArray{Int64, 1}, CuArray{Float64, 1}}, transpose_perm::CuArray{Int64, 1}, pinj::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, adj_pinj::SubArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2, CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, Tuple{UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, qinj::CuArray{Float64, 1}, edge_vm_from::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, edge_vm_to::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, edge_va_from::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, edge_va_to::CuArray{ForwardDiff.Dual{Nothing, Float64, 1}, 2}, pv::CuArray{Int64, 1}, pq::CuArray{Int64, 1}, nbus::Int64)\n      @ ExaPF /scratch/mschanen/git/ExaPF.jl/src/Polar/batch_kernel.jl:124"}]}]}]},{"client_msg_id":"8fd0b9f3-ce47-41d0-a231-855a8a14e2e4","type":"message","text":"hm that is not helpful","user":"U67BJLYCS","ts":"1617657926.006600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PalTg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hm that is not helpful"}]}]}]},{"client_msg_id":"d80f4e2c-acbc-4433-83b9-78f473ec1411","type":"message","text":"can you run with `julia -g2`","user":"U67BJLYCS","ts":"1617657940.006900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2vNC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"can you run with "},{"type":"text","text":"julia -g2","style":{"code":true}}]}]}]},{"client_msg_id":"896840ec-dc31-4f77-bc41-7aacd4bb8949","type":"message","text":"sure","user":"ULL3KSGBS","ts":"1617657946.007100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DKrYK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"sure"}]}]}]},{"client_msg_id":"98f4cb89-0250-4338-9b4f-01284cf8ddd9","type":"message","text":"this is a device level exception...","user":"U67BJLYCS","ts":"1617657961.007500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qgP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this is a device level exception..."}]}]}]},{"client_msg_id":"a87864c3-33a2-414a-b583-16cf021978d5","type":"message","text":"regarding size problems:","user":"U67BJLYCS","ts":"1617657973.007800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"68NbM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"regarding size problems:"}]}]}]},{"client_msg_id":"420f6eb5-9444-47f1-b5c0-d612f4a4882e","type":"message","text":"the maximum size of a block is `1024`","user":"U67BJLYCS","ts":"1617657983.008100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5wnT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the maximum size of a block is "},{"type":"text","text":"1024","style":{"code":true}}]}]}]},{"client_msg_id":"c0f52914-02f0-4ae7-87c6-b3011ef02bfc","type":"message","text":"So the not maximum number of blocks, but the maximum size of a block?","user":"ULL3KSGBS","ts":"1617658031.008800","team":"T68168MUP","edited":{"user":"ULL3KSGBS","ts":"1617658042.000000"},"blocks":[{"type":"rich_text","block_id":"CuIgm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So the not maximum number of blocks, but the maximum size of a block?"}]}]}]},{"client_msg_id":"8ee882bb-db52-4006-920b-6bb5ce541b31","type":"message","text":"but you should be able to have `2^(31-1)` blocks","user":"U67BJLYCS","ts":"1617658038.009100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1PW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but you should be able to have "},{"type":"text","text":"2^(31-1)","style":{"code":true}},{"type":"text","text":" blocks"}]}]}]},{"client_msg_id":"913d3e23-aec9-450d-8c44-ecf417c569ae","type":"message","text":"ok","user":"ULL3KSGBS","ts":"1617658047.009600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dlsU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ok"}]}]}]},{"client_msg_id":"bfe185e6-0642-40d5-9803-00561a9a6077","type":"message","text":"yeah the maximum size of a block","user":"U67BJLYCS","ts":"1617658050.009800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"a3RW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah the maximum size of a block"}]}]}]},{"client_msg_id":"950898d9-08f3-41ab-bf31-9608a0459a09","type":"message","text":"brr with `-g2` it does not seem to crash. of course.","user":"ULL3KSGBS","ts":"1617658130.010300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DpZUK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"brr with "},{"type":"text","text":"-g2","style":{"code":true}},{"type":"text","text":" it does not seem to crash. of course."}]}]}]},{"client_msg_id":"8fc4fbc3-3da2-48b2-a404-c77b11acaed3","type":"message","text":"what are the sizes for `workgroupsize` and `ndrange`?","user":"U67BJLYCS","ts":"1617658135.010500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KON","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what are the sizes for "},{"type":"text","text":"workgroupsize","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"ndrange","style":{"code":true}},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"45ef5bd0-1cbe-4985-815a-dba65387f5ab","type":"message","text":"we did not set a workgroup size. the ndrange was `(667, 64)` now, but I'm running a bigger case.","user":"ULL3KSGBS","ts":"1617658226.011100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HDf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"we did not set a workgroup size. the ndrange was "},{"type":"text","text":"(667, 64)","style":{"code":true}},{"type":"text","text":" now, but I'm running a bigger case."}]}]}]},{"client_msg_id":"b8c78dea-435f-4425-8fb6-e78d84c6260d","type":"message","text":"okay","user":"U67BJLYCS","ts":"1617658252.011300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TBE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"okay"}]}]}]},{"client_msg_id":"24e07845-f555-4a83-b9ea-e631957c3c9b","type":"message","text":"On 0.4.6 not passing a workgroup size will default you to 256 -- <https://github.com/JuliaGPU/KernelAbstractions.jl/blob/2d99c3fdb689ab7a2b827d511c9d7c5b3d980811/src/backends/cuda.jl#L150>","user":"U67BJLYCS","ts":"1617658337.011900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gQPD=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"On 0.4.6 not passing a workgroup size will default you to 256 -- "},{"type":"link","url":"https://github.com/JuliaGPU/KernelAbstractions.jl/blob/2d99c3fdb689ab7a2b827d511c9d7c5b3d980811/src/backends/cuda.jl#L150"}]}]}]},{"client_msg_id":"4708c409-bc1d-46a4-8378-cfd993db3263","type":"message","text":"`(2966, 64)` is for the larger case that we use for debugging.","user":"ULL3KSGBS","ts":"1617658347.012200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ai4h/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(2966, 64)","style":{"code":true}},{"type":"text","text":" is for the larger case that we use for debugging."}]}]}]},{"client_msg_id":"47f73ec7-ea07-4d09-920c-600ea6fa2cad","type":"message","text":"on 0.5.5 we try to auto-tune your kernel","user":"U67BJLYCS","ts":"1617658400.012500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TFN8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"on 0.5.5 we try to auto-tune your kernel"}]}]}]},{"client_msg_id":"9a91088b-2eb4-406f-bcd4-c4f7662325b8","type":"message","text":"<https://github.com/JuliaGPU/KernelAbstractions.jl/blob/cd2a4c00743f523d5722d140a246ea79ccaec010/src/backends/cuda.jl#L180-L199>","user":"U67BJLYCS","ts":"1617658400.012700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QDm","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/JuliaGPU/KernelAbstractions.jl/blob/cd2a4c00743f523d5722d140a246ea79ccaec010/src/backends/cuda.jl#L180-L199"}]}]}]}]}