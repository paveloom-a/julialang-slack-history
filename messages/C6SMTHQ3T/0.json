{"cursor": 1, "messages": [{"client_msg_id":"b74d124b-f12e-473a-a783-94ae9204bfe2","type":"message","text":"<https://github.com/JuliaLang/julia/issues/35689>","user":"U6QGE7S86","ts":"1611791888.014100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HAHZj","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/JuliaLang/julia/issues/35689"}]}]}]},{"client_msg_id":"cece9e96-76d2-49c9-808f-dd51c9a2812b","type":"message","text":"Yep, that is it!","user":"U67BXBF99","ts":"1611803827.014300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pgCFS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yep, that is it!"}]}]}]},{"client_msg_id":"98c7a938-e180-46d5-a962-755bf659fe27","type":"message","text":"Awesome, because","user":"U6QGE7S86","ts":"1611804772.014500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rDaip","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Awesome, because"}]}]}]},{"client_msg_id":"0e55a14f-090b-4bec-9d05-a29166917aac","type":"message","text":"I have no clue how to begin with tackling that.","user":"U6QGE7S86","ts":"1611804912.015000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lT0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have no clue how to begin with tackling that."}]}]}]},{"client_msg_id":"ef06ce00-8da5-46fa-bcb8-208974f3f31c","type":"message","text":":seedling:","user":"U6QGE7S86","ts":"1611804924.015300","team":"T68168MUP","edited":{"user":"U6QGE7S86","ts":"1611805311.000000"},"blocks":[{"type":"rich_text","block_id":"AZJV/","elements":[{"type":"rich_text_section","elements":[{"type":"emoji","name":"seedling"}]}]}]},{"client_msg_id":"0708a371-695d-4ad1-98fd-663f5ec7fc5f","type":"message","text":"But I will soon! Just need some reading and a bit of elbow grease.","user":"U6QGE7S86","ts":"1611804939.015600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7tw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But I will soon! Just need some reading and a bit of elbow grease."}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"(If anyone has a handy tutorial for advance C programming just a bit beyond structs it's more than welcome at this point)","user":"U6QGE7S86","ts":"1612318339.017600","thread_ts":"1611791884.013900","root":{"client_msg_id":"bfe4f465-3214-4ec9-bdd8-d91a7958746c","type":"message","text":"Hey <@U687RKK0E> and <@U67BXBF99> - is this the finalizers issue you discussed in the call?","user":"U6QGE7S86","ts":"1611791884.013900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DUB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey "},{"type":"user","user_id":"U687RKK0E"},{"type":"text","text":" and "},{"type":"user","user_id":"U67BXBF99"},{"type":"text","text":" - is this the finalizers issue you discussed in the call?"}]}]}],"thread_ts":"1611791884.013900","reply_count":9,"reply_users_count":2,"latest_reply":"1612377985.019200","reply_users":["U6QGE7S86","U687RKK0E"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"unB9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(If anyone has a handy tutorial for advance C programming just a bit beyond structs it's more than welcome at this point)"}]}]}],"client_msg_id":"942ca386-7081-4b68-b762-aaa53438a6f9"},{"client_msg_id":"45caafda-882d-48bb-8e64-337b4c8690fc","type":"message","text":"Found a decent tutorial so far","user":"U6QGE7S86","ts":"1612325514.018000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ecu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Found a decent tutorial so far"}]}]}]},{"client_msg_id":"ccf4e22d-87bf-4d1b-bf0a-49fb979f38ae","type":"message","text":"<https://nikhilm.github.io/uvbook/filesystem.html>","user":"U6QGE7S86","ts":"1612325516.018200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UuP","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://nikhilm.github.io/uvbook/filesystem.html"}]}]}]},{"client_msg_id":"FCA87329-566F-40A1-9336-DB65D80F442E","type":"message","text":"How does Julia’s profiler interact with having multiple threads? I assume the profiler is just showing time for the main thread, including time the main thread spends blocked? In my flame graph I see something separate from my computation called task_done_hook taking up a significant amount of time. Clearly it has something to do with the threaded task system, but what is it exactly?","user":"ULD19UCPK","ts":"1612393496.024000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yi=Y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How does Julia’s profiler interact with having multiple threads? I assume the profiler is just showing time for the main thread, including time the main thread spends blocked? In my flame graph I see something separate from my computation called task_done_hook taking up a significant amount of time. Clearly it has something to do with the threaded task system, but what is it exactly?"}]}]}],"thread_ts":"1612393496.024000","reply_count":1,"reply_users_count":1,"latest_reply":"1612445571.028100","reply_users":["U6A0PD8CR"],"subscribed":false},{"client_msg_id":"94f943ce-8c4a-42e8-b99f-74b26357c414","type":"message","text":"it samples all threads","user":"U67BJLYCS","ts":"1612396905.024400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gQe3K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it samples all threads"}]}]}]},{"client_msg_id":"a6658344-fabb-45e9-8bb5-810356c9ef96","type":"message","text":"<@U8JAMQGQY> and I are looking for a solution to make PooledArrays and CategoricalArrays thread-safe, despite their using a `Dict` internally. Let's imagine one thread does only `Dict` lookups, and another one only adds new entries to it (without modifying existing ones). Is that OK, or does the addition of new entries leave the `Dict` in a temporarily invalid state that would make lookups from the other thread be incorrect? (Assuming that the table doesn't need to be resized for now.)","user":"U67431ELR","ts":"1612441539.027800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"53u","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U8JAMQGQY"},{"type":"text","text":" and I are looking for a solution to make PooledArrays and CategoricalArrays thread-safe, despite their using a "},{"type":"text","text":"Dict","style":{"code":true}},{"type":"text","text":" internally. Let's imagine one thread does only "},{"type":"text","text":"Dict","style":{"code":true}},{"type":"text","text":" lookups, and another one only adds new entries to it (without modifying existing ones). Is that OK, or does the addition of new entries leave the "},{"type":"text","text":"Dict","style":{"code":true}},{"type":"text","text":" in a temporarily invalid state that would make lookups from the other thread be incorrect? (Assuming that the table doesn't need to be resized for now.)"}]}]}],"thread_ts":"1612441539.027800","reply_count":1,"reply_users_count":1,"latest_reply":"1612441801.027900","reply_users":["U8JAMQGQY"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"That’s kind of what I thought. I was profiling code using the old thread macro, Tullio, and ThreadsX and seeing a lot of time spent waiting in task_done_hook. The code using Tullio, for example, has 70% of traced samples in that function. I assume that means Tullio is splitting work up too finely between tasks. ","user":"ULD19UCPK","ts":"1612465816.033600","thread_ts":"1612393496.024000","root":{"client_msg_id":"FCA87329-566F-40A1-9336-DB65D80F442E","type":"message","text":"How does Julia’s profiler interact with having multiple threads? I assume the profiler is just showing time for the main thread, including time the main thread spends blocked? In my flame graph I see something separate from my computation called task_done_hook taking up a significant amount of time. Clearly it has something to do with the threaded task system, but what is it exactly?","user":"ULD19UCPK","ts":"1612393496.024000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yi=Y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How does Julia’s profiler interact with having multiple threads? I assume the profiler is just showing time for the main thread, including time the main thread spends blocked? In my flame graph I see something separate from my computation called task_done_hook taking up a significant amount of time. Clearly it has something to do with the threaded task system, but what is it exactly?"}]}]}],"thread_ts":"1612393496.024000","reply_count":4,"reply_users_count":2,"latest_reply":"1612466173.038500","reply_users":["U6A0PD8CR","ULD19UCPK"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"kIC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That’s kind of what I thought. I was profiling code using the old thread macro, Tullio, and ThreadsX and seeing a lot of time spent waiting in task_done_hook. The code using Tullio, for example, has 70% of traced samples in that function. I assume that means Tullio is splitting work up too finely between tasks. "}]}]}],"client_msg_id":"23FC90B4-8623-47EF-80F3-6D39AD7897D1"},{"type":"message","subtype":"thread_broadcast","text":"Does the main thread sit waiting or does it also do work? In my (not at all comparable to Tullio) code using the threads macro I see roughly ~20-25% of my time in task_done_hook on my 4 core machine, which  would make sense if the main thread was waiting for the threaded code to end. ","user":"ULD19UCPK","ts":"1612466021.036700","thread_ts":"1612393496.024000","root":{"client_msg_id":"FCA87329-566F-40A1-9336-DB65D80F442E","type":"message","text":"How does Julia’s profiler interact with having multiple threads? I assume the profiler is just showing time for the main thread, including time the main thread spends blocked? In my flame graph I see something separate from my computation called task_done_hook taking up a significant amount of time. Clearly it has something to do with the threaded task system, but what is it exactly?","user":"ULD19UCPK","ts":"1612393496.024000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yi=Y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How does Julia’s profiler interact with having multiple threads? I assume the profiler is just showing time for the main thread, including time the main thread spends blocked? In my flame graph I see something separate from my computation called task_done_hook taking up a significant amount of time. Clearly it has something to do with the threaded task system, but what is it exactly?"}]}]}],"thread_ts":"1612393496.024000","reply_count":4,"reply_users_count":2,"latest_reply":"1612466173.038500","reply_users":["U6A0PD8CR","ULD19UCPK"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"MYJBN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does the main thread sit waiting or does it also do work? In my (not at all comparable to Tullio) code using the threads macro I see roughly ~20-25% of my time in task_done_hook on my 4 core machine, which  would make sense if the main thread was waiting for the threaded code to end. "}]}]}],"client_msg_id":"F4D5E145-3F62-49AE-9575-3B28221BA6DE"},{"client_msg_id":"6876ff0b-f813-41fe-ba58-ae62d1ccad1a","type":"message","text":"I am slowly getting familiar with julia's multi threading system. Except for the Computation Thinking course and a few other stuff(docs etc.) there isn't a great info/example of the capabilities.\nI wish to use multithreading(or other parallel methods) to speedup reading and writing into an in-memory data structure. Anything(pacakge, gist, blog)  covering lock/unlock, @async etc. would be really helpful. Thank you. :slightly_smiling_face:","user":"ULX78CTC3","ts":"1612698271.050000","team":"T68168MUP","edited":{"user":"ULX78CTC3","ts":"1612698427.000000"},"blocks":[{"type":"rich_text","block_id":"3vW/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am slowly getting familiar with julia's multi threading system. Except for the Computation Thinking course and a few other stuff(docs etc.) there isn't a great info/example of the capabilities.\nI wish to use multithreading(or other parallel methods) to speedup reading and writing into an in-memory data structure. Anything(pacakge, gist, blog)  covering lock/unlock, @async etc. would be really helpful. Thank you. "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"3a29e15e-e1dd-4359-969b-dd310a30fa69","type":"message","text":"Hi everyone!\n\nI'm interested in lock-free and wait-free datastructures, does anyone know about implementations/drafts/challenges/ideas in combination with julia? I'd be happy about any pointers (hehe). I'm aware of some basic capability in `Base.Threads`, but as far as I can tell that's only lock-based. Thank you very much!","user":"UH24GRBLL","ts":"1612772094.053600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qAtBv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi everyone!\n\nI'm interested in lock-free and wait-free datastructures, does anyone know about implementations/drafts/challenges/ideas in combination with julia? I'd be happy about any pointers (hehe). I'm aware of some basic capability in "},{"type":"text","text":"Base.Threads","style":{"code":true}},{"type":"text","text":", but as far as I can tell that's only lock-based. Thank you very much!"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"In particular, I think I'd need atomic references, but Base.Threads only seems to have atomics for isbits number types like Bool, Ints, Floats..","user":"UH24GRBLL","ts":"1612777531.056200","thread_ts":"1612772094.053600","root":{"client_msg_id":"3a29e15e-e1dd-4359-969b-dd310a30fa69","type":"message","text":"Hi everyone!\n\nI'm interested in lock-free and wait-free datastructures, does anyone know about implementations/drafts/challenges/ideas in combination with julia? I'd be happy about any pointers (hehe). I'm aware of some basic capability in `Base.Threads`, but as far as I can tell that's only lock-based. Thank you very much!","user":"UH24GRBLL","ts":"1612772094.053600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qAtBv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi everyone!\n\nI'm interested in lock-free and wait-free datastructures, does anyone know about implementations/drafts/challenges/ideas in combination with julia? I'd be happy about any pointers (hehe). I'm aware of some basic capability in "},{"type":"text","text":"Base.Threads","style":{"code":true}},{"type":"text","text":", but as far as I can tell that's only lock-based. Thank you very much!"}]}]}],"thread_ts":"1612772094.053600","reply_count":7,"reply_users_count":2,"latest_reply":"1612777531.056200","reply_users":["UH24GRBLL","U01CQTKB86N"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"okd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In particular, I think I'd need atomic references, but Base.Threads only seems to have atomics for isbits number types like Bool, Ints, Floats.."}]}]}],"client_msg_id":"c983b452-55a9-4be7-b090-fb74576d2820"},{"client_msg_id":"4fd6125d-9cf3-461e-8745-1cbe55eb6edd","type":"message","text":"Is mul!(A, B, C, 1, 1)  thread safe in the sense that multiple threads can call it with possibly the same A without changing the result?","user":"UGUAWEMMK","ts":"1612808541.063700","team":"T68168MUP","edited":{"user":"UGUAWEMMK","ts":"1612808578.000000"},"blocks":[{"type":"rich_text","block_id":"Z6=DX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is mul!(A, B, C, 1, 1)  thread safe in the sense that multiple threads can call it with possibly the same A without changing the result?"}]}]}]},{"client_msg_id":"cbf64f6e-7127-44ea-b5c1-84f75239bde5","type":"message","text":"No.","user":"U8D9768Q6","ts":"1612808610.064000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"itI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"No."}]}]}],"reactions":[{"name":"sob","users":["UGUAWEMMK"],"count":1}]},{"client_msg_id":"3b2ea08f-9165-42c7-bb33-17d6924d6023","type":"message","text":"Every element of `A` is being mutated in place, so it'd be disastrous to have multiple threads try to do that simultaneously","user":"U8D9768Q6","ts":"1612808684.065100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"N8HTz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Every element of "},{"type":"text","text":"A","style":{"code":true}},{"type":"text","text":" is being mutated in place, so it'd be disastrous to have multiple threads try to do that simultaneously"}]}]}]},{"client_msg_id":"e3408e9c-e3e2-4a5d-881b-9243f9cb40b7","type":"message","text":"But we are only adding to the elements, no?","user":"UGUAWEMMK","ts":"1612808699.065600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PTE0b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But we are only adding to the elements, no?"}]}]}]},{"client_msg_id":"920b9271-2962-4ab3-8750-fc5d997fdf85","type":"message","text":"Any function which mutates an array in place without locks will be thread-unsafe. If you put locks all over the place, it'd presumably be too slow to be appropriate for BLAS","user":"U8D9768Q6","ts":"1612808819.067600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G52","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any function which mutates an array in place without locks will be thread-unsafe. If you put locks all over the place, it'd presumably be too slow to be appropriate for BLAS"}]}]}]},{"client_msg_id":"23299805-e114-4daa-a703-dbcf985def88","type":"message","text":"`mul!` will not do an atomic update","user":"U67BJLYCS","ts":"1612808920.070800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qels","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"mul!","style":{"code":true}},{"type":"text","text":" will not do an atomic update"}]}]}]},{"client_msg_id":"5a79c342-27e3-4cba-ba0f-f169b3e5b391","type":"message","text":"so mason is right, multiple writers will cause corrupted results","user":"U67BJLYCS","ts":"1612808945.071800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UlRV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so mason is right, multiple writers will cause corrupted results"}]}]}]},{"client_msg_id":"a9ccb667-977a-4c74-8448-897bb052516a","type":"message","text":"It's possible that with something like Octavian.jl's threading scheme, you could lock chunks and mark them as safe and then multiple of it's matmuls could happen in tandem in theory, but I doubt it'd be worth it","user":"U8D9768Q6","ts":"1612808951.072100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DIu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's possible that with something like Octavian.jl's threading scheme, you could lock chunks and mark them as safe and then multiple of it's matmuls could happen in tandem in theory, but I doubt it'd be worth it"}]}]}],"reactions":[{"name":"point_up","users":["U6A0PD8CR","U7THT3TM3"],"count":2}]},{"client_msg_id":"f7ad9372-e1cd-47e0-ae9f-59af2fa71de7","type":"message","text":"Example of this not behaving as you'd desire:\nT1: Read A (1.0)\nT2: Read A (1.0)\nT1: Add 1.0 to local A (2.0)\nT2: Sub 1.0 from local A (0.0)\nT1 and T2: Store local A to A (2.0 or 0.0, neither is what you wanted)","user":"U6A0PD8CR","ts":"1612808952.072300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9HC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Example of this not behaving as you'd desire:\nT1: Read A (1.0)\nT2: Read A (1.0)\nT1: Add 1.0 to local A (2.0)\nT2: Sub 1.0 from local A (0.0)\nT1 and T2: Store local A to A (2.0 or 0.0, neither is what you wanted)"}]}]}]},{"client_msg_id":"f27f9901-447f-425d-973a-898ac0a369d9","type":"message","text":"If your R-M-W is not \"atomic\" w.r.t other threads, you'll have a bad time","user":"U6A0PD8CR","ts":"1612808983.072800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"e3PE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If your R-M-W is not \"atomic\" w.r.t other threads, you'll have a bad time"}]}]}]},{"client_msg_id":"e4bf0b0e-08cd-4575-963f-a4a871b6d0ce","type":"message","text":"And atomics are necessarily slow","user":"U6A0PD8CR","ts":"1612808996.073100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QYMg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And atomics are necessarily slow"}]}]}]},{"client_msg_id":"d2aed8f6-9c1a-4c64-bfe7-ceefa7201607","type":"message","text":"It's important to remember that memory doesn't work like registers: unless you use atomics, you can only do a read or a write, but not both","user":"U6A0PD8CR","ts":"1612809121.074800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rguuP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's important to remember that memory doesn't work like registers: unless you use atomics, you can only do a read or a write, but not both"}]}]}]},{"client_msg_id":"13c8edbe-5eb9-499a-8545-e808608f350b","type":"message","text":"synchronization is slow, so it's best to avoid it altogether. That's why I asked about lock-free and wait-free stuff in the first place :)","user":"UH24GRBLL","ts":"1612809135.075300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Cbc1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"synchronization is slow, so it's best to avoid it altogether. That's why I asked about lock-free and wait-free stuff in the first place :)"}]}]}]},{"client_msg_id":"698bf3dc-2f8f-42ee-b5b0-135cd2f2e103","type":"message","text":"I see, so basically the best thing to do here is to pre-allocated each thread their own copy of the output and then sum them up after the threaded loop finishes","user":"UGUAWEMMK","ts":"1612809206.076100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n/Au","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I see, so basically the best thing to do here is to pre-allocated each thread their own copy of the output and then sum them up after the threaded loop finishes"}]}]}]},{"client_msg_id":"c5090ace-cc4a-4857-914d-b5eae3b4215f","type":"message","text":"Thanks! I guess I was being a bit optimistic there :smile:","user":"UGUAWEMMK","ts":"1612809263.076700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HKHUM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks! I guess I was being a bit optimistic there "},{"type":"emoji","name":"smile"}]}]}]},{"client_msg_id":"1ea7711a-b34f-418e-ae13-bf68996644e0","type":"message","text":"Yeah, that can work, or you can do it in blocks as Mason pointed it","user":"U6A0PD8CR","ts":"1612809280.077100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"esNy6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, that can work, or you can do it in blocks as Mason pointed it"}]}]}]},{"client_msg_id":"082990f0-665d-4eae-86db-5553d99aafe1","type":"message","text":"There's a reason that people say multithreading is hard :slightly_smiling_face:","user":"U6A0PD8CR","ts":"1612809304.077400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T0d","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's a reason that people say multithreading is hard "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"79df7517-65a6-4543-9a12-2d84215c2343","type":"message","text":"I want to finally parallelize my code and to gauge my success I wish to see how it scales with the number of threads. Is there a way of accomplishing this without restarting Julia over and over again?\n\nI was thinking maybe starting Julia with the maximum number of threads, then in the `Threads.@threads` loop only work in the first `n` threads, letting the other idle. Will this work the way I expect?","user":"UC6LC14MA","ts":"1612855279.080300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+g2/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I want to finally parallelize my code and to gauge my success I wish to see how it scales with the number of threads. Is there a way of accomplishing this without restarting Julia over and over again?\n\nI was thinking maybe starting Julia with the maximum number of threads, then in the "},{"type":"text","text":"Threads.@threads","style":{"code":true}},{"type":"text","text":" loop only work in the first "},{"type":"text","text":"n","style":{"code":true}},{"type":"text","text":" threads, letting the other idle. Will this work the way I expect?"}]}]}]},{"client_msg_id":"52a8859f-ac34-4364-8bc0-feea29138fe3","type":"message","text":"On a tangent, when should I use `Threads.@threads`, and when is `Threads.@spawn` more appropriate?","user":"UC6LC14MA","ts":"1612855390.081000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LGC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"On a tangent, when should I use "},{"type":"text","text":"Threads.@threads","style":{"code":true}},{"type":"text","text":", and when is "},{"type":"text","text":"Threads.@spawn","style":{"code":true}},{"type":"text","text":" more appropriate?"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"Looks like this week is again our regularly scheduled #multithreaded discussion call on Wednesday! Let me know if you have any items for the agenda. I’m hoping to soon start actually tackling some of the implementation work I’ve been planning for many months and finalizing some remaining design questions.\n<@U67BJLYCS> <@U6A0PD8CR> <@U687RKK0E> <@U6QGE7S86> <@U680B1MTJ> <@UB7JS9CHF> <@U679VPJ8L>\n<@UP9P4JFNJ> <@UDGT4PM41> <@U01GX4L17PW> <@U68A3ASP9> <@U01M9K523NW> et al.\n\n<https://calendar.google.com/event?action=TEMPLATE&amp;tmeid=MzQ1MnZxMGNucGt2NGQwYW1zZjA4MzM5dGtfMjAyMTAyMTdUMTYzMDAwWiBqdWxpYWxhbmcub3JnX2tvbWF1YXFldDE0ZW9nOW9pdjNwNm83cG1nQGc&amp;tmsrc=julialang.org_komauaqet14eog9oiv3p6o7pmg%40group.calendar.google.com&amp;scp=ALL>","user":"U67BXBF99","ts":"1613415691.085200","thread_ts":"1596507680.147500","root":{"client_msg_id":"a983bc33-e374-450e-a499-326eed3b14d9","type":"message","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on <https://meet.google.com/ugr-sbmu-wts>, for anyone that wants to drop by and discuss threads and atomics!","user":"U67BXBF99","ts":"1596507680.147500","team":"T68168MUP","attachments":[{"title":"Meet","title_link":"https://meet.google.com/ugr-sbmu-wts","text":"Real-time meetings by Google. Using your browser, share your video, desktop, and presentations with teammates and customers.","fallback":"Meet","thumb_url":"https://www.gstatic.com/images/branding/product/2x/meet_96dp.png","from_url":"https://meet.google.com/ugr-sbmu-wts","thumb_width":192,"thumb_height":192,"service_icon":"http://www.gstatic.com/images/branding/product/1x/meet_16dp.png","service_name":"meet.google.com","id":1,"original_url":"https://meet.google.com/ugr-sbmu-wts"}],"blocks":[{"type":"rich_text","block_id":"HrV1l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on "},{"type":"link","url":"https://meet.google.com/ugr-sbmu-wts"},{"type":"text","text":", for anyone that wants to drop by and discuss threads and atomics!"}]}]}],"thread_ts":"1596507680.147500","reply_count":62,"reply_users_count":10,"latest_reply":"1613415691.085200","reply_users":["ULY7Q1X53","U67BXBF99","UF9T3JL4D","USU9FRPEU","U6A936746","UB7JS9CHF","U67BJLYCS","U6A0PD8CR","U6QGE7S86","UP9P4JFNJ"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"XcP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looks like this week is again our regularly scheduled #multithreaded discussion call on Wednesday! Let me know if you have any items for the agenda. I’m hoping to soon start actually tackling some of the implementation work I’ve been planning for many months and finalizing some remaining design questions.\n"},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":" "},{"type":"user","user_id":"U6A0PD8CR"},{"type":"text","text":" "},{"type":"user","user_id":"U687RKK0E"},{"type":"text","text":" "},{"type":"user","user_id":"U6QGE7S86"},{"type":"text","text":" "},{"type":"user","user_id":"U680B1MTJ"},{"type":"text","text":" "},{"type":"user","user_id":"UB7JS9CHF"},{"type":"text","text":" "},{"type":"user","user_id":"U679VPJ8L"},{"type":"text","text":"\n"},{"type":"user","user_id":"UP9P4JFNJ"},{"type":"text","text":" "},{"type":"user","user_id":"UDGT4PM41"},{"type":"text","text":" "},{"type":"user","user_id":"U01GX4L17PW"},{"type":"text","text":" "},{"type":"user","user_id":"U68A3ASP9"},{"type":"text","text":" "},{"type":"user","user_id":"U01M9K523NW"},{"type":"text","text":" et al.\n\n"},{"type":"link","url":"https://calendar.google.com/event?action=TEMPLATE&tmeid=MzQ1MnZxMGNucGt2NGQwYW1zZjA4MzM5dGtfMjAyMTAyMTdUMTYzMDAwWiBqdWxpYWxhbmcub3JnX2tvbWF1YXFldDE0ZW9nOW9pdjNwNm83cG1nQGc&tmsrc=julialang.org_komauaqet14eog9oiv3p6o7pmg%40group.calendar.google.com&scp=ALL"}]}]}],"client_msg_id":"5c9e1285-90bc-4ff5-bbe8-862a9e394c86"},{"type":"message","subtype":"channel_join","ts":"1613420701.086300","user":"U01M9K523NW","text":"<@U01M9K523NW> has joined the channel","inviter":"U67BXBF99"},{"client_msg_id":"3e99b10e-8011-4f8c-b201-9e4fd9d8d7a3","type":"message","text":"Did I get the time wrong?  Google calendar has it at 11:30EST","user":"UB7JS9CHF","ts":"1613579559.088600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Z8G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Did I get the time wrong?  Google calendar has it at 11:30EST"}]}]}]},{"client_msg_id":"888c81c5-aeba-43e4-b0e8-c83ec25b23c0","type":"message","text":"<@UC7AF7NSU> The call discussed some of your work with Tapir and Julia integration. Is it something you can share/talk about here?","user":"U6QGE7S86","ts":"1613584675.089900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1xsJ","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UC7AF7NSU"},{"type":"text","text":" The call discussed some of your work with Tapir and Julia integration. Is it something you can share/talk about here?"}]}]}]},{"client_msg_id":"6409f8e0-a10d-4f80-beb5-cf0d39039123","type":"message","text":"(It sounds great!)","user":"U6QGE7S86","ts":"1613584717.090100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eNFlL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(It sounds great!)"}]}]}]},{"client_msg_id":"42977d94-3090-488d-a753-fa0dee890bfb","type":"message","text":"ah, it was brought up in the meeting? sorry I missed it...","user":"UC7AF7NSU","ts":"1613589441.090600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"N+31y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ah, it was brought up in the meeting? sorry I missed it..."}]}]}]},{"client_msg_id":"12a45c78-4bea-4bea-847a-3c2dd2f98a70","type":"message","text":"there's no recorded talk about this yet. but I'm thinking to open a PR for kicking off some discussions","user":"UC7AF7NSU","ts":"1613589448.090800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iA3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"there's no recorded talk about this yet. but I'm thinking to open a PR for kicking off some discussions"}]}]}]},{"client_msg_id":"62d849ee-c246-422e-ae06-19a9af97bc0f","type":"message","text":"What is the best way to make a multithreaded map(), Threadtools?","user":"U01C3624SGJ","ts":"1613589663.091700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7mB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is the best way to make a multithreaded map(), Threadtools?"}]}]}]},{"client_msg_id":"23d660f7-99b7-4f5b-9280-30dc81b013a9","type":"message","text":"You just do something like <https://github.com/SciML/SciMLBase.jl/blob/master/src/ensemble/basic_ensemble_solve.jl#L218-L224>","user":"U69BL50BF","ts":"1613589707.091900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tPTSi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You just do something like "},{"type":"link","url":"https://github.com/SciML/SciMLBase.jl/blob/master/src/ensemble/basic_ensemble_solve.jl#L218-L224"}]}]}],"reactions":[{"name":"thumbsup_all","users":["U01C3624SGJ"],"count":1}]},{"client_msg_id":"18ae40e4-7cf5-4501-b570-8dd383d448cf","type":"message","text":"there's an adjoint for this as well","user":"U69BL50BF","ts":"1613589713.092100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"c55","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"there's an adjoint for this as well"}]}]}]},{"client_msg_id":"6c478fc2-88d6-438f-80ec-21505b9ee6f9","type":"message","text":"I'd definitely reccomend using ThreadsX.jl or Folds.jl","user":"U8D9768Q6","ts":"1613589882.092600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ItHtk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd definitely reccomend using ThreadsX.jl or Folds.jl"}]}]}]},{"client_msg_id":"5a2bb656-3f93-4de9-adad-f7c939697eb8","type":"message","text":"IIRC they did individual spawning and had high overhead from that instead of partitioning?","user":"U69BL50BF","ts":"1613590312.093400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QrN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"IIRC they did individual spawning and had high overhead from that instead of partitioning?"}]}]}]},{"client_msg_id":"799d37de-ca0f-4cb9-a140-0455ac702597","type":"message","text":"They partition using a 'splitting' algorithm <https://github.com/JuliaFolds/SplittablesBase.jl>. It does have higher overhead than the function you linked, but it has the advantages of load balancing, composability with other multithdreaded functions (`Threads.@threads` will destructively interfere with any other multi-threaded work happening), working on more general datstructures, and not relying on `Core.Compiler.return_type`","user":"U8D9768Q6","ts":"1613591112.096000","team":"T68168MUP","edited":{"user":"U8D9768Q6","ts":"1613591184.000000"},"blocks":[{"type":"rich_text","block_id":"T4wra","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"They partition using a 'splitting' algorithm "},{"type":"link","url":"https://github.com/JuliaFolds/SplittablesBase.jl"},{"type":"text","text":". It does have higher overhead than the function you linked, but it has the advantages of load balancing, composability with other multithdreaded functions ("},{"type":"text","text":"Threads.@threads","style":{"code":true}},{"type":"text","text":" will destructively interfere with any other multi-threaded work happening), working on more general datstructures, and not relying on "},{"type":"text","text":"Core.Compiler.return_type","style":{"code":true}}]}]}]},{"client_msg_id":"0c845f93-ddc8-4d03-8b50-9aed88c1c1ef","type":"message","text":"You also can specify your own `basesize` for the partitioning which lets you encode prior knowledge about what sizes are the most appropriate","user":"U8D9768Q6","ts":"1613591273.097300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"L5mfK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You also can specify your own "},{"type":"text","text":"basesize","style":{"code":true}},{"type":"text","text":" for the partitioning which lets you encode prior knowledge about what sizes are the most appropriate"}]}]}]},{"client_msg_id":"866e9d87-e1fb-40e2-9614-3a22391def7a","type":"message","text":"the approach partitioning the loop first (e.g., using `Iterators.partition`) serializes the spawn and so has lesser parallelism. otoh, with the divide-and-conquer approach, different workers can register the tasks in their private queue in parallel. so, it helps you when you do load-balancing by spawning many tasks. this also applies to the conquer phase (which can be expensive in some reductions; e.g., doing `Set(iterator)` in parallel). of course, it doesn't matter if the \"loop body\" is slow enough. but then the spawn strategy does not matter either if so.","user":"UC7AF7NSU","ts":"1613593691.098100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FIGIl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the approach partitioning the loop first (e.g., using "},{"type":"text","text":"Iterators.partition","style":{"code":true}},{"type":"text","text":") serializes the spawn and so has lesser parallelism. otoh, with the divide-and-conquer approach, different workers can register the tasks in their private queue in parallel. so, it helps you when you do load-balancing by spawning many tasks. this also applies to the conquer phase (which can be expensive in some reductions; e.g., doing "},{"type":"text","text":"Set(iterator)","style":{"code":true}},{"type":"text","text":" in parallel). of course, it doesn't matter if the \"loop body\" is slow enough. but then the spawn strategy does not matter either if so."}]}]}]},{"client_msg_id":"85bf7d25-ce07-4751-9830-54d59301de9c","type":"message","text":"Now that I decoupled the executor from the frontend, it should be rather trivial to add the partitioning-based execution mechanism in JuliaFolds as well. It'd be interesting to see if we can find scenarios where the partitioning-based mechanism works better (and so I can document when to use it).","user":"UC7AF7NSU","ts":"1613593856.100600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"49OOq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Now that I decoupled the executor from the frontend, it should be rather trivial to add the partitioning-based execution mechanism in JuliaFolds as well. It'd be interesting to see if we can find scenarios where the partitioning-based mechanism works better (and so I can document when to use it)."}]}]}]},{"client_msg_id":"69a1fc29-c724-4a22-9e7f-f13420938bbc","type":"message","text":"I suspect the relative overhead of `ThreadsX.map`/`Folds.map` simply comes from that it uses `push!` when it can use `setindex!`, rather than the parallelization strategy. It's doable but I just want to design a generic framework first.","user":"UC7AF7NSU","ts":"1613594265.101700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"t=K//","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I suspect the relative overhead of "},{"type":"text","text":"ThreadsX.map","style":{"code":true}},{"type":"text","text":"/"},{"type":"text","text":"Folds.map","style":{"code":true}},{"type":"text","text":" simply comes from that it uses "},{"type":"text","text":"push!","style":{"code":true}},{"type":"text","text":" when it can use "},{"type":"text","text":"setindex!","style":{"code":true}},{"type":"text","text":", rather than the parallelization strategy. It's doable but I just want to design a generic framework first."}]}]}]},{"client_msg_id":"21b1594a-c2e7-40d4-aed8-eefaa32fc431","type":"message","text":"I just opened a PR for \"teaching\" parallelism to the compiler <https://github.com/JuliaLang/julia/pull/39773>","user":"UC7AF7NSU","ts":"1613887980.000300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"etCG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I just opened a PR for \"teaching\" parallelism to the compiler "},{"type":"link","url":"https://github.com/JuliaLang/julia/pull/39773"}]}]}]},{"client_msg_id":"af7c9bdc-38a1-4c0f-b0e9-c09676315e4a","type":"message","text":"...and an interface (executor) for Transducers.jl/Folds.jl/FLoops.jl using it: <https://github.com/JuliaFolds/FoldsTapir.jl>","user":"UC7AF7NSU","ts":"1613896211.003800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"06I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"...and an interface (executor) for Transducers.jl/Folds.jl/FLoops.jl using it: "},{"type":"link","url":"https://github.com/JuliaFolds/FoldsTapir.jl"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"What an amazing PR!","user":"U6QGE7S86","ts":"1613919059.004900","thread_ts":"1613589448.090800","root":{"client_msg_id":"12a45c78-4bea-4bea-847a-3c2dd2f98a70","type":"message","text":"there's no recorded talk about this yet. but I'm thinking to open a PR for kicking off some discussions","user":"UC7AF7NSU","ts":"1613589448.090800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iA3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"there's no recorded talk about this yet. but I'm thinking to open a PR for kicking off some discussions"}]}]}],"thread_ts":"1613589448.090800","reply_count":3,"reply_users_count":2,"latest_reply":"1613919059.004900","reply_users":["U6QGE7S86","UC7AF7NSU"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"Cqj6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What an amazing PR!"}]}]}],"client_msg_id":"4751a997-891f-4886-8ff4-28a11252398d"},{"client_msg_id":"000a7864-b624-4f6b-8044-fac732882d68","type":"message","text":"Most of the time I don't use multithreading, but it's annoying to specify `--threads` when I need it. Is there any caveat in always setting `JULIA_NUM_THREADS` in my shell for when multithreading is not actually needed?","user":"U6QPTG69E","ts":"1614335317.009900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0CK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Most of the time I don't use multithreading, but it's annoying to specify "},{"type":"text","text":"--threads","style":{"code":true}},{"type":"text","text":" when I need it. Is there any caveat in always setting "},{"type":"text","text":"JULIA_NUM_THREADS","style":{"code":true}},{"type":"text","text":" in my shell for when multithreading is not actually needed?"}]}]}]},{"client_msg_id":"FCD7E544-5917-4BAF-B87D-76A943F7E884","type":"message","text":"Is there a package that helps with creating and managing preallocated pools of variables for use with threads? Right now I’m just allocating a set of variables per thread, but that is a bit inefficient if every thread isn’t in flight at once","user":"ULD19UCPK","ts":"1614794595.016300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hyn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a package that helps with creating and managing preallocated pools of variables for use with threads? Right now I’m just allocating a set of variables per thread, but that is a bit inefficient if every thread isn’t in flight at once"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"Our tri-weekly meetup is upon us again tomorrow!","user":"U67BXBF99","ts":"1615327032.017300","thread_ts":"1596507680.147500","root":{"client_msg_id":"a983bc33-e374-450e-a499-326eed3b14d9","type":"message","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on <https://meet.google.com/ugr-sbmu-wts>, for anyone that wants to drop by and discuss threads and atomics!","user":"U67BXBF99","ts":"1596507680.147500","team":"T68168MUP","attachments":[{"title":"Meet","title_link":"https://meet.google.com/ugr-sbmu-wts","text":"Real-time meetings by Google. Using your browser, share your video, desktop, and presentations with teammates and customers.","fallback":"Meet","thumb_url":"https://www.gstatic.com/images/branding/product/2x/meet_96dp.png","from_url":"https://meet.google.com/ugr-sbmu-wts","thumb_width":192,"thumb_height":192,"service_icon":"http://www.gstatic.com/images/branding/product/1x/meet_16dp.png","service_name":"meet.google.com","id":1,"original_url":"https://meet.google.com/ugr-sbmu-wts"}],"blocks":[{"type":"rich_text","block_id":"HrV1l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on "},{"type":"link","url":"https://meet.google.com/ugr-sbmu-wts"},{"type":"text","text":", for anyone that wants to drop by and discuss threads and atomics!"}]}]}],"thread_ts":"1596507680.147500","reply_count":69,"reply_users_count":11,"latest_reply":"1615327681.017800","reply_users":["ULY7Q1X53","U67BXBF99","UF9T3JL4D","USU9FRPEU","U6A936746","UB7JS9CHF","U67BJLYCS","U6A0PD8CR","U6QGE7S86","UP9P4JFNJ","UH24GRBLL"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"ZWHx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Our tri-weekly meetup is upon us again tomorrow!"}]}]}],"client_msg_id":"ce90b7f3-7175-4781-94ba-8b0b229d78b7","reactions":[{"name":"three","users":["UH24GRBLL"],"count":1},{"name":"date","users":["UH24GRBLL"],"count":1}]},{"type":"message","subtype":"thread_broadcast","text":"I’ve updated the calendar to use the following zoom link for this week (Thanks <@U67BJLYCS>): <https://mit.zoom.us/j/92625773516?pwd=TG0zUVpvSnlCdVRJd3NHeW9XK1ErQT09>","user":"U67BXBF99","ts":"1615327681.017800","thread_ts":"1596507680.147500","root":{"client_msg_id":"a983bc33-e374-450e-a499-326eed3b14d9","type":"message","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on <https://meet.google.com/ugr-sbmu-wts>, for anyone that wants to drop by and discuss threads and atomics!","user":"U67BXBF99","ts":"1596507680.147500","team":"T68168MUP","attachments":[{"title":"Meet","title_link":"https://meet.google.com/ugr-sbmu-wts","text":"Real-time meetings by Google. Using your browser, share your video, desktop, and presentations with teammates and customers.","fallback":"Meet","thumb_url":"https://www.gstatic.com/images/branding/product/2x/meet_96dp.png","from_url":"https://meet.google.com/ugr-sbmu-wts","thumb_width":192,"thumb_height":192,"service_icon":"http://www.gstatic.com/images/branding/product/1x/meet_16dp.png","service_name":"meet.google.com","id":1,"original_url":"https://meet.google.com/ugr-sbmu-wts"}],"blocks":[{"type":"rich_text","block_id":"HrV1l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on "},{"type":"link","url":"https://meet.google.com/ugr-sbmu-wts"},{"type":"text","text":", for anyone that wants to drop by and discuss threads and atomics!"}]}]}],"thread_ts":"1596507680.147500","reply_count":69,"reply_users_count":11,"latest_reply":"1615327681.017800","reply_users":["ULY7Q1X53","U67BXBF99","UF9T3JL4D","USU9FRPEU","U6A936746","UB7JS9CHF","U67BJLYCS","U6A0PD8CR","U6QGE7S86","UP9P4JFNJ","UH24GRBLL"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"hsy3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’ve updated the calendar to use the following zoom link for this week (Thanks "},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":"): "},{"type":"link","url":"https://mit.zoom.us/j/92625773516?pwd=TG0zUVpvSnlCdVRJd3NHeW9XK1ErQT09"}]}]}],"client_msg_id":"7c6b09c1-c8bd-4790-ac52-f6a51ab3a02f"},{"client_msg_id":"f47e1c4b-c074-4b3b-9086-e157e07cdf35","type":"message","text":"I'd like to talk a bit about <https://github.com/JuliaLang/julia/pull/39773>. Very impressive implementation of essentially tapir/cilk but pure julia.","user":"U687RKK0E","ts":"1615329268.019200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"36L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd like to talk a bit about "},{"type":"link","url":"https://github.com/JuliaLang/julia/pull/39773"},{"type":"text","text":". Very impressive implementation of essentially tapir/cilk but pure julia."}]}]}],"reactions":[{"name":"+1","users":["U7THT3TM3","U8D9768Q6"],"count":2}]},{"client_msg_id":"e0910413-5182-4c3e-8625-014e63d05cdb","type":"message","text":"cc: <@UC7AF7NSU>","user":"U67BJLYCS","ts":"1615332396.019800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xZz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"cc: "},{"type":"user","user_id":"UC7AF7NSU"}]}]}]},{"client_msg_id":"cbb05014-923e-4187-a0b3-19e3aaafb627","type":"message","text":"I'll join!","user":"UC7AF7NSU","ts":"1615332657.020500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"txL3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'll join!"}]}]}],"reactions":[{"name":"fast_parrot","users":["U680THK2S"],"count":1}]},{"client_msg_id":"eeebe5e8-134b-40f7-97ab-5971b2e9be53","type":"message","text":"&gt; essentially tapir/cilk\nminus continuation stealing, I guess. (Working with OpenCilk team makes me want continuation stealing so badly...)","user":"UC7AF7NSU","ts":"1615332759.021000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=mP=h","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"essentially tapir/cilk"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nminus continuation stealing, I guess. (Working with OpenCilk team makes me want continuation stealing so badly...)"}]}]}]},{"type":"message","subtype":"channel_join","ts":"1615394211.023900","user":"U01GE1N0EP9","text":"<@U01GE1N0EP9> has joined the channel","inviter":"U67BXBF99"},{"client_msg_id":"a641c8f6-fbef-4d0a-9f4e-a30a711d129a","type":"message","text":"Sorry I'm late for the BoF. I'm trying to join but my laptop is just frozen now. <@U67BJLYCS> <@U687RKK0E>","user":"UC7AF7NSU","ts":"1615394914.026800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9yA0t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sorry I'm late for the BoF. I'm trying to join but my laptop is just frozen now. "},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":" "},{"type":"user","user_id":"U687RKK0E"}]}]}],"thread_ts":"1615394914.026800","reply_count":3,"reply_users_count":3,"latest_reply":"1615395855.027900","reply_users":["U67BJLYCS","UC7AF7NSU","U6A0PD8CR"],"subscribed":false,"reactions":[{"name":"snowflake","users":["UDB26738Q","U011V2YN59N","U6QGE7S86"],"count":3}]},{"client_msg_id":"4c0561f5-b0d2-4ae5-a96e-6a85af7ca21d","type":"message","text":"Thanks for the feedback, forks. I noted the important points I remember in the PR:\n\n&gt; Discussed in multithreading BoF.\n&gt; \n&gt; (1) Managing task outputs by assigning to local variables is hard to use. It would be better to have a future-like object that can be fetched/dereferenced after sync.\n&gt; \n&gt; (2) We can merge normal `@sync` and `Tapir.@sync`. The new `@sync` emits the synchronization object/token for both normal task and Tapir task. It should be fairly easy to optimize out the thing that is not used (e.g., synchronization token for Tapir when `@sync` is used for normal tasks). We can then only have to provide a single API `Tapir.@spawn`.\n(<https://github.com/JuliaLang/julia/pull/39773#issuecomment-795875907>)","user":"UC7AF7NSU","ts":"1615401251.028300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wYuE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for the feedback, forks. I noted the important points I remember in the PR:\n\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"Discussed in multithreading BoF.\n\n(1) Managing task outputs by assigning to local variables is hard to use. It would be better to have a future-like object that can be fetched/dereferenced after sync.\n\n(2) We can merge normal "},{"type":"text","text":"@sync","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"Tapir.@sync","style":{"code":true}},{"type":"text","text":". The new "},{"type":"text","text":"@sync","style":{"code":true}},{"type":"text","text":" emits the synchronization object/token for both normal task and Tapir task. It should be fairly easy to optimize out the thing that is not used (e.g., synchronization token for Tapir when "},{"type":"text","text":"@sync","style":{"code":true}},{"type":"text","text":" is used for normal tasks). We can then only have to provide a single API "},{"type":"text","text":"Tapir.@spawn","style":{"code":true}},{"type":"text","text":"."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n("},{"type":"link","url":"https://github.com/JuliaLang/julia/pull/39773#issuecomment-795875907"},{"type":"text","text":")"}]}]}],"reactions":[{"name":"fork_and_knife","users":["UDB26738Q","U680THK2S","U6QGE7S86","UH24GRBLL"],"count":4}]},{"client_msg_id":"b6dc1bba-d122-4885-8bd8-2067bde3c75a","type":"message","text":"oops, I'm Japanese so can't tell the difference between `l` and `r`  :joy:","user":"UC7AF7NSU","ts":"1615401403.028800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aJUm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oops, I'm Japanese so can't tell the difference between "},{"type":"text","text":"l","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"r","style":{"code":true}},{"type":"text","text":"  "},{"type":"emoji","name":"joy"}]}]}],"reactions":[{"name":"joy","users":["U680THK2S","UDB26738Q","U67BJLYCS","U6QGE7S86","UH24GRBLL"],"count":5},{"name":"heart","users":["U680THK2S","UDB26738Q","U67BJLYCS","U6QGE7S86","UH24GRBLL"],"count":5},{"name":"jp","users":["U680THK2S","UDB26738Q","U6QGE7S86","UH24GRBLL"],"count":4}]},{"client_msg_id":"ae8b0991-c834-4047-8f9b-d074623265a5","type":"message","text":"Want to check my understanding with some experts. I'm using Threads.@threads in for loops at various locations in a program. If there is a point within a loop which is already threaded, I probably shouldn't start another Threads.@threads for... at that point as well, correct? I.e. it should be one or the other and it's a question of where the overhead and memory hit is most worth it for the parallelism. Doing it in both spots will just clog the threads so that the one which *should* be multithreaded can't because the thread is busy?","user":"U01BD7YGV27","ts":"1615998634.003400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sII","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Want to check my understanding with some experts. I'm using Threads.@threads in for loops at various locations in a program. If there is a point within a loop which is already threaded, I probably shouldn't start another Threads.@threads for... at that point as well, correct? I.e. it should be one or the other and it's a question of where the overhead and memory hit is most worth it for the parallelism. Doing it in both spots will just clog the threads so that the one which "},{"type":"text","text":"should","style":{"bold":true}},{"type":"text","text":" be multithreaded can't because the thread is busy?"}]}]}],"thread_ts":"1615998634.003400","reply_count":8,"reply_users_count":3,"latest_reply":"1615999087.006000","reply_users":["U011V2YN59N","U67BJLYCS","U01BD7YGV27"],"subscribed":false},{"client_msg_id":"e09e851a-4834-4f3e-9079-823c845198d5","type":"message","text":"I think this has been mentioned somewhere, but what’s the best way to do error handling inside spawned tasks? i.e. I think I have errors happening inside a non-tracked spawned task and I’d like to check if any of these spawned tasks throw an error. So if any have errors, I want to throw from the main thread loop.","user":"U681ELA87","ts":"1616040270.007700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YQDZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think this has been mentioned somewhere, but what’s the best way to do error handling inside spawned tasks? i.e. I think I have errors happening inside a non-tracked spawned task and I’d like to check if any of these spawned tasks throw an error. So if any have errors, I want to throw from the main thread loop."}]}]}],"thread_ts":"1616040270.007700","reply_count":2,"reply_users_count":1,"latest_reply":"1616041184.011400","reply_users":["U8MPCDJAY"],"subscribed":false},{"client_msg_id":"4e717dc4-f6ba-406a-9dc9-daf98a1024c6","type":"message","text":"Is is correct, that if I have some code of the form\n```Threads.@threads for i in 1:20\n   # do something\nend```\nthen Julia will just split 1:20 into equal sized pieces and not take into consideration that not each value might have the same runtime?","user":"UBEF50B7C","ts":"1616116477.015100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KOs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is is correct, that if I have some code of the form\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Threads.@threads for i in 1:20\n   # do something\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"then Julia will just split 1:20 into equal sized pieces and not take into consideration that not each value might have the same runtime?"}]}]}],"thread_ts":"1616116477.015100","reply_count":6,"reply_users_count":4,"latest_reply":"1616118358.017400","reply_users":["U01C3624SGJ","UBEF50B7C","U67BJLYCS","U8D9768Q6"],"subscribed":false},{"client_msg_id":"02409341-1d75-4fc0-b48f-c1873a0f6d4a","type":"message","text":"<https://news.ycombinator.com/item?id=26537298>","user":"U67BXBF99","ts":"1616510316.020400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+bBk","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://news.ycombinator.com/item?id=26537298"}]}]}]},{"client_msg_id":"5b1fbe86-435a-424c-8fb9-05fe44dcc8a6","type":"message","text":"If I start 73k tasks (1 line scalar tests), all independent, and they take anywhere from 1s to .001s, will  that wreck the scheduler?\nWhat's the best way to feed those tasks to Julia in parallel if every single computation is a single line in a file?","user":"U6QGE7S86","ts":"1616560113.022500","team":"T68168MUP","edited":{"user":"U6QGE7S86","ts":"1616560297.000000"},"blocks":[{"type":"rich_text","block_id":"6ePF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If I start 73k tasks (1 line scalar tests), all independent, and they take anywhere from 1s to .001s, will  that wreck the scheduler?\nWhat's the best way to feed those tasks to Julia in parallel if every single computation is a single line in a file?"}]}]}]},{"client_msg_id":"5ee18bf6-2568-4879-9ba4-38bf7f7eee95","type":"message","text":"I've read many times that some operations don't benefit from multithreading because they are memory bound. But in practice, what kind of operations does this apply to? I imagine it depends a lot on the hardware, i.e. a machine with 100 CPUs has a much higher RAM bandwidth than a 4-CPU laptop?","user":"U67431ELR","ts":"1616783927.029500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"X3X","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've read many times that some operations don't benefit from multithreading because they are memory bound. But in practice, what kind of operations does this apply to? I imagine it depends a lot on the hardware, i.e. a machine with 100 CPUs has a much higher RAM bandwidth than a 4-CPU laptop?"}]}]}],"thread_ts":"1616783927.029500","reply_count":3,"reply_users_count":1,"latest_reply":"1616786522.032400","reply_users":["U881D0W2C"],"is_locked":false,"subscribed":false},{"client_msg_id":"ed7f1811-ff88-473f-bef8-b5873ef09d7e","type":"message","text":"Well, I was surprised to see that dot products benefit from threading... more memory lanes can help","user":"U6N6VQE30","ts":"1616785199.031000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FsR/X","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Well, I was surprised to see that dot products benefit from threading... more memory lanes can help"}]}]}]},{"client_msg_id":"fcce6221-1f96-4d72-8bfb-94ef76b4189b","type":"message","text":"It depends... With Intel's SMT you actually need to use both cores to use the memory subsystem fully","user":"U67BJLYCS","ts":"1616785305.031600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aEZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It depends... With Intel's SMT you actually need to use both cores to use the memory subsystem fully"}]}]}]},{"client_msg_id":"5f5b7662-e5e7-4320-b75b-81ff4e51bee6","type":"message","text":"Can I pin Julia threads to specific cores? If so, how?","user":"U881D0W2C","ts":"1616799582.036100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"h7t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can I pin Julia threads to specific cores? If so, how?"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"Due to the recent change to DST, I need to change the <#C6SMTHQ3T|multithreading> BoF time going forward. I could make it during the afternoon, or a different week day, but my current proposal is to shift it back to 10am EDT (2pm UTC), as that seemed to accommodate the most time zones. Would this work for others as well?","user":"U67BXBF99","ts":"1617033766.039600","thread_ts":"1596507680.147500","root":{"client_msg_id":"a983bc33-e374-450e-a499-326eed3b14d9","type":"message","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on <https://meet.google.com/ugr-sbmu-wts>, for anyone that wants to drop by and discuss threads and atomics!","user":"U67BXBF99","ts":"1596507680.147500","team":"T68168MUP","attachments":[{"title":"Meet","title_link":"https://meet.google.com/ugr-sbmu-wts","text":"Real-time meetings by Google. Using your browser, share your video, desktop, and presentations with teammates and customers.","fallback":"Meet","thumb_url":"https://www.gstatic.com/images/branding/product/2x/meet_96dp.png","from_url":"https://meet.google.com/ugr-sbmu-wts","thumb_width":192,"thumb_height":192,"service_icon":"http://www.gstatic.com/images/branding/product/1x/meet_16dp.png","service_name":"meet.google.com","id":1,"original_url":"https://meet.google.com/ugr-sbmu-wts"}],"blocks":[{"type":"rich_text","block_id":"HrV1l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on "},{"type":"link","url":"https://meet.google.com/ugr-sbmu-wts"},{"type":"text","text":", for anyone that wants to drop by and discuss threads and atomics!"}]}]}],"thread_ts":"1596507680.147500","reply_count":76,"reply_users_count":12,"latest_reply":"1617033766.039600","reply_users":["ULY7Q1X53","U67BXBF99","UF9T3JL4D","USU9FRPEU","U6A936746","UB7JS9CHF","U67BJLYCS","U6A0PD8CR","U6QGE7S86","UP9P4JFNJ","UH24GRBLL","U687RKK0E"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"A=4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Due to the recent change to DST, I need to change the "},{"type":"channel","channel_id":"C6SMTHQ3T"},{"type":"text","text":" BoF time going forward. I could make it during the afternoon, or a different week day, but my current proposal is to shift it back to 10am EDT (2pm UTC), as that seemed to accommodate the most time zones. Would this work for others as well?"}]}]}],"client_msg_id":"5bdd18ff-28ad-49ae-8fa9-d3ef340a4f6c"},{"client_msg_id":"b59643ce-3b24-47e7-972c-b138b295bff6","type":"message","text":"I’ve been promising for several months to return to my atomics PR, and I’ve finally really done so! There’s many details and optimizations remaining, but one of the major agenda items I’d like to focus on for this meeting is discussion and review of <https://github.com/JuliaLang/julia/pull/37847>","user":"U67BXBF99","ts":"1617034075.041500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XIFm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’ve been promising for several months to return to my atomics PR, and I’ve finally really done so! There’s many details and optimizations remaining, but one of the major agenda items I’d like to focus on for this meeting is discussion and review of "},{"type":"link","url":"https://github.com/JuliaLang/julia/pull/37847"}]}]}],"reactions":[{"name":"juliabouncing","users":["UH24GRBLL"],"count":1}]},{"client_msg_id":"809c0cd5-7020-418e-820e-e9702af6254c","type":"message","text":"Is there a reason to expect that KernelAbstractions.jl would fail and produce obscure errors when running with `julia -O0 --compile=min`?","user":"UEP056STX","ts":"1617084142.042700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VL0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a reason to expect that KernelAbstractions.jl would fail and produce obscure errors when running with "},{"type":"text","text":"julia -O0 --compile=min","style":{"code":true}},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"65C9B08E-17C8-4D2C-8472-CCD31E4B711E","type":"message","text":"People are much more likely to help if you provide a minimal working example of your error","user":"U8D9768Q6","ts":"1617085395.043900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bbIv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"People are much more likely to help if you provide a minimal working example of your error"}]}]}]},{"client_msg_id":"f8f81f58-d5c0-41bb-8ca4-c7488fab4831","type":"message","text":"True. I didn't have any particular example in mind I guess. I used `-O0 --compile=min` to speed up the compiler since compile time was getting over 20 minutes but then encountered weird errors so I removed the flags. Couldn't find the `--compile` flag mentioned in `julia --help` so maybe it's an internal flag I shouldn't be using.","user":"UEP056STX","ts":"1617085788.046000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"quCi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"True. I didn't have any particular example in mind I guess. I used "},{"type":"text","text":"-O0 --compile=min","style":{"code":true}},{"type":"text","text":" to speed up the compiler since compile time was getting over 20 minutes but then encountered weird errors so I removed the flags. Couldn't find the "},{"type":"text","text":"--compile","style":{"code":true}},{"type":"text","text":" flag mentioned in "},{"type":"text","text":"julia --help","style":{"code":true}},{"type":"text","text":" so maybe it's an internal flag I shouldn't be using."}]}]}]},{"client_msg_id":"2df71729-7e3e-41f2-8025-4257380f9a5f","type":"message","text":"Would be a useful  flag though so I'll see if I can reproduce in a minimal working example and open an issue.","user":"UEP056STX","ts":"1617085903.046500","team":"T68168MUP","edited":{"user":"UEP056STX","ts":"1617085915.000000"},"blocks":[{"type":"rich_text","block_id":"denn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Would be a useful  flag though so I'll see if I can reproduce in a minimal working example and open an issue."}]}]}]},{"client_msg_id":"cf5fc9b9-c950-4f3c-8c56-1c119431ec09","type":"message","text":"Can someone who is deep down in the rabbit hole of Julia’s multithreading infrastructure take a look at <https://discourse.julialang.org/t/thread-affinitization-pinning-julia-threads-to-cores/58069/5> ? In particular the `likwid-pin` part which almost seems to allow pinning julia threads to specific cores. There might also be something that the `likwid` developers can do, but unfortunately I don’t know what is going on with pthread in Julia at all. So I’d very much appreciate it if someone could shine some light onto this issue.","user":"U881D0W2C","ts":"1617102769.050400","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Thread affinitization: pinning Julia threads to cores","title_link":"https://discourse.julialang.org/t/thread-affinitization-pinning-julia-threads-to-cores/58069/5","text":"Alright, I’ve done some testing and had some discussion on Slack/GitHub. Let me share my findings. 1) Query the core id of a thread. Let’s start with the second question of the OP first: Is there a way in Julia to figure out which core a thread is running on? Thanks @pbayer for the pointer to schedule_getcpu(). We can call it in Julia like so: glibc_coreid() = @ccall sched_getcpu()::Cint and query the core id of a specific thread using ThreadPools’ @tspawnat: using ThreadPools tglibc_co...","fallback":"JuliaLang: Thread affinitization: pinning Julia threads to cores","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1617097649,"from_url":"https://discourse.julialang.org/t/thread-affinitization-pinning-julia-threads-to-cores/58069/5","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/thread-affinitization-pinning-julia-threads-to-cores/58069/5"}],"blocks":[{"type":"rich_text","block_id":"n0s7C","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can someone who is deep down in the rabbit hole of Julia’s multithreading infrastructure take a look at "},{"type":"link","url":"https://discourse.julialang.org/t/thread-affinitization-pinning-julia-threads-to-cores/58069/5"},{"type":"text","text":" ? In particular the "},{"type":"text","text":"likwid-pin","style":{"code":true}},{"type":"text","text":" part which almost seems to allow pinning julia threads to specific cores. There might also be something that the "},{"type":"text","text":"likwid","style":{"code":true}},{"type":"text","text":" developers can do, but unfortunately I don’t know what is going on with pthread in Julia at all. So I’d very much appreciate it if someone could shine some light onto this issue."}]}]}]},{"client_msg_id":"e856dfb8-9422-433f-94f3-d231e547adc3","type":"message","text":"(I would also appreciate pointers to resources explaining how Julia actually starts threads under hood etc.)","user":"U881D0W2C","ts":"1617103681.051300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ukPuB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(I would also appreciate pointers to resources explaining how Julia actually starts threads under hood etc.)"}]}]}],"reactions":[{"name":"true","users":["U01QRM4E8HL"],"count":1}]},{"type":"message","subtype":"thread_broadcast","text":"In about 9 hours now. See the zoom link above. <@U67BJLYCS> <@U6A0PD8CR> <@U687RKK0E> <@U6QGE7S86> <@U680B1MTJ> <@UB7JS9CHF> <@U679VPJ8L>\n<@UP9P4JFNJ> <@UDGT4PM41> <@U01GX4L17PW> <@U68A3ASP9> <@U01M9K523NW> et al.\n\nHoping to look at  <https://github.com/JuliaLang/julia/pull/37847> together today. Plus the usual link for minutes: <https://docs.google.com/document/d/1rDgdFH94QL4wlEAdzBbdxJJ0Wk2CkBhWuptzPETSRc0/and> any other questions you may have","user":"U67BXBF99","ts":"1617167691.054500","thread_ts":"1596507680.147500","root":{"client_msg_id":"a983bc33-e374-450e-a499-326eed3b14d9","type":"message","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on <https://meet.google.com/ugr-sbmu-wts>, for anyone that wants to drop by and discuss threads and atomics!","user":"U67BXBF99","ts":"1596507680.147500","team":"T68168MUP","attachments":[{"title":"Meet","title_link":"https://meet.google.com/ugr-sbmu-wts","text":"Real-time meetings by Google. Using your browser, share your video, desktop, and presentations with teammates and customers.","fallback":"Meet","thumb_url":"https://www.gstatic.com/images/branding/product/2x/meet_96dp.png","from_url":"https://meet.google.com/ugr-sbmu-wts","thumb_width":192,"thumb_height":192,"service_icon":"http://www.gstatic.com/images/branding/product/1x/meet_16dp.png","service_name":"meet.google.com","id":1,"original_url":"https://meet.google.com/ugr-sbmu-wts"}],"blocks":[{"type":"rich_text","block_id":"HrV1l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For this week’s multithreading-BoF, I’m thinking of hosting at 9:30a EDT (13h30 UTC) on "},{"type":"link","url":"https://meet.google.com/ugr-sbmu-wts"},{"type":"text","text":", for anyone that wants to drop by and discuss threads and atomics!"}]}]}],"thread_ts":"1596507680.147500","reply_count":77,"reply_users_count":12,"latest_reply":"1617167691.054500","reply_users":["ULY7Q1X53","U67BXBF99","UF9T3JL4D","USU9FRPEU","U6A936746","UB7JS9CHF","U67BJLYCS","U6A0PD8CR","U6QGE7S86","UP9P4JFNJ","UH24GRBLL","U687RKK0E"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"nh9ln","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In about 9 hours now. See the zoom link above. "},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":" "},{"type":"user","user_id":"U6A0PD8CR"},{"type":"text","text":" "},{"type":"user","user_id":"U687RKK0E"},{"type":"text","text":" "},{"type":"user","user_id":"U6QGE7S86"},{"type":"text","text":" "},{"type":"user","user_id":"U680B1MTJ"},{"type":"text","text":" "},{"type":"user","user_id":"UB7JS9CHF"},{"type":"text","text":" "},{"type":"user","user_id":"U679VPJ8L"},{"type":"text","text":"\n"},{"type":"user","user_id":"UP9P4JFNJ"},{"type":"text","text":" "},{"type":"user","user_id":"UDGT4PM41"},{"type":"text","text":" "},{"type":"user","user_id":"U01GX4L17PW"},{"type":"text","text":" "},{"type":"user","user_id":"U68A3ASP9"},{"type":"text","text":" "},{"type":"user","user_id":"U01M9K523NW"},{"type":"text","text":" et al.\n\nHoping to look at  "},{"type":"link","url":"https://github.com/JuliaLang/julia/pull/37847"},{"type":"text","text":" together today. Plus the usual link for minutes: "},{"type":"link","url":"https://docs.google.com/document/d/1rDgdFH94QL4wlEAdzBbdxJJ0Wk2CkBhWuptzPETSRc0/and"},{"type":"text","text":" any other questions you may have"}]}]}],"client_msg_id":"0c3c021c-7062-4141-b01f-ac41f070f19b"},{"type":"message","subtype":"channel_join","ts":"1617199228.055700","user":"U68A3ASP9","text":"<@U68A3ASP9> has joined the channel","inviter":"U67BXBF99"},{"client_msg_id":"da39e61e-d2be-4c61-a5b9-2207de8b3842","type":"message","text":"<https://mobile.twitter.com/jonhoo/status/1378100383495512064|https://mobile.twitter.com/jonhoo/status/1378100383495512064>","user":"U6QGE7S86","ts":"1617402004.057200","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/jonhoo|@jonhoo>: I'm very happy with how today's stream on atomics and memory ordering in <https://twitter.com/rustlang|@rustlang> turned out. Hopefully this'll help clear up the confusion and mystery that surrounds the std::sync::atomic module, and allow more people to write good concurrent code! 🧮\n<https://youtu.be/rMGWeSjctlY>","ts":1617399709,"author_name":"Jon Gjengset","author_link":"https://twitter.com/jonhoo/status/1378100383495512064","author_icon":"https://pbs.twimg.com/profile_images/1114594272077066240/86ze0W_P_normal.png","author_subname":"@jonhoo","text":"I'm very happy with how today's stream on atomics and memory ordering in <https://twitter.com/rustlang|@rustlang> turned out. Hopefully this'll help clear up the confusion and mystery that surrounds the std::sync::atomic module, and allow more people to write good concurrent code! 🧮\n<https://youtu.be/rMGWeSjctlY>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://mobile.twitter.com/jonhoo/status/1378100383495512064","id":1,"original_url":"https://mobile.twitter.com/jonhoo/status/1378100383495512064","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"LdbX","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://mobile.twitter.com/jonhoo/status/1378100383495512064","text":"https://mobile.twitter.com/jonhoo/status/1378100383495512064"}]}]}]},{"client_msg_id":"d5be0a11-a3de-4b20-aae7-a4cdaf556c74","type":"message","text":"Looks fun! I will use this excuse also to request review on my atomic implementation / memory ordering PR :smile:","user":"U67BXBF99","ts":"1617403975.058100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V7o","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looks fun! I will use this excuse also to request review on my atomic implementation / memory ordering PR "},{"type":"emoji","name":"smile"}]}]}]},{"client_msg_id":"47f75645-d58d-4ae3-beed-79bd9788a495","type":"message","text":"^  <@U674T3KB3> <@U687RKK0E> <@U68A3ASP9> and perhaps <@U6QGE7S86> :slightly_smiling_face:","user":"U67BXBF99","ts":"1617421699.058800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bFz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"^  "},{"type":"user","user_id":"U674T3KB3"},{"type":"text","text":" "},{"type":"user","user_id":"U687RKK0E"},{"type":"text","text":" "},{"type":"user","user_id":"U68A3ASP9"},{"type":"text","text":" and perhaps "},{"type":"user","user_id":"U6QGE7S86"},{"type":"text","text":" "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"6abd6574-10e9-43d1-9832-017056cd1431","type":"message","text":"<https://github.com/JuliaLang/julia/pull/37847>","user":"U67BXBF99","ts":"1617421699.059000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"t/n","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/JuliaLang/julia/pull/37847"}]}]}]}]}