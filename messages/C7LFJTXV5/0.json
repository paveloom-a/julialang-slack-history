{"cursor": 0, "messages": [{"type":"message","subtype":"channel_join","ts":"1608169106.205800","user":"U01GWRMB43Y","text":"<@U01GWRMB43Y> has joined the channel","inviter":"UD0SQV5LL"},{"client_msg_id":"cd0f1e65-242b-41d1-9b4b-82cf8f5492d9","type":"message","text":"I think I am hitting a Zygote 0.5 bug. Can we increase the compat bound so that Flux can use Zygote 0.6?","user":"U7YD3DKL2","ts":"1608572338.208600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nq1T","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think I am hitting a Zygote 0.5 bug. Can we increase the compat bound so that Flux can use Zygote 0.6?"}]}]}],"thread_ts":"1608572338.208600","reply_count":9,"reply_users_count":2,"latest_reply":"1608577514.210400","reply_users":["U7YD3DKL2","UM30MT6RF"],"subscribed":false},{"client_msg_id":"418d3bd5-eec4-4802-8b0e-0e099411379c","type":"message","text":"<https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html>","user":"UDGT4PM41","ts":"1608837807.210900","team":"T68168MUP","attachments":[{"service_name":"Yangzai’s Blog","title":"Is Julia Ready for Deep Learning","title_link":"https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html","text":"I heard about Swift and Julia for deep learning during <http://fast.ai|fast.ai>’s course. Then I spent quite some time to try figuring out whether any of these languages is a better choice for deep learning than Python. However, soon I realized that Chris Lattner left Google and Swift for Tensorflow project is slowing down and even Jeremy Howard is less passionate about it. Then the only choice left for now is Julia AFAIK. The Question is whether Julia is ready for deep learning.","fallback":"Yangzai’s Blog: Is Julia Ready for Deep Learning","ts":1605058098,"from_url":"https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html","id":1,"original_url":"https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html"}],"blocks":[{"type":"rich_text","block_id":"Vc0","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html"}]}]}]},{"client_msg_id":"B9B8E182-A041-4C85-B43B-831E9605154A","type":"message","text":"Any owners of the FluxML organization around?","user":"U7THT3TM3","ts":"1609191265.212400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6E5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any owners of the FluxML organization around?"}]}]}]},{"client_msg_id":"0F87BA95-44AA-4409-AA69-F092949A1866","type":"message","text":"Could you (temporarily) make Tim (<@U68A3ASP9>) an owner of the FluxML organization so that he can finish setting up Buildkite for GPU CI?","user":"U7THT3TM3","ts":"1609191301.213400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"njrS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Could you (temporarily) make Tim ("},{"type":"user","user_id":"U68A3ASP9"},{"type":"text","text":") an owner of the FluxML organization so that he can finish setting up Buildkite for GPU CI?"}]}]}]},{"client_msg_id":"907500A7-BA7B-4ACB-9EB5-9397A5EFFACC","type":"message","text":"You can convert him back to a regular member once he's done.","user":"U7THT3TM3","ts":"1609191345.213800","team":"T68168MUP","edited":{"user":"U7THT3TM3","ts":"1609191361.000000"},"blocks":[{"type":"rich_text","block_id":"=Yn1O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can convert him back to a regular member once he's done."}]}]}]},{"client_msg_id":"282846ef-5896-4a1f-a1d8-744b9ea17e10","type":"message","text":"Anyone around who maintains the webpage <http://fluxml.ai|fluxml.ai> ? It throws a 404 when hitting the \"Try it out\" button pointing to this address: <https://fluxml.ai/getting_started.html> .","user":"ULL3KSGBS","ts":"1609223126.215500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vqrwl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone around who maintains the webpage "},{"type":"link","url":"http://fluxml.ai","text":"fluxml.ai"},{"type":"text","text":" ? It throws a 404 when hitting the \"Try it out\" button pointing to this address: "},{"type":"link","url":"https://fluxml.ai/getting_started.html"},{"type":"text","text":" ."}]}]}]},{"client_msg_id":"71574f36-01d6-450a-a95b-c3401fa4a9fc","type":"message","text":"Fixed, thanks <@ULL3KSGBS>! Sorry about that, we are updating that part of the website","user":"UC4QQPG4A","ts":"1609226322.216400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7vD2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Fixed, thanks "},{"type":"user","user_id":"ULL3KSGBS"},{"type":"text","text":"! Sorry about that, we are updating that part of the website"}]}]}]},{"type":"message","subtype":"channel_join","ts":"1609333499.218500","user":"U01HYEN2ES0","text":"<@U01HYEN2ES0> has joined the channel","inviter":"UEP056STX"},{"client_msg_id":"efe5ad02-f4ec-43e1-b783-2018f78380a6","type":"message","text":"Not seeing as much Flux discussion here lately, are people discussing Flux elsewhere?","user":"U9RDM8ZGT","ts":"1609886938.219800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uVz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not seeing as much Flux discussion here lately, are people discussing Flux elsewhere?"}]}]}],"thread_ts":"1609886938.219800","reply_count":3,"reply_users_count":2,"latest_reply":"1609889372.220900","reply_users":["UGU761DU2","U9RDM8ZGT"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"This channel was boosted by a lot of help-focused threads. Not exactly sure why those tapered off, but I haven't seen one in a while despite no noticeable change in the rate of related help threads on Discourse.","user":"UMY1LV01G","ts":"1609892625.222300","thread_ts":"1609886938.219800","root":{"client_msg_id":"efe5ad02-f4ec-43e1-b783-2018f78380a6","type":"message","text":"Not seeing as much Flux discussion here lately, are people discussing Flux elsewhere?","user":"U9RDM8ZGT","ts":"1609886938.219800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uVz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not seeing as much Flux discussion here lately, are people discussing Flux elsewhere?"}]}]}],"thread_ts":"1609886938.219800","reply_count":10,"reply_users_count":3,"latest_reply":"1609892625.222300","reply_users":["UGU761DU2","U9RDM8ZGT","UMY1LV01G"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"n6NP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This channel was boosted by a lot of help-focused threads. Not exactly sure why those tapered off, but I haven't seen one in a while despite no noticeable change in the rate of related help threads on Discourse."}]}]}],"client_msg_id":"569de717-8292-4474-91bb-4e4c4fc8ed09","reactions":[{"name":"+1","users":["UGU761DU2"],"count":1}]},{"client_msg_id":"f25eef3a-9f87-435b-be58-f6a0954b4550","type":"message","text":"This doesn't seem to be the only slack channel effected.","user":"U9RDM8ZGT","ts":"1609892673.222800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KX/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This doesn't seem to be the only slack channel effected."}]}]}]},{"client_msg_id":"290e1c62-f354-4331-aac5-eff43d82fc49","type":"message","text":"<#C690QRAA3|machine-learning> traffic seems way down as well. I'm guessing it's the holiday lull, but it's possible that there's some movement away from Slack - but there isn't (wasn't) even a <#C7120PCUQ|flux> channel over on Zulip until I just made one.","user":"U9RDM8ZGT","ts":"1609892760.224300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4+M","elements":[{"type":"rich_text_section","elements":[{"type":"channel","channel_id":"C690QRAA3"},{"type":"text","text":" traffic seems way down as well. I'm guessing it's the holiday lull, but it's possible that there's some movement away from Slack - but there isn't (wasn't) even a "},{"type":"channel","channel_id":"C7120PCUQ"},{"type":"text","text":" channel over on Zulip until I just made one."}]}]}]},{"client_msg_id":"df604fa4-805d-49fb-9bc8-b1006555b2b2","type":"message","text":"There aren't that many flux related posts on Zulip that aren't also design posts, so we just stuck to using the ML stream","user":"UMY1LV01G","ts":"1609893094.226000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nh=n9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There aren't that many flux related posts on Zulip that aren't also design posts, so we just stuck to using the ML stream"}]}]}]},{"client_msg_id":"e0367249-dfea-45e9-ba4d-4693c3cd191d","type":"message","text":"I can tell you that GH issue discussion and comments are quite active right now :) Zulip ML streams are likely quieter because of the holiday too.","user":"UMY1LV01G","ts":"1609893186.227900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"U0vj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can tell you that GH issue discussion and comments are quite active right now :) Zulip ML streams are likely quieter because of the holiday too."}]}]}]},{"type":"message","text":"gradient falls on StructArray. loss is calculated alright. <@UC4QQPG4A>, any suggestions how to fix that? Thanks!","files":[{"id":"F01HZ4UFMSS","created":1610000287,"timestamp":1610000287,"name":"Untitled","title":"Untitled","mimetype":"text/plain","filetype":"julia","pretty_type":"Julia","user":"UJZNB9CSV","editable":true,"size":1095,"mode":"snippet","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HZ4UFMSS/untitled","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HZ4UFMSS/download/untitled","permalink":"https://julialang.slack.com/files/UJZNB9CSV/F01HZ4UFMSS/untitled","permalink_public":"https://slack-files.com/T68168MUP-F01HZ4UFMSS-2700fc7140","edit_link":"https://julialang.slack.com/files/UJZNB9CSV/F01HZ4UFMSS/untitled/edit","preview":"julia> d[1]\n2×128 StructArray(::Array{Bool,2}, ::Array{Bool,2}, ::Array{Bool,2}) with eltype NamedTuple{(:x1, :x2, :x3),Tuple{Bool,Bool,Bool}}:\n (x1 = 1, x2 = 1, x3 = 0)  (x1 = 1, x2 = 0, x3 = 0)  …  (x1 = 0, x2 = 1, x3 = 0)  (x1 = 0, x2 = 1, x3 = 0)\n (x1 = 0, x2 = 0, x3 = 1)  (x1 = 0, x2 = 1, x3 = 1)     (x1 = 1, x2 = 0, x3 = 1)  (x1 = 1, x2 = 0, x3 = 1)\n","preview_highlight":"<div class=\"CodeMirror cm-s-default CodeMirrorServer\" oncopy=\"if(event.clipboardData){event.clipboardData.setData('text/plain',window.getSelection().toString().replace(/\\u200b/g,''));event.preventDefault();event.stopPropagation();}\">\n<div class=\"CodeMirror-code\">\n<div><pre><span class=\"cm-variable\">julia</span><span class=\"cm-operator\">&gt;</span> <span class=\"cm-variable\">d</span>[<span class=\"cm-number\">1</span>]</pre></div>\n<div><pre><span class=\"cm-number\">2</span><span class=\"cm-operator\">×</span><span class=\"cm-number\">128</span> <span class=\"cm-builtin\">StructArray</span>(<span class=\"cm-builtin\">::Array{Bool,2</span><span class=\"cm-builtin\">}</span>, <span class=\"cm-builtin\">::Array{Bool,2</span><span class=\"cm-builtin\">}</span>, <span class=\"cm-builtin\">::Array{Bool,2</span><span class=\"cm-builtin\">}</span>) <span class=\"cm-variable\">with</span> <span class=\"cm-variable\">eltype</span> <span class=\"cm-variable\">NamedTuple</span>{(<span class=\"cm-builtin\">:x1</span>, <span class=\"cm-builtin\">:x2</span>, <span class=\"cm-builtin\">:x3</span>),<span class=\"cm-variable\">Tuple</span>{<span class=\"cm-variable\">Bool</span>,<span class=\"cm-variable\">Bool</span>,<span class=\"cm-variable\">Bool</span>}}<span class=\"cm-operator\">:</span></pre></div>\n<div><pre> (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>)  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>)  <span class=\"cm-variable\">…</span>  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>)  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>)</pre></div>\n<div><pre> (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>)  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>)     (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>)  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>)</pre></div>\n</div>\n</div>\n","lines":20,"lines_more":15,"preview_is_truncated":true,"is_starred":false,"has_rich_preview":false}],"upload":true,"blocks":[{"type":"rich_text","block_id":"ldvQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"gradient falls on StructArray. loss is calculated alright. "},{"type":"user","user_id":"UC4QQPG4A"},{"type":"text","text":", any suggestions how to fix that? Thanks!"}]}]}],"user":"UJZNB9CSV","display_as_bot":false,"ts":"1610000289.228000","edited":{"user":"UJZNB9CSV","ts":"1610000544.000000"},"client_msg_id":"50a496f4-2627-4a38-a6a2-61df78cc359c"},{"client_msg_id":"BDC7DBEB-8688-41D1-A89F-73060BECB256","type":"message","text":"Has there been much work on latency reduction in Flux? SnoopCompile etc. I’m keen to improve latency in some downstream packages so thought I’d check","user":"U8MPCDJAY","ts":"1610210034.230300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jUHR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Has there been much work on latency reduction in Flux? SnoopCompile etc. I’m keen to improve latency in some downstream packages so thought I’d check"}]}]}]},{"client_msg_id":"1ff27999-0a3f-4f6b-ba64-e5ff871457ef","type":"message","text":"I haven't seen or heard of anything, but it would be very much welcome","user":"UMY1LV01G","ts":"1610215332.230700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Rr7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I haven't seen or heard of anything, but it would be very much welcome"}]}]}]},{"client_msg_id":"fc9e3e64-bb75-45f0-9061-e69009d6d6d2","type":"message","text":"IIRC Zygote and CUDA are the two biggest offenders, in that order","user":"UMY1LV01G","ts":"1610215353.231200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"R2S","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"IIRC Zygote and CUDA are the two biggest offenders, in that order"}]}]}]},{"client_msg_id":"230f77c4-4bd1-45e9-aa52-dc5a17b5e052","type":"message","text":"Yes, that would be awesome! I think it might even be interesting to see if for Zygote, we could use the new experimental infrastructure to just not specialize at all in the compiler parts.","user":"UM30MT6RF","ts":"1610221400.233900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ywJh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, that would be awesome! I think it might even be interesting to see if for Zygote, we could use the new experimental infrastructure to just not specialize at all in the compiler parts."}]}]}]},{"client_msg_id":"2358C6D3-0314-4760-958A-0CB67AB51264","type":"message","text":"Ok cool. I can’t promise much, but thought it would be good to learn the tools on something core like Zygote. I’ll open a PR if I make any progress","user":"U8MPCDJAY","ts":"1610224415.235400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9Cg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok cool. I can’t promise much, but thought it would be good to learn the tools on something core like Zygote. I’ll open a PR if I make any progress"}]}]}],"reactions":[{"name":"+1","users":["UMY1LV01G","UH9KWTTD3","UM30MT6RF"],"count":3}]},{"client_msg_id":"d37a3d0f-b85e-4b53-bd45-517efcad3685","type":"message","text":"That'd be brilliant! Although zygote by itself seems to have gotten better anecdotally. It would be a huge help if you'd gather your findings in an issue/ PR anyway to see where we can go with it. Flux still takes longer than I'd expect to precompile.","user":"UC4QQPG4A","ts":"1610227373.240800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ab9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That'd be brilliant! Although zygote by itself seems to have gotten better anecdotally. It would be a huge help if you'd gather your findings in an issue/ PR anyway to see where we can go with it. Flux still takes longer than I'd expect to precompile."}]}]}],"thread_ts":"1610227373.240800","reply_count":1,"reply_users_count":1,"latest_reply":"1610231008.241000","reply_users":["U8MPCDJAY"],"subscribed":false},{"client_msg_id":"f67d1a43-41d4-4711-8d43-96b7e0df139a","type":"message","text":"Hi, I have changed activation functions in my models from `relu` to `sigmoid` and I save them into `.bson` which used to work with `relu` . Now, I am getting `typeof` error with sigmoid. Do not understand why. Thanks for any help. Error:\n\n```julia&gt; res = BSON.load(file_with_dictionary_results)\nERROR: MethodError: no method matching typeof(σ)()\nStacktrace:\n [1] (::BSON.var\"#37#38\")(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:76\n [2] _raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:79\n [3] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:89\n [4] (::BSON.var\"#39#40\"{IdDict{Any,Any}})(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [5] iterate at ./generator.jl:47 [inlined]\n [6] collect_to!(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:732\n [7] collect_to!(::Array{Real,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:740 (repeats 3 times)\n [8] collect_to_with_first!(::Array{Int64,1}, ::Int64, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64) at ./array.jl:710\n [9] _collect(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Base.EltypeUnknown, ::Base.HasShape{1}) at ./array.jl:704\n [10] collect_similar(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}) at ./array.jl:628\n [11] map(::Function, ::Array{Any,1}) at ./abstractarray.jl:2162\n [12] newstruct_raw(::IdDict{Any,Any}, ::Type{T} where T, ::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [13] (::BSON.var\"#43#44\")(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:140\n [14] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:88\n [15] (::BSON.var\"#21#22\"{IdDict{Any,Any}})(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:94\n [16] applychildren!(::BSON.var\"#21#22\"{IdDict{Any,Any}}, ::Array{Any,1}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/BSON.jl:28\n [17] raise_recursive at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:94 [inlined]\n [18] (::BSON.var\"#39#40\"{IdDict{Any,Any}})(::Array{Any,1}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [19] iterate at ./generator.jl:47 [inlined]\n [20] collect_to!(::Array{Array{Any,1},1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:732\n [21] collect_to_with_first!(::Array{Array{Any,1},1}, ::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64) at ./array.jl:710\n [22] _collect(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Base.EltypeUnknown, ::Base.HasShape{1}) at ./array.jl:704\n [23] collect_similar(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}) at ./array.jl:628\n [24] map(::Function, ::Array{Any,1}) at ./abstractarray.jl:2162\n [25] newstruct_raw(::IdDict{Any,Any}, ::Type{T} where T, ::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [26] (::BSON.var\"#43#44\")(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:140\n [27] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:88\n [28] raise_recursive at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:99 [inlined]\n [29] load(::String) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:104\n [30] top-level scope at REPL[20]:1```","user":"UP345RMJR","ts":"1610360933.246600","team":"T68168MUP","edited":{"user":"UP345RMJR","ts":"1610360997.000000"},"blocks":[{"type":"rich_text","block_id":"PifXU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I have changed activation functions in my models from "},{"type":"text","text":"relu","style":{"code":true}},{"type":"text","text":" to "},{"type":"text","text":"sigmoid","style":{"code":true}},{"type":"text","text":" and I save them into "},{"type":"text","text":".bson","style":{"code":true}},{"type":"text","text":" which used to work with "},{"type":"text","text":"relu","style":{"code":true}},{"type":"text","text":" . Now, I am getting "},{"type":"text","text":"typeof","style":{"code":true}},{"type":"text","text":" error with sigmoid. Do not understand why. Thanks for any help. Error:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> res = BSON.load(file_with_dictionary_results)\nERROR: MethodError: no method matching typeof(σ)()\nStacktrace:\n [1] (::BSON.var\"#37#38\")(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:76\n [2] _raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:79\n [3] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:89\n [4] (::BSON.var\"#39#40\"{IdDict{Any,Any}})(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [5] iterate at ./generator.jl:47 [inlined]\n [6] collect_to!(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:732\n [7] collect_to!(::Array{Real,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:740 (repeats 3 times)\n [8] collect_to_with_first!(::Array{Int64,1}, ::Int64, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64) at ./array.jl:710\n [9] _collect(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Base.EltypeUnknown, ::Base.HasShape{1}) at ./array.jl:704\n [10] collect_similar(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}) at ./array.jl:628\n [11] map(::Function, ::Array{Any,1}) at ./abstractarray.jl:2162\n [12] newstruct_raw(::IdDict{Any,Any}, ::Type{T} where T, ::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [13] (::BSON.var\"#43#44\")(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:140\n [14] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:88\n [15] (::BSON.var\"#21#22\"{IdDict{Any,Any}})(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:94\n [16] applychildren!(::BSON.var\"#21#22\"{IdDict{Any,Any}}, ::Array{Any,1}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/BSON.jl:28\n [17] raise_recursive at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:94 [inlined]\n [18] (::BSON.var\"#39#40\"{IdDict{Any,Any}})(::Array{Any,1}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [19] iterate at ./generator.jl:47 [inlined]\n [20] collect_to!(::Array{Array{Any,1},1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:732\n [21] collect_to_with_first!(::Array{Array{Any,1},1}, ::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64) at ./array.jl:710\n [22] _collect(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Base.EltypeUnknown, ::Base.HasShape{1}) at ./array.jl:704\n [23] collect_similar(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}) at ./array.jl:628\n [24] map(::Function, ::Array{Any,1}) at ./abstractarray.jl:2162\n [25] newstruct_raw(::IdDict{Any,Any}, ::Type{T} where T, ::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [26] (::BSON.var\"#43#44\")(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:140\n [27] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:88\n [28] raise_recursive at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:99 [inlined]\n [29] load(::String) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:104\n [30] top-level scope at REPL[20]:1"}]}]}]},{"client_msg_id":"61cc67ba-92cb-4482-bebc-1821952feec4","type":"message","text":"<https://github.com/sdobber/FluxArchitectures/issues/15>","user":"UDGT4PM41","ts":"1611078237.006300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0MSe","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/sdobber/FluxArchitectures/issues/15"}]}]}]},{"client_msg_id":"fce1a509-74dd-4a4a-966f-77e9ada5a3f7","type":"message","text":"Can I print the current learning rate when using learning rate decay?","user":"U014K4SE396","ts":"1611161820.007200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OOk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can I print the current learning rate when using learning rate decay?"}]}]}],"thread_ts":"1611161820.007200","reply_count":1,"reply_users_count":1,"latest_reply":"1611163357.010100","reply_users":["UH9KWTTD3"],"subscribed":false},{"client_msg_id":"77fae6f8-0842-414f-8350-fa7e4f1ad056","type":"message","text":"Thoughts on <https://github.com/FluxML/Flux.jl/pull/1471|https://github.com/FluxML/Flux.jl/pull/1471>?","user":"UC4QQPG4A","ts":"1611162745.007500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0KPe8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thoughts on "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/pull/1471","text":"https://github.com/FluxML/Flux.jl/pull/1471"},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"28a4ca71-529f-47d9-9a88-d35823a67295","type":"message","text":"With that PR you could define a prehook to print it pretty trivially","user":"UC4QQPG4A","ts":"1611162771.008400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sqwG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"With that PR you could define a prehook to print it pretty trivially"}]}]}]},{"client_msg_id":"0eb9bdf5-3a3d-48fa-be7e-6422ff2cc72e","type":"message","text":"Oh you could also just define a callback to accept the optimiser and print the learning rate like that","user":"UC4QQPG4A","ts":"1611162815.009500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8jSf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh you could also just define a callback to accept the optimiser and print the learning rate like that"}]}]}],"reactions":[{"name":"+1","users":["U014K4SE396"],"count":1}]},{"client_msg_id":"078a6475-fe20-4bc0-b5ee-69ad01a4d215","type":"message","text":"Thank you and looking forward to that","user":"U014K4SE396","ts":"1611163073.010000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Z1=R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you and looking forward to that"}]}]}]},{"client_msg_id":"f18e0e93-36e8-4265-8b2a-871db69af432","type":"message","text":"Hi! New to Flux/Zygote from Pytorch, what are the best ways to make your functions play nice with Float32?","user":"UM9Q1BM9Q","ts":"1611451037.002200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Zd3a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi! New to Flux/Zygote from Pytorch, what are the best ways to make your functions play nice with Float32?"}]}]}]},{"client_msg_id":"d0b154b4-dd04-44e3-893a-86b49d2fa174","type":"message","text":"To elaborate: let's say i have a function `f(x, arg1) = x - arg1`. If x is Float32, Julia's behavior is to treat arg1 as a Float64, and the function will return a Float64","user":"UM9Q1BM9Q","ts":"1611451136.003800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"diFR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"To elaborate: let's say i have a function "},{"type":"text","text":"f(x, arg1) = x - arg1","style":{"code":true}},{"type":"text","text":". If x is Float32, Julia's behavior is to treat arg1 as a Float64, and the function will return a Float64"}]}]}],"thread_ts":"1611451136.003800","reply_count":2,"reply_users_count":1,"latest_reply":"1611451815.008400","reply_users":["UH9KWTTD3"],"subscribed":false},{"client_msg_id":"a07c6a0f-7d19-4b88-8636-b03af5d2b741","type":"message","text":"and this, logically, makes Julia complain about type mismatches and/or spends a lot of resources on type inference","user":"UM9Q1BM9Q","ts":"1611451198.004600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=qs8n","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and this, logically, makes Julia complain about type mismatches and/or spends a lot of resources on type inference"}]}]}]},{"client_msg_id":"43e36bcb-6b8d-42b1-ad7d-63bc43217d39","type":"message","text":"i'm sure there's a really simple way to do this, i just can't find it online","user":"UM9Q1BM9Q","ts":"1611451262.005600","team":"T68168MUP","edited":{"user":"UM9Q1BM9Q","ts":"1611451309.000000"},"blocks":[{"type":"rich_text","block_id":"KzO9u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"i'm sure there's a really simple way to do this, i just can't find it online"}]}]}]},{"client_msg_id":"f17c4667-c8c9-4f70-bba9-81cc41cb5eb1","type":"message","text":"`f` should only promote to Float64 if arg is already. Viz.\n```julia&gt; f(1.0, 2f0) |&gt; typeof\nFloat64\n\njulia&gt; f(1f0, 2f0) |&gt; typeof\nFloat32```\nWithout more context, I assume you are seeing that floating point constants are 64-bit by default in Julia. That's easily remedied by appending an `f0` though.","user":"UMY1LV01G","ts":"1611451673.007700","team":"T68168MUP","edited":{"user":"UMY1LV01G","ts":"1611451684.000000"},"blocks":[{"type":"rich_text","block_id":"k9n+r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"f","style":{"code":true}},{"type":"text","text":" should only promote to Float64 if arg is already. Viz.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> f(1.0, 2f0) |> typeof\nFloat64\n\njulia> f(1f0, 2f0) |> typeof\nFloat32"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Without more context, I assume you are seeing that floating point constants are 64-bit by default in Julia. That's easily remedied by appending an "},{"type":"text","text":"f0","style":{"code":true}},{"type":"text","text":" though."}]}]}]},{"client_msg_id":"0c50cadb-5fe5-42cf-a6cb-0769d4632563","type":"message","text":"thanks for the replies! so this requires adding `f0` or using something like `f(x::T, arg1) = x - T(arg1)` like <@UH9KWTTD3> said","user":"UM9Q1BM9Q","ts":"1611451935.010300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WJUR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thanks for the replies! so this requires adding "},{"type":"text","text":"f0","style":{"code":true}},{"type":"text","text":" or using something like "},{"type":"text","text":"f(x::T, arg1) = x - T(arg1)","style":{"code":true}},{"type":"text","text":" like "},{"type":"user","user_id":"UH9KWTTD3"},{"type":"text","text":" said"}]}]}]},{"client_msg_id":"00b52b3c-684d-4b3b-9a99-fd9afd52882a","type":"message","text":"so if i want to distribute my model, training etc over several functions with numerical arguments, is there a more \"scalable\" way to do this? like a nice design pattern?","user":"UM9Q1BM9Q","ts":"1611451978.011700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9ok","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so if i want to distribute my model, training etc over several functions with numerical arguments, is there a more \"scalable\" way to do this? like a nice design pattern?"}]}]}]},{"client_msg_id":"4edc9636-6588-4c5f-8c51-db65d3684a71","type":"message","text":"I think you'll have to provide an example we can actually dig into, because f should never return Float64 if you're only passing it Float32s.","user":"UMY1LV01G","ts":"1611452004.012200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lbE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think you'll have to provide an example we can actually dig into, because f should never return Float64 if you're only passing it Float32s."}]}]}]},{"client_msg_id":"7f5b1f91-b218-47b7-aa42-5d7c48b7d59c","type":"message","text":"sure, here's the function that was causing me grief: `function soft_threshold(x, λ)`\n    `relu(x - λ) - relu(-x - λ)`\n`end`","user":"UM9Q1BM9Q","ts":"1611452055.013200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"f6Z+G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"sure, here's the function that was causing me grief: "},{"type":"text","text":"function soft_threshold(x, λ)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    relu(x - λ) - relu(-x - λ)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"end","style":{"code":true}}]}]}]},{"client_msg_id":"2b917b55-b1cf-42b5-8c96-61d4592c0a4a","type":"message","text":"with `x::Array{Float32,N}, λ=some_float`","user":"UM9Q1BM9Q","ts":"1611452111.014000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aoYu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"with "},{"type":"text","text":"x::Array{Float32,N}, λ=some_float","style":{"code":true}}]}]}]},{"client_msg_id":"2974DDCF-9855-45B8-B037-41D3935C90A3","type":"message","text":"So lambda needs to specifically be Float32","user":"UH9KWTTD3","ts":"1611452133.014500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GI1M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So lambda needs to specifically be Float32"}]}]}]},{"client_msg_id":"1f364db1-ad45-4a8b-9db9-a95b628fa08a","type":"message","text":"And how/where is relu defined?","user":"UMY1LV01G","ts":"1611452147.015100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vg7EU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And how/where is relu defined?"}]}]}]},{"client_msg_id":"EF027CB9-E7E8-4A6D-95C7-2E300DF80DBB","type":"message","text":"The right approach would be to use `f0` like Brian suggested","user":"UH9KWTTD3","ts":"1611452169.015900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZtG57","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The right approach would be to use "},{"type":"text","text":"f0","style":{"code":true}},{"type":"text","text":" like Brian suggested"}]}]}],"reactions":[{"name":"+1","users":["UM9Q1BM9Q"],"count":1}]},{"client_msg_id":"9732b350-e16f-45ef-9001-699039017ce8","type":"message","text":"good point. this is the relu from Flux. `relu(x) = max(zero(x), x)`","user":"UM9Q1BM9Q","ts":"1611452190.016300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VPg4d","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"good point. this is the relu from Flux. "},{"type":"text","text":"relu(x) = max(zero(x), x)","style":{"code":true}}]}]}]},{"client_msg_id":"8d383806-dfa7-40be-beb8-c08d5efb5257","type":"message","text":"but let's say i have a bunch of functions that have float arguments","user":"UM9Q1BM9Q","ts":"1611452221.017200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WP6j","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but let's say i have a bunch of functions that have float arguments"}]}]}]},{"client_msg_id":"f121427d-eb34-4ba4-a69e-8e156399ff66","type":"message","text":"is the best way to do this to explicitly put every float argument in with an `f0`?","user":"UM9Q1BM9Q","ts":"1611452284.018200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0wfM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is the best way to do this to explicitly put every float argument in with an "},{"type":"text","text":"f0","style":{"code":true}},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"dac259d3-e694-49c4-88bf-6ccaed402180","type":"message","text":"This only applies to constant floats, which I imagine you'll have very few of","user":"UMY1LV01G","ts":"1611452324.018600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0uFbh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This only applies to constant floats, which I imagine you'll have very few of"}]}]}]},{"client_msg_id":"da0d8819-a9a6-4a14-8932-8b29cf1c330a","type":"message","text":"fair","user":"UM9Q1BM9Q","ts":"1611452357.019500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yat/l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"fair"}]}]}]},{"client_msg_id":"d8778982-4dac-4281-9423-d6b207328e64","type":"message","text":"Flux already inits model params to float32 by default","user":"UMY1LV01G","ts":"1611452359.019800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LaCJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Flux already inits model params to float32 by default"}]}]}]},{"client_msg_id":"7b016954-8982-46f5-bbd1-c941424de176","type":"message","text":"ok cool, this should make my life easier","user":"UM9Q1BM9Q","ts":"1611452418.021200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"52qm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ok cool, this should make my life easier"}]}]}]},{"client_msg_id":"bd4e3f18-32db-4f63-b5b7-8b0d8a023676","type":"message","text":"thanks!","user":"UM9Q1BM9Q","ts":"1611452421.021400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JGH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thanks!"}]}]}]},{"client_msg_id":"226DE114-C9FB-4164-B6FD-989545B96587","type":"message","text":"Or when you create an array like `x = rand(Float32, 3, 4)`. Basically, only when you create and allocate variables should you need to explicitly say “I want a Float32.” The rest should all be handled via Julia’s <https://docs.julialang.org/en/v1/manual/conversion-and-promotion/#Promotion|promotion system>.","user":"UH9KWTTD3","ts":"1611452547.023300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vv8K1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Or when you create an array like "},{"type":"text","text":"x = rand(Float32, 3, 4)","style":{"code":true}},{"type":"text","text":". Basically, only when you create and allocate variables should you need to explicitly say “I want a Float32.” The rest should all be handled via Julia’s "},{"type":"link","url":"https://docs.julialang.org/en/v1/manual/conversion-and-promotion/#Promotion","text":"promotion system"},{"type":"text","text":"."}]}]}],"reactions":[{"name":"+1","users":["UM9Q1BM9Q"],"count":1}]},{"client_msg_id":"c8a62483-1a69-4b1b-9cf8-ec57280bf0c4","type":"message","text":"hi folks, a quick question out of curiosity: what kinds of compiler optimizations happen in flux in regards to the networks that get built? is there any tensor graph optimization happening? we are building a particularly unique general purpose customizable optimization package for Julia and the techniques we implemented fit really well for optimizing signal flow graphs. we are curious about what's already happening in Flux and we'd like to try applying those techniques to flux nets soon\\ :rocket:","user":"U01K2JB9GPJ","ts":"1611747369.027200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"997","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hi folks, a quick question out of curiosity: what kinds of compiler optimizations happen in flux in regards to the networks that get built? is there any tensor graph optimization happening? we are building a particularly unique general purpose customizable optimization package for Julia and the techniques we implemented fit really well for optimizing signal flow graphs. we are curious about what's already happening in Flux and we'd like to try applying those techniques to flux nets soon\\ "},{"type":"emoji","name":"rocket"}]}]}],"thread_ts":"1611747369.027200","reply_count":2,"reply_users_count":2,"latest_reply":"1611765648.027600","reply_users":["UC4QQPG4A","UDGT4PM41"],"subscribed":false},{"client_msg_id":"5b63a507-7dd8-413d-9551-f3bcb9046518","type":"message","text":"Is it possible to change the AD backend in Flux?","user":"URLJH245D","ts":"1611790245.028000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hL2i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it possible to change the AD backend in Flux?"}]}]}]},{"type":"message","subtype":"bot_message","text":"`function g(x)     if x &lt; 0          print(\"Enter function name: \")         getfield(Base, Symbol(readline()))(x)     else         2*x^3 + 4*x^2 +5*x     end end`  `julia&gt; g'(-pi/6) Enter function name: sin ERROR: Can't differentiate foreigncall expression ` g'(2) works fine but the above case fails, why?","ts":"1611804254.028400","username":"[gitter] <adhikarirsr>","bot_id":"B795XHD0X","blocks":[{"type":"section","block_id":"matterbridge_c05cuukg27ibs0bi3tjg","text":{"type":"mrkdwn","text":"`function g(x)\n    if x &lt; 0 \n        print(\"Enter function name: \")\n        getfield(Base, Symbol(readline()))(x)\n    else\n        2*x^3 + 4*x^2 +5*x\n    end\nend`\n\n`julia&gt; g'(-pi/6)\nEnter function name: sin\nERROR: Can't differentiate foreigncall expression\n`\ng'(2) works fine but the above case fails, why?","verbatim":false}}]},{"type":"message","subtype":"bot_message","text":"&gt; &gt;```function g(x) &gt;     if x &lt; 0  &gt;         print(\"Enter function name: \") &gt;         getfield(Base, Symbol(readline()))(x) &gt;     else &gt;         2*x^3 + 4*x^2 +5*x &gt;     end &gt; end``` &gt;  &gt; `julia&gt; g'(-pi/6) &gt; Enter function name: sin &gt; ERROR: Can't differentiate foreigncall expression &gt; ` &gt; g'(2) works fine but the above case fails, why?  ","ts":"1611804398.028500","username":"[gitter] <adhikarirsr>","bot_id":"B795XHD0X","blocks":[{"type":"section","block_id":"matterbridge_c05cuukg27ibs0bi3tjg","text":{"type":"mrkdwn","text":"&gt; &gt;```function g(x)\n&gt;     if x &lt; 0 \n&gt;         print(\"Enter function name: \")\n&gt;         getfield(Base, Symbol(readline()))(x)\n&gt;     else\n&gt;         2*x^3 + 4*x^2 +5*x\n&gt;     end\n&gt; end```\n&gt; \n&gt; `julia&gt; g'(-pi/6)\n&gt; Enter function name: sin\n&gt; ERROR: Can't differentiate foreigncall expression\n&gt; `\n&gt; g'(2) works fine but the above case fails, why?\n\n","verbatim":false}}]},{"type":"message","subtype":"bot_message","text":"`using Flux using Zygote: forwarddiff using Trebuchet  function shoot(wind, angle, weight)   Trebuchet.shoot((wind, Trebuchet.deg2rad(angle), weight))[2] end `  `julia&gt; shoot'(5,50,220) ERROR: MethodError: no method matching (::Zygote.var\"#43#44\"{typeof(shoot)})(::Int64, ::Int64, ::Int64)`  This  also fails","ts":"1611806377.028600","username":"[gitter] <adhikarirsr>","bot_id":"B795XHD0X","blocks":[{"type":"section","block_id":"matterbridge_c05cuukg27ibs0bi3tjg","text":{"type":"mrkdwn","text":"`using Flux\nusing Zygote: forwarddiff\nusing Trebuchet\n\nfunction shoot(wind, angle, weight)\n  Trebuchet.shoot((wind, Trebuchet.deg2rad(angle), weight))[2]\nend\n`\n\n`julia&gt; shoot'(5,50,220)\nERROR: MethodError: no method matching (::Zygote.var\"#43#44\"{typeof(shoot)})(::Int64, ::Int64, ::Int64)`\n\nThis  also fails","verbatim":false}}]},{"type":"message","subtype":"bot_message","text":"here's the stacktrace for g(x):  `julia&gt; g'(-pi/6)  Enter function name: sin ERROR: Can't differentiate foreigncall expression Stacktrace:  [1] error(::String) at ./error.jl:33  [2] Symbol at ./boot.jl:438 [inlined]  [3] (::typeof(∂(Symbol)))(::Nothing) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface2.jl:0  [4] g at /home/user/julia_control/cm_control.jl:17 [inlined]  [5] (::typeof(∂(g)))(::Float64) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface2.jl:0  [6] (::Zygote.var\"#41#42\"{typeof(∂(g))})(::Float64) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface.jl:40  [7] gradient(::Function, ::Float64) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface.jl:49  [8] (::Zygote.var\"#43#44\"{typeof(g)})(::Float64) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface.jl:52  [9] top-level scope at none:1`  ","ts":"1611821151.029000","username":"[gitter] <adhikarirsr>","bot_id":"B795XHD0X","blocks":[{"type":"section","block_id":"matterbridge_c05cuukg27ibs0bi3tjg","text":{"type":"mrkdwn","text":"here's the stacktrace for g(x):\n\n`julia&gt; g'(-pi/6) \nEnter function name: sin\nERROR: Can't differentiate foreigncall expression\nStacktrace:\n [1] error(::String) at ./error.jl:33\n [2] Symbol at ./boot.jl:438 [inlined]\n [3] (::typeof(∂(Symbol)))(::Nothing) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface2.jl:0\n [4] g at /home/user/julia_control/cm_control.jl:17 [inlined]\n [5] (::typeof(∂(g)))(::Float64) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface2.jl:0\n [6] (::Zygote.var\"#41#42\"{typeof(∂(g))})(::Float64) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface.jl:40\n [7] gradient(::Function, ::Float64) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface.jl:49\n [8] (::Zygote.var\"#43#44\"{typeof(g)})(::Float64) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface.jl:52\n [9] top-level scope at none:1`\n\n","verbatim":false}}]},{"type":"message","subtype":"bot_message","text":"Here's the one for Trebuchet: `julia&gt; shoot'(5,55,200) ERROR: MethodError: no method matching (::Zygote.var\"#43#44\"{typeof(shoot)})(::Int64, ::Int64, ::Int64) Closest candidates are:   #43(::Any) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface.jl:52 Stacktrace:  [1] top-level scope at none:1`","ts":"1611821546.029100","username":"[gitter] <adhikarirsr>","bot_id":"B795XHD0X","blocks":[{"type":"section","block_id":"matterbridge_c05cuukg27ibs0bi3tjg","text":{"type":"mrkdwn","text":"Here's the one for Trebuchet:\n`julia&gt; shoot'(5,55,200)\nERROR: MethodError: no method matching (::Zygote.var\"#43#44\"{typeof(shoot)})(::Int64, ::Int64, ::Int64)\nClosest candidates are:\n  #43(::Any) at /home/user/.julia/packages/Zygote/ggM8Z/src/compiler/interface.jl:52\nStacktrace:\n [1] top-level scope at none:1`","verbatim":false}}]},{"type":"message","subtype":"bot_message","text":"thanks @Dhairya what is `@nograd Symbol` and what does it do? I am new to `zygote`. How should I fix trebuchet?","ts":"1611861292.030600","username":"[gitter] <adhikarirsr>","bot_id":"B795XHD0X","blocks":[{"type":"section","block_id":"matterbridge_c05cuukg27ibs0bi3tjg","text":{"type":"mrkdwn","text":"thanks @Dhairya what is `@nograd Symbol` and what does it do? I am new to `zygote`. How should I fix trebuchet?","verbatim":false}}]},{"client_msg_id":"6124ec5c-9cab-49b9-8c84-f427828fbeb1","type":"message","text":"I’m trying to extend Flux’s `Recur` to return both the cell and hidden state. When I do that, training on the GPU breaks, whereas it works fine on the CPU.  Does anyone have an idea why?\nMWE is the following, and stacktrace is in the thread:\n```using Flux\n\nmutable struct FullRecur{T}\n    cell::T\n    init\n    state\nend\nFullRecur(m, h = Flux.hidden(m)) = FullRecur(m, h, h)\n\nfunction (m::FullRecur)(xs...)\n    h, y = m.cell(m.state, xs...)\n    m.state = h\n    return h   # &lt;--- return value changed from `Recur`\nend\n\nFlux.@functor FullRecur cell, init\n\nlstm = FullRecur(Flux.LSTMCell(10,5)) |&gt; gpu\n\nx = rand(Float32, 10,30) |&gt; gpu\ny = rand(Float32, 10,30) |&gt; gpu\n\nm = (x) -&gt; cat(lstm(x)..., dims=1) |&gt; gpu\nloss(x,y) = Flux.mse(m(x),y)\n\nFlux.train!(loss, Flux.params(lstm), [(x,y)], ADAM())\n# ERROR: MethodError: no method matching size(::Nothing, ::Int64)```\n","user":"UNZKG0909","ts":"1611929867.031200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"np9Qm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m trying to extend Flux’s "},{"type":"text","text":"Recur","style":{"code":true}},{"type":"text","text":" to return both the cell and hidden state. When I do that, training on the GPU breaks, whereas it works fine on the CPU.  Does anyone have an idea why?\nMWE is the following, and stacktrace is in the thread:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Flux\n\nmutable struct FullRecur{T}\n    cell::T\n    init\n    state\nend\nFullRecur(m, h = Flux.hidden(m)) = FullRecur(m, h, h)\n\nfunction (m::FullRecur)(xs...)\n    h, y = m.cell(m.state, xs...)\n    m.state = h\n    return h   # <--- return value changed from `Recur`\nend\n\nFlux.@functor FullRecur cell, init\n\nlstm = FullRecur(Flux.LSTMCell(10,5)) |> gpu\n\nx = rand(Float32, 10,30) |> gpu\ny = rand(Float32, 10,30) |> gpu\n\nm = (x) -> cat(lstm(x)..., dims=1) |> gpu\nloss(x,y) = Flux.mse(m(x),y)\n\nFlux.train!(loss, Flux.params(lstm), [(x,y)], ADAM())\n# ERROR: MethodError: no method matching size(::Nothing, ::Int64)"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1611929867.031200","reply_count":5,"reply_users_count":2,"latest_reply":"1611947066.032400","reply_users":["UNZKG0909","UC4QQPG4A"],"subscribed":false},{"client_msg_id":"64a18a96-b76c-4785-a176-d9c5d76bbdb2","type":"message","text":"<https://discourse.julialang.org/t/1d-gan-with-flux/54179|https://discourse.julialang.org/t/1d-gan-with-flux/54179>","user":"UDGT4PM41","ts":"1611937465.031600","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"1D GAN with Flux","title_link":"https://discourse.julialang.org/t/1d-gan-with-flux/54179","text":"Hey everyone. So I’ve been trying to use Flux for Generative Adversarial Networks (GAN). And unfortunately, it’s not working properly. At the moment, I’m trying to replicate a 1D GAN example (this one here 1D GAN with Keras). But the results are just not good. First, the discriminator takes a lot to properly learn to discern the data, and the generator is even worse. I was wondering if anyone here has implemented GANs on Flux, and perhaps can show how to implement this 1D example. I’ve based my...","fallback":"JuliaLang: 1D GAN with Flux","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1611924742,"from_url":"https://discourse.julialang.org/t/1d-gan-with-flux/54179","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/1d-gan-with-flux/54179"}],"blocks":[{"type":"rich_text","block_id":"ktd","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://discourse.julialang.org/t/1d-gan-with-flux/54179","text":"https://discourse.julialang.org/t/1d-gan-with-flux/54179"}]}]}]},{"client_msg_id":"5a1faf5f-f687-4c34-8aaa-34678af50402","type":"message","text":"I'm super new to Flux so probably a very basic question but how do I get Flux to recognize the parameters of my custom layer? Based on docs I tried this but doesn't seem to work:\n```struct LinearCombo{T}\n    c :: T\nend\n(lc::LinearCombo)(x, y) = @. x + lc.c * y\nFlux.@functor LinearCombo\nparams(LinearCombo(1)) # gives Params([])```","user":"UUMJUCYRK","ts":"1612051204.034500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YXXfN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm super new to Flux so probably a very basic question but how do I get Flux to recognize the parameters of my custom layer? Based on docs I tried this but doesn't seem to work:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"struct LinearCombo{T}\n    c :: T\nend\n(lc::LinearCombo)(x, y) = @. x + lc.c * y\nFlux.@functor LinearCombo\nparams(LinearCombo(1)) # gives Params([])"}]}]}],"thread_ts":"1612051204.034500","reply_count":4,"reply_users_count":3,"latest_reply":"1612080823.035300","reply_users":["UMY1LV01G","UUMJUCYRK","UNG2XJJP3"],"subscribed":false},{"client_msg_id":"39ca300e-7dcb-4812-97ab-93c5b75ec6f1","type":"message","text":"<https://julialang.slack.com/archives/C7120PCUQ/p1612217592004700>","user":"UM70NJEER","ts":"1612246737.036100","team":"T68168MUP","attachments":[{"from_url":"https://julialang.slack.com/archives/C7120PCUQ/p1612217592004700","fallback":"[February 1st, 2021 2:13 PM] lazarus.alon: Hello, it seems that the new LSTM, doesn't allow to put the activation function within the call, as the source code says :`LSTM(in::Integer, out::Integer, σ = tanh),`  any idea how could I achieve the same result. `Chain(LSTM(3,10), Flux.relu, Dense(10,1))` gives problems also because of broadcasting.","ts":"1612217592.004700","author_id":"UM70NJEER","author_subname":"Lazaro","channel_id":"C7120PCUQ","channel_name":"flux","is_msg_unfurl":true,"text":"Hello, it seems that the new LSTM, doesn't allow to put the activation function within the call, as the source code says :`LSTM(in::Integer, out::Integer, σ = tanh),`  any idea how could I achieve the same result. `Chain(LSTM(3,10), Flux.relu, Dense(10,1))` gives problems also because of broadcasting.","author_name":"Lazaro","author_link":"https://julialang.slack.com/team/UM70NJEER","author_icon":"https://avatars.slack-edge.com/2019-10-29/801496800483_d1d644dfbd61c7e4a7f8_48.png","mrkdwn_in":["text"],"id":1,"original_url":"https://julialang.slack.com/archives/C7120PCUQ/p1612217592004700","footer":"Posted in #flux"}],"blocks":[{"type":"rich_text","block_id":"wES","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://julialang.slack.com/archives/C7120PCUQ/p1612217592004700"}]}]}],"thread_ts":"1612246737.036100","reply_count":14,"reply_users_count":2,"latest_reply":"1612370238.050100","reply_users":["UMY1LV01G","UM70NJEER"],"subscribed":false},{"client_msg_id":"f76ebaa6-e01c-47ff-977a-2c29611fb1f3","type":"message","text":"I am training via Flux right now and it seems to be consuming up to JULIA_NUM_THREADS CPUs. Rudimentary GitHub searching for spawn and Threads is not getting me anywhere.\n\nWhich part of the stack is causing this? Or, alternatively, is none of it causing it?","user":"USDM93QF8","ts":"1612317735.042200","team":"T68168MUP","edited":{"user":"USDM93QF8","ts":"1612319100.000000"},"blocks":[{"type":"rich_text","block_id":"sB4nJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am training via Flux right now and it seems to be consuming up to JULIA_NUM_THREADS CPUs. Rudimentary GitHub searching for spawn and Threads is not getting me anywhere.\n\nWhich part of the stack is causing this? Or, alternatively, is none of it causing it?"}]}]}]},{"client_msg_id":"9b4d8561-70eb-4f60-a5d4-7624774ac572","type":"message","text":"Blas is","user":"U6N6VQE30","ts":"1612338737.044900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"otZlM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Blas is"}]}]}],"reactions":[{"name":"point_up","users":["UMY1LV01G","USDM93QF8"],"count":2}]},{"client_msg_id":"ca946b7b-04cc-4379-bb87-54c96cb432a5","type":"message","text":"We respect the usual settings of a Julia instance. Blas would already multithread some stuff, but tweaking the environment variable would allow more threads to be used for other tasks etc.","user":"UC4QQPG4A","ts":"1612338772.045900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8xjXI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We respect the usual settings of a Julia instance. Blas would already multithread some stuff, but tweaking the environment variable would allow more threads to be used for other tasks etc."}]}]}]},{"client_msg_id":"bf2fa43b-a348-40b4-b30a-0332f0b6d9c0","type":"message","text":"Got it, thanks. I had been training multiple models in parallel, which was using all my allocated threads (expected) but then I stopped training in parallel and was still using all threads (what?). This explains it and lets me reduce peak RAM demand while not taking too much of a latency penalty","user":"USDM93QF8","ts":"1612368068.048400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YMucv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Got it, thanks. I had been training multiple models in parallel, which was using all my allocated threads (expected) but then I stopped training in parallel and was still using all threads (what?). This explains it and lets me reduce peak RAM demand while not taking too much of a latency penalty"}]}]}]},{"client_msg_id":"0e45b01e-c636-427e-a4c9-7cdb53a25d11","type":"message","text":"Yeah, at work we also stumbled upon that.\nIf you want to make lots of things in parallel by yourself and not let blas take many threads, you can do.\n```BLAS.set_num_threads(1)```\nin fact, we have\n```function __init__()\n  if Threads.nthreads() &gt; 1\n    @warn \"Detected JULIA_NUM_THREADS &gt; 1. Setting BLAS threads to 1.\"\n    BLAS.set_num_threads(1)\n  end\nend```\nin one of our internal libraries :smile:","user":"USBKT1275","ts":"1612370033.050000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"C7GF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, at work we also stumbled upon that.\nIf you want to make lots of things in parallel by yourself and not let blas take many threads, you can do.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"BLAS.set_num_threads(1)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"in fact, we have\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function __init__()\n  if Threads.nthreads() > 1\n    @warn \"Detected JULIA_NUM_THREADS > 1. Setting BLAS threads to 1.\"\n    BLAS.set_num_threads(1)\n  end\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"in one of our internal libraries "},{"type":"emoji","name":"smile"}]}]}]},{"client_msg_id":"1fd94bb6-9cfa-431b-9cce-74185dae85a2","type":"message","text":"Is it kind of like a slap on the wrist? :joy: :joy:","user":"UC4QQPG4A","ts":"1612371087.050800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Jgt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it kind of like a slap on the wrist? "},{"type":"emoji","name":"joy"},{"type":"text","text":" "},{"type":"emoji","name":"joy"}]}]}]},{"client_msg_id":"377581ef-465c-42d2-9ac9-26fd711eb1b3","type":"message","text":"I've successfully used Flux for multi-label classification several times, using this example from the model zoo as my starting point:\n\n<https://github.com/FluxML/model-zoo/blob/master/vision/mnist/mlp.jl>\n\nToday I needed binary classification. I naively assumed I could achieve this by not one-hot-encoding the labels, having just a single output from the final layer, and replacing the `logitcrossentropy` loss function with `Flux.Losses.logitbinarycrossentropy`, with no other changes. However, this does not work at all. The model is not learning.\n\nWhen I revert to multi-label classification (one-hot-encoded labels, two outputs from the final layer, logitcrossentropy loss) everything works as expected.\n\nI'm feeling really stupid. What am I missing?","user":"UGQRDMRCG","ts":"1612454297.055900","team":"T68168MUP","edited":{"user":"UGQRDMRCG","ts":"1612455395.000000"},"blocks":[{"type":"rich_text","block_id":"XHAHN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've successfully used Flux for multi-label classification several times, using this example from the model zoo as my starting point:\n\n"},{"type":"link","url":"https://github.com/FluxML/model-zoo/blob/master/vision/mnist/mlp.jl"},{"type":"text","text":"\n\nToday I needed binary classification. I naively assumed I could achieve this by not one-hot-encoding the labels, having just a single output from the final layer, and replacing the "},{"type":"text","text":"logitcrossentropy","style":{"code":true}},{"type":"text","text":" loss function with "},{"type":"text","text":"Flux.Losses.logitbinarycrossentropy","style":{"code":true}},{"type":"text","text":", with no other changes. However, this does not work at all. The model is not learning.\n\nWhen I revert to multi-label classification (one-hot-encoded labels, two outputs from the final layer, logitcrossentropy loss) everything works as expected.\n\nI'm feeling really stupid. What am I missing?"}]}]}],"thread_ts":"1612454297.055900","reply_count":3,"reply_users_count":2,"latest_reply":"1612455430.056500","reply_users":["UMY1LV01G","UGQRDMRCG"],"subscribed":false},{"client_msg_id":"7d4f0c16-788d-4e51-b3f4-41e852d6fd9a","type":"message","text":"Hi, I stumbled across some posts on Discourse comparing the speed of Flux with Pytorch. I know there’s been intense development done to Flux, both extending it’s API and accelerating specific operations, but I couldn’t find any recent speed comparisons.","user":"UPM0H43C7","ts":"1612468619.058800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2sEs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I stumbled across some posts on Discourse comparing the speed of Flux with Pytorch. I know there’s been intense development done to Flux, both extending it’s API and accelerating specific operations, but I couldn’t find any recent speed comparisons."}]}]}]},{"type":"message","text":"What would be the recommended approach to add a new optimizer to Flux?","user":"U9MD78Z9N","ts":"1612555966.067500","team":"T68168MUP","thread_ts":"1612555966.067500","reply_count":2,"reply_users_count":2,"latest_reply":"1612556097.068300","reply_users":["UH9KWTTD3","U9MD78Z9N"],"subscribed":false},{"client_msg_id":"de12c684-f8b0-498b-9016-0c1709486273","type":"message","text":"I saved a model with @save like so:\n`julia&gt; @save \"count_ones_model.bson\" model`\nNow when I try to load it back in I get:\n`julia&gt; @load \"count_ones_model.bson\" mymod`\nERROR: KeyError: key :mymod not found\nStacktrace:\n [1] getindex(::Dict{Symbol,Any}, ::Symbol) at ./dict.jl:467\n [2] top-level scope at /home/phil/.julia/packages/BSON/XAts7/src/BSON.jl:53","user":"U9RDM8ZGT","ts":"1612563825.073100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nRh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I saved a model with @save like so:\n"},{"type":"text","text":"julia> @save \"count_ones_model.bson\" model","style":{"code":true}},{"type":"text","text":"\nNow when I try to load it back in I get:\n"},{"type":"text","text":"julia> @load \"count_ones_model.bson\" mymod","style":{"code":true}},{"type":"text","text":"\nERROR: KeyError: key :mymod not found\nStacktrace:\n [1] getindex(::Dict{Symbol,Any}, ::Symbol) at ./dict.jl:467\n [2] top-level scope at /home/phil/.julia/packages/BSON/XAts7/src/BSON.jl:53"}]}]}],"thread_ts":"1612563825.073100","reply_count":2,"reply_users_count":2,"latest_reply":"1612565580.074500","reply_users":["UH9KWTTD3","U9RDM8ZGT"],"subscribed":false},{"client_msg_id":"9cdea95b-88dd-448c-a204-c1d73d20b1b0","type":"message","text":"Let's say I train an NN model in Flux using batchsizse 100 and after some number of epochs I get 95% accuracy. How could I examine some of the failing 5% of testcases given that the batchsize is 100? It seems pretty easily doable with batchsize 1, but that runs very slow.","user":"U9RDM8ZGT","ts":"1612649267.076900","team":"T68168MUP","edited":{"user":"U9RDM8ZGT","ts":"1612649297.000000"},"blocks":[{"type":"rich_text","block_id":"Q1Pee","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Let's say I train an NN model in Flux using batchsizse 100 and after some number of epochs I get 95% accuracy. How could I examine some of the failing 5% of testcases given that the batchsize is 100? It seems pretty easily doable with batchsize 1, but that runs very slow."}]}]}]},{"client_msg_id":"cc8cb69e-59d8-44df-ab52-306fce319c60","type":"message","text":"What I ended up doing was re-running DataLoader using batchsize=1 in order to more easily query the testcases... I'm hoping there's an easier way already built-in for doing this.","user":"U9RDM8ZGT","ts":"1612649390.078300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7w4I0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What I ended up doing was re-running DataLoader using batchsize=1 in order to more easily query the testcases... I'm hoping there's an easier way already built-in for doing this."}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"I've setup a simple NN that counts the number of 1's in a 60 slot vector. What I found was that the failing testcases were cases where there was only one 1 in the vector and also the case where the input had nine 1's.","user":"U9RDM8ZGT","ts":"1612650280.079200","thread_ts":"1612649267.076900","root":{"client_msg_id":"9cdea95b-88dd-448c-a204-c1d73d20b1b0","type":"message","text":"Let's say I train an NN model in Flux using batchsizse 100 and after some number of epochs I get 95% accuracy. How could I examine some of the failing 5% of testcases given that the batchsize is 100? It seems pretty easily doable with batchsize 1, but that runs very slow.","user":"U9RDM8ZGT","ts":"1612649267.076900","team":"T68168MUP","edited":{"user":"U9RDM8ZGT","ts":"1612649297.000000"},"blocks":[{"type":"rich_text","block_id":"Q1Pee","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Let's say I train an NN model in Flux using batchsizse 100 and after some number of epochs I get 95% accuracy. How could I examine some of the failing 5% of testcases given that the batchsize is 100? It seems pretty easily doable with batchsize 1, but that runs very slow."}]}]}],"thread_ts":"1612649267.076900","reply_count":6,"reply_users_count":2,"latest_reply":"1612652520.080000","reply_users":["UH9KWTTD3","U9RDM8ZGT"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"5zs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've setup a simple NN that counts the number of 1's in a 60 slot vector. What I found was that the failing testcases were cases where there was only one 1 in the vector and also the case where the input had nine 1's."}]}]}],"client_msg_id":"6b76f9a1-2f76-4967-894f-05b827e378a3"},{"type":"message","subtype":"thread_broadcast","text":"But I had to reload my testdata with DataLoader and batchsize=1 in order to figure this out. I'm hoping there's a nicer way to do that.","user":"U9RDM8ZGT","ts":"1612650349.079500","thread_ts":"1612649267.076900","root":{"client_msg_id":"9cdea95b-88dd-448c-a204-c1d73d20b1b0","type":"message","text":"Let's say I train an NN model in Flux using batchsizse 100 and after some number of epochs I get 95% accuracy. How could I examine some of the failing 5% of testcases given that the batchsize is 100? It seems pretty easily doable with batchsize 1, but that runs very slow.","user":"U9RDM8ZGT","ts":"1612649267.076900","team":"T68168MUP","edited":{"user":"U9RDM8ZGT","ts":"1612649297.000000"},"blocks":[{"type":"rich_text","block_id":"Q1Pee","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Let's say I train an NN model in Flux using batchsizse 100 and after some number of epochs I get 95% accuracy. How could I examine some of the failing 5% of testcases given that the batchsize is 100? It seems pretty easily doable with batchsize 1, but that runs very slow."}]}]}],"thread_ts":"1612649267.076900","reply_count":6,"reply_users_count":2,"latest_reply":"1612652520.080000","reply_users":["UH9KWTTD3","U9RDM8ZGT"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"zgX6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But I had to reload my testdata with DataLoader and batchsize=1 in order to figure this out. I'm hoping there's a nicer way to do that."}]}]}],"client_msg_id":"befdf432-c05b-4ddb-8dca-fbd3d25e9d2e"},{"client_msg_id":"ae44a2f6-29f7-4902-976a-6b4d11026919","type":"message","text":"might be interesting to look at... <https://github.com/google-research/sputnik> gpu kernels for sparse ops","user":"UPUBAM63X","ts":"1612704101.084000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2h9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"might be interesting to look at... "},{"type":"link","url":"https://github.com/google-research/sputnik"},{"type":"text","text":" gpu kernels for sparse ops"}]}]}]},{"client_msg_id":"6813c4f7-0ec9-4092-8cb0-3a45ecb0ab34","type":"message","text":"<https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941|https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941>","user":"UDGT4PM41","ts":"1612894653.084400","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Different behaviour between Flux.jl and Pytorch","title_link":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941","text":"I am trying to generate the results of this paper <https://arxiv.org/abs/1808.03856>. I have created two similar models using Flux.jl and Pytorch. There is no equivalence to pytorch.gather function in Flux.jl, so I created a custom function called gather and it returns the correct value. The problem is that my Pytorch loss decreases but my Flux.jl doesn’t decrease and my Pytorch code generates the distribution correctly but my Flux.jl code only shows a nearly uniform distribution which is wrong. ...","fallback":"JuliaLang: Different behaviour between Flux.jl and Pytorch","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1612889188,"from_url":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941"}],"blocks":[{"type":"rich_text","block_id":"fu2IA","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941","text":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941"}]}]}],"thread_ts":"1612894653.084400","reply_count":1,"reply_users_count":1,"latest_reply":"1612896081.084600","reply_users":["UMY1LV01G"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"&gt; Another question: How can I trace the behaviour of gradient?\nI'm going to shamelessly post <https://github.com/FluxML/Flux.jl/pull/1471#issuecomment-765801411> again :troll:","user":"UMY1LV01G","ts":"1612896081.084600","thread_ts":"1612894653.084400","root":{"client_msg_id":"6813c4f7-0ec9-4092-8cb0-3a45ecb0ab34","type":"message","text":"<https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941|https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941>","user":"UDGT4PM41","ts":"1612894653.084400","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Different behaviour between Flux.jl and Pytorch","title_link":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941","text":"I am trying to generate the results of this paper <https://arxiv.org/abs/1808.03856>. I have created two similar models using Flux.jl and Pytorch. There is no equivalence to pytorch.gather function in Flux.jl, so I created a custom function called gather and it returns the correct value. The problem is that my Pytorch loss decreases but my Flux.jl doesn’t decrease and my Pytorch code generates the distribution correctly but my Flux.jl code only shows a nearly uniform distribution which is wrong. ...","fallback":"JuliaLang: Different behaviour between Flux.jl and Pytorch","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1612889188,"from_url":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941"}],"blocks":[{"type":"rich_text","block_id":"fu2IA","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941","text":"https://discourse.julialang.org/t/different-behaviour-between-flux-jl-and-pytorch/54941"}]}]}],"thread_ts":"1612894653.084400","reply_count":1,"reply_users_count":1,"latest_reply":"1612896081.084600","reply_users":["UMY1LV01G"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"kZYM","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"Another question: How can I trace the behaviour of gradient?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nI'm going to shamelessly post "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/pull/1471#issuecomment-765801411"},{"type":"text","text":" again "},{"type":"emoji","name":"troll"}]}]}],"client_msg_id":"46fe3b22-6f62-46da-a0bb-f374ea53e334","edited":{"user":"UMY1LV01G","ts":"1612896119.000000"}},{"client_msg_id":"0BBDE7A2-4CD8-4BC1-90EF-34ADD9C087D0","type":"message","text":"I think there's something weird about destructure and how it's adjoint interact with layers that don't use all the fields defined in a particular struct. ","user":"UPM0H43C7","ts":"1613015595.086800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"15b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think there's something weird about destructure and how it's adjoint interact with layers that don't use all the fields defined in a particular struct. "}]}]}],"thread_ts":"1613015595.086800","reply_count":1,"reply_users_count":1,"latest_reply":"1613016091.095700","reply_users":["UPM0H43C7"],"subscribed":false},{"client_msg_id":"56f983fa-2d0e-4f28-806c-fa1e9f3f4db3","type":"message","text":"Thinking of writing a small package for assorted early stopping criteria (patience, generalized loss threshold, etc). I have multiple use-cases and so want something separate.  Is there code for this already sitting around somewhere?","user":"UD0SQV5LL","ts":"1613074876.099200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"s+5o","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thinking of writing a small package for assorted early stopping criteria (patience, generalized loss threshold, etc). I have multiple use-cases and so want something separate.  Is there code for this already sitting around somewhere?"}]}]}]},{"client_msg_id":"e3a23b05-875e-49a2-b81d-95efe69110bf","type":"message","text":"FluxTraining.jl has `StopOnNaNLoss` and a generic `EarlyStopping` callback, but other than that I'm not aware of any. Curious to hear more about your design for this :slightly_smiling_face:","user":"UMY1LV01G","ts":"1613075340.100100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"d7gZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"FluxTraining.jl has "},{"type":"text","text":"StopOnNaNLoss","style":{"code":true}},{"type":"text","text":" and a generic "},{"type":"text","text":"EarlyStopping","style":{"code":true}},{"type":"text","text":" callback, but other than that I'm not aware of any. Curious to hear more about your design for this "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"5075b5d9-afd1-447b-b371-1001af4af8a8","type":"message","text":"I sincerely hope that we can write a simple helper package that is a collection of callbacks to be used with Flux.","user":"UC4QQPG4A","ts":"1613077919.101200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FJp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I sincerely hope that we can write a simple helper package that is a collection of callbacks to be used with Flux."}]}]}]},{"client_msg_id":"6e2decbd-ad30-4ad9-ac26-af0c7474cd63","type":"message","text":"You might also be interested in <https://github.com/FluxML/Flux.jl/blob/312643fb77226bc24e0aba04b277780206f7c70e/src/optimise/train.jl#L122|https://github.com/FluxML/Flux.jl/blob/312643fb77226bc24e0aba04b277780206f7c70e/src/optimise/train.jl#L122>\n\nThis way we could hook into generics. Using hooks itself might be dirty, but perhaps exposing a context to have local variables in scope. I haven't gotten down to write it yet, but hopeful that just making some of these things available to callbacks at all is a win.","user":"UC4QQPG4A","ts":"1613078181.104700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xsd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You might also be interested in "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/blob/312643fb77226bc24e0aba04b277780206f7c70e/src/optimise/train.jl#L122","text":"https://github.com/FluxML/Flux.jl/blob/312643fb77226bc24e0aba04b277780206f7c70e/src/optimise/train.jl#L122"},{"type":"text","text":"\n\nThis way we could hook into generics. Using hooks itself might be dirty, but perhaps exposing a context to have local variables in scope. I haven't gotten down to write it yet, but hopeful that just making some of these things available to callbacks at all is a win."}]}]}]},{"client_msg_id":"833cc011-1788-439b-81b3-7ce9ae411b9e","type":"message","text":"I'm trying to implement word2vec with Flux (thought it shouldn't be too hard), but am having some performance issues around what gradients are being calculated. Any suggestions would be greatly appreciated!\n<https://discourse.julialang.org/t/how-to-implement-embeddings-in-flux-that-arent-tragically-slow/55201>","user":"U01KGUEEBJA","ts":"1613214975.106700","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"How to implement embeddings in Flux that aren't tragically slow?","title_link":"https://discourse.julialang.org/t/how-to-implement-embeddings-in-flux-that-arent-tragically-slow/55201","text":"I have recently started learning Julia and Flux for machine learning. I am trying to implement word2vec as a starting point, but the gradient calculations slow down dramatically with larger vocabulary sizes. With negative sampling, each iteration should be independent of the vocabulary size. I use two custom layers: struct Embedding W::Array{Float32,2} end Embedding(vocab_size::Integer, embedding_size::Integer) = Embedding(randn(vocab_size, embedding_size)) @functor Embedding (m::Embedding...","fallback":"JuliaLang: How to implement embeddings in Flux that aren't tragically slow?","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1613212736,"from_url":"https://discourse.julialang.org/t/how-to-implement-embeddings-in-flux-that-arent-tragically-slow/55201","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/how-to-implement-embeddings-in-flux-that-arent-tragically-slow/55201"}],"blocks":[{"type":"rich_text","block_id":"GtmIT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm trying to implement word2vec with Flux (thought it shouldn't be too hard), but am having some performance issues around what gradients are being calculated. Any suggestions would be greatly appreciated!\n"},{"type":"link","url":"https://discourse.julialang.org/t/how-to-implement-embeddings-in-flux-that-arent-tragically-slow/55201"}]}]}],"thread_ts":"1613214975.106700","reply_count":5,"reply_users_count":2,"latest_reply":"1613218341.107900","reply_users":["UD0NS8PDF","U01KGUEEBJA"],"subscribed":false},{"client_msg_id":"28ed4ddc-de0f-4373-846c-9b5909b06cde","type":"message","text":"So this might need some documenting. <https://discourse.julialang.org/t/how-to-implement-embeddings-in-flux-that-arent-tragically-slow/55201/2?u=dhairyagandhi96> shows that we can have the performant version (over 170x faster) if we use arrays over integers when interested in reverse mode.\n\nMaybe just maybe there’s something that we can do for automatic switching which isn’t completely nightmarish in practice.","user":"UC4QQPG4A","ts":"1613226344.111200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Qg+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So this might need some documenting. "},{"type":"link","url":"https://discourse.julialang.org/t/how-to-implement-embeddings-in-flux-that-arent-tragically-slow/55201/2?u=dhairyagandhi96"},{"type":"text","text":" shows that we can have the performant version (over 170x faster) if we use arrays over integers when interested in reverse mode.\n\nMaybe just maybe there’s something that we can do for automatic switching which isn’t completely nightmarish in practice."}]}]}]},{"client_msg_id":"0366f3aa-71ca-4ca1-bf50-5c6a02e4c2e1","type":"message","text":"Hey Folks, I was wondering if anyone knows of an example using Flux for a sequence-2-sequence model. I am doing some time-series forecasting, but even if the model uses text that this fine. I was looking at this example in the phoneme model in the model-zoo -- <https://github.com/FluxML/model-zoo/blob/master/text/phonemes/1-model.jl> , which is indicated as a sequence-to-sequence model. But I know in pytorch when I create a seq2seq model, I have to write a `for` loop to manually pass the hidden state from the currently computed timestep to the next timestep in the decoder. I did not see that kind of loop in the phoneme model, hence why I am asking.","user":"UDDSTBX19","ts":"1613341252.115500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wF+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey Folks, I was wondering if anyone knows of an example using Flux for a sequence-2-sequence model. I am doing some time-series forecasting, but even if the model uses text that this fine. I was looking at this example in the phoneme model in the model-zoo -- "},{"type":"link","url":"https://github.com/FluxML/model-zoo/blob/master/text/phonemes/1-model.jl"},{"type":"text","text":" , which is indicated as a sequence-to-sequence model. But I know in pytorch when I create a seq2seq model, I have to write a "},{"type":"text","text":"for","style":{"code":true}},{"type":"text","text":" loop to manually pass the hidden state from the currently computed timestep to the next timestep in the decoder. I did not see that kind of loop in the phoneme model, hence why I am asking."}]}]}]},{"client_msg_id":"869ffac2-d143-4390-a298-2dbd2fbdfe30","type":"message","text":"I can be way more explicit if that will help. I even have pytorch code if that would help. But the basic idea is that in the decoder, you compute the new hidden state given the prediction at that timestep in the decoder, and then you have to pass that hidden state to the next timestep in the loop.","user":"UDDSTBX19","ts":"1613341360.117200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"f/74b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can be way more explicit if that will help. I even have pytorch code if that would help. But the basic idea is that in the decoder, you compute the new hidden state given the prediction at that timestep in the decoder, and then you have to pass that hidden state to the next timestep in the loop."}]}]}]},{"client_msg_id":"8bd48367-df6a-4cb5-8032-64b39ef16024","type":"message","text":"sure, you can use regular functions. you don’t have to use chain. Alternativrly, if you write a layer which contains both the encoder and decoder, the forward pass can do the indirections as well.","user":"UC4QQPG4A","ts":"1613376040.118700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"c9Uk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"sure, you can use regular functions. you don’t have to use chain. Alternativrly, if you write a layer which contains both the encoder and decoder, the forward pass can do the indirections as well."}]}]}]},{"client_msg_id":"26fc6186-d722-414a-bb97-e2d2e8518b45","type":"message","text":"<@UC4QQPG4A> Oh that is good. Okay. So is there a good tutorial or example for using a function instead of the `chain` call. I am new to flux, so I was doing the 60 minute blitz, and that is very helpful. But then I compared that to the model zoo phoneme's example, and that example was a bit too advanced--meaning that there are a lot of syntax calls that I was not sure how to interpret; for example `vcat.(forward.(tokens), flip(backward, tokens))`. What is the next tutorial to look at after the 60 minute blitz, or is there any prescribed sequence for going through the model zoo examples. Like I said, the challenge is just understanding some of the syntactic manipulations, more than anything else.","user":"UDDSTBX19","ts":"1613401457.122200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Tiam6","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UC4QQPG4A"},{"type":"text","text":" Oh that is good. Okay. So is there a good tutorial or example for using a function instead of the "},{"type":"text","text":"chain","style":{"code":true}},{"type":"text","text":" call. I am new to flux, so I was doing the 60 minute blitz, and that is very helpful. But then I compared that to the model zoo phoneme's example, and that example was a bit too advanced--meaning that there are a lot of syntax calls that I was not sure how to interpret; for example "},{"type":"text","text":"vcat.(forward.(tokens), flip(backward, tokens))","style":{"code":true}},{"type":"text","text":". What is the next tutorial to look at after the 60 minute blitz, or is there any prescribed sequence for going through the model zoo examples. Like I said, the challenge is just understanding some of the syntactic manipulations, more than anything else."}]}]}]},{"client_msg_id":"76cedab8-0a43-4714-89a7-53fca974aae5","type":"message","text":"Thanks again for your help. I want to get a good handle on flux so that I can connect it back to other Julia tools that I use. As always, it is a gradual process :slightly_smiling_face:. Thanks again.","user":"UDDSTBX19","ts":"1613401575.123600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HvPwM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks again for your help. I want to get a good handle on flux so that I can connect it back to other Julia tools that I use. As always, it is a gradual process "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":". Thanks again."}]}]}]},{"type":"message","text":"So this is really, really silly, but I'm confused. Why does this fail?\n```hidden(m::SRUCell) = m.cₜ```","files":[{"id":"F01NK2ZKF2M","created":1613433791,"timestamp":1613433791,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"ULG5V164A","editable":false,"size":393292,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01NK2ZKF2M/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01NK2ZKF2M/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01NK2ZKF2M-7659d04a64/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01NK2ZKF2M-7659d04a64/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01NK2ZKF2M-7659d04a64/image_360.png","thumb_360_w":360,"thumb_360_h":225,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01NK2ZKF2M-7659d04a64/image_480.png","thumb_480_w":480,"thumb_480_h":301,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01NK2ZKF2M-7659d04a64/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01NK2ZKF2M-7659d04a64/image_720.png","thumb_720_w":720,"thumb_720_h":451,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01NK2ZKF2M-7659d04a64/image_800.png","thumb_800_w":800,"thumb_800_h":501,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01NK2ZKF2M-7659d04a64/image_960.png","thumb_960_w":960,"thumb_960_h":601,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01NK2ZKF2M-7659d04a64/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":641,"original_w":1674,"original_h":1048,"thumb_tiny":"AwAeADCnwB060Yz2FGcj/wCtTcj0FADtv0o2/Sm59qM+1ADtv0pCtNooAkP3M0wkmnH7lMoAKKKKACiiigD/2Q==","permalink":"https://julialang.slack.com/files/ULG5V164A/F01NK2ZKF2M/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01NK2ZKF2M-8293377fcc","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"K5EpU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So this is really, really silly, but I'm confused. Why does this fail?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"hidden(m::SRUCell) = m.cₜ"}]}]}],"user":"ULG5V164A","display_as_bot":false,"ts":"1613433806.125800","thread_ts":"1613433806.125800","reply_count":5,"reply_users_count":2,"latest_reply":"1613434102.127100","reply_users":["UH9KWTTD3","ULG5V164A"],"subscribed":false},{"client_msg_id":"1ffd0746-ff92-4596-b6c6-5ff16a890765","type":"message","text":"This looks like a bug: <https://discourse.julialang.org/t/gradient-of-sum/55389>","user":"U7YD3DKL2","ts":"1613476204.127600","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Gradient of sum","title_link":"https://discourse.julialang.org/t/gradient-of-sum/55389","text":"T = randn(10,10) ps = Flux.params(T) opt=ADAM() for iter = 1:100 gs = gradient(ps) do sum(T) end Flux.update!(opt, ps, gs) end throws an error: ArgumentError: Cannot setindex! to 0.0009999999900000003 for an AbstractFill with value 1.0. Stacktrace: [1] setindex! at /home/cossio/.julia/packages/FillArrays/tE9Xq/src/FillArrays.jl:41 [inlined] [2] _setindex! at ./abstractarray.jl:1176 [inlined] [3] setindex! at ./abstractarray.jl:1153 [inlined] [4] macro expansion at ./br...","fallback":"JuliaLang: Gradient of sum","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1613473740,"from_url":"https://discourse.julialang.org/t/gradient-of-sum/55389","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/gradient-of-sum/55389"}],"blocks":[{"type":"rich_text","block_id":"3Rcmd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This looks like a bug: "},{"type":"link","url":"https://discourse.julialang.org/t/gradient-of-sum/55389"}]}]}]},{"client_msg_id":"6c4b1903-a472-4edb-b51f-8a425a46113e","type":"message","text":"Is there some example code for plotting the loss using the train! callback function? (the callback function passed to train!)","user":"U9RDM8ZGT","ts":"1613519550.129300","team":"T68168MUP","edited":{"user":"U9RDM8ZGT","ts":"1613519724.000000"},"blocks":[{"type":"rich_text","block_id":"8OmxL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there some example code for plotting the loss using the train! callback function? (the callback function passed to train!)"}]}]}]},{"client_msg_id":"b8abdfd4-81d3-45c4-a37a-00e6ae8fd0ea","type":"message","text":"I have written a small package, EarlyStopping.j, which might possibly be of interest to Flux developers. I wrote it with future control of iterative MLJ models (incl. MLJFlux) in mind. Any feedback welcome. It is not registered yet but fairy polished. <https://github.com/ablaom/EarlyStopping.jl> <@UMY1LV01G>","user":"UD0SQV5LL","ts":"1613522334.132200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NaR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have written a small package, EarlyStopping.j, which might possibly be of interest to Flux developers. I wrote it with future control of iterative MLJ models (incl. MLJFlux) in mind. Any feedback welcome. It is not registered yet but fairy polished. "},{"type":"link","url":"https://github.com/ablaom/EarlyStopping.jl"},{"type":"text","text":" "},{"type":"user","user_id":"UMY1LV01G"}]}]}],"reactions":[{"name":"tada","users":["UMY1LV01G","UH9KWTTD3"],"count":2},{"name":"+1","users":["UMY1LV01G"],"count":1}]},{"client_msg_id":"051378ad-ae68-42c8-a9fe-a4b7a3819db0","type":"message","text":"Why does `destructure` not work on `NamedTuple` instances?","user":"UKA81L34J","ts":"1613583597.136300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F=h","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Why does "},{"type":"text","text":"destructure","style":{"code":true}},{"type":"text","text":" not work on "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" instances?"}]}]}],"thread_ts":"1613583597.136300","reply_count":8,"reply_users_count":2,"latest_reply":"1613584976.141600","reply_users":["UH9KWTTD3","UKA81L34J"],"subscribed":false},{"client_msg_id":"01620afa-8809-4c71-a664-771d91fbc17d","type":"message","text":"```z = (x = 10, y = 20)\ntheta, re = Flux.destructure(z)\n# (Any[], Flux.var\"#34#36\"{NamedTuple{(:x, :y), Tuple{Float64, Float64}}}((x = 10.0, y = 20.0)))```","user":"UKA81L34J","ts":"1613583629.137300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hjjx2","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"z = (x = 10, y = 20)\ntheta, re = Flux.destructure(z)\n# (Any[], Flux.var\"#34#36\"{NamedTuple{(:x, :y), Tuple{Float64, Float64}}}((x = 10.0, y = 20.0)))"}]}]}]},{"client_msg_id":"38c3ed9c-9a6e-41ec-ad19-7694bf605aea","type":"message","text":"Hi I'm trying to save my model to bson file with `@save` command after each iteration of train, everything is okay in CPU. When I did that on GPU, seems the `@save` command could only save the final model which means the model saved after first  and second train would finally be the same as the model saved after all trainings. From manual, it suggests transfer weights to CPU but seems it's different thing for my model is saved but it's not the one I want. Am I missing some key points here?","user":"U01977X150R","ts":"1613583846.139900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5u/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi I'm trying to save my model to bson file with"},{"type":"text","text":" @save","style":{"code":true}},{"type":"text","text":" command after each iteration of train, everything is okay in CPU. When I did that on GPU, seems the "},{"type":"text","text":"@save","style":{"code":true}},{"type":"text","text":" command could only save the final model which means the model saved after first  and second train would finally be the same as the model saved after all trainings. From manual, it suggests transfer weights to CPU but seems it's different thing for my model is saved but it's not the one I want. Am I missing some key points here?"}]}]}],"thread_ts":"1613583846.139900","reply_count":2,"reply_users_count":2,"latest_reply":"1613585335.141800","reply_users":["UH9KWTTD3","U01977X150R"],"subscribed":false},{"client_msg_id":"7766b8ab-013e-4d2e-b212-f8126bfd8cd6","type":"message","text":"Does anyone know if it is possible to use an external function for the activation function?","user":"UDVQM5U1Z","ts":"1613677411.155200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qWv21","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know if it is possible to use an external function for the activation function?"}]}]}]},{"client_msg_id":"82cbac36-6aa2-4d9d-8e67-e7dc1151dfb0","type":"message","text":"I think this used to be possible but I am getting \"Can't differentiate foreigncall expression\" now?","user":"UDVQM5U1Z","ts":"1613677424.155600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zhT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think this used to be possible but I am getting \"Can't differentiate foreigncall expression\" now?"}]}]}],"thread_ts":"1613677424.155600","reply_count":9,"reply_users_count":2,"latest_reply":"1613678608.158300","reply_users":["UH9KWTTD3","UDVQM5U1Z"],"subscribed":false},{"client_msg_id":"e8db1518-5a59-4900-a896-733a6d88cdbc","type":"message","text":"Hi I'm try the `ExpDecay` of Flux and seems it doesn't work.\n`opt = Flux.Optimiser(ExpDecay(0.001, 0.1, 1, 1e-4), Descent())`\n`for i=1:10`\n    `println(opt.os[2].eta)`\n    `Flux.train!(loss,θ,trainData,opt)`     \n`end`\nHere's my toy example. I thought the learning rate should decrease by 0.1 after each training following the document, but the toy return me same learning rate for 10 training. Am I missing anything here?","user":"U01977X150R","ts":"1613872391.004000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dxd3z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi I'm try the "},{"type":"text","text":"ExpDecay","style":{"code":true}},{"type":"text","text":" of Flux and seems it doesn't work.\n"},{"type":"text","text":"opt = Flux.Optimiser(ExpDecay(0.001, 0.1, 1, 1e-4), Descent())","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"for i=1:10","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    println(opt.os[2].eta)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    Flux.train!(loss,θ,trainData,opt)     ","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"end","style":{"code":true}},{"type":"text","text":"\nHere's my toy example. I thought the learning rate should decrease by 0.1 after each training following the document, but the toy return me same learning rate for 10 training. Am I missing anything here?"}]}]}],"thread_ts":"1613872391.004000","reply_count":3,"reply_users_count":2,"latest_reply":"1613874113.005400","reply_users":["UH9KWTTD3","UMY1LV01G"],"subscribed":false},{"client_msg_id":"610b85f4-b57c-46e8-8221-b2cb304af9df","type":"message","text":"I’m looking at implementing a “data front-end” for the MLJ implementation of some Flux models (<https://alan-turing-institute.github.io/MLJ.jl/dev/adding_models_for_general_use/#Implementing-a-data-front-end-1>). Doing so will avoid some copying that currently happens when one retrains a model after changing hyper-parameters (among other things). Currently we use `Flux.train!` which assumes features/inputs X and  labels/target y observations are “zipped”. So, in a simple example, `train!` is called on `[(X1, y1), (X2, y2), …]`  This “conflation” of inputs and target occurs nowhere else I know of in the MLJ ecosystem, and is currently a deal-breaker as far as a data front-end for MLJFlux. My question: *is there an essential performance reason for zipping the data?* Or can I just keep the two steams separate and replace `Flux.train!` with a custom version. <@UMY1LV01G> <@U8RHPM4KF>","user":"UD0SQV5LL","ts":"1614056466.020600","team":"T68168MUP","edited":{"user":"UD0SQV5LL","ts":"1614056813.000000"},"blocks":[{"type":"rich_text","block_id":"5V7v","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m looking at implementing a “data front-end” for the MLJ implementation of some Flux models ("},{"type":"link","url":"https://alan-turing-institute.github.io/MLJ.jl/dev/adding_models_for_general_use/#Implementing-a-data-front-end-1"},{"type":"text","text":"). Doing so will avoid some copying that currently happens when one retrains a model after changing hyper-parameters (among other things). Currently we use "},{"type":"text","text":"Flux.train!","style":{"code":true}},{"type":"text","text":" which assumes features/inputs X and  labels/target y observations are “zipped”. So, in a simple example, "},{"type":"text","text":"train!","style":{"code":true}},{"type":"text","text":" is called on "},{"type":"text","text":"[(X1, y1), (X2, y2), …]","style":{"code":true}},{"type":"text","text":"  This “conflation” of inputs and target occurs nowhere else I know of in the MLJ ecosystem, and is currently a deal-breaker as far as a data front-end for MLJFlux. My question: "},{"type":"text","text":"is there an essential performance reason for zipping the data?","style":{"bold":true}},{"type":"text","text":" Or can I just keep the two steams separate and replace "},{"type":"text","text":"Flux.train!","style":{"code":true}},{"type":"text","text":" with a custom version. "},{"type":"user","user_id":"UMY1LV01G"},{"type":"text","text":" "},{"type":"user","user_id":"U8RHPM4KF"}]}]}]},{"client_msg_id":"418c13df-5271-4931-8525-604d94376b42","type":"message","text":"You can definitely replace that with a custom version. The thinking behind this design is that rather than thinking of the “minibatches” as zipped data and labels, it is a tuple of arguments to a function that is to be differentiated. There is no requirement for that, but outside of straightforward dl examples, we prolly want arguments to the objective function other than the data and labels","user":"UC4QQPG4A","ts":"1614059231.023400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"c/=7w","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can definitely replace that with a custom version. The thinking behind this design is that rather than thinking of the “minibatches” as zipped data and labels, it is a tuple of arguments to a function that is to be differentiated. There is no requirement for that, but outside of straightforward dl examples, we prolly want arguments to the objective function other than the data and labels"}]}]}]},{"client_msg_id":"25db3af1-f515-4902-be8a-3261dc422629","type":"message","text":"`Flux.train!` is more of an end-user function than anything else and hardly the pinnacle of performance optimization, so I think it's safe to circumvent :slightly_smiling_face:","user":"UMY1LV01G","ts":"1614065379.025000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fc0Tn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Flux.train!","style":{"code":true}},{"type":"text","text":" is more of an end-user function than anything else and hardly the pinnacle of performance optimization, so I think it's safe to circumvent "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"1faf0dab-cf0b-473d-b2ef-0090166007ab","type":"message","text":"<@UC4QQPG4A>'s point about carrying through data that isn't strictly model inputs or targets is important though. One reason something like <http://Fast.ai|Fast.ai> is so frustrating to extend is because it doesn't allow for this and forces you to sneak metadata through in unique ways.","user":"UMY1LV01G","ts":"1614065471.026600","team":"T68168MUP","edited":{"user":"UMY1LV01G","ts":"1614065485.000000"},"blocks":[{"type":"rich_text","block_id":"lPuo","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UC4QQPG4A"},{"type":"text","text":"'s point about carrying through data that isn't strictly model inputs or targets is important though. One reason something like "},{"type":"link","url":"http://Fast.ai","text":"Fast.ai"},{"type":"text","text":" is so frustrating to extend is because it doesn't allow for this and forces you to sneak metadata through in unique ways."}]}]}]},{"client_msg_id":"9e0303c7-5be7-438c-b987-2c38ad705bba","type":"message","text":"Not relying on `zip` also opens up the possibility to make full use of smarter data containers like DataLoaders.jl (which supports random access loading on demand)","user":"UMY1LV01G","ts":"1614065663.028100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HTc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not relying on "},{"type":"text","text":"zip","style":{"code":true}},{"type":"text","text":" also opens up the possibility to make full use of smarter data containers like DataLoaders.jl (which supports random access loading on demand)"}]}]}]},{"client_msg_id":"84ab4094-d0c3-43f8-828a-213499e07644","type":"message","text":"I think it makes sense to rely on `Flux.train!` for the simple reason that any clever tricks you might want to do would end up as implementation details of the dataloader itself, not of the loop specifically. I think <https://github.com/FluxML/Flux.jl/pull/1471> is a net positive. It actually makes the callback system more robust, to mess with the loop outside of the cases we serve usually","user":"UC4QQPG4A","ts":"1614066298.032600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WLz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think it makes sense to rely on "},{"type":"text","text":"Flux.train!","style":{"code":true}},{"type":"text","text":" for the simple reason that any clever tricks you might want to do would end up as implementation details of the dataloader itself, not of the loop specifically. I think "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/pull/1471"},{"type":"text","text":" is a net positive. It actually makes the callback system more robust, to mess with the loop outside of the cases we serve usually"}]}]}]},{"client_msg_id":"4a85d3eb-9e60-47cf-a9a4-a67dbca692d3","type":"message","text":"I think gradient accumulation is a good counterexample that is not an implementation detail of the dataloader. I do wish we collectively had something better than callbacks for customizing the train loop though. There are essentially `O(LOC in training loop)` possible extension points, and it's a slippery slope to something like <https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html> (which has what, 30+ hooks and methods?)","user":"UMY1LV01G","ts":"1614067536.038000","team":"T68168MUP","edited":{"user":"UMY1LV01G","ts":"1614067607.000000"},"blocks":[{"type":"rich_text","block_id":"NqQs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think gradient accumulation is a good counterexample that is not an implementation detail of the dataloader. I do wish we collectively had something better than callbacks for customizing the train loop though. There are essentially "},{"type":"text","text":"O(LOC in training loop)","style":{"code":true}},{"type":"text","text":" possible extension points, and it's a slippery slope to something like "},{"type":"link","url":"https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html"},{"type":"text","text":" (which has what, 30+ hooks and methods?)"}]}]}]},{"client_msg_id":"1a68f22d-5bbf-4b90-aee1-f91374f31f92","type":"message","text":"Gradient accumulation can happen at the Zygote level.","user":"UC4QQPG4A","ts":"1614081995.039300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZLW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Gradient accumulation can happen at the Zygote level."}]}]}]},{"client_msg_id":"ca0298a2-b201-4e20-b622-a63cd7a73ec2","type":"message","text":"I don’t think there is a replacement for hooks that DL people want to use, currently. Callbacks are convenient for sequential models.","user":"UC4QQPG4A","ts":"1614082079.040400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/qhr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don’t think there is a replacement for hooks that DL people want to use, currently. Callbacks are convenient for sequential models."}]}]}]},{"client_msg_id":"287b032e-1dc4-42d4-90a0-35039d1db4d3","type":"message","text":"I continue to dislike `Flux.train!` . Most people should implement custom training loops.","user":"U6A936746","ts":"1614085038.042300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"905I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I continue to dislike "},{"type":"text","text":"Flux.train!","style":{"code":true}},{"type":"text","text":" . Most people should implement custom training loops."}]}]}],"reactions":[{"name":"+1","users":["UDXST8ARK"],"count":1}]},{"client_msg_id":"84fdb87d-bb23-49be-b55c-e186a95b5322","type":"message","text":"Callbacks seems like they are just a more limited and confusing way of doing it, esp since as Brian says, there are basically desire for them at every possibly step, and futher: also with every possible piece of intermediate state","user":"U6A936746","ts":"1614085132.043800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nBsAx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Callbacks seems like they are just a more limited and confusing way of doing it, esp since as Brian says, there are basically desire for them at every possibly step, and futher: also with every possible piece of intermediate state"}]}]}]},{"client_msg_id":"f7ddfad1-be37-4f2e-a8d9-84291b5406a6","type":"message","text":"Also the way train does batching and epochs with iterator constructs is just kinds of confusing to me. A custom loop is much clearer.","user":"U6A936746","ts":"1614085173.044700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RSW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also the way train does batching and epochs with iterator constructs is just kinds of confusing to me. A custom loop is much clearer."}]}]}]},{"client_msg_id":"0f3f3b59-8cc6-45d7-853d-5723cca3f2b2","type":"message","text":"Maybe it's a silly idea, but wouldn't something basic like\n\n`function optimize!(loss, params, data, opt)\n    loss_value, back = pullback(() -&gt; loss(data), params)\n    grads = back(one(loss_value))\n    update!(opt, params, grads)\n    return loss_value, grads # for diagnostics\nend`\n\nbe a decent compromise? This way a custom loop is essentially as easy to write as a call to `train!` (It is just a one-line for loop)","user":"U6BJ9E351","ts":"1614087481.055600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"++J","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe it's a silly idea, but wouldn't something basic like\n\n"},{"type":"text","text":"function optimize!(loss, params, data, opt)\n","style":{"code":true}},{"type":"text","text":"    loss_value, back = pullback(() -> loss(data), params)\n","style":{"code":true}},{"type":"text","text":"    grads = back(one(loss_value))\n","style":{"code":true}},{"type":"text","text":"    update!(opt, params, grads)\n","style":{"code":true}},{"type":"text","text":"    return loss_value, grads # for diagnostics\n","style":{"code":true}},{"type":"text","text":"end\n","style":{"code":true}},{"type":"text","text":"\nbe a decent compromise? This way a custom loop is essentially as easy to write as a call to "},{"type":"text","text":"train!","style":{"code":true}},{"type":"text","text":" (It is just a one-line for loop)"}]}]}]},{"client_msg_id":"92f74205-2553-404c-bb77-13810e206c04","type":"message","text":"See <https://github.com/FluxML/Flux.jl/pull/1471|https://github.com/FluxML/Flux.jl/pull/1471> which is doing basically that","user":"UC4QQPG4A","ts":"1614088155.056100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OT5n","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"See "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/pull/1471","text":"https://github.com/FluxML/Flux.jl/pull/1471"},{"type":"text","text":" which is doing basically that"}]}]}],"reactions":[{"name":"+1","users":["U6BJ9E351"],"count":1}]},{"client_msg_id":"d1a4c9ec-b6e1-48b6-9f38-cd5105707bc8","type":"message","text":"That and <https://github.com/FluxML/Flux.jl/pull/1017|https://github.com/FluxML/Flux.jl/pull/1017>","user":"UC4QQPG4A","ts":"1614088263.056700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KW/FJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That and "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/pull/1017","text":"https://github.com/FluxML/Flux.jl/pull/1017"}]}]}]},{"client_msg_id":"21d27f95-ba09-41c3-b2f3-f457575008d9","type":"message","text":"It makes sense for us to fix our dataloaders to act for tuples of arguments approach. Further, we should think about the needs beyond strict sequential computer vision tasks. Something that would consolidate a lot of data management repos in the wild","user":"UC4QQPG4A","ts":"1614088415.059200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"c4q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It makes sense for us to fix our dataloaders to act for tuples of arguments approach. Further, we should think about the needs beyond strict sequential computer vision tasks. Something that would consolidate a lot of data management repos in the wild"}]}]}]},{"client_msg_id":"4FA26759-CF92-4BE8-BF98-79B078338344","type":"message","text":"I don’t think <https://github.com/FluxML/Flux.jl/pull/1471|https://github.com/FluxML/Flux.jl/pull/1471> does what <@U6BJ9E351> suggested. The proposed `optimize!` is the same as the `step!` suggested in the comments of the PR. I think that’s something we all want.\n\n1471 could use `step!` but right now it looks like it is using the callback approach. I’m with Lyndon and Brian on this.","user":"UH9KWTTD3","ts":"1614093592.062700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kboqM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don’t think "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/pull/1471","text":"https://github.com/FluxML/Flux.jl/pull/1471"},{"type":"text","text":" does what "},{"type":"user","user_id":"U6BJ9E351"},{"type":"text","text":" suggested. The proposed "},{"type":"text","text":"optimize!","style":{"code":true}},{"type":"text","text":" is the same as the "},{"type":"text","text":"step!","style":{"code":true}},{"type":"text","text":" suggested in the comments of the PR. I think that’s something we all want.\n"},{"type":"text","text":"\n1471 could use "},{"type":"text","text":"step!","style":{"code":true}},{"type":"text","text":" but right now it looks like it is using the callback approach. I’m with Lyndon and Brian on this."}]}]}]},{"client_msg_id":"471C1B7A-07FF-4434-A66E-1FF2F7C7DD00","type":"message","text":"1017 looks pretty good though","user":"UH9KWTTD3","ts":"1614093648.063000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Phgz+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"1017 looks pretty good though"}]}]}]},{"client_msg_id":"b943d800-eefd-4b0b-a269-15452b44ddc6","type":"message","text":"I mean, the second one is the one he wants but the first one manages the callbacks. It's weird to say one is okay and the other isn't, because even without the hooks, passing the stuff into callbacks is strictly better than the current status","user":"UC4QQPG4A","ts":"1614095769.065200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YY/Tm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I mean, the second one is the one he wants but the first one manages the callbacks. It's weird to say one is okay and the other isn't, because even without the hooks, passing the stuff into callbacks is strictly better than the current status"}]}]}]},{"client_msg_id":"F4233BBD-D010-4B96-9E0D-7DFA8E2C8362","type":"message","text":"One expands the functionality of callbacks and the other collapses the forward pass, backwards pass, and parameter update into a single function. I like the latter but not the former.\n\nExpanding callbacks is only strictly better from the perspective of “can I do X with a callback.” It doesn’t address whether callbacks are clearest or most intuitive way to do X.","user":"UH9KWTTD3","ts":"1614096755.069000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/Vw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One expands the functionality of callbacks and the other collapses the forward pass, backwards pass, and parameter update into a single function. I like the latter but not the former.\n"},{"type":"text","text":"\nExpanding callbacks is only strictly better from the perspective of “can I do X with a callback.” It doesn’t address whether callbacks are clearest or most intuitive way to do X."}]}]}]},{"client_msg_id":"3942994d-5d31-4917-8318-bd9852cc6f46","type":"message","text":"Sure, but isn't the effect restricting the usability of the callbacks for the tasks they are meant for? Today you can't do basic things like printing the current running loss, stop on nan loss/ gradients, debug gradients easily, or hook into a logger neatly.\n\nWhen they try to do non trivial tasks, we should absolutely guide them to the loop, but before that, :shrug:.","user":"UC4QQPG4A","ts":"1614101276.079300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eXAG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sure, but isn't the effect restricting the usability of the callbacks for the tasks they are meant for? Today you can't do basic things like printing the current running loss, stop on nan loss/ gradients, debug gradients easily, or hook into a logger neatly.\n\nWhen they try to do non trivial tasks, we should absolutely guide them to the loop, but before that, "},{"type":"emoji","name":"shrug"},{"type":"text","text":"."}]}]}]},{"client_msg_id":"20e9ba4b-3454-4797-a7a8-47a6a52b87bd","type":"message","text":"The million-dollar question is where we draw the proverbial line in the sand. 1471 is a pretty decent 80/20 implementation, but do we freeze it there and clamp down on any further expansion?","user":"UMY1LV01G","ts":"1614101648.080600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"g9g","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The million-dollar question is where we draw the proverbial line in the sand. 1471 is a pretty decent 80/20 implementation, but do we freeze it there and clamp down on any further expansion?"}]}]}]},{"client_msg_id":"568928fd-4417-4c69-96d9-a17fca60d29a","type":"message","text":"Perhaps, but that can be left for the future. 1471 (minus the hooks) is not the 80/20 of anything. We have had callbacks for a while, and this is strictly improving that. Intentionally kneecapping them doesn't make sense. I'm assuming the consensus would be to deprecate them entirely?","user":"UC4QQPG4A","ts":"1614102997.092300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"D04","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Perhaps, but that can be left for the future. 1471 (minus the hooks) is not the 80/20 of anything. We have had callbacks for a while, and this is strictly improving that. Intentionally kneecapping them doesn't make sense. I'm assuming the consensus would be to deprecate them entirely?"}]}]}]},{"type":"message","text":"What's the meeting code for the ML and AD Development/Usage call?","user":"U9MD78Z9N","ts":"1614270806.095200","team":"T68168MUP"},{"client_msg_id":"c7814180-a072-47d3-a44b-1b47c5a3ff68","type":"message","text":"All the details should be on <https://www.google.com/calendar/event?eid=NDY0YW51c3JhdWtpcHZxam91YzFpazh2bjdfMjAyMTAyMjVUMTYzMDAwWiBqdWxpYWxhbmcub3JnX2tvbWF1YXFldDE0ZW9nOW9pdjNwNm83cG1nQGc&amp;ctz=America/Vancouver|https://www.google.com/calendar/event?eid=NDY0YW51c3JhdWtpcHZxam91YzFpazh2bjdfMjAyMT[…]X2tvbWF1YXFldDE0ZW9nOW9pdjNwNm83cG1nQGc>","user":"UMY1LV01G","ts":"1614271756.095500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TcfU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"All the details should be on "},{"type":"link","url":"https://www.google.com/calendar/event?eid=NDY0YW51c3JhdWtpcHZxam91YzFpazh2bjdfMjAyMTAyMjVUMTYzMDAwWiBqdWxpYWxhbmcub3JnX2tvbWF1YXFldDE0ZW9nOW9pdjNwNm83cG1nQGc&ctz=America/Vancouver","text":"https://www.google.com/calendar/event?eid=NDY0YW51c3JhdWtpcHZxam91YzFpazh2bjdfMjAyMT[…]X2tvbWF1YXFldDE0ZW9nOW9pdjNwNm83cG1nQGc"}]}]}]},{"client_msg_id":"73b3c2c7-38b6-43cd-859e-8aad78a6d4bb","type":"message","text":"Can you not join through <https://https>:&lt;//www.google.com/url?q=https://mit.zoom.us/j/96251790289&gt; directly?","user":"UMY1LV01G","ts":"1614271777.095900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hd+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can you not join through "},{"type":"link","url":"https://https"},{"type":"text","text":":"},{"type":"link","url":"//www.google.com/url?q=https://mit.zoom.us/j/96251790289"},{"type":"text","text":" directly?"}]}]}]},{"client_msg_id":"c24d835c-ae36-4489-8b57-0ea5d94e2438","type":"message","text":"he's on.","user":"U69BL50BF","ts":"1614271789.096200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ehn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"he's on."}]}]}]},{"client_msg_id":"c694143d-46b2-441e-9dc7-28aa32d2b4ad","type":"message","text":"Ah I see you already got on","user":"UMY1LV01G","ts":"1614271792.096400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wBUP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah I see you already got on"}]}]}]},{"client_msg_id":"f12f76c0-a7ed-450e-b7ef-84b7a86763f3","type":"message","text":"That's what I get for checking  <#C6G240ENA|autodiff> after posting","user":"UMY1LV01G","ts":"1614271832.096900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KqnOL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's what I get for checking  "},{"type":"channel","channel_id":"C6G240ENA"},{"type":"text","text":" after posting"}]}]}]},{"client_msg_id":"eabb82d4-23cb-4bad-92ea-e68f95c8905e","type":"message","text":"Short progress update on the FastAI.jl development: it's not released yet, but large parts are already working and I've set up documentation, so check it out if you're interested: <https://lorenzoh.github.io/FastAI.jl/dev/README.html>\n\nI usually post over on the Zulip channel, but figured some people who might be interested are only active here. Let me know what you think!","user":"U010XUS4MT7","ts":"1614282534.099400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"03xd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Short progress update on the FastAI.jl development: it's not released yet, but large parts are already working and I've set up documentation, so check it out if you're interested: "},{"type":"link","url":"https://lorenzoh.github.io/FastAI.jl/dev/README.html"},{"type":"text","text":"\n\nI usually post over on the Zulip channel, but figured some people who might be interested are only active here. Let me know what you think!"}]}]}],"reactions":[{"name":"+1","users":["UGD4K0Z25"],"count":1}]},{"client_msg_id":"04f77148-53d9-474f-8721-171b9779cee8","type":"message","text":"Follow <https://julialang.zulipchat.com/#narrow/stream/237432-ml-ecosystem-coordination/topic/FastAI.2Ejl.20development/near/227827979> for more frequent updates","user":"U010XUS4MT7","ts":"1614282979.100000","team":"T68168MUP","attachments":[{"service_name":"Zulip","title":"JuliaLang","title_link":"https://julialang.zulipchat.com/#narrow/stream/237432-ml-ecosystem-coordination/topic/FastAI.2Ejl.20development/near/227827979","text":"This is the Zulip server for the Julia programming language community. We ask anyone joining to adhere to the Julia Code of Conduct. | To learn more about Julia, check out <https://julialang.org/>, or just come ask us here! | You can reach out to the admins of this Zulip by sending a direct message to @zulip-admins.","fallback":"Zulip: JuliaLang","thumb_url":"https://zulip-avatars.s3.amazonaws.com/7178/realm/icon.png?version=6","from_url":"https://julialang.zulipchat.com/#narrow/stream/237432-ml-ecosystem-coordination/topic/FastAI.2Ejl.20development/near/227827979","thumb_width":100,"thumb_height":100,"id":1,"original_url":"https://julialang.zulipchat.com/#narrow/stream/237432-ml-ecosystem-coordination/topic/FastAI.2Ejl.20development/near/227827979"}],"blocks":[{"type":"rich_text","block_id":"vaPg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Follow "},{"type":"link","url":"https://julialang.zulipchat.com/#narrow/stream/237432-ml-ecosystem-coordination/topic/FastAI.2Ejl.20development/near/227827979"},{"type":"text","text":" for more frequent updates"}]}]}]},{"client_msg_id":"27cefc8b-f685-459b-93be-f89d57efed89","type":"message","text":"```julia&gt; Flux.OneHotArray\nERROR: UndefVarError: OneHotArray not defined```","user":"U7YD3DKL2","ts":"1614283926.100800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gcME","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> Flux.OneHotArray\nERROR: UndefVarError: OneHotArray not defined"}]}]}]},{"client_msg_id":"4b9ce7b4-9e03-4e0b-b218-03fc53267f00","type":"message","text":"Where is OneHotArray defined?","user":"U7YD3DKL2","ts":"1614283931.101100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ydvpW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Where is OneHotArray defined?"}]}]}]},{"client_msg_id":"8b64941d-19b6-4149-a955-34fadc2f48c1","type":"message","text":"Are you using master?","user":"UH9KWTTD3","ts":"1614284377.101300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cDm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are you using master?"}]}]}]},{"client_msg_id":"a09ca423-f64b-48ce-960d-296a4f228b70","type":"message","text":"No. The last released version.","user":"U7YD3DKL2","ts":"1614284389.101800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lUUuf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"No. The last released version."}]}]}]},{"client_msg_id":"5123929f-f489-41ba-afff-08f3c05c2587","type":"message","text":"`OneHotArray` is still unreleased I think","user":"UH9KWTTD3","ts":"1614284390.101900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wg7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"OneHotArray","style":{"code":true}},{"type":"text","text":" is still unreleased I think"}]}]}]},{"client_msg_id":"884fe263-4084-44c0-88a3-9d300b22930e","type":"message","text":"But I just checked that PR was included since 0.11.4. <https://github.com/FluxML/Flux.jl/releases/tag/v0.11.4>","user":"U7YD3DKL2","ts":"1614284416.102600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"M2BFN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But I just checked that PR was included since 0.11.4. "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/releases/tag/v0.11.4"}]}]}]},{"client_msg_id":"ff70017c-a595-439f-8096-9d4011ea789e","type":"message","text":"The release notes on Github are all screwed up. I’ve already told <@UC4QQPG4A> about it, and he’s working on fixing it for future releases.","user":"UH9KWTTD3","ts":"1614284431.102900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+axp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The release notes on Github are all screwed up. I’ve already told "},{"type":"user","user_id":"UC4QQPG4A"},{"type":"text","text":" about it, and he’s working on fixing it for future releases."}]}]}]},{"client_msg_id":"b59ae55f-153c-4276-b4b1-2a7a49263d03","type":"message","text":"Oh","user":"U7YD3DKL2","ts":"1614284442.103100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mLVQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh"}]}]}]},{"client_msg_id":"c71e8e46-cb34-4134-8b81-0d497bf41833","type":"message","text":"Why it hasn't been released?","user":"U7YD3DKL2","ts":"1614284448.103300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GC89L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Why it hasn't been released?"}]}]}]},{"client_msg_id":"6a42ff36-cc6a-429b-9cbd-53c9daf1f8f2","type":"message","text":"Not 100% positive cause I’m still hazy on semver but I think the struct/constructor changes means it is breaking. So it will have to wait until v0.12.","user":"UH9KWTTD3","ts":"1614284508.104100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"leEj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not 100% positive cause I’m still hazy on semver but I think the struct/constructor changes means it is breaking. So it will have to wait until v0.12."}]}]}]},{"client_msg_id":"8a628d46-354c-41a4-acc5-b001c0d6845c","type":"message","text":"Even though the highest level APIs like `onehotbatch` are the same","user":"UH9KWTTD3","ts":"1614284564.104400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5PB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Even though the highest level APIs like "},{"type":"text","text":"onehotbatch","style":{"code":true}},{"type":"text","text":" are the same"}]}]}]},{"client_msg_id":"ffe91dcc-ed16-4e00-8b2d-73c9cd1863fd","type":"message","text":"<https://github.com/FluxML/Flux.jl/compare/v0.11.6...master>","user":"UH9KWTTD3","ts":"1614284665.104600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gkT","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/FluxML/Flux.jl/compare/v0.11.6...master"}]}]}],"thread_ts":"1614284665.104600","reply_count":1,"reply_users_count":1,"latest_reply":"1614285221.104700","reply_users":["UMY1LV01G"],"subscribed":false},{"client_msg_id":"5f19a4fe-0d5f-497c-b364-aac3a556e669","type":"message","text":"I posted a question regarding training only part of a matrix in <#C690QRAA3|machine-learning> I'm using Flux. If anyone can answer or point me in the right direction, I'd appreciate it. Thanks.","user":"U01L0KU0SDV","ts":"1614311593.107400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jGCy5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I posted a question regarding training only part of a matrix in "},{"type":"channel","channel_id":"C690QRAA3"},{"type":"text","text":" I'm using Flux. If anyone can answer or point me in the right direction, I'd appreciate it. Thanks."}]}]}]},{"type":"message","text":"Do we have performant implicit layers (the OptNet layer is one example but more generally): z_i+1 is such that f(z_i, z_i+1) = 0 where the f is defined by weights somehow?","user":"U9MD78Z9N","ts":"1614554176.108000","team":"T68168MUP"},{"client_msg_id":"b93f451f-b086-45bd-b504-e11b646fd6a9","type":"message","text":"That's just a Steady state problem","user":"U69BL50BF","ts":"1614554291.108700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xqywW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's just a Steady state problem"}]}]}]},{"type":"message","text":"Yes. Sorry that i had a different name than you. However seaching for \"Steady State\" layers in the Flux eco system i didn't find anything either","user":"U9MD78Z9N","ts":"1614554418.108800","team":"T68168MUP","edited":{"user":"U9MD78Z9N","ts":"1614555958.000000"}}]}