{"cursor": 0, "messages": [{"type":"message","subtype":"channel_join","ts":"1608169106.205800","user":"U01GWRMB43Y","text":"<@U01GWRMB43Y> has joined the channel","inviter":"UD0SQV5LL"},{"client_msg_id":"cd0f1e65-242b-41d1-9b4b-82cf8f5492d9","type":"message","text":"I think I am hitting a Zygote 0.5 bug. Can we increase the compat bound so that Flux can use Zygote 0.6?","user":"U7YD3DKL2","ts":"1608572338.208600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nq1T","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think I am hitting a Zygote 0.5 bug. Can we increase the compat bound so that Flux can use Zygote 0.6?"}]}]}],"thread_ts":"1608572338.208600","reply_count":9,"reply_users_count":2,"latest_reply":"1608577514.210400","reply_users":["U7YD3DKL2","UM30MT6RF"],"subscribed":false},{"client_msg_id":"418d3bd5-eec4-4802-8b0e-0e099411379c","type":"message","text":"<https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html>","user":"UDGT4PM41","ts":"1608837807.210900","team":"T68168MUP","attachments":[{"service_name":"Yangzai’s Blog","title":"Is Julia Ready for Deep Learning","title_link":"https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html","text":"I heard about Swift and Julia for deep learning during <http://fast.ai|fast.ai>’s course. Then I spent quite some time to try figuring out whether any of these languages is a better choice for deep learning than Python. However, soon I realized that Chris Lattner left Google and Swift for Tensorflow project is slowing down and even Jeremy Howard is less passionate about it. Then the only choice left for now is Julia AFAIK. The Question is whether Julia is ready for deep learning.","fallback":"Yangzai’s Blog: Is Julia Ready for Deep Learning","ts":1605058098,"from_url":"https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html","id":1,"original_url":"https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html"}],"blocks":[{"type":"rich_text","block_id":"Vc0","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://sychen52.github.io/2020/11/11/IsJuliaReadyForDeepLearning.html"}]}]}]},{"client_msg_id":"B9B8E182-A041-4C85-B43B-831E9605154A","type":"message","text":"Any owners of the FluxML organization around?","user":"U7THT3TM3","ts":"1609191265.212400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6E5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any owners of the FluxML organization around?"}]}]}]},{"client_msg_id":"0F87BA95-44AA-4409-AA69-F092949A1866","type":"message","text":"Could you (temporarily) make Tim (<@U68A3ASP9>) an owner of the FluxML organization so that he can finish setting up Buildkite for GPU CI?","user":"U7THT3TM3","ts":"1609191301.213400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"njrS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Could you (temporarily) make Tim ("},{"type":"user","user_id":"U68A3ASP9"},{"type":"text","text":") an owner of the FluxML organization so that he can finish setting up Buildkite for GPU CI?"}]}]}]},{"client_msg_id":"907500A7-BA7B-4ACB-9EB5-9397A5EFFACC","type":"message","text":"You can convert him back to a regular member once he's done.","user":"U7THT3TM3","ts":"1609191345.213800","team":"T68168MUP","edited":{"user":"U7THT3TM3","ts":"1609191361.000000"},"blocks":[{"type":"rich_text","block_id":"=Yn1O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can convert him back to a regular member once he's done."}]}]}]},{"client_msg_id":"282846ef-5896-4a1f-a1d8-744b9ea17e10","type":"message","text":"Anyone around who maintains the webpage <http://fluxml.ai|fluxml.ai> ? It throws a 404 when hitting the \"Try it out\" button pointing to this address: <https://fluxml.ai/getting_started.html> .","user":"ULL3KSGBS","ts":"1609223126.215500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vqrwl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone around who maintains the webpage "},{"type":"link","url":"http://fluxml.ai","text":"fluxml.ai"},{"type":"text","text":" ? It throws a 404 when hitting the \"Try it out\" button pointing to this address: "},{"type":"link","url":"https://fluxml.ai/getting_started.html"},{"type":"text","text":" ."}]}]}]},{"client_msg_id":"71574f36-01d6-450a-a95b-c3401fa4a9fc","type":"message","text":"Fixed, thanks <@ULL3KSGBS>! Sorry about that, we are updating that part of the website","user":"UC4QQPG4A","ts":"1609226322.216400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7vD2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Fixed, thanks "},{"type":"user","user_id":"ULL3KSGBS"},{"type":"text","text":"! Sorry about that, we are updating that part of the website"}]}]}]},{"type":"message","subtype":"channel_join","ts":"1609333499.218500","user":"U01HYEN2ES0","text":"<@U01HYEN2ES0> has joined the channel","inviter":"UEP056STX"},{"client_msg_id":"efe5ad02-f4ec-43e1-b783-2018f78380a6","type":"message","text":"Not seeing as much Flux discussion here lately, are people discussing Flux elsewhere?","user":"U9RDM8ZGT","ts":"1609886938.219800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uVz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not seeing as much Flux discussion here lately, are people discussing Flux elsewhere?"}]}]}],"thread_ts":"1609886938.219800","reply_count":3,"reply_users_count":2,"latest_reply":"1609889372.220900","reply_users":["UGU761DU2","U9RDM8ZGT"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"This channel was boosted by a lot of help-focused threads. Not exactly sure why those tapered off, but I haven't seen one in a while despite no noticeable change in the rate of related help threads on Discourse.","user":"UMY1LV01G","ts":"1609892625.222300","thread_ts":"1609886938.219800","root":{"client_msg_id":"efe5ad02-f4ec-43e1-b783-2018f78380a6","type":"message","text":"Not seeing as much Flux discussion here lately, are people discussing Flux elsewhere?","user":"U9RDM8ZGT","ts":"1609886938.219800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uVz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not seeing as much Flux discussion here lately, are people discussing Flux elsewhere?"}]}]}],"thread_ts":"1609886938.219800","reply_count":10,"reply_users_count":3,"latest_reply":"1609892625.222300","reply_users":["UGU761DU2","U9RDM8ZGT","UMY1LV01G"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"n6NP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This channel was boosted by a lot of help-focused threads. Not exactly sure why those tapered off, but I haven't seen one in a while despite no noticeable change in the rate of related help threads on Discourse."}]}]}],"client_msg_id":"569de717-8292-4474-91bb-4e4c4fc8ed09","reactions":[{"name":"+1","users":["UGU761DU2"],"count":1}]},{"client_msg_id":"f25eef3a-9f87-435b-be58-f6a0954b4550","type":"message","text":"This doesn't seem to be the only slack channel effected.","user":"U9RDM8ZGT","ts":"1609892673.222800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KX/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This doesn't seem to be the only slack channel effected."}]}]}]},{"client_msg_id":"290e1c62-f354-4331-aac5-eff43d82fc49","type":"message","text":"<#C690QRAA3|machine-learning> traffic seems way down as well. I'm guessing it's the holiday lull, but it's possible that there's some movement away from Slack - but there isn't (wasn't) even a <#C7120PCUQ|flux> channel over on Zulip until I just made one.","user":"U9RDM8ZGT","ts":"1609892760.224300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4+M","elements":[{"type":"rich_text_section","elements":[{"type":"channel","channel_id":"C690QRAA3"},{"type":"text","text":" traffic seems way down as well. I'm guessing it's the holiday lull, but it's possible that there's some movement away from Slack - but there isn't (wasn't) even a "},{"type":"channel","channel_id":"C7120PCUQ"},{"type":"text","text":" channel over on Zulip until I just made one."}]}]}]},{"client_msg_id":"df604fa4-805d-49fb-9bc8-b1006555b2b2","type":"message","text":"There aren't that many flux related posts on Zulip that aren't also design posts, so we just stuck to using the ML stream","user":"UMY1LV01G","ts":"1609893094.226000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nh=n9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There aren't that many flux related posts on Zulip that aren't also design posts, so we just stuck to using the ML stream"}]}]}]},{"client_msg_id":"e0367249-dfea-45e9-ba4d-4693c3cd191d","type":"message","text":"I can tell you that GH issue discussion and comments are quite active right now :) Zulip ML streams are likely quieter because of the holiday too.","user":"UMY1LV01G","ts":"1609893186.227900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"U0vj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can tell you that GH issue discussion and comments are quite active right now :) Zulip ML streams are likely quieter because of the holiday too."}]}]}]},{"type":"message","text":"gradient falls on StructArray. loss is calculated alright. <@UC4QQPG4A>, any suggestions how to fix that? Thanks!","files":[{"id":"F01HZ4UFMSS","created":1610000287,"timestamp":1610000287,"name":"Untitled","title":"Untitled","mimetype":"text/plain","filetype":"julia","pretty_type":"Julia","user":"UJZNB9CSV","editable":true,"size":1095,"mode":"snippet","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HZ4UFMSS/untitled","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HZ4UFMSS/download/untitled","permalink":"https://julialang.slack.com/files/UJZNB9CSV/F01HZ4UFMSS/untitled","permalink_public":"https://slack-files.com/T68168MUP-F01HZ4UFMSS-2700fc7140","edit_link":"https://julialang.slack.com/files/UJZNB9CSV/F01HZ4UFMSS/untitled/edit","preview":"julia> d[1]\n2×128 StructArray(::Array{Bool,2}, ::Array{Bool,2}, ::Array{Bool,2}) with eltype NamedTuple{(:x1, :x2, :x3),Tuple{Bool,Bool,Bool}}:\n (x1 = 1, x2 = 1, x3 = 0)  (x1 = 1, x2 = 0, x3 = 0)  …  (x1 = 0, x2 = 1, x3 = 0)  (x1 = 0, x2 = 1, x3 = 0)\n (x1 = 0, x2 = 0, x3 = 1)  (x1 = 0, x2 = 1, x3 = 1)     (x1 = 1, x2 = 0, x3 = 1)  (x1 = 1, x2 = 0, x3 = 1)\n","preview_highlight":"<div class=\"CodeMirror cm-s-default CodeMirrorServer\" oncopy=\"if(event.clipboardData){event.clipboardData.setData('text/plain',window.getSelection().toString().replace(/\\u200b/g,''));event.preventDefault();event.stopPropagation();}\">\n<div class=\"CodeMirror-code\">\n<div><pre><span class=\"cm-variable\">julia</span><span class=\"cm-operator\">&gt;</span> <span class=\"cm-variable\">d</span>[<span class=\"cm-number\">1</span>]</pre></div>\n<div><pre><span class=\"cm-number\">2</span><span class=\"cm-operator\">×</span><span class=\"cm-number\">128</span> <span class=\"cm-builtin\">StructArray</span>(<span class=\"cm-builtin\">::Array{Bool,2</span><span class=\"cm-builtin\">}</span>, <span class=\"cm-builtin\">::Array{Bool,2</span><span class=\"cm-builtin\">}</span>, <span class=\"cm-builtin\">::Array{Bool,2</span><span class=\"cm-builtin\">}</span>) <span class=\"cm-variable\">with</span> <span class=\"cm-variable\">eltype</span> <span class=\"cm-variable\">NamedTuple</span>{(<span class=\"cm-builtin\">:x1</span>, <span class=\"cm-builtin\">:x2</span>, <span class=\"cm-builtin\">:x3</span>),<span class=\"cm-variable\">Tuple</span>{<span class=\"cm-variable\">Bool</span>,<span class=\"cm-variable\">Bool</span>,<span class=\"cm-variable\">Bool</span>}}<span class=\"cm-operator\">:</span></pre></div>\n<div><pre> (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>)  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>)  <span class=\"cm-variable\">…</span>  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>)  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>)</pre></div>\n<div><pre> (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>)  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>)     (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>)  (<span class=\"cm-variable\">x1</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>, <span class=\"cm-variable\">x2</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">0</span>, <span class=\"cm-variable\">x3</span> <span class=\"cm-operator\">=</span> <span class=\"cm-number\">1</span>)</pre></div>\n</div>\n</div>\n","lines":20,"lines_more":15,"preview_is_truncated":true,"is_starred":false,"has_rich_preview":false}],"upload":true,"blocks":[{"type":"rich_text","block_id":"ldvQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"gradient falls on StructArray. loss is calculated alright. "},{"type":"user","user_id":"UC4QQPG4A"},{"type":"text","text":", any suggestions how to fix that? Thanks!"}]}]}],"user":"UJZNB9CSV","display_as_bot":false,"ts":"1610000289.228000","edited":{"user":"UJZNB9CSV","ts":"1610000544.000000"},"client_msg_id":"50a496f4-2627-4a38-a6a2-61df78cc359c"},{"client_msg_id":"BDC7DBEB-8688-41D1-A89F-73060BECB256","type":"message","text":"Has there been much work on latency reduction in Flux? SnoopCompile etc. I’m keen to improve latency in some downstream packages so thought I’d check","user":"U8MPCDJAY","ts":"1610210034.230300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jUHR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Has there been much work on latency reduction in Flux? SnoopCompile etc. I’m keen to improve latency in some downstream packages so thought I’d check"}]}]}]},{"client_msg_id":"1ff27999-0a3f-4f6b-ba64-e5ff871457ef","type":"message","text":"I haven't seen or heard of anything, but it would be very much welcome","user":"UMY1LV01G","ts":"1610215332.230700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Rr7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I haven't seen or heard of anything, but it would be very much welcome"}]}]}]},{"client_msg_id":"fc9e3e64-bb75-45f0-9061-e69009d6d6d2","type":"message","text":"IIRC Zygote and CUDA are the two biggest offenders, in that order","user":"UMY1LV01G","ts":"1610215353.231200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"R2S","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"IIRC Zygote and CUDA are the two biggest offenders, in that order"}]}]}]},{"client_msg_id":"230f77c4-4bd1-45e9-aa52-dc5a17b5e052","type":"message","text":"Yes, that would be awesome! I think it might even be interesting to see if for Zygote, we could use the new experimental infrastructure to just not specialize at all in the compiler parts.","user":"UM30MT6RF","ts":"1610221400.233900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ywJh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, that would be awesome! I think it might even be interesting to see if for Zygote, we could use the new experimental infrastructure to just not specialize at all in the compiler parts."}]}]}]},{"client_msg_id":"2358C6D3-0314-4760-958A-0CB67AB51264","type":"message","text":"Ok cool. I can’t promise much, but thought it would be good to learn the tools on something core like Zygote. I’ll open a PR if I make any progress","user":"U8MPCDJAY","ts":"1610224415.235400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9Cg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok cool. I can’t promise much, but thought it would be good to learn the tools on something core like Zygote. I’ll open a PR if I make any progress"}]}]}],"reactions":[{"name":"+1","users":["UMY1LV01G","UH9KWTTD3","UM30MT6RF"],"count":3}]},{"client_msg_id":"d37a3d0f-b85e-4b53-bd45-517efcad3685","type":"message","text":"That'd be brilliant! Although zygote by itself seems to have gotten better anecdotally. It would be a huge help if you'd gather your findings in an issue/ PR anyway to see where we can go with it. Flux still takes longer than I'd expect to precompile.","user":"UC4QQPG4A","ts":"1610227373.240800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ab9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That'd be brilliant! Although zygote by itself seems to have gotten better anecdotally. It would be a huge help if you'd gather your findings in an issue/ PR anyway to see where we can go with it. Flux still takes longer than I'd expect to precompile."}]}]}],"thread_ts":"1610227373.240800","reply_count":1,"reply_users_count":1,"latest_reply":"1610231008.241000","reply_users":["U8MPCDJAY"],"subscribed":false},{"client_msg_id":"f67d1a43-41d4-4711-8d43-96b7e0df139a","type":"message","text":"Hi, I have changed activation functions in my models from `relu` to `sigmoid` and I save them into `.bson` which used to work with `relu` . Now, I am getting `typeof` error with sigmoid. Do not understand why. Thanks for any help. Error:\n\n```julia&gt; res = BSON.load(file_with_dictionary_results)\nERROR: MethodError: no method matching typeof(σ)()\nStacktrace:\n [1] (::BSON.var\"#37#38\")(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:76\n [2] _raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:79\n [3] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:89\n [4] (::BSON.var\"#39#40\"{IdDict{Any,Any}})(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [5] iterate at ./generator.jl:47 [inlined]\n [6] collect_to!(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:732\n [7] collect_to!(::Array{Real,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:740 (repeats 3 times)\n [8] collect_to_with_first!(::Array{Int64,1}, ::Int64, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64) at ./array.jl:710\n [9] _collect(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Base.EltypeUnknown, ::Base.HasShape{1}) at ./array.jl:704\n [10] collect_similar(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}) at ./array.jl:628\n [11] map(::Function, ::Array{Any,1}) at ./abstractarray.jl:2162\n [12] newstruct_raw(::IdDict{Any,Any}, ::Type{T} where T, ::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [13] (::BSON.var\"#43#44\")(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:140\n [14] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:88\n [15] (::BSON.var\"#21#22\"{IdDict{Any,Any}})(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:94\n [16] applychildren!(::BSON.var\"#21#22\"{IdDict{Any,Any}}, ::Array{Any,1}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/BSON.jl:28\n [17] raise_recursive at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:94 [inlined]\n [18] (::BSON.var\"#39#40\"{IdDict{Any,Any}})(::Array{Any,1}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [19] iterate at ./generator.jl:47 [inlined]\n [20] collect_to!(::Array{Array{Any,1},1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:732\n [21] collect_to_with_first!(::Array{Array{Any,1},1}, ::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64) at ./array.jl:710\n [22] _collect(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Base.EltypeUnknown, ::Base.HasShape{1}) at ./array.jl:704\n [23] collect_similar(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}) at ./array.jl:628\n [24] map(::Function, ::Array{Any,1}) at ./abstractarray.jl:2162\n [25] newstruct_raw(::IdDict{Any,Any}, ::Type{T} where T, ::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [26] (::BSON.var\"#43#44\")(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:140\n [27] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:88\n [28] raise_recursive at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:99 [inlined]\n [29] load(::String) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:104\n [30] top-level scope at REPL[20]:1```","user":"UP345RMJR","ts":"1610360933.246600","team":"T68168MUP","edited":{"user":"UP345RMJR","ts":"1610360997.000000"},"blocks":[{"type":"rich_text","block_id":"PifXU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I have changed activation functions in my models from "},{"type":"text","text":"relu","style":{"code":true}},{"type":"text","text":" to "},{"type":"text","text":"sigmoid","style":{"code":true}},{"type":"text","text":" and I save them into "},{"type":"text","text":".bson","style":{"code":true}},{"type":"text","text":" which used to work with "},{"type":"text","text":"relu","style":{"code":true}},{"type":"text","text":" . Now, I am getting "},{"type":"text","text":"typeof","style":{"code":true}},{"type":"text","text":" error with sigmoid. Do not understand why. Thanks for any help. Error:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> res = BSON.load(file_with_dictionary_results)\nERROR: MethodError: no method matching typeof(σ)()\nStacktrace:\n [1] (::BSON.var\"#37#38\")(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:76\n [2] _raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:79\n [3] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:89\n [4] (::BSON.var\"#39#40\"{IdDict{Any,Any}})(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [5] iterate at ./generator.jl:47 [inlined]\n [6] collect_to!(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:732\n [7] collect_to!(::Array{Real,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:740 (repeats 3 times)\n [8] collect_to_with_first!(::Array{Int64,1}, ::Int64, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64) at ./array.jl:710\n [9] _collect(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Base.EltypeUnknown, ::Base.HasShape{1}) at ./array.jl:704\n [10] collect_similar(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}) at ./array.jl:628\n [11] map(::Function, ::Array{Any,1}) at ./abstractarray.jl:2162\n [12] newstruct_raw(::IdDict{Any,Any}, ::Type{T} where T, ::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [13] (::BSON.var\"#43#44\")(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:140\n [14] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:88\n [15] (::BSON.var\"#21#22\"{IdDict{Any,Any}})(::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:94\n [16] applychildren!(::BSON.var\"#21#22\"{IdDict{Any,Any}}, ::Array{Any,1}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/BSON.jl:28\n [17] raise_recursive at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:94 [inlined]\n [18] (::BSON.var\"#39#40\"{IdDict{Any,Any}})(::Array{Any,1}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [19] iterate at ./generator.jl:47 [inlined]\n [20] collect_to!(::Array{Array{Any,1},1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64, ::Int64) at ./array.jl:732\n [21] collect_to_with_first!(::Array{Array{Any,1},1}, ::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Int64) at ./array.jl:710\n [22] _collect(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}, ::Base.EltypeUnknown, ::Base.HasShape{1}) at ./array.jl:704\n [23] collect_similar(::Array{Any,1}, ::Base.Generator{Array{Any,1},BSON.var\"#39#40\"{IdDict{Any,Any}}}) at ./array.jl:628\n [24] map(::Function, ::Array{Any,1}) at ./abstractarray.jl:2162\n [25] newstruct_raw(::IdDict{Any,Any}, ::Type{T} where T, ::Dict{Symbol,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:124\n [26] (::BSON.var\"#43#44\")(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/extensions.jl:140\n [27] raise_recursive(::Dict{Symbol,Any}, ::IdDict{Any,Any}) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:88\n [28] raise_recursive at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:99 [inlined]\n [29] load(::String) at /Users/luboshanus/.julia/packages/BSON/XAts7/src/read.jl:104\n [30] top-level scope at REPL[20]:1"}]}]}]},{"client_msg_id":"61cc67ba-92cb-4482-bebc-1821952feec4","type":"message","text":"<https://github.com/sdobber/FluxArchitectures/issues/15>","user":"UDGT4PM41","ts":"1611078237.006300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0MSe","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/sdobber/FluxArchitectures/issues/15"}]}]}]},{"client_msg_id":"fce1a509-74dd-4a4a-966f-77e9ada5a3f7","type":"message","text":"Can I print the current learning rate when using learning rate decay?","user":"U014K4SE396","ts":"1611161820.007200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OOk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can I print the current learning rate when using learning rate decay?"}]}]}],"thread_ts":"1611161820.007200","reply_count":1,"reply_users_count":1,"latest_reply":"1611163357.010100","reply_users":["UH9KWTTD3"],"subscribed":false},{"client_msg_id":"77fae6f8-0842-414f-8350-fa7e4f1ad056","type":"message","text":"Thoughts on <https://github.com/FluxML/Flux.jl/pull/1471|https://github.com/FluxML/Flux.jl/pull/1471>?","user":"UC4QQPG4A","ts":"1611162745.007500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0KPe8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thoughts on "},{"type":"link","url":"https://github.com/FluxML/Flux.jl/pull/1471","text":"https://github.com/FluxML/Flux.jl/pull/1471"},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"28a4ca71-529f-47d9-9a88-d35823a67295","type":"message","text":"With that PR you could define a prehook to print it pretty trivially","user":"UC4QQPG4A","ts":"1611162771.008400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sqwG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"With that PR you could define a prehook to print it pretty trivially"}]}]}]},{"client_msg_id":"0eb9bdf5-3a3d-48fa-be7e-6422ff2cc72e","type":"message","text":"Oh you could also just define a callback to accept the optimiser and print the learning rate like that","user":"UC4QQPG4A","ts":"1611162815.009500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8jSf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh you could also just define a callback to accept the optimiser and print the learning rate like that"}]}]}],"reactions":[{"name":"+1","users":["U014K4SE396"],"count":1}]},{"client_msg_id":"078a6475-fe20-4bc0-b5ee-69ad01a4d215","type":"message","text":"Thank you and looking forward to that","user":"U014K4SE396","ts":"1611163073.010000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Z1=R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you and looking forward to that"}]}]}]},{"client_msg_id":"f18e0e93-36e8-4265-8b2a-871db69af432","type":"message","text":"Hi! New to Flux/Zygote from Pytorch, what are the best ways to make your functions play nice with Float32?","user":"UM9Q1BM9Q","ts":"1611451037.002200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Zd3a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi! New to Flux/Zygote from Pytorch, what are the best ways to make your functions play nice with Float32?"}]}]}]},{"client_msg_id":"d0b154b4-dd04-44e3-893a-86b49d2fa174","type":"message","text":"To elaborate: let's say i have a function `f(x, arg1) = x - arg1`. If x is Float32, Julia's behavior is to treat arg1 as a Float64, and the function will return a Float64","user":"UM9Q1BM9Q","ts":"1611451136.003800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"diFR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"To elaborate: let's say i have a function "},{"type":"text","text":"f(x, arg1) = x - arg1","style":{"code":true}},{"type":"text","text":". If x is Float32, Julia's behavior is to treat arg1 as a Float64, and the function will return a Float64"}]}]}],"thread_ts":"1611451136.003800","reply_count":2,"reply_users_count":1,"latest_reply":"1611451815.008400","reply_users":["UH9KWTTD3"],"subscribed":false},{"client_msg_id":"a07c6a0f-7d19-4b88-8636-b03af5d2b741","type":"message","text":"and this, logically, makes Julia complain about type mismatches and/or spends a lot of resources on type inference","user":"UM9Q1BM9Q","ts":"1611451198.004600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=qs8n","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and this, logically, makes Julia complain about type mismatches and/or spends a lot of resources on type inference"}]}]}]},{"client_msg_id":"43e36bcb-6b8d-42b1-ad7d-63bc43217d39","type":"message","text":"i'm sure there's a really simple way to do this, i just can't find it online","user":"UM9Q1BM9Q","ts":"1611451262.005600","team":"T68168MUP","edited":{"user":"UM9Q1BM9Q","ts":"1611451309.000000"},"blocks":[{"type":"rich_text","block_id":"KzO9u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"i'm sure there's a really simple way to do this, i just can't find it online"}]}]}]},{"client_msg_id":"f17c4667-c8c9-4f70-bba9-81cc41cb5eb1","type":"message","text":"`f` should only promote to Float64 if arg is already. Viz.\n```julia&gt; f(1.0, 2f0) |&gt; typeof\nFloat64\n\njulia&gt; f(1f0, 2f0) |&gt; typeof\nFloat32```\nWithout more context, I assume you are seeing that floating point constants are 64-bit by default in Julia. That's easily remedied by appending an `f0` though.","user":"UMY1LV01G","ts":"1611451673.007700","team":"T68168MUP","edited":{"user":"UMY1LV01G","ts":"1611451684.000000"},"blocks":[{"type":"rich_text","block_id":"k9n+r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"f","style":{"code":true}},{"type":"text","text":" should only promote to Float64 if arg is already. Viz.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> f(1.0, 2f0) |> typeof\nFloat64\n\njulia> f(1f0, 2f0) |> typeof\nFloat32"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Without more context, I assume you are seeing that floating point constants are 64-bit by default in Julia. That's easily remedied by appending an "},{"type":"text","text":"f0","style":{"code":true}},{"type":"text","text":" though."}]}]}]},{"client_msg_id":"0c50cadb-5fe5-42cf-a6cb-0769d4632563","type":"message","text":"thanks for the replies! so this requires adding `f0` or using something like `f(x::T, arg1) = x - T(arg1)` like <@UH9KWTTD3> said","user":"UM9Q1BM9Q","ts":"1611451935.010300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WJUR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thanks for the replies! so this requires adding "},{"type":"text","text":"f0","style":{"code":true}},{"type":"text","text":" or using something like "},{"type":"text","text":"f(x::T, arg1) = x - T(arg1)","style":{"code":true}},{"type":"text","text":" like "},{"type":"user","user_id":"UH9KWTTD3"},{"type":"text","text":" said"}]}]}]},{"client_msg_id":"00b52b3c-684d-4b3b-9a99-fd9afd52882a","type":"message","text":"so if i want to distribute my model, training etc over several functions with numerical arguments, is there a more \"scalable\" way to do this? like a nice design pattern?","user":"UM9Q1BM9Q","ts":"1611451978.011700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9ok","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so if i want to distribute my model, training etc over several functions with numerical arguments, is there a more \"scalable\" way to do this? like a nice design pattern?"}]}]}]},{"client_msg_id":"4edc9636-6588-4c5f-8c51-db65d3684a71","type":"message","text":"I think you'll have to provide an example we can actually dig into, because f should never return Float64 if you're only passing it Float32s.","user":"UMY1LV01G","ts":"1611452004.012200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lbE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think you'll have to provide an example we can actually dig into, because f should never return Float64 if you're only passing it Float32s."}]}]}]},{"client_msg_id":"7f5b1f91-b218-47b7-aa42-5d7c48b7d59c","type":"message","text":"sure, here's the function that was causing me grief: `function soft_threshold(x, λ)`\n    `relu(x - λ) - relu(-x - λ)`\n`end`","user":"UM9Q1BM9Q","ts":"1611452055.013200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"f6Z+G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"sure, here's the function that was causing me grief: "},{"type":"text","text":"function soft_threshold(x, λ)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    relu(x - λ) - relu(-x - λ)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"end","style":{"code":true}}]}]}]},{"client_msg_id":"2b917b55-b1cf-42b5-8c96-61d4592c0a4a","type":"message","text":"with `x::Array{Float32,N}, λ=some_float`","user":"UM9Q1BM9Q","ts":"1611452111.014000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aoYu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"with "},{"type":"text","text":"x::Array{Float32,N}, λ=some_float","style":{"code":true}}]}]}]},{"client_msg_id":"2974DDCF-9855-45B8-B037-41D3935C90A3","type":"message","text":"So lambda needs to specifically be Float32","user":"UH9KWTTD3","ts":"1611452133.014500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GI1M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So lambda needs to specifically be Float32"}]}]}]},{"client_msg_id":"1f364db1-ad45-4a8b-9db9-a95b628fa08a","type":"message","text":"And how/where is relu defined?","user":"UMY1LV01G","ts":"1611452147.015100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vg7EU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And how/where is relu defined?"}]}]}]},{"client_msg_id":"EF027CB9-E7E8-4A6D-95C7-2E300DF80DBB","type":"message","text":"The right approach would be to use `f0` like Brian suggested","user":"UH9KWTTD3","ts":"1611452169.015900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZtG57","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The right approach would be to use "},{"type":"text","text":"f0","style":{"code":true}},{"type":"text","text":" like Brian suggested"}]}]}],"reactions":[{"name":"+1","users":["UM9Q1BM9Q"],"count":1}]},{"client_msg_id":"9732b350-e16f-45ef-9001-699039017ce8","type":"message","text":"good point. this is the relu from Flux. `relu(x) = max(zero(x), x)`","user":"UM9Q1BM9Q","ts":"1611452190.016300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VPg4d","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"good point. this is the relu from Flux. "},{"type":"text","text":"relu(x) = max(zero(x), x)","style":{"code":true}}]}]}]},{"client_msg_id":"8d383806-dfa7-40be-beb8-c08d5efb5257","type":"message","text":"but let's say i have a bunch of functions that have float arguments","user":"UM9Q1BM9Q","ts":"1611452221.017200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WP6j","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but let's say i have a bunch of functions that have float arguments"}]}]}]},{"client_msg_id":"f121427d-eb34-4ba4-a69e-8e156399ff66","type":"message","text":"is the best way to do this to explicitly put every float argument in with an `f0`?","user":"UM9Q1BM9Q","ts":"1611452284.018200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0wfM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is the best way to do this to explicitly put every float argument in with an "},{"type":"text","text":"f0","style":{"code":true}},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"dac259d3-e694-49c4-88bf-6ccaed402180","type":"message","text":"This only applies to constant floats, which I imagine you'll have very few of","user":"UMY1LV01G","ts":"1611452324.018600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0uFbh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This only applies to constant floats, which I imagine you'll have very few of"}]}]}]},{"client_msg_id":"da0d8819-a9a6-4a14-8932-8b29cf1c330a","type":"message","text":"fair","user":"UM9Q1BM9Q","ts":"1611452357.019500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yat/l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"fair"}]}]}]},{"client_msg_id":"d8778982-4dac-4281-9423-d6b207328e64","type":"message","text":"Flux already inits model params to float32 by default","user":"UMY1LV01G","ts":"1611452359.019800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LaCJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Flux already inits model params to float32 by default"}]}]}]},{"client_msg_id":"7b016954-8982-46f5-bbd1-c941424de176","type":"message","text":"ok cool, this should make my life easier","user":"UM9Q1BM9Q","ts":"1611452418.021200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"52qm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ok cool, this should make my life easier"}]}]}]},{"client_msg_id":"bd4e3f18-32db-4f63-b5b7-8b0d8a023676","type":"message","text":"thanks!","user":"UM9Q1BM9Q","ts":"1611452421.021400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JGH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thanks!"}]}]}]},{"client_msg_id":"226DE114-C9FB-4164-B6FD-989545B96587","type":"message","text":"Or when you create an array like `x = rand(Float32, 3, 4)`. Basically, only when you create and allocate variables should you need to explicitly say “I want a Float32.” The rest should all be handled via Julia’s <https://docs.julialang.org/en/v1/manual/conversion-and-promotion/#Promotion|promotion system>.","user":"UH9KWTTD3","ts":"1611452547.023300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vv8K1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Or when you create an array like "},{"type":"text","text":"x = rand(Float32, 3, 4)","style":{"code":true}},{"type":"text","text":". Basically, only when you create and allocate variables should you need to explicitly say “I want a Float32.” The rest should all be handled via Julia’s "},{"type":"link","url":"https://docs.julialang.org/en/v1/manual/conversion-and-promotion/#Promotion","text":"promotion system"},{"type":"text","text":"."}]}]}],"reactions":[{"name":"+1","users":["UM9Q1BM9Q"],"count":1}]},{"client_msg_id":"c8a62483-1a69-4b1b-9cf8-ec57280bf0c4","type":"message","text":"hi folks, a quick question out of curiosity: what kinds of compiler optimizations happen in flux in regards to the networks that get built? is there any tensor graph optimization happening? we are building a particularly unique general purpose customizable optimization package for Julia and the techniques we implemented fit really well for optimizing signal flow graphs. we are curious about what's already happening in Flux and we'd like to try applying those techniques to flux nets soon\\ :rocket:","user":"U01K2JB9GPJ","ts":"1611747369.027200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"997","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hi folks, a quick question out of curiosity: what kinds of compiler optimizations happen in flux in regards to the networks that get built? is there any tensor graph optimization happening? we are building a particularly unique general purpose customizable optimization package for Julia and the techniques we implemented fit really well for optimizing signal flow graphs. we are curious about what's already happening in Flux and we'd like to try applying those techniques to flux nets soon\\ "},{"type":"emoji","name":"rocket"}]}]}],"thread_ts":"1611747369.027200","reply_count":2,"reply_users_count":2,"latest_reply":"1611765648.027600","reply_users":["UC4QQPG4A","UDGT4PM41"],"subscribed":false}]}