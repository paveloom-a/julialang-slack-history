{"cursor": 0, "messages": [{"client_msg_id":"7f6cbbd5-1f9a-40b6-87b3-f58aa8af3d86","type":"message","text":"<@U011TRN4QBU> After <https://github.com/JuliaStats/Distances.jl/pull/194> generalizes `pairwise` to any iterator, I think it would be nice to generalize it to any function, and add support for skipping missing values like the draft at <https://github.com/nalimilan/FreqTables.jl/pull/54>. Actually this could probably be split in two parts that would live in two different packages: one part which would be similar to `pairwise` in Distances, and one that would depend on Tables and NamedArrays to preserve names. (After discussing with <@U8JAMQGQY> and <@U681ELA87>, it seems we can fix the dispatch problem by requiring people to use table types defined in Tables.jl.) Do you have an opinion on this? I'm not sure where the generic method would live: still Distances? StatsBase? Statistics?","user":"U67431ELR","ts":"1608129553.292000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G+Fw","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U011TRN4QBU"},{"type":"text","text":" After "},{"type":"link","url":"https://github.com/JuliaStats/Distances.jl/pull/194"},{"type":"text","text":" generalizes "},{"type":"text","text":"pairwise","style":{"code":true}},{"type":"text","text":" to any iterator, I think it would be nice to generalize it to any function, and add support for skipping missing values like the draft at "},{"type":"link","url":"https://github.com/nalimilan/FreqTables.jl/pull/54"},{"type":"text","text":". Actually this could probably be split in two parts that would live in two different packages: one part which would be similar to "},{"type":"text","text":"pairwise","style":{"code":true}},{"type":"text","text":" in Distances, and one that would depend on Tables and NamedArrays to preserve names. (After discussing with "},{"type":"user","user_id":"U8JAMQGQY"},{"type":"text","text":" and "},{"type":"user","user_id":"U681ELA87"},{"type":"text","text":", it seems we can fix the dispatch problem by requiring people to use table types defined in Tables.jl.) Do you have an opinion on this? I'm not sure where the generic method would live: still Distances? StatsBase? Statistics?"}]}]}]},{"type":"message","subtype":"channel_join","ts":"1608129560.292200","user":"U011TRN4QBU","text":"<@U011TRN4QBU> has joined the channel","inviter":"U67431ELR"},{"client_msg_id":"25fa8c5d-c7f4-4068-8f4f-028d146b55c8","type":"message","text":"Thanks for inviting me here, <@U67431ELR>. I'm not (yet) familiar with the stats ecosystem, so I don't think I can really help on where things should live. But in the discussion that I followed so far (the FreqTable PR), I was thinking whether one should indeed define methods in some `*Base` package, and then let other packages (including Distances.jl) import and extend them. Another example is the `return_type` function, that seems to be fairly generic (and, as you know, people were showing interest in extending it), but is owned by the rather narrow Distances.jl package. Moving that to some kind of base-package for the most generic case seems reasonable to me.","user":"U011TRN4QBU","ts":"1608135042.296700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hE1v","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for inviting me here, "},{"type":"user","user_id":"U67431ELR"},{"type":"text","text":". I'm not (yet) familiar with the stats ecosystem, so I don't think I can really help on where things should live. But in the discussion that I followed so far (the FreqTable PR), I was thinking whether one should indeed define methods in some "},{"type":"text","text":"*Base","style":{"code":true}},{"type":"text","text":" package, and then let other packages (including Distances.jl) import and extend them. Another example is the "},{"type":"text","text":"return_type","style":{"code":true}},{"type":"text","text":" function, that seems to be fairly generic (and, as you know, people were showing interest in extending it), but is owned by the rather narrow Distances.jl package. Moving that to some kind of base-package for the most generic case seems reasonable to me."}]}]}],"thread_ts":"1608135042.296700","reply_count":9,"reply_users_count":2,"latest_reply":"1608138713.298500","reply_users":["U67431ELR","U011TRN4QBU"],"subscribed":false,"reactions":[{"name":"+1","users":["U7QLM6E2E"],"count":1}]},{"type":"message","text":"`eigen`  seems to give a different answer for StaticMatrix :open_mouth:\nhere is a funny thing\n```m = [4.59965   -0.457675;\n    -0.457675   1.5904]\nsm = SMatrix{2,2}(m)\nprod(eigvecs(m) .≈ eigvecs(sm)) # false!!!```\nas the result the ellipse with from SMatrix is wrong!","files":[{"id":"F01HC6DDB52","created":1608232687,"timestamp":1608232687,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01087W46CF","editable":false,"size":79372,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HC6DDB52/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HC6DDB52/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HC6DDB52-c9fbcbcb0c/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HC6DDB52-c9fbcbcb0c/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HC6DDB52-c9fbcbcb0c/image_360.png","thumb_360_w":360,"thumb_360_h":239,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HC6DDB52-c9fbcbcb0c/image_480.png","thumb_480_w":480,"thumb_480_h":319,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HC6DDB52-c9fbcbcb0c/image_160.png","original_w":708,"original_h":471,"thumb_tiny":"AwAfADDSHU0EgdaB14Oajm+4T6UAI9wqnt9O9OSQHjIOPzqk3Jz1Pr60KSDmgVzQByKam/PzUyGQOOvI61NQMTuaRgGxml6GjPtQBXeEkDjnOOOmKj8g9z+VXO/Sj8KAGIm3B6ewqSkyfSjPPSgD/9k=","permalink":"https://julialang.slack.com/files/U01087W46CF/F01HC6DDB52/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HC6DDB52-f76aea8df9","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"NqFt4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"eigen","style":{"code":true}},{"type":"text","text":"  seems to give a different answer for StaticMatrix "},{"type":"emoji","name":"open_mouth"},{"type":"text","text":"\nhere is a funny thing\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"m = [4.59965   -0.457675;\n    -0.457675   1.5904]\nsm = SMatrix{2,2}(m)\nprod(eigvecs(m) .≈ eigvecs(sm)) # false!!!"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"as the result the ellipse with from SMatrix is wrong!"}]}]}],"user":"U01087W46CF","display_as_bot":false,"ts":"1608232851.302100","edited":{"user":"U01087W46CF","ts":"1608233310.000000"},"reactions":[{"name":"scream","users":["U8R9JE0D6","UPUBAM63X"],"count":2}]},{"client_msg_id":"cc606f7c-f964-4d69-b26c-78d647c045dd","type":"message","text":"well, if `v` is eigenvect, `-v` is also an eigen vec, so this is not \"wrong\"","user":"UH8A351DJ","ts":"1608233978.302900","team":"T68168MUP","edited":{"user":"UH8A351DJ","ts":"1608234014.000000"},"blocks":[{"type":"rich_text","block_id":"m6uW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"well, if "},{"type":"text","text":"v","style":{"code":true}},{"type":"text","text":" is eigenvect, "},{"type":"text","text":"-v","style":{"code":true}},{"type":"text","text":" is also an eigen vec, so this is not \"wrong\""}]}]}]},{"client_msg_id":"a832b354-f475-4f0a-b41b-e467b99994c6","type":"message","text":"that is right. looks like different conventions in `eigvec`  in two calls.\nMy way to determine the angle of the ellipse `θ = atan(evec[1,2],evec[1,1])`  is not reliable.","user":"U01087W46CF","ts":"1608237589.305400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/2O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that is right. looks like different conventions in "},{"type":"text","text":"eigvec","style":{"code":true}},{"type":"text","text":"  in two calls.\nMy way to determine the angle of the ellipse "},{"type":"text","text":"θ = atan(evec[1,2],evec[1,1])","style":{"code":true}},{"type":"text","text":"  is not reliable."}]}]}],"thread_ts":"1608237589.305400","reply_count":1,"reply_users_count":1,"latest_reply":"1608237904.305500","reply_users":["U01087W46CF"],"subscribed":false},{"client_msg_id":"fa1598e9-cd88-4468-ad02-399b4f619837","type":"message","text":"I do not see what is special about my matrix. it is always the same of the random one\n```function check_equality(m)\n    sm = SMatrix{2,2}(m)\n    prod(eigvecs(m) .≈ eigvecs(sm))\nend\n# \nsum(check_equality(2*rand(2,2) .- 1) == true for _ in 1:1_000_000) # 1_000_000, i.e. true for all\n# \ncheck_equality([4.59965   -0.457675;\n               -0.457675   1.5904])  # false!```","user":"U01087W46CF","ts":"1608241885.306500","team":"T68168MUP","edited":{"user":"U01087W46CF","ts":"1608241947.000000"},"blocks":[{"type":"rich_text","block_id":"jOgRK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I do not see what is special about my matrix. it is always the same of the random one\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function check_equality(m)\n    sm = SMatrix{2,2}(m)\n    prod(eigvecs(m) .≈ eigvecs(sm))\nend\n# \nsum(check_equality(2*rand(2,2) .- 1) == true for _ in 1:1_000_000) # 1_000_000, i.e. true for all\n# \ncheck_equality([4.59965   -0.457675;\n               -0.457675   1.5904])  # false!"}]}]}],"thread_ts":"1608241885.306500","reply_count":3,"reply_users_count":2,"latest_reply":"1608244995.307200","reply_users":["U01087W46CF","UHDQQ4GN6"],"subscribed":false},{"client_msg_id":"117fdbf6-b5e1-431c-b8b5-f57d924cba68","type":"message","text":"Could anyone take a look at the following PR? <https://github.com/JuliaStats/Distributions.jl/pull/1195>  Thanks!","user":"UKLKS1WC8","ts":"1608249486.308400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tsWfT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Could anyone take a look at the following PR? "},{"type":"link","url":"https://github.com/JuliaStats/Distributions.jl/pull/1195"},{"type":"text","text":"  Thanks!"}]}]}]},{"client_msg_id":"e1b0821b-3d2c-4bde-94ef-297292981e8b","type":"message","text":"I would like to compute the relative entropy (KL divergence) between two Beta distributions but am running into some computational problems.\n\nWikipedia gives an <https://en.wikipedia.org/wiki/Beta_distribution#Quantities_of_information_(entropy)|expression> in terms of the beta and digamma functions, but implementing  it causes underflow since the beta function values can get <https://www.wolframalpha.com/input/?i=beta%281000%2C+20000%29|quite small> and in Julia go to zero: `beta(1000, 20000) == 0.0`, resulting in `log(0.0) == -Inf`.\n\nDoes anybody have an idea for computing the relative entropy with Beta parameters in the 1,000–200,000 range? I'm learning these distributions from count data, so those are realistic ranges for the α and β parameters.\n\nHere's my current implementation:\n```function relative_entropy(x::Beta, y::Beta)\n\tα, β = params(x)\n\tα′, β′ = params(y)\n\tψ, B = digamma, beta\n\tlog(B(α′, β′)) - log(B(α, β)) \n\t\t(α - α′)ψ(α) + (β - β′)ψ(β) + \n\t\t(α′ - α + β′ - β)ψ(α + β)\nend```","user":"U68M6ERG8","ts":"1608326587.311700","team":"T68168MUP","edited":{"user":"U68M6ERG8","ts":"1608326831.000000"},"blocks":[{"type":"rich_text","block_id":"PdN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I would like to compute the relative entropy (KL divergence) between two Beta distributions but am running into some computational problems.\n\nWikipedia gives an "},{"type":"link","url":"https://en.wikipedia.org/wiki/Beta_distribution#Quantities_of_information_(entropy)","text":"expression"},{"type":"text","text":" in terms of the beta and digamma functions, but implementing  it causes underflow since the beta function values can get "},{"type":"link","url":"https://www.wolframalpha.com/input/?i=beta%281000%2C+20000%29","text":"quite small"},{"type":"text","text":" and in Julia go to zero: "},{"type":"text","text":"beta(1000, 20000) == 0.0","style":{"code":true}},{"type":"text","text":", resulting in "},{"type":"text","text":"log(0.0) == -Inf","style":{"code":true}},{"type":"text","text":".\n\nDoes anybody have an idea for computing the relative entropy with Beta parameters in the 1,000–200,000 range? I'm learning these distributions from count data, so those are realistic ranges for the α and β parameters.\n\nHere's my current implementation:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function relative_entropy(x::Beta, y::Beta)\n\tα, β = params(x)\n\tα′, β′ = params(y)\n\tψ, B = digamma, beta\n\tlog(B(α′, β′)) - log(B(α, β)) \n\t\t(α - α′)ψ(α) + (β - β′)ψ(β) + \n\t\t(α′ - α + β′ - β)ψ(α + β)\nend"}]}]}],"thread_ts":"1608326587.311700","reply_count":7,"reply_users_count":2,"latest_reply":"1608328065.315200","reply_users":["U68M6ERG8","U6C937ENB"],"subscribed":false},{"type":"message","text":"I noticed the `BinomialTest` function in `HypothesisTests.jl`   seems to be giving erroneous p-values. It reports a two sided p value but it does not agree with R even in simple cases. What is the reason for this?","files":[{"id":"F01H7Q8P8PP","created":1608447565,"timestamp":1608447565,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01EF0QVAB0","editable":false,"size":65615,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01H7Q8P8PP/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01H7Q8P8PP/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8P8PP-9966e20ea1/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8P8PP-9966e20ea1/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8P8PP-9966e20ea1/image_360.png","thumb_360_w":360,"thumb_360_h":152,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8P8PP-9966e20ea1/image_480.png","thumb_480_w":480,"thumb_480_h":203,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8P8PP-9966e20ea1/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8P8PP-9966e20ea1/image_720.png","thumb_720_w":720,"thumb_720_h":304,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8P8PP-9966e20ea1/image_800.png","thumb_800_w":800,"thumb_800_h":338,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8P8PP-9966e20ea1/image_960.png","thumb_960_w":960,"thumb_960_h":406,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8P8PP-9966e20ea1/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":433,"original_w":1050,"original_h":444,"thumb_tiny":"AwAUADCiM5wf5Uf56U80hxQAzNGadu9qTd7UAJRS7vagnPagAyfWjJpKKACiiigAooooA//Z","permalink":"https://julialang.slack.com/files/U01EF0QVAB0/F01H7Q8P8PP/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01H7Q8P8PP-e99de67396","is_starred":false,"has_rich_preview":false},{"id":"F01H7Q8VC3X","created":1608447594,"timestamp":1608447594,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01EF0QVAB0","editable":false,"size":62587,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01H7Q8VC3X/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01H7Q8VC3X/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8VC3X-e8aa2347e0/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8VC3X-e8aa2347e0/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8VC3X-e8aa2347e0/image_360.png","thumb_360_w":360,"thumb_360_h":221,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8VC3X-e8aa2347e0/image_480.png","thumb_480_w":480,"thumb_480_h":294,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8VC3X-e8aa2347e0/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8VC3X-e8aa2347e0/image_720.png","thumb_720_w":720,"thumb_720_h":441,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01H7Q8VC3X-e8aa2347e0/image_800.png","thumb_800_w":800,"thumb_800_h":490,"original_w":852,"original_h":522,"thumb_tiny":"AwAdADCrgY6UhHoooUgZ5pcjuaYDc+wpKcTn+KjPHDYoAbRTuf71IST1oAUEjqDQSDSBsds0bvagAyOwoBHcUFs9qCc0AGR6UUlFAH//2Q==","permalink":"https://julialang.slack.com/files/U01EF0QVAB0/F01H7Q8VC3X/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01H7Q8VC3X-abb8e8fb6d","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"c6r7w","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I noticed the "},{"type":"text","text":"BinomialTest ","style":{"code":true}},{"type":"text","text":"function in "},{"type":"text","text":"HypothesisTests.jl ","style":{"code":true}},{"type":"text","text":"  seems to be giving erroneous p-values. It reports a two sided p value but it does not agree with R even in simple cases. What is the reason for this?"}]}]}],"user":"U01EF0QVAB0","ts":"1608447615.317900","thread_ts":"1608447615.317900","reply_count":7,"reply_users_count":3,"latest_reply":"1608570460.320600","reply_users":["U67431ELR","U680T6770","U01EF0QVAB0"],"subscribed":false},{"client_msg_id":"51042f1f-fcae-4613-8d32-8eea94a3a6b2","type":"message","text":"Looking for comments on an old package that I just got updated / agreed to take over: <https://discourse.julialang.org/t/rfc-poweranalysis-jl/52241>","user":"U8JP5B9T2","ts":"1608665089.321600","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"[RFC] PowerAnalysis.jl","title_link":"https://discourse.julialang.org/t/rfc-poweranalysis-jl/52241","text":"I recently stumbled on a package from @johnmyleswhite circa julia v0.3 that had some functionality I needed, though it hadn’t been updated for a while. It was a fairly simple code base, and I was able to get it working on julia v1.6. John doesn’t have time to maintain it, and he agreed that I could take it over, though I’m by no means an expert on this topic. Before I register it, I thought I’d post here for comments/suggestions. In particular, I wanted to know Would it be possible to absorb ...","fallback":"JuliaLang: [RFC] PowerAnalysis.jl","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1608665010,"from_url":"https://discourse.julialang.org/t/rfc-poweranalysis-jl/52241","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/rfc-poweranalysis-jl/52241"}],"blocks":[{"type":"rich_text","block_id":"LHn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looking for comments on an old package that I just got updated / agreed to take over: "},{"type":"link","url":"https://discourse.julialang.org/t/rfc-poweranalysis-jl/52241"}]}]}]},{"client_msg_id":"f78ceb6b-5840-4110-b3b9-a9101f1d90b3","type":"message","text":"<https://twitter.com/xuanalogue/status/1343318361338470402>","user":"UDGT4PM41","ts":"1609200932.322800","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/xuanalogue|@xuanalogue>: Something I've been working on over the past semester: Genify, a program transformation tool that makes arbitrary Julia code controllable by a probabilistic programming system like Gen (<https://www.gen.dev/>)!\n\n<https://github.com/probcomp/Genify.jl>","ts":1609107029,"author_name":"xuan (sh-yen / ɕɥɛn)","author_link":"https://twitter.com/xuanalogue/status/1343318361338470402","author_icon":"https://pbs.twimg.com/profile_images/1328187269631647749/qnCcd8M3_normal.jpg","author_subname":"@xuanalogue","text":"Something I've been working on over the past semester: Genify, a program transformation tool that makes arbitrary Julia code controllable by a probabilistic programming system like Gen (<https://www.gen.dev/>)!\n\n<https://github.com/probcomp/Genify.jl>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/xuanalogue/status/1343318361338470402","id":1,"original_url":"https://twitter.com/xuanalogue/status/1343318361338470402","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"CMFny","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/xuanalogue/status/1343318361338470402"}]}]}]},{"client_msg_id":"3dc72917-16dc-4b12-99dc-e44f2f985f37","type":"message","text":"Wondering if there is any stomach for creating a light-weight method-stubs only package for stats and ml. For example, MLJBase used to extend `fit` and `predict`  from `StatsBase` but the demand for a light-weight base package (`MJLModelInterface`) meant we no longer do so. I’ve bumping up against this again as I try to separate out a metrics package from MLJBase because metrics share a bunch of traits with models (for example `prediction_type` - probabilistic or deterministic). The new StatisticalMeasures package ought not to depend on any of our machine learning model code, but without introducing a third package for the trait stubs I’m stuck. I could create one but it seems the more sensible thing would to get buy-in from StatsBase, and other packages. Thoughts anyone? (I know there is MLBase, but this is more than method stubs).","user":"UD0SQV5LL","ts":"1609203596.330200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iA2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Wondering if there is any stomach for creating a light-weight method-stubs only package for stats and ml. For example, MLJBase used to extend `fit` and `predict`  from `StatsBase` but the demand for a light-weight base package (`MJLModelInterface`) meant we no longer do so. I’ve bumping up against this again as I try to separate out a metrics package from MLJBase because metrics share a bunch of traits with models (for example "},{"type":"text","text":"prediction_type","style":{"code":true}},{"type":"text","text":" - probabilistic or deterministic). The new StatisticalMeasures package ought not to depend on any of our machine learning model code, but without introducing a third package for the trait stubs I’m stuck. I could create one but it seems the more sensible thing would to get buy-in from StatsBase, and other packages. Thoughts anyone? (I know there is MLBase, but this is more than method stubs)."}]}]}],"thread_ts":"1609203596.330200","reply_count":8,"reply_users_count":4,"latest_reply":"1609207183.333400","reply_users":["UDGT4PM41","U6A936746","UMY1LV01G","UD0SQV5LL"],"subscribed":false,"reactions":[{"name":"+1","users":["U6A936746"],"count":1}]},{"type":"message","subtype":"channel_join","ts":"1609203669.330600","user":"UMY1LV01G","text":"<@UMY1LV01G> has joined the channel","inviter":"UDGT4PM41"},{"type":"message","subtype":"channel_join","ts":"1609203703.331100","user":"UEYL7UA64","text":"<@UEYL7UA64> has joined the channel","inviter":"UDGT4PM41"},{"client_msg_id":"5a274567-8a03-4b4c-aa76-aafee17193a3","type":"message","text":"<https://en.wikipedia.org/wiki/Landau_distribution> does Distributions.jl welcome this being added?","user":"UH8A351DJ","ts":"1609205328.332500","team":"T68168MUP","edited":{"user":"UH8A351DJ","ts":"1609205334.000000"},"blocks":[{"type":"rich_text","block_id":"XcV","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://en.wikipedia.org/wiki/Landau_distribution"},{"type":"text","text":" does Distributions.jl welcome this being added?"}]}]}],"thread_ts":"1609205328.332500","reply_count":1,"reply_users_count":1,"latest_reply":"1609206719.332800","reply_users":["UH8A351DJ"],"subscribed":false},{"type":"message","text":"","files":[{"id":"F01HHP7UK7G","created":1609211109,"timestamp":1609211109,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UH8A351DJ","editable":false,"size":72805,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HHP7UK7G/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HHP7UK7G/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HHP7UK7G-7cc2f74558/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HHP7UK7G-7cc2f74558/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HHP7UK7G-7cc2f74558/image_360.png","thumb_360_w":360,"thumb_360_h":263,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HHP7UK7G-7cc2f74558/image_480.png","thumb_480_w":480,"thumb_480_h":350,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HHP7UK7G-7cc2f74558/image_160.png","original_w":626,"original_h":457,"thumb_tiny":"AwAjADC0bKIsTl+eeGpPsMX96T/vqrIpaAK32GL+8/8A31R9hi/vSf8AfVWaKAKhsoh/FJ/31TktI0cMDJkc8tVmkPSgAFLSAgGjIoAWikzRkUALQeRSZFGRQAmaM0d6KADJozRRQAZo70UDrQB//9k=","permalink":"https://julialang.slack.com/files/UH8A351DJ/F01HHP7UK7G/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HHP7UK7G-e8df43ba4c","is_starred":false,"has_rich_preview":false}],"upload":false,"user":"UH8A351DJ","display_as_bot":false,"ts":"1609211112.334400","thread_ts":"1609205328.332500","parent_user_id":"UH8A351DJ","subtype":"thread_broadcast","root":{"client_msg_id":"5a274567-8a03-4b4c-aa76-aafee17193a3","type":"message","text":"<https://en.wikipedia.org/wiki/Landau_distribution> does Distributions.jl welcome this being added?","user":"UH8A351DJ","ts":"1609205328.332500","team":"T68168MUP","edited":{"user":"UH8A351DJ","ts":"1609205334.000000"},"blocks":[{"type":"rich_text","block_id":"XcV","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://en.wikipedia.org/wiki/Landau_distribution"},{"type":"text","text":" does Distributions.jl welcome this being added?"}]}]}],"thread_ts":"1609205328.332500","reply_count":3,"reply_users_count":1,"latest_reply":"1609211112.334400","reply_users":["UH8A351DJ"],"subscribed":false}},{"type":"message","subtype":"channel_join","ts":"1609213352.335100","user":"U010XUS4MT7","text":"<@U010XUS4MT7> has joined the channel","inviter":"UDGT4PM41"},{"client_msg_id":"3fc72d03-ecc4-4e90-83a7-ba1993eb9718","type":"message","text":"What is the Julia equivalent of this Python function?\n```In [4]: dmatrix('x', {'x': ['a', 'b', 'c', 'a', 'a', 'a', 'a', 'a']})\nOut[4]: \nDesignMatrix with shape (8, 3)\n  Intercept  x[T.b]  x[T.c]\n          1       0       0\n          1       1       0\n          1       0       1\n          1       0       0\n          1       0       0\n          1       0       0\n          1       0       0\n          1       0       0\n  Terms:\n    'Intercept' (column 0)\n    'x' (columns 1:3)```","user":"U01ARRMLM7E","ts":"1609379074.341200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9H3rE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is the Julia equivalent of this Python function?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"In [4]: dmatrix('x', {'x': ['a', 'b', 'c', 'a', 'a', 'a', 'a', 'a']})\nOut[4]: \nDesignMatrix with shape (8, 3)\n  Intercept  x[T.b]  x[T.c]\n          1       0       0\n          1       1       0\n          1       0       1\n          1       0       0\n          1       0       0\n          1       0       0\n          1       0       0\n          1       0       0\n  Terms:\n    'Intercept' (column 0)\n    'x' (columns 1:3)"}]}]}]},{"client_msg_id":"392348a9-7d44-4c60-b04b-95dfc8bb0103","type":"message","text":"I thought it would be\n```julia&gt; StatsModels.ContrastsMatrix(DummyCoding(), [\"a\", \"b\", \"c\", \"a\", \"a\", \"a\"]).matrix\n6×5 Array{Float64,2}:\n 0.0  0.0  0.0  0.0  0.0\n 1.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  1.0```\nbut apparently not","user":"U01ARRMLM7E","ts":"1609379270.341700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XViVJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I thought it would be\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> StatsModels.ContrastsMatrix(DummyCoding(), [\"a\", \"b\", \"c\", \"a\", \"a\", \"a\"]).matrix\n6×5 Array{Float64,2}:\n 0.0  0.0  0.0  0.0  0.0\n 1.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  1.0"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"but apparently not"}]}]}]},{"client_msg_id":"01da1372-cc27-40fd-8d11-3fa94080d9de","type":"message","text":"you're on the right track.  there isn't a super-convenient way to do that in a one-liner but you can do something liek this:","user":"U66M57AN4","ts":"1609385754.346200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SJcP+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you're on the right track.  there isn't a super-convenient way to do that in a one-liner but you can do something liek this:"}]}]}]},{"client_msg_id":"504beea3-ec56-4662-9abe-ce9bf52a7122","type":"message","text":"```julia&gt; d = (x = [\"a\", \"b\", \"c\", \"a\", \"a\", \"a\"])\n6-element Array{String,1}:\n \"a\"\n \"b\"\n \"c\"\n \"a\"\n \"a\"\n \"a\"\n\njulia&gt; modelmatrix(term(1) + term(:x), d)\n6×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 1.0  1.0  0.0\n 1.0  0.0  1.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0```","user":"U66M57AN4","ts":"1609385930.346500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TG=","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> d = (x = [\"a\", \"b\", \"c\", \"a\", \"a\", \"a\"])\n6-element Array{String,1}:\n \"a\"\n \"b\"\n \"c\"\n \"a\"\n \"a\"\n \"a\"\n\njulia> modelmatrix(term(1) + term(:x), d)\n6×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 1.0  1.0  0.0\n 1.0  0.0  1.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0"}]}]}]},{"client_msg_id":"16013515-419a-4a82-b7f0-aab9d41a9b40","type":"message","text":"or","user":"U66M57AN4","ts":"1609385940.346700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"U4a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"or"}]}]}]},{"client_msg_id":"565ab4c4-18be-43ed-844f-af688f1c63f1","type":"message","text":"```julia&gt; modelmatrix(@formula(0 ~ 1 + x), d)\n6×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 1.0  1.0  0.0\n 1.0  0.0  1.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0```","user":"U66M57AN4","ts":"1609385970.347000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YJXuO","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> modelmatrix(@formula(0 ~ 1 + x), d)\n6×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 1.0  1.0  0.0\n 1.0  0.0  1.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0"}]}]}]},{"client_msg_id":"4a94b01e-cc03-4a29-8b87-c7cbc9fbe0dc","type":"message","text":"Thanks","user":"U01ARRMLM7E","ts":"1609386177.347500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1U8E","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks"}]}]}]},{"client_msg_id":"c2a78f71-8613-46dc-be26-88573ef36949","type":"message","text":"the more verbose but future-proof way is","user":"U66M57AN4","ts":"1609386193.347700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CoLQ4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the more verbose but future-proof way is"}]}]}],"reactions":[{"name":"+1","users":["U7THT3TM3"],"count":1}]},{"client_msg_id":"92944a23-c101-45d9-80bc-78e790532dc7","type":"message","text":"```julia&gt; ff = apply_schema(@formula(0 ~ 1 + x), schema(d))\nFormulaTerm\nResponse:\n  0\nPredictors:\n  1\n  x(DummyCoding:3→2)\n\njulia&gt; modelcols(ff.rhs, d)\n6×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 1.0  1.0  0.0\n 1.0  0.0  1.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0```","user":"U66M57AN4","ts":"1609386266.348100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1YO","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> ff = apply_schema(@formula(0 ~ 1 + x), schema(d))\nFormulaTerm\nResponse:\n  0\nPredictors:\n  1\n  x(DummyCoding:3→2)\n\njulia> modelcols(ff.rhs, d)\n6×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 1.0  1.0  0.0\n 1.0  0.0  1.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0\n 1.0  0.0  0.0"}]}]}]},{"client_msg_id":"f821c417-ee48-4dd8-9e85-5aeb06fc4942","type":"message","text":"(if you look at the source of `modelmatrix` that's basically what it's doing...)","user":"U66M57AN4","ts":"1609386710.348500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UeE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(if you look at the source of "},{"type":"text","text":"modelmatrix","style":{"code":true}},{"type":"text","text":" that's basically what it's doing...)"}]}]}]},{"client_msg_id":"6af7bd1f-e555-4ce9-9b28-8b903d88d157","type":"message","text":"Hi, suppose I have 2 groups - A and B. From those groups we can draw the distribution (median/mean) etc. and do some statistical tests, such as T-test or Wilcoxon test.\n\nIs there any test (similarly, considering group's distribution, to test whether a new sample belongs to which group? This sounds like classification tasks, but is there any statistical tests that I can use for simple-classifier?","user":"UUT4VGTE2","ts":"1610374564.350300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QC0j","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, suppose I have 2 groups - A and B. From those groups we can draw the distribution (median/mean) etc. and do some statistical tests, such as T-test or Wilcoxon test.\n\nIs there any test (similarly, considering group's distribution, to test whether a new sample belongs to which group? This sounds like classification tasks, but is there any statistical tests that I can use for simple-classifier?"}]}]}]},{"client_msg_id":"30d8ea03-d92e-4d96-9ca0-e465299dc3c2","type":"message","text":"Another question on statistical test. I'd like to test 5 groups with Kruskal-Wallis (non-parametric tests on median). However, 2 of those are paired, so I have A, A', B, C, D. My question is, with the presence of a pair in those groups, is it okay to use Kruskal-Wallis still?","user":"UUT4VGTE2","ts":"1610410401.353300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kBdX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Another question on statistical test. I'd like to test 5 groups with Kruskal-Wallis (non-parametric tests on median). However, 2 of those are paired, so I have A, A', B, C, D. My question is, with the presence of a pair in those groups, is it okay to use Kruskal-Wallis still?"}]}]}]},{"client_msg_id":"2cac25a6-b9d3-4f16-8541-afb855849f7d","type":"message","text":"Dear Julia Statistics experts,\nf2 = LinearMixedModel(@formula(fmri~AMP+SLP+aSLP+(0+AMP|session)+(0+SLP|session)+(0+aSLP|session)), PPainData\nf2.optsum.maxfeval = 100;\nf2.optsum.optimizer = :LN_COBYLA;\nm2 = fit!(f2,verbose=true)\n\nI am running the code above to compute linear mixed effects models for brain data.\nThere are o lot of data to crunch but a few seem to have problems. These brain regions are probably not the relevant ones but I need to run them all.\nThe problem is that I am getting stuck after some iterations:\n\nf_1: 3286.48149 [1.0, 1.0, 1.0]\nf_2: 3289.83915 [1.75, 1.0, 1.0]\nf_3: 3289.82313 [1.0, 1.75, 1.0]\n.\n.\n.\nf_76: 3226.80068 [0.0, 2.7939677307853295e-9, 0.0]\nf_77: 3226.80068 [0.0, 1.3969838688621117e-9, 0.0]\nf_78: 3226.80068 [1.7546089477954183e-108, 6.938893903907228e-18, 2.0801101616529191e-10]\n\nDoes anyone hav a idea how to prevent this? I have thousends of data and can not supervise every single one.\nf2.optsum.maxfeval = 77 would solve it for this but are there other options?\n\nThank you!","user":"UTCHVGK6Y","ts":"1610721312.003000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qAP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Dear Julia Statistics experts,\nf2 = LinearMixedModel(@formula(fmri~AMP+SLP+aSLP+(0+AMP|session)+(0+SLP|session)+(0+aSLP|session)), PPainData\nf2.optsum.maxfeval = 100;\nf2.optsum.optimizer = :LN_COBYLA;\nm2 = fit!(f2,verbose=true)\n\nI am running the code above to compute linear mixed effects models for brain data.\nThere are o lot of data to crunch but a few seem to have problems. These brain regions are probably not the relevant ones but I need to run them all.\nThe problem is that I am getting stuck after some iterations:\n\nf_1: 3286.48149 [1.0, 1.0, 1.0]\nf_2: 3289.83915 [1.75, 1.0, 1.0]\nf_3: 3289.82313 [1.0, 1.75, 1.0]\n.\n.\n.\nf_76: 3226.80068 [0.0, 2.7939677307853295e-9, 0.0]\nf_77: 3226.80068 [0.0, 1.3969838688621117e-9, 0.0]\nf_78: 3226.80068 [1.7546089477954183e-108, 6.938893903907228e-18, 2.0801101616529191e-10]\n\nDoes anyone hav a idea how to prevent this? I have thousends of data and can not supervise every single one.\nf2.optsum.maxfeval = 77 would solve it for this but are there other options?\n\nThank you!"}]}]}]},{"client_msg_id":"71b59f2e-d761-4ec2-9c52-0972bce7474c","type":"message","text":"Do we have a package that calculates sample sizes given expected effect sizes/variability and desired power for multi-group comparisons? I found <https://github.com/johnmyleswhite/PowerAnalysis.jl> but it seems to be doing two-group comparisons only? I have an experimental design which involves six groups (formed based on the levels of two categorical variables, one with 3 and the other with 2 levels) and need to test for differences between them for both continuous and binary measures.","user":"U7JQGPGCQ","ts":"1611066578.054400","team":"T68168MUP","edited":{"user":"U7JQGPGCQ","ts":"1611074745.000000"},"blocks":[{"type":"rich_text","block_id":"Tkjd4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Do we have a package that calculates sample sizes given expected effect sizes/variability and desired power for multi-group comparisons? I found "},{"type":"link","url":"https://github.com/johnmyleswhite/PowerAnalysis.jl"},{"type":"text","text":" but it seems to be doing two-group comparisons only? I have an experimental design which involves six groups (formed based on the levels of two categorical variables, one with 3 and the other with 2 levels) and need to test for differences between them for both continuous and binary measures."}]}]}],"thread_ts":"1611066578.054400","reply_count":2,"reply_users_count":2,"latest_reply":"1611127561.055700","reply_users":["UAVMYR0F4","U7JQGPGCQ"],"subscribed":false},{"client_msg_id":"9d727152-5310-4f61-8048-9b8bc0b09626","type":"message","text":"<@U81PB6N77> Just saw your comment “I guess it will get a little complicated since we’re moving away from Distributions.jl”. Just curious, what are you moving to?","user":"U680T6770","ts":"1611177793.056800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9UP","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U81PB6N77"},{"type":"text","text":" Just saw your comment “I guess it will get a little complicated since we’re moving away from Distributions.jl”. Just curious, what are you moving to?"}]}]}]},{"client_msg_id":"010d73b1-1640-49f3-8cdc-6a539b7175a9","type":"message","text":"MeasureTheory.jl","user":"U81PB6N77","ts":"1611177805.057000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"039O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"MeasureTheory.jl"}]}]}],"reactions":[{"name":"+1","users":["U7THT3TM3","UKLKS1WC8","U680T6770","U7QLM6E2E"],"count":4}]},{"client_msg_id":"f82dad2b-1cac-4a93-ae0d-4dc1a9b26217","type":"message","text":"There are a few reasons for this:\n- The design of Distributions makes it awkward to build new ones\n- The types are very constrained, so it doesn't work well with symbolics\n- Bounds checks change from one distribution to the next\n- For some algorithms, we can save some computation time by avoiding renormalization at each step","user":"U81PB6N77","ts":"1611178035.059600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Wv8Q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There are a few reasons for this:\n- The design of Distributions makes it awkward to build new ones\n- The types are very constrained, so it doesn't work well with symbolics\n- Bounds checks change from one distribution to the next\n- For some algorithms, we can save some computation time by avoiding renormalization at each step"}]}]}]},{"client_msg_id":"0809a7f7-66cc-4b46-b58a-69bf79a158ca","type":"message","text":"Also, it's not very friendly toward singular distributions, and it's so widely used that changing anything is a very slow process.","user":"U81PB6N77","ts":"1611178110.060600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"abVuY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also, it's not very friendly toward singular distributions, and it's so widely used that changing anything is a very slow process."}]}]}],"reactions":[{"name":"+1","users":["U680T6770","U6A936746","U85JBUGGP"],"count":3},{"name":"slow_parrot","users":["U019K6Q9N15"],"count":1}]},{"client_msg_id":"5ec2b023-a20c-4c84-9f46-6bd8e6b2712f","type":"message","text":"Currently using <https://juliastats.org/GLM.jl/v0.11/>\n\nIs it possible to create a custom Link function?\n\nI’m trying to go for Log2 as opposed to just Log.\n\nI’m assuming the SE and P values will also change accordingly right?","user":"U01FAHWCMFF","ts":"1611193749.000600","team":"T68168MUP","edited":{"user":"U01FAHWCMFF","ts":"1611193795.000000"},"blocks":[{"type":"rich_text","block_id":"xgdOd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Currently using "},{"type":"link","url":"https://juliastats.org/GLM.jl/v0.11/"},{"type":"text","text":"\n\nIs it possible to create a custom Link function?\n\nI’m trying to go for Log2 as opposed to just Log.\n\nI’m assuming the SE and P values will also change accordingly right?"}]}]}],"thread_ts":"1611193749.000600","reply_count":1,"reply_users_count":1,"latest_reply":"1611217750.000900","reply_users":["U67431ELR"],"subscribed":false},{"client_msg_id":"0a2f33bd-ebe9-4ec4-943e-20ad5e9bb02e","type":"message","text":"Following up from <@U680T6770>’s question, here's a little example of what we can do with MeasureTheory.jl + Soss.jl:\n```julia&gt; using Soss\n\njulia&gt; m = @model x, α begin\n           σ ~ Normal(0,α)\n           β ~ Normal(0,1) \n           y ~ For(1:10) do j\n               Normal(x[j] * β, σ)\n           end\n           return y\n       end;\n\njulia&gt; x = randn(10);\n\njulia&gt; tr = simulate(m(x=x, α=1.0)).trace\n(y = [3.8746216264672046, 4.070841165904433, 0.5861945092982052, 0.04991832730055079, 2.6193000436341736, 1.8970453478810443, 1.1333786298392112, -0.9652291603688541, 1.2851465121616734, -2.43239474159502], β = -0.72005026769353, σ = -1.4926901301729563)\n\njulia&gt; y = tr.y;\n\njulia&gt; symlogdensity(m(x=x, α=1.0) | (;y))\n-10log(σ) + -0.5((β^2) + (σ^2)) + -0.5(52.174430346203465 + 58.127152240288424β + 24.529854231286606(β^2))*(σ^-2)\n\njulia&gt; symlogdensity(m(x=x, α=1.0) | (;y); noinline=(:α,))\n-1log(α) + -10log(σ) + -0.5(β^2) + -0.5(52.174430346203465 + 58.12715224028842β + 24.5298542312866(β^2))*(σ^-2) + -0.5(α^-2)*(σ^2)```\nThe symbolic part relies on SymbolicUtils.jl. There are still lots of cases it doesn't handle, but it's getting there. But given that, out codegen is pretty reliable:\n```julia&gt; codegen(m(x=x, α=1.0) | (;y)).f\nfunction = (_args, _data, _pars;) -&gt; begin\n    begin\n        β = (Main).getproperty(_pars, :β)\n        σ = (Main).getproperty(_pars, :σ)\n        y = (Main).getproperty(_data, :y)\n        α = (Main).getproperty(_args, :α)\n        x = (Main).getproperty(_args, :x)\n        var\"##1733\" = (log)(σ)\n        var\"##1734\" = (*)(-10, var\"##1733\")\n        var\"##1735\" = (^)(β, 2)\n        var\"##1736\" = (^)(σ, 2)\n        var\"##1737\" = (+)(var\"##1735\", var\"##1736\")\n        var\"##1738\" = (*)(-0.5, var\"##1737\")\n        var\"##1739\" = (*)(58.127152240288424, β)\n        var\"##1740\" = (*)(24.529854231286606, var\"##1735\")\n        var\"##1741\" = (+)(52.174430346203465, var\"##1739\", var\"##1740\")\n        var\"##1742\" = (^)(σ, -2)\n        var\"##1743\" = (*)(-0.5, var\"##1741\", var\"##1742\")\n        var\"##1744\" = (+)(var\"##1734\", var\"##1738\", var\"##1743\")\n    end\nend```\nSo we can use this as a very fast way to evaluate the log-density. I expect that for exponential family likelihood functions, this will blow Stan out of the water :slightly_smiling_face:","user":"U81PB6N77","ts":"1611240737.005300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=pALL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Following up from "},{"type":"user","user_id":"U680T6770"},{"type":"text","text":"’s question, here's a little example of what we can do with MeasureTheory.jl + Soss.jl:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> using Soss\n\njulia> m = @model x, α begin\n           σ ~ Normal(0,α)\n           β ~ Normal(0,1) \n           y ~ For(1:10) do j\n               Normal(x[j] * β, σ)\n           end\n           return y\n       end;\n\njulia> x = randn(10);\n\njulia> tr = simulate(m(x=x, α=1.0)).trace\n(y = [3.8746216264672046, 4.070841165904433, 0.5861945092982052, 0.04991832730055079, 2.6193000436341736, 1.8970453478810443, 1.1333786298392112, -0.9652291603688541, 1.2851465121616734, -2.43239474159502], β = -0.72005026769353, σ = -1.4926901301729563)\n\njulia> y = tr.y;\n\njulia> symlogdensity(m(x=x, α=1.0) | (;y))\n-10log(σ) + -0.5((β^2) + (σ^2)) + -0.5(52.174430346203465 + 58.127152240288424β + 24.529854231286606(β^2))*(σ^-2)\n\njulia> symlogdensity(m(x=x, α=1.0) | (;y); noinline=(:α,))\n-1log(α) + -10log(σ) + -0.5(β^2) + -0.5(52.174430346203465 + 58.12715224028842β + 24.5298542312866(β^2))*(σ^-2) + -0.5(α^-2)*(σ^2)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nThe symbolic part relies on SymbolicUtils.jl. There are still lots of cases it doesn't handle, but it's getting there. But given that, out codegen is pretty reliable:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> codegen(m(x=x, α=1.0) | (;y)).f\nfunction = (_args, _data, _pars;) -> begin\n    begin\n        β = (Main).getproperty(_pars, :β)\n        σ = (Main).getproperty(_pars, :σ)\n        y = (Main).getproperty(_data, :y)\n        α = (Main).getproperty(_args, :α)\n        x = (Main).getproperty(_args, :x)\n        var\"##1733\" = (log)(σ)\n        var\"##1734\" = (*)(-10, var\"##1733\")\n        var\"##1735\" = (^)(β, 2)\n        var\"##1736\" = (^)(σ, 2)\n        var\"##1737\" = (+)(var\"##1735\", var\"##1736\")\n        var\"##1738\" = (*)(-0.5, var\"##1737\")\n        var\"##1739\" = (*)(58.127152240288424, β)\n        var\"##1740\" = (*)(24.529854231286606, var\"##1735\")\n        var\"##1741\" = (+)(52.174430346203465, var\"##1739\", var\"##1740\")\n        var\"##1742\" = (^)(σ, -2)\n        var\"##1743\" = (*)(-0.5, var\"##1741\", var\"##1742\")\n        var\"##1744\" = (+)(var\"##1734\", var\"##1738\", var\"##1743\")\n    end\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nSo we can use this as a very fast way to evaluate the log-density. I expect that for exponential family likelihood functions, this will blow Stan out of the water "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"thread_ts":"1611240737.005300","reply_count":14,"reply_users_count":2,"latest_reply":"1611257949.010800","reply_users":["UN97XTLCV","U81PB6N77"],"subscribed":false,"reactions":[{"name":"+1","users":["U680T6770","U7THT3TM3","UE91V9CUC","UKLKS1WC8","U82LX4ACB","UB197FRCL","UJB9LTG5V","U85JBUGGP","U6LMK53QC"],"count":9}]},{"client_msg_id":"a5c241d7-8ff0-4640-a715-fe0abfdb4692","type":"message","text":"ultra cool","user":"U7PGB5DU3","ts":"1611240783.005500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PeNY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ultra cool"}]}]}],"reactions":[{"name":"grin","users":["U81PB6N77"],"count":1}]},{"client_msg_id":"b51e02e1-7ab8-4622-919b-760d8c9a45d3","type":"message","text":"Hello!\n\nSuppose we have some data (e.g. the lengths of all the people on Earth). It is then easy to compute and plot a histogram of these data.\n*What are good (and frequently used) ways to compute error bars/confidence intervals on a histogram?*\n\nBoth code and formulas are welcome!\nThank you, in advance,\nBest,\nIgnace","user":"U01HC60USTH","ts":"1611257001.008400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HYFpj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello!\n\nSuppose we have some data (e.g. the lengths of all the people on Earth). It is then easy to compute and plot a histogram of these data.\n"},{"type":"text","text":"What are good (and frequently used) ways to compute error bars/confidence intervals on a histogram?","style":{"bold":true}},{"type":"text","text":"\n\nBoth code and formulas are welcome!\nThank you, in advance,\nBest,\nIgnace"}]}]}],"thread_ts":"1611257001.008400","reply_count":9,"reply_users_count":5,"latest_reply":"1611626383.013700","reply_users":["UH8A351DJ","U019K6Q9N15","U01HC60USTH","U017JTQFNEQ","U6C937ENB"],"subscribed":false},{"client_msg_id":"4a6e9b41-66da-4b1f-9672-1b1e27a7db9e","type":"message","text":"I have two 2d kerneldensity estimates (with KernelDensity.jl). I’d like to get the difference between them plotted as a contour plot. Can I subtract two kde objects? The method for `-` doesn’t seem to be supported, but would it make sense, statistically, to implement it?","user":"U73KENNG4","ts":"1611916388.016600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1Ei","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have two 2d kerneldensity estimates (with KernelDensity.jl). I’d like to get the difference between them plotted as a contour plot. Can I subtract two kde objects? The method for "},{"type":"text","text":"-","style":{"code":true}},{"type":"text","text":" doesn’t seem to be supported, but would it make sense, statistically, to implement it?"}]}]}]},{"type":"message","text":"ggplot2 says: yes","files":[{"id":"F01KW2657PH","created":1611916644,"timestamp":1611916644,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U836PQXSN","editable":false,"size":34923,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01KW2657PH/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01KW2657PH/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01KW2657PH-4181c10af6/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01KW2657PH-4181c10af6/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01KW2657PH-4181c10af6/image_360.png","thumb_360_w":360,"thumb_360_h":360,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01KW2657PH-4181c10af6/image_160.png","original_w":400,"original_h":400,"thumb_tiny":"AwAwADDTPSmbjTj0plACPLtxnuaduNVbh/nwO1WFOVB9RTash6Eo5FFN3KoGTinUhDc53D0ptPI64qKRtkZNAFORsux96tQHMK/lVNRmrNof3bD0am5X0M43u33HTHEsVWAcjtUMsbNJGwHAqYDHc0rGmop6GqE8nmNtU/KO/rV/Gab5a/3R+VAFAD1p0DBJSCeGHX3q3tXdjZ+OKd5a/wB0flUqNim01awq9BS0DgUVRJ//2Q==","permalink":"https://julialang.slack.com/files/U836PQXSN/F01KW2657PH/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01KW2657PH-e84148cbcb","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"y6jE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ggplot2 says: yes"}]}]}],"user":"U836PQXSN","display_as_bot":false,"ts":"1611916663.016800"},{"client_msg_id":"233bad7c-4552-46bc-870e-13f10356e3ba","type":"message","text":"(these densities are stacked)","user":"U836PQXSN","ts":"1611916694.017500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FhQDR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(these densities are stacked)"}]}]}]},{"client_msg_id":"51fde6a9-45b6-4137-b493-7b8809c69bf2","type":"message","text":"So if you can add you can also subtract. That makes sense","user":"U73KENNG4","ts":"1611916785.017800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZeL7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So if you can add you can also subtract. That makes sense"}]}]}]},{"client_msg_id":"3976abee-a830-4043-9ea5-12939c61ee54","type":"message","text":"Well they're no longer densities at that point since they don't integrate to one","user":"U66M57AN4","ts":"1611929929.018800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"51i9i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Well they're no longer densities at that point since they don't integrate to one"}]}]}],"reactions":[{"name":"+1","users":["U73KENNG4"],"count":1}]},{"client_msg_id":"3767fc89-404c-4111-ad7a-0824e34de03e","type":"message","text":"My hunch is that a possibly more meaningful comparison is the ratio (subtract log-densities) but that might get wacky with KDE","user":"U66M57AN4","ts":"1611929970.019400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TJafv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My hunch is that a possibly more meaningful comparison is the ratio (subtract log-densities) but that might get wacky with KDE"}]}]}],"reactions":[{"name":"thinking_face","users":["U73KENNG4"],"count":1}]},{"client_msg_id":"6e0cc454-4d0f-4b72-b098-051db404f27e","type":"message","text":"(since the log-ratio is, e.g., what's averaged to compute the KL divergence between two distributions)","user":"U66M57AN4","ts":"1611930049.020300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"I0yf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(since the log-ratio is, e.g., what's averaged to compute the KL divergence between two distributions)"}]}]}]},{"client_msg_id":"c43aef7f-750f-4378-b077-f760c5c056fa","type":"message","text":"If you ensure that the bandwidth is the same, I guess the difference is a somewhat reasonable object: you are basically smoothing a generalized function which is a sum of delta functions multiplied by `± 1`.  If the bandwidths are different, you may end up seeing some artifacts due to smoothing.","user":"U6BJ9E351","ts":"1611935580.023000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vNKIQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you ensure that the bandwidth is the same, I guess the difference is a somewhat reasonable object: you are basically smoothing a generalized function which is a sum of delta functions multiplied by "},{"type":"text","text":"± 1","style":{"code":true}},{"type":"text","text":".  If the bandwidths are different, you may end up seeing some artifacts due to smoothing."}]}]}]},{"client_msg_id":"4c5cac48-ac95-4533-b47e-c5685a97c031","type":"message","text":"But the KDE object behaves pretty much like a `Distribution`, right, so you’d think that `+` was a convolution of the densities.","user":"U680T6770","ts":"1611937290.025100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zNBDy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But the KDE object behaves pretty much like a "},{"type":"text","text":"Distribution","style":{"code":true}},{"type":"text","text":", right, so you’d think that "},{"type":"text","text":"+","style":{"code":true}},{"type":"text","text":" was a convolution of the densities."}]}]}],"reactions":[{"name":"point_up","users":["U66M57AN4","U6A936746"],"count":2},{"name":"+1","users":["U73KENNG4"],"count":1}]},{"client_msg_id":"9571f25a-f503-45f0-aeee-dfd3bca33429","type":"message","text":"Although it's not the only interpretation for `+` on Distributions, e.g., I would interpret something like `0.5*Normal(0,1) + 0.5*Normal(1,2)` as a mixture of the two (and without the `0.5`, it would represent a bounded measure rather than a probability measure). One place where taking the difference of densities comes up is when computing the total variation distance between distributions, which is equal to the integral of | f(x)- g(x)|/2, where f,g, are the two densities.","user":"UKLKS1WC8","ts":"1611955422.029700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"morBG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Although it's not the only interpretation for "},{"type":"text","text":"+","style":{"code":true}},{"type":"text","text":" on Distributions, e.g., I would interpret something like "},{"type":"text","text":"0.5*Normal(0,1) + 0.5*Normal(1,2)","style":{"code":true}},{"type":"text","text":" as a mixture of the two (and without the "},{"type":"text","text":"0.5","style":{"code":true}},{"type":"text","text":", it would represent a bounded measure rather than a probability measure). One place where taking the difference of densities comes up is when computing the total variation distance between distributions, which is equal to the integral of | f(x)- g(x)|/2, where f,g, are the two densities."}]}]}]},{"type":"message","text":"","user":"U011V2YN59N","ts":"1611964826.029900","team":"T68168MUP","attachments":[{"fallback":"[January 29th, 2021 6:59 PM] pjentsch: Will I run into performance issues if I use a matrix of  different distributions? My understanding is that this will be an abstract typed matrix which will be slow. What is a better way to do this?","ts":"1611964770.152200","author_id":"U011V2YN59N","author_subname":"Peter J","channel_id":"C6A044SQH","channel_name":"helpdesk","is_msg_unfurl":true,"is_thread_root_unfurl":true,"text":"Will I run into performance issues if I use a matrix of  different distributions? My understanding is that this will be an abstract typed matrix which will be slow. What is a better way to do this?","author_name":"Peter J","author_link":"https://julialang.slack.com/team/U011V2YN59N","author_icon":"https://avatars.slack-edge.com/2020-04-22/1103390456848_2f885299664a3012f2e3_48.jpg","mrkdwn_in":["text"],"color":"D0D0D0","from_url":"https://julialang.slack.com/archives/C6A044SQH/p1611964770152200?thread_ts=1611964770152200&cid=C6A044SQH","is_share":true,"footer":"Thread in #helpdesk"}]},{"client_msg_id":"44cf31c3-7075-4f6b-87ba-c8830ce11bdb","type":"message","text":"&gt; which will be slow.\nWell, it will have dynamic dispatch but if it will be slow depends on the amount of work you do with each element.","user":"U67D54KS8","ts":"1612108828.030700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"f8p1z","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"which will be slow."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nWell, it will have dynamic dispatch but if it will be slow depends on the amount of work you do with each element."}]}]}],"reactions":[{"name":"+1","users":["U6A936746"],"count":1}]},{"client_msg_id":"c00cb055-7ef1-4853-9c61-5abcd0048c71","type":"message","text":"I have a basic version of a Minuit2 wrapper working. Minuit2 is a function minimization engine that is widely used in HEP. I don't have the resources to maintain the package, though. If you are interested in taking this over, please ping me.","user":"UDFRYRTBL","ts":"1612146322.033200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xPr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a basic version of a Minuit2 wrapper working. Minuit2 is a function minimization engine that is widely used in HEP. I don't have the resources to maintain the package, though. If you are interested in taking this over, please ping me."}]}]}]},{"type":"message","text":"<@U680T6770> <@U6BJ9E351> <@U66M57AN4> thanks for those comments. It sounds like what I’m after is not easily circumscribed exactly.\n\nTo be explicit my issue is this: I have the density of some variables (individual species plotted in a two-dimensional trait space after ordination) in two situations - before and after human disturbance of an island ecosystem. What I’m after is the difference - what areas of the trait space have become less occupied.","files":[{"id":"F01LVU1T1K3","created":1612170031,"timestamp":1612170031,"name":"kdes.png","title":"kdes.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U73KENNG4","editable":false,"size":51048,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01LVU1T1K3/kdes.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01LVU1T1K3/download/kdes.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_360.png","thumb_360_w":360,"thumb_360_h":144,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_480.png","thumb_480_w":480,"thumb_480_h":192,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_720.png","thumb_720_w":720,"thumb_720_h":288,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_800.png","thumb_800_w":800,"thumb_800_h":320,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_960.png","thumb_960_w":960,"thumb_960_h":384,"original_w":1000,"original_h":400,"thumb_tiny":"AwATADBt/NIlyQkjKMDgGq/2iYniV/8AvqpdR/4+z9BVdWKnI69qtbF9DWsnZ4Y9zEkgnJ+tVb+aVLoqkjKMDgGprE/LF/ut/Oq2of8AH2eOwpJakrch+0Tf89X/AO+q07J2eGPcxYkE5P1rJDbeR1rSsT8sQ/2W/nRJDkWXgidizxqxx1IpPssH/PJfyqU9/pR6/SpJGrEiEFVAwMDFNeCJ2LPGpOOpFS0h7/SgCL7LBz+6X8qesSIQVUDAwMU49/pS0Af/2Q==","permalink":"https://julialang.slack.com/files/U73KENNG4/F01LVU1T1K3/kdes.png","permalink_public":"https://slack-files.com/T68168MUP-F01LVU1T1K3-487b385fda","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"IKJ","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U680T6770"},{"type":"text","text":" "},{"type":"user","user_id":"U6BJ9E351"},{"type":"text","text":" "},{"type":"user","user_id":"U66M57AN4"},{"type":"text","text":" thanks for those comments. It sounds like what I’m after is not easily circumscribed exactly.\n\nTo be explicit my issue is this: I have the density of some variables (individual species plotted in a two-dimensional trait space after ordination) in two situations - before and after human disturbance of an island ecosystem. What I’m after is the difference - what areas of the trait space have become less occupied."}]}]}],"user":"U73KENNG4","display_as_bot":false,"ts":"1612170034.035800","thread_ts":"1612170034.035800","reply_count":3,"reply_users_count":2,"latest_reply":"1612260435.050100","reply_users":["UA3UH56HL","U73KENNG4"],"subscribed":false},{"client_msg_id":"a395d246-fddc-487c-a1ed-226a1f7e21f9","type":"message","text":"I’m wondering to what extend it’s useful to represent the thing here with a type. You could just define a closure like `t -&gt; kde1(t) - kde2(t)` and use that for plotting, right? Are there a broad range of functions that are meaningful on an object representing the difference between two densities?","user":"U680T6770","ts":"1612170667.038800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hFrN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m wondering to what extend it’s useful to represent the thing here with a type. You could just define a closure like "},{"type":"text","text":"t -> kde1(t) - kde2(t)","style":{"code":true}},{"type":"text","text":" and use that for plotting, right? Are there a broad range of functions that are meaningful on an object representing the difference between two densities?"}]}]}],"thread_ts":"1612170667.038800","reply_count":3,"reply_users_count":2,"latest_reply":"1612173934.040000","reply_users":["U73KENNG4","U680T6770"],"subscribed":false,"reactions":[{"name":"+1","users":["U73KENNG4","U66M57AN4"],"count":2}]},{"client_msg_id":"4b663cb8-77c6-438a-a0d2-cbc012260efd","type":"message","text":"Yes good question. It might just be a plotting-specific thing :thinking_face:","user":"U73KENNG4","ts":"1612170738.039300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jvl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes good question. It might just be a plotting-specific thing "},{"type":"emoji","name":"thinking_face"}]}]}]},{"client_msg_id":"ebd4225a-f846-46d4-9856-58eb86137e1e","type":"message","text":"I have collection of neural networks that i have trained on a cognitive task. The output, `y` is a probability of choosing right/left. I want to run a generalized-linear mixed model on some aspect of the activity of the network on it’s output (`y~X`) (basically doing “neuroscience” on the RNN). However, since `y` is a probability, `MixelModels.jl` doesn’t allow me to specify  `Bernoulli()` as the distribution. Other than “sampling” binary choices from the network, is there another way to fit this? In MATLAB `fitglm` is ok with this kind of data.","user":"U017JTQFNEQ","ts":"1612189925.045500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GN9W7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have collection of neural networks that i have trained on a cognitive task. The output, "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":" is a probability of choosing right/left. I want to run a generalized-linear mixed model on some aspect of the activity of the network on it’s output ("},{"type":"text","text":"y~X","style":{"code":true}},{"type":"text","text":") (basically doing “neuroscience” on the RNN). However, since "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":" is a probability, "},{"type":"text","text":"MixelModels.jl","style":{"code":true}},{"type":"text","text":" doesn’t allow me to specify  "},{"type":"text","text":"Bernoulli()","style":{"code":true}},{"type":"text","text":" as the distribution. Other than “sampling” binary choices from the network, is there another way to fit this? In MATLAB "},{"type":"text","text":"fitglm ","style":{"code":true}},{"type":"text","text":"is ok with this kind of data."}]}]}],"thread_ts":"1612189925.045500","reply_count":10,"reply_users_count":3,"latest_reply":"1612287739.050600","reply_users":["U67431ELR","U017JTQFNEQ","ULG5V164A"],"subscribed":false},{"client_msg_id":"5da8d43d-047e-480e-89f3-178a64b8f5b6","type":"message","text":"Perhaps <https://github.com/JuliaStats/GLM.jl|https://github.com/JuliaStats/GLM.jl>?","user":"UM30MT6RF","ts":"1612190095.045900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YI6e","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Perhaps "},{"type":"link","url":"https://github.com/JuliaStats/GLM.jl","text":"https://github.com/JuliaStats/GLM.jl"},{"type":"text","text":"?"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"DensityRatioEstimation.jl can be useful: <https://github.com/JuliaEarth/DensityRatioEstimation.jl> You can estimate this ratio function r(x,y) efficiently and highlight areas with r &lt; 1 for example.","user":"UA3UH56HL","ts":"1612199111.048100","thread_ts":"1612170034.035800","root":{"type":"message","text":"<@U680T6770> <@U6BJ9E351> <@U66M57AN4> thanks for those comments. It sounds like what I’m after is not easily circumscribed exactly.\n\nTo be explicit my issue is this: I have the density of some variables (individual species plotted in a two-dimensional trait space after ordination) in two situations - before and after human disturbance of an island ecosystem. What I’m after is the difference - what areas of the trait space have become less occupied.","files":[{"id":"F01LVU1T1K3","created":1612170031,"timestamp":1612170031,"name":"kdes.png","title":"kdes.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U73KENNG4","editable":false,"size":51048,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01LVU1T1K3/kdes.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01LVU1T1K3/download/kdes.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_360.png","thumb_360_w":360,"thumb_360_h":144,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_480.png","thumb_480_w":480,"thumb_480_h":192,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_720.png","thumb_720_w":720,"thumb_720_h":288,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_800.png","thumb_800_w":800,"thumb_800_h":320,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01LVU1T1K3-6729e4031d/kdes_960.png","thumb_960_w":960,"thumb_960_h":384,"original_w":1000,"original_h":400,"thumb_tiny":"AwATADBt/NIlyQkjKMDgGq/2iYniV/8AvqpdR/4+z9BVdWKnI69qtbF9DWsnZ4Y9zEkgnJ+tVb+aVLoqkjKMDgGprE/LF/ut/Oq2of8AH2eOwpJakrch+0Tf89X/AO+q07J2eGPcxYkE5P1rJDbeR1rSsT8sQ/2W/nRJDkWXgidizxqxx1IpPssH/PJfyqU9/pR6/SpJGrEiEFVAwMDFNeCJ2LPGpOOpFS0h7/SgCL7LBz+6X8qesSIQVUDAwMU49/pS0Af/2Q==","permalink":"https://julialang.slack.com/files/U73KENNG4/F01LVU1T1K3/kdes.png","permalink_public":"https://slack-files.com/T68168MUP-F01LVU1T1K3-487b385fda","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"IKJ","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U680T6770"},{"type":"text","text":" "},{"type":"user","user_id":"U6BJ9E351"},{"type":"text","text":" "},{"type":"user","user_id":"U66M57AN4"},{"type":"text","text":" thanks for those comments. It sounds like what I’m after is not easily circumscribed exactly.\n\nTo be explicit my issue is this: I have the density of some variables (individual species plotted in a two-dimensional trait space after ordination) in two situations - before and after human disturbance of an island ecosystem. What I’m after is the difference - what areas of the trait space have become less occupied."}]}]}],"user":"U73KENNG4","display_as_bot":false,"ts":"1612170034.035800","thread_ts":"1612170034.035800","reply_count":3,"reply_users_count":2,"latest_reply":"1612260435.050100","reply_users":["UA3UH56HL","U73KENNG4"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"Rry","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"DensityRatioEstimation.jl can be useful: "},{"type":"link","url":"https://github.com/JuliaEarth/DensityRatioEstimation.jl"},{"type":"text","text":" You can estimate this ratio function r(x,y) efficiently and highlight areas with r < 1 for example."}]}]}],"client_msg_id":"766e1630-f558-4939-b398-0d7dd5398d6e"},{"client_msg_id":"8a202d0b-ca03-4460-ab12-7fda7cd82618","type":"message","text":"<https://github.com/JuliaStats/StatsBase.jl/blob/462054536ee70a924887e5ea01a19fc76edf4e90/src/scalarstats.jl#L549>\n\nshould this line be:\n```scale = sum(x-&gt;x^\\alpha, p)```\n? also it doesn't consider if there's negative value? (the loop considered)","user":"UH8A351DJ","ts":"1612310128.051500","team":"T68168MUP","edited":{"user":"UH8A351DJ","ts":"1612310182.000000"},"blocks":[{"type":"rich_text","block_id":"bf0","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/JuliaStats/StatsBase.jl/blob/462054536ee70a924887e5ea01a19fc76edf4e90/src/scalarstats.jl#L549"},{"type":"text","text":"\n\nshould this line be:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"scale = sum(x->x^\\alpha, p)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"? also it doesn't consider if there's negative value? (the loop considered)"}]}]}],"thread_ts":"1612310128.051500","reply_count":5,"reply_users_count":2,"latest_reply":"1612375129.052600","reply_users":["U67431ELR","UH8A351DJ"],"subscribed":false},{"client_msg_id":"4d5070a3-4eb6-415a-b84e-5be18b8b3962","type":"message","text":"I have a vector of random values (particles from MonteCarloMeasurements actually). The random variable is not a Gaussian, although it has a single peak (like a triangle). How do I evaluate a confidence interval for that sort of random variable? (disclaimer: not a statistician)","user":"UB197FRCL","ts":"1612494783.054900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fdB8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a vector of random values (particles from MonteCarloMeasurements actually). The random variable is not a Gaussian, although it has a single peak (like a triangle). How do I evaluate a confidence interval for that sort of random variable? (disclaimer: not a statistician)"}]}]}],"thread_ts":"1612494783.054900","reply_count":1,"reply_users_count":1,"latest_reply":"1612494914.055000","reply_users":["UB197FRCL"],"subscribed":false},{"client_msg_id":"a830ab0d-1865-4bcd-8c46-cbff18b640fb","type":"message","text":"I am trying to plot the pdf of a distribution using `StatsPlots` but I can’t increase the thickness of the line. `linewidth` and `lw` don’t work. It seems `lw` should (<https://docs.juliaplots.org/latest/tutorial/#Using-a-Type-Recipe>). Can someone reproduce this?","user":"U85JBUGGP","ts":"1612713953.062800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SWNzV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am trying to plot the pdf of a distribution using "},{"type":"text","text":"StatsPlots","style":{"code":true}},{"type":"text","text":" but I can’t increase the thickness of the line. "},{"type":"text","text":"linewidth","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"lw","style":{"code":true}},{"type":"text","text":" don’t work. It seems "},{"type":"text","text":"lw","style":{"code":true}},{"type":"text","text":" should ("},{"type":"link","url":"https://docs.juliaplots.org/latest/tutorial/#Using-a-Type-Recipe"},{"type":"text","text":"). Can someone reproduce this?"}]}]}]},{"client_msg_id":"0c829f61-44b5-4199-bbe4-ffc37609d583","type":"message","text":"Probably wrong channel :sweat_smile: I will cross-post to <#C6E4SU1D3|plotting>","user":"U85JBUGGP","ts":"1612714088.063100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hg00E","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Probably wrong channel "},{"type":"emoji","name":"sweat_smile"},{"type":"text","text":" I will cross-post to "},{"type":"channel","channel_id":"C6E4SU1D3"}]}]}]},{"type":"message","text":"```using StatsPlots, Distributions; plot(Beta(40, 30), linewidth = 50)```\n","files":[{"id":"F01M6DLJWF7","created":1612719759,"timestamp":1612719759,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U7JQGPGCQ","editable":false,"size":15681,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01M6DLJWF7/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01M6DLJWF7/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01M6DLJWF7-db5663d65d/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01M6DLJWF7-db5663d65d/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01M6DLJWF7-db5663d65d/image_360.png","thumb_360_w":360,"thumb_360_h":234,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01M6DLJWF7-db5663d65d/image_480.png","thumb_480_w":480,"thumb_480_h":312,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01M6DLJWF7-db5663d65d/image_160.png","original_w":584,"original_h":379,"thumb_tiny":"AwAfADDSFLSCloAKz1kPnh8/xVekO2Nj6Cs/b+5Df7WK1pmVR7GlSY96FOVB9RS1kaiClqF/N3Yj2475pp+0j+5VWJcvIddNiE+/FRMn+hD86V4ppCN5GB6VPgNHtxwRiqvZIm3M2xtud0C+3FS1Vjjnjyqlce9SKZww37dvfFJrW9xxelmj/9k=","permalink":"https://julialang.slack.com/files/U7JQGPGCQ/F01M6DLJWF7/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01M6DLJWF7-ae9ab7c345","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"Ljz","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using StatsPlots, Distributions; plot(Beta(40, 30), linewidth = 50)"}]},{"type":"rich_text_section","elements":[]}]}],"user":"U7JQGPGCQ","display_as_bot":false,"ts":"1612719772.063900"},{"client_msg_id":"11e341ab-e04f-4e63-9ad2-becea15e1834","type":"message","text":"Hi,\n\nI'm just wondering if I have Group A (N=20) and group B (N=1), does it valid to do a statistical test, such as (independent) Wilcoxon rank sums or independent t-test?\n\nGiven that these tests works on class distribution, it seems that it wouldn't be correct to draw class distribution from only 1 sample. Any thoughts?\n\nThanks","user":"UUT4VGTE2","ts":"1612747178.066200","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1612747676.000000"},"blocks":[{"type":"rich_text","block_id":"Tj0AC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi,\n\nI'm just wondering if I have Group A (N=20) and group B (N=1), does it valid to do a statistical test, such as (independent) Wilcoxon rank sums or independent t-test?\n\nGiven that these tests works on class distribution, it seems that it wouldn't be correct to draw class distribution from only 1 sample. Any thoughts?\n\nThanks"}]}]}]},{"client_msg_id":"b227c908-d422-4bcf-93a8-89fb3ef8a76e","type":"message","text":"Any robust, mature forecasting libraries in Julia? Mainly looking for things like ARMA, ARIMA, bonus points for prophet","user":"U01FAHWCMFF","ts":"1612817471.069300","team":"T68168MUP","edited":{"user":"U01FAHWCMFF","ts":"1612817479.000000"},"blocks":[{"type":"rich_text","block_id":"7jp8b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any robust, mature forecasting libraries in Julia? Mainly looking for things like ARMA, ARIMA, bonus points for prophet"}]}]}]},{"client_msg_id":"c012e5e8-3538-4166-953c-ebe0ab739d7f","type":"message","text":"Hi all,\n \nI have found myself in need of the ability to sample from the Generalized Inverse Gaussian distribution. I noticed that this is not currently implemented in Distributions.jl, and that there was a (perhaps now dormant?) effort to implement it (pull request: <https://github.com/JuliaStats/Distributions.jl/pull/587>). In fact, it looks like maybe someone (some combination of <@UC4UZF1C2> and <@U7QLM6E2E> perhaps?) was successful (though perhaps lacking an implementation for the CDF) but a PR was never created (as far as I can tell), and the conversation seems to have ended inconclusively on the PR linked above. So my question is this: is this something that someone is actively working on? If not, I am interested in finishing (or re-implementing, if necessary) it and so am interested in hearing what challenges are left to be completed or if anyone has any advice on implementing this.","user":"U01LZHJUGGP","ts":"1612828252.070800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+=s","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all,\n \nI have found myself in need of the ability to sample from the Generalized Inverse Gaussian distribution. I noticed that this is not currently implemented in Distributions.jl, and that there was a (perhaps now dormant?) effort to implement it (pull request: "},{"type":"link","url":"https://github.com/JuliaStats/Distributions.jl/pull/587"},{"type":"text","text":"). In fact, it looks like maybe someone (some combination of "},{"type":"user","user_id":"UC4UZF1C2"},{"type":"text","text":" and "},{"type":"user","user_id":"U7QLM6E2E"},{"type":"text","text":" perhaps?) was successful (though perhaps lacking an implementation for the CDF) but a PR was never created (as far as I can tell), and the conversation seems to have ended inconclusively on the PR linked above. So my question is this: is this something that someone is actively working on? If not, I am interested in finishing (or re-implementing, if necessary) it and so am interested in hearing what challenges are left to be completed or if anyone has any advice on implementing this."}]}]}]},{"client_msg_id":"41561b7f-4b58-4436-873c-36f4aa505537","type":"message","text":"I've just noticed that `StatsBase.skewness` does not have a `dims` keyword. Is there a fundamental reason for this, or it simply wasn't implemented by anyone?","user":"U8J1KET6K","ts":"1612875471.074900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9FCy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've just noticed that "},{"type":"text","text":"StatsBase.skewness","style":{"code":true}},{"type":"text","text":" does not have a "},{"type":"text","text":"dims","style":{"code":true}},{"type":"text","text":" keyword. Is there a fundamental reason for this, or it simply wasn't implemented by anyone?"}]}]}]},{"client_msg_id":"ab352e9d-8269-4d4e-a2da-f5713394631f","type":"message","text":"The `density` function in StatsPlots, is there a way to designate how course I want the smoothing to be?","user":"UC6B1TT7B","ts":"1613046067.078900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zW4G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The "},{"type":"text","text":"density","style":{"code":true}},{"type":"text","text":" function in StatsPlots, is there a way to designate how course I want the smoothing to be?"}]}]}]},{"client_msg_id":"cea42725-25f4-4d1e-8632-780126de33f0","type":"message","text":"Does anyone know how `Statistics.quantile` treats `NaN` and why?\n```julia&gt; using StatsBase\njulia&gt; b = rand(20,20)\njulia&gt; b[3,3] = NaN\njulia&gt; quantile(vec(b), 0.5)\n0.5152183269708394\n\njulia&gt; quantile(b[isfinite.(b)], 0.5)\n0.5118644684150617```\nThe numbers differ - not really sure why?\n\nThe docs <https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.quantile> mysteriously say “An ArgumentError is thrown if v contains NaN or missing values.”","user":"U73KENNG4","ts":"1613114642.082600","team":"T68168MUP","edited":{"user":"U73KENNG4","ts":"1613115819.000000"},"blocks":[{"type":"rich_text","block_id":"C5/K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know how "},{"type":"text","text":"Statistics.quantile","style":{"code":true}},{"type":"text","text":" treats "},{"type":"text","text":"NaN","style":{"code":true}},{"type":"text","text":" and why?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> using StatsBase\njulia> b = rand(20,20)\njulia> b[3,3] = NaN\njulia> quantile(vec(b), 0.5)\n0.5152183269708394\n\njulia> quantile(b[isfinite.(b)], 0.5)\n0.5118644684150617"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"The numbers differ - not really sure why?\n\nThe docs "},{"type":"link","url":"https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.quantile"},{"type":"text","text":" mysteriously say “An ArgumentError is thrown if v contains NaN or missing values.”"}]}]}],"thread_ts":"1613114642.082600","reply_count":3,"reply_users_count":2,"latest_reply":"1613117608.083600","reply_users":["UHDQQ4GN6","U73KENNG4"],"subscribed":false},{"client_msg_id":"89a1079f-b02a-4e23-a3a6-194aa8b4c5e8","type":"message","text":"Hello; I'm a bit curious how active the maintainers of the Distributions.jl package tend to be around here.\n\nI'm sort of interested in sorting out an issue that exists in the package with truncated distributions that have parameters set such that there is 0 support, but I'm unsure who to talk with regarding it.\n\nAs an example of how wonky things can get in the current version of Distributions.jl:\n\n```julia&gt; d = Truncated(Gamma(1.0, 2.0), -5.0, -3.0)\nTruncated(Gamma{Float64}(α=1.0, θ=2.0), range=(-5.0, -3.0))\n\njulia&gt; maximum(d)\n-3.0\n\njulia&gt; minimum(d)\n0.0```\nThere's been a github issue (<https://github.com/JuliaStats/Distributions.jl/issues/843>) touching on this since 2019.\n\nThere are a couple possible ways to resolve this, so I'd like to first seek opinions from active maintainers of the package before embarking on a rather large pull request.\n\nThanks.","user":"U01MVLLU4PQ","ts":"1613327291.089200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2gx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello; I'm a bit curious how active the maintainers of the Distributions.jl package tend to be around here.\n\nI'm sort of interested in sorting out an issue that exists in the package with truncated distributions that have parameters set such that there is 0 support, but I'm unsure who to talk with regarding it.\n\nAs an example of how wonky things can get in the current version of Distributions.jl:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> d = Truncated(Gamma(1.0, 2.0), -5.0, -3.0)\nTruncated(Gamma{Float64}(α=1.0, θ=2.0), range=(-5.0, -3.0))\n\njulia> maximum(d)\n-3.0\n\njulia> minimum(d)\n0.0"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nThere's been a github issue ("},{"type":"link","url":"https://github.com/JuliaStats/Distributions.jl/issues/843"},{"type":"text","text":") touching on this since 2019.\n\nThere are a couple possible ways to resolve this, so I'd like to first seek opinions from active maintainers of the package before embarking on a rather large pull request.\n\nThanks."}]}]}]},{"client_msg_id":"baa40106-9a4e-4038-9ba0-6a2cef0e7180","type":"message","text":"You should do so in an issue.","user":"U6A936746","ts":"1613341945.089600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WW+sh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You should do so in an issue."}]}]}]},{"client_msg_id":"351ec3e9-b0c1-4110-a38a-49b98172a3c4","type":"message","text":"Slack is highly transient.","user":"U6A936746","ts":"1613341959.090100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cXc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Slack is highly transient."}]}]}]},{"client_msg_id":"799f7c25-cc6e-434f-b707-3ec705dd0ce5","type":"message","text":"A random question; can someone give me insight on why it might be controversial to call a point of a distribution with infinite density a \"mode\"? One such example might be Beta(0.5, 2). What are the potential problems that might arise with calling the mode of this distribution 0?","user":"U01MVLLU4PQ","ts":"1613361559.092200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gf1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"A random question; can someone give me insight on why it might be controversial to call a point of a distribution with infinite density a \"mode\"? One such example might be Beta(0.5, 2). What are the potential problems that might arise with calling the mode of this distribution 0?"}]}]}]},{"client_msg_id":"6b5ba65c-5924-4401-868a-ea44865f44a7","type":"message","text":"is there a package in julia similar to `equivalence`  in R? this package implements TOST hypothesis tests for equivalence.","user":"U011V2YN59N","ts":"1613365806.093700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LMg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a package in julia similar to "},{"type":"text","text":"equivalence","style":{"code":true}},{"type":"text","text":"  in R? this package implements TOST hypothesis tests for equivalence."}]}]}]},{"client_msg_id":"246af4df-d6f9-4a60-9e15-6ec39e542fdd","type":"message","text":"Hi :wave: Quick question on `lag` for `crosscor`...","user":"U8R9JE0D6","ts":"1613507260.095300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7mrP0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi "},{"type":"emoji","name":"wave"},{"type":"text","text":" Quick question on "},{"type":"text","text":"lag","style":{"code":true}},{"type":"text","text":" for "},{"type":"text","text":"crosscor","style":{"code":true}},{"type":"text","text":"..."}]}]}],"thread_ts":"1613507260.095300","reply_count":11,"reply_users_count":2,"latest_reply":"1613508675.097600","reply_users":["U8R9JE0D6","U7JQGPGCQ"],"subscribed":false},{"client_msg_id":"15089b96-efe0-439e-b850-13805492f895","type":"message","text":"Is it correct to say that being a whitening projection is a different condition on the projection matrix than simply being orthogonal?\nPCA’s projection matrix orthogonal, and PCA is a whitening projection.\nBut not all othogonal matrixes are whitening projections, are they?\n(both my test and my memory say they are not, but someone is diagreeing with me)","user":"U6A936746","ts":"1613661373.101700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dBF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it correct to say that being a whitening projection is a different condition on the projection matrix than simply being orthogonal?\nPCA’s projection matrix orthogonal, and PCA is a whitening projection.\nBut not all othogonal matrixes are whitening projections, are they?\n(both my test and my memory say they are not, but someone is diagreeing with me)"}]}]}]},{"client_msg_id":"66c9e56a-84f9-467d-a4b3-ecd686ec22ec","type":"message","text":"I have a StatsModels formula in a string and I want to parse it into a `FormulaTerm` . Is that possible?","user":"U01ARRMLM7E","ts":"1614026026.003200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Gao","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a StatsModels formula in a string and I want to parse it into a "},{"type":"text","text":"FormulaTerm","style":{"code":true}},{"type":"text","text":" . Is that possible?"}]}]}],"thread_ts":"1614026026.003200","reply_count":12,"reply_users_count":2,"latest_reply":"1614027582.005600","reply_users":["UBF9YRB6H","U01ARRMLM7E"],"subscribed":false},{"client_msg_id":"d348a9c6-f3fd-4587-8f90-348305ec8396","type":"message","text":"Two questions:\n• Does anyone know a Julia package for point processes? Is there a need for one?\n• Is there a Julia package more general than `Distributions.jl`, in which the sample can have an arbitrary type?\nContext: I’m trying to apply HMMs with point process emissions. I recoded some point processes and the Baum-Welch algorithm, but I would like to make my code available. I like the concept behind <https://github.com/maxmouchet/HMMBase.jl>, which contains distribution-independent inference and learning algorithms. Only problem is: `Distributions.jl`  only supports reals or arrays as sample types, and the observations in my case are point process histories","user":"U01GMP3HF9C","ts":"1614028542.008900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MxEbm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Two questions:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know a Julia package for point processes? Is there a need for one?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a Julia package more general than "},{"type":"text","text":"Distributions.jl","style":{"code":true}},{"type":"text","text":", in which the sample can have an arbitrary type?"}]}],"style":"bullet","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"Context: I’m trying to apply HMMs with point process emissions. I recoded some point processes and the Baum-Welch algorithm, but I would like to make my code available. I like the concept behind "},{"type":"link","url":"https://github.com/maxmouchet/HMMBase.jl"},{"type":"text","text":", which contains distribution-independent inference and learning algorithms. Only problem is: "},{"type":"text","text":"Distributions.jl","style":{"code":true}},{"type":"text","text":"  only supports reals or arrays as sample types, and the observations in my case are point process histories"}]}]}],"thread_ts":"1614028542.008900","reply_count":4,"reply_users_count":3,"latest_reply":"1614028961.009600","reply_users":["U01GMP3HF9C","U7THT3TM3","U7QLM6E2E"],"subscribed":false},{"client_msg_id":"697d26a0-b7ed-4df6-91e6-41a9529dcb9b","type":"message","text":"I'm curious... is there any reason why functions like `var` and `std` doesn't return result as `Float64` when the input data is `Float32`?\n```julia&gt; var(rand(Float32, 10))\n0.07476148f0```","user":"U8T0YV7QC","ts":"1614194069.025700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UlS3w","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm curious... is there any reason why functions like "},{"type":"text","text":"var","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"std","style":{"code":true}},{"type":"text","text":" doesn't return result as "},{"type":"text","text":"Float64","style":{"code":true}},{"type":"text","text":" when the input data is "},{"type":"text","text":"Float32","style":{"code":true}},{"type":"text","text":"?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> var(rand(Float32, 10))\n0.07476148f0"}]}]}],"thread_ts":"1614194069.025700","reply_count":4,"reply_users_count":2,"latest_reply":"1614194296.026400","reply_users":["UH8A351DJ","U8T0YV7QC"],"subscribed":false},{"client_msg_id":"92369eb5-1655-4928-9f7d-2837bb54d310","type":"message","text":"Naming question. What sounds better when a function returns sample variance - `sample_variance`  or `biased_variance` or something else?","user":"U8T0YV7QC","ts":"1614279805.032500","team":"T68168MUP","edited":{"user":"U8T0YV7QC","ts":"1614279814.000000"},"blocks":[{"type":"rich_text","block_id":"YR3j","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Naming question. What sounds better when a function returns sample variance - "},{"type":"text","text":"sample_variance","style":{"code":true}},{"type":"text","text":"  or "},{"type":"text","text":"biased_variance","style":{"code":true}},{"type":"text","text":" or something else?"}]}]}],"reactions":[{"name":"one","users":["U680THK2S"],"count":1}]},{"client_msg_id":"8dbb54b0-6389-468f-a009-c00142ef3f25","type":"message","text":"Does anyone know of/have an implementation of K-shape clustering in Julia? I didn't find one with a cursory search through Clustering.jl","user":"UNH0PT5D3","ts":"1614286329.036900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"M759","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know of/have an implementation of K-shape clustering in Julia? I didn't find one with a cursory search through Clustering.jl"}]}]}]},{"client_msg_id":"54c4d1dd-230b-4044-bbfb-24edd4b7398c","type":"message","text":"What is our idiom for the pointwise median say of a vector of vectors?","user":"U6C937ENB","ts":"1614327889.040500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dlo/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is our idiom for the pointwise median say of a vector of vectors?"}]}]}]},{"client_msg_id":"e19e4eeb-52ac-46f0-b91c-4d75f8ba73e7","type":"message","text":"Does anyone know what the term for a random sample(/w replacement) is when it is subject to the constraint that no 2 samples consecutively are identical. Or... the Autoregressive lag of 1 is not equal to the current value.","user":"UPUBAM63X","ts":"1614431220.042900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hx5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know what the term for a random sample(/w replacement) is when it is subject to the constraint that no 2 samples consecutively are identical. Or... the Autoregressive lag of 1 is not equal to the current value."}]}]}],"thread_ts":"1614431220.042900","reply_count":9,"reply_users_count":2,"latest_reply":"1614432079.044800","reply_users":["U6A936746","UPUBAM63X"],"subscribed":false},{"client_msg_id":"7e261298-de8b-4fd1-9918-d4b98da565da","type":"message","text":"How would you call a vector that is sparse/mostly black (most values are zero), but the non-zeros are close together/likely to be neighbours?","user":"U6C937ENB","ts":"1614602627.048700","team":"T68168MUP","edited":{"user":"U6C937ENB","ts":"1614602688.000000"},"blocks":[{"type":"rich_text","block_id":"51Hwt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How would you call a vector that is sparse/mostly black (most values are zero), but the non-zeros are close together/likely to be neighbours?"}]}]}]},{"type":"message","text":"Does anybody here knows the name of the distribution with this CDF?","files":[{"id":"F01PMNZ6J2J","created":1614682219,"timestamp":1614682219,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U680T6770","editable":false,"size":2019,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01PMNZ6J2J/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01PMNZ6J2J/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01PMNZ6J2J-59c7379a3d/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01PMNZ6J2J-59c7379a3d/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01PMNZ6J2J-59c7379a3d/image_360.png","thumb_360_w":184,"thumb_360_h":42,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01PMNZ6J2J-59c7379a3d/image_160.png","original_w":184,"original_h":42,"thumb_tiny":"AwAKADDR3fT86RWGTgjnnrT8D0poA3ngUAG44+UAn600M247hjpipKMUAMZhkZI6+tBfKnBHTsacwG08CgAYHAoA/9k=","permalink":"https://julialang.slack.com/files/U680T6770/F01PMNZ6J2J/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01PMNZ6J2J-38b8c85e4d","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"B9p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anybody here knows the name of the distribution with this CDF?"}]}]}],"user":"U680T6770","display_as_bot":false,"ts":"1614682284.055900"},{"client_msg_id":"4c7d205c-1e58-4281-add0-b81bb06a9164","type":"message","text":"Or possibly `t*exp(1-t)` for t in (0,1)","user":"U680T6770","ts":"1614682622.056800","team":"T68168MUP","edited":{"user":"U680T6770","ts":"1614682639.000000"},"blocks":[{"type":"rich_text","block_id":"j9uG8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Or possibly "},{"type":"text","text":"t*exp(1-t)","style":{"code":true}},{"type":"text","text":" for t in (0,1)"}]}]}]},{"client_msg_id":"c6fd6ef8-f6c7-480d-bb4c-a28ac2711d37","type":"message","text":"Is there a distribution in Distributions.jl that's discrete on `K` values according to fixed probabilities?","user":"UBF9YRB6H","ts":"1614735012.058600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fq3jx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a distribution in Distributions.jl that's discrete on "},{"type":"text","text":"K","style":{"code":true}},{"type":"text","text":" values according to fixed probabilities?"}]}]}],"thread_ts":"1614735012.058600","reply_count":6,"reply_users_count":2,"latest_reply":"1614736107.060600","reply_users":["U019K6Q9N15","UBF9YRB6H"],"subscribed":false},{"client_msg_id":"ce3995ba-59f0-4269-b270-2fa5a7f595b7","type":"message","text":"Is there a package for computing / visualizing conditional probabilities? It’s mostly for pedagogy, not for “real” work. Maybe something that would work with `BayesNets.jl` or `Turing.jl`","user":"U017JTQFNEQ","ts":"1614736203.061500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mAS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a package for computing / visualizing conditional probabilities? It’s mostly for pedagogy, not for “real” work. Maybe something that would work with "},{"type":"text","text":"BayesNets.jl","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"Turing.jl","style":{"code":true}}]}]}]},{"client_msg_id":"7B2691B6-E019-4A27-9CA0-D66C9B259F40","type":"message","text":"Is there an implementation for Rician distributions in Julia? Distributions.jl doesn't seem to have it, and a quick Google search didn't yield one","user":"U017AJ68PFZ","ts":"1614754027.065200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JFiA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there an implementation for Rician distributions in Julia? Distributions.jl doesn't seem to have it, and a quick Google search didn't yield one"}]}]}]},{"client_msg_id":"7c862fbe-6aa2-4a94-93f0-45f1b6c5e1d7","type":"message","text":"<https://towardsdatascience.com/cdsm-casual-inference-using-deep-bayesian-dynamic-survival-models-7d9f9ec7c989|https://towardsdatascience.com/cdsm-casual-inference-using-deep-bayesian-dynamic-survival-models-7d9f9ec7c989>","user":"UDGT4PM41","ts":"1614885392.068900","team":"T68168MUP","attachments":[{"service_name":"Medium","title":"CDSM — Casual Inference using Deep Bayesian Dynamic Survival Models","title_link":"https://towardsdatascience.com/cdsm-casual-inference-using-deep-bayesian-dynamic-survival-models-7d9f9ec7c989","text":"A causal Bayesian recurrent sub-networks to estimate the survival treatment effects.","fallback":"Medium: CDSM — Casual Inference using Deep Bayesian Dynamic Survival Models","image_url":"https://miro.medium.com/max/763/1*hRMDkQZO3zZoADAoQve4RQ.png","fields":[{"title":"Reading time","value":"7 min read","short":true}],"ts":1614820348,"from_url":"https://towardsdatascience.com/cdsm-casual-inference-using-deep-bayesian-dynamic-survival-models-7d9f9ec7c989","image_width":306,"image_height":250,"image_bytes":111860,"service_icon":"https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png","id":1,"original_url":"https://towardsdatascience.com/cdsm-casual-inference-using-deep-bayesian-dynamic-survival-models-7d9f9ec7c989"}],"blocks":[{"type":"rich_text","block_id":"WEgMI","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://towardsdatascience.com/cdsm-casual-inference-using-deep-bayesian-dynamic-survival-models-7d9f9ec7c989","text":"https://towardsdatascience.com/cdsm-casual-inference-using-deep-bayesian-dynamic-survival-models-7d9f9ec7c989"}]}]}]},{"client_msg_id":"1EC3024D-5D4E-441E-803A-E779E496E86A","type":"message","text":"Hey guys, I’m wondering about the assumption of &gt;2 classes tests such as Kruskal-Walis or ANOVA.\n\nDoes those tests assume independent groups, i.e. none of the groups dependent to another? The reason is that I want to compare 3 groups, but 2 of the groups are before and after (i.e. same participants, but observed before and after activity).\n\nIf so, is there any alternative for this?\n\nAnother question on hypothesis tests, in theory, should the &gt;groups tests be equivalent to multiple binary tests? E.g. ANOVA(group_a, group_b, group_c) == union(ttest(group_a, group_b), ttest(group_b, group_c), ttest(group_a, group_c)). \n\nAny help would be greatly appreciated!","user":"UUT4VGTE2","ts":"1614992319.072900","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1614994455.000000"},"blocks":[{"type":"rich_text","block_id":"VQWQT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey guys, I’m wondering about the assumption of >2 classes tests such as Kruskal-Walis or ANOVA.\n\nDoes those tests assume independent groups, i.e. none of the groups dependent to another? The reason is that I want to compare 3 groups, but 2 of the groups are before and after (i.e. same participants, but observed before and after activity).\n\nIf so, is there any alternative for this?\n\nAnother question on hypothesis tests, in theory, should the >groups tests be equivalent to multiple binary tests? E.g. ANOVA(group_a, group_b, group_c) == union(ttest(group_a, group_b), ttest(group_b, group_c), ttest(group_a, group_c)). \n\nAny help would be greatly appreciated!"}]}]}]},{"client_msg_id":"647db3a2-1f95-4afc-b28b-35bd8f7fdfc5","type":"message","text":"Hi guys, suppose I have this p-values taken from multiple binary tests.\n```Compared Groups | Variable | p-value\nG1vsG2          | var1     | 0.5\n                | var2     | 0.03\n                | var3     | 0.01\nG2vsG3          | var1     | 0.2\n                | var2     | 0.0232\n                | var3     | 0.0.15\nG1vsG3          | var1     | 0.005\n                | var2     | 0.06\n                | var3     | 0.8```\nI am just wondering how should I approach multiple tests correction here? Options:\n1. For each compared group, e.g. in G1vsG2 correction([p_val_var1_g1g2, p_val_var2_g1g2, p_val_var3_g1g2)\n2. For each variable, e.g. in var1 correction([p_val_var1_g1g2, p_val_var1_g2g3, p_val_var1_g1g3)\n3. Combine all those p-values and correct correction(all_p_values_list). I think this doesn't make sense since each variable will have multiple p-values and the correction can't distinguish which comes from the same variable but different tests, but I could be wrong.\nAny thoughts?","user":"UUT4VGTE2","ts":"1615251194.098200","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1615251275.000000"},"blocks":[{"type":"rich_text","block_id":"8Up","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys, suppose I have this p-values taken from multiple binary tests.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Compared Groups | Variable | p-value\nG1vsG2          | var1     | 0.5\n                | var2     | 0.03\n                | var3     | 0.01\nG2vsG3          | var1     | 0.2\n                | var2     | 0.0232\n                | var3     | 0.0.15\nG1vsG3          | var1     | 0.005\n                | var2     | 0.06\n                | var3     | 0.8"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I am just wondering how should I approach multiple tests correction here? Options:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For each compared group, e.g. in G1vsG2 correction([p_val_var1_g1g2, p_val_var2_g1g2, p_val_var3_g1g2)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"For each variable, e.g. in var1 correction([p_val_var1_g1g2, p_val_var1_g2g3, p_val_var1_g1g3)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Combine all those p-values and correct correction(all_p_values_list). I think this doesn't make sense since each variable will have multiple p-values and the correction can't distinguish which comes from the same variable but different tests, but I could be wrong."}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"Any thoughts?"}]}]}],"thread_ts":"1615251194.098200","reply_count":11,"reply_users_count":3,"latest_reply":"1615253502.101100","reply_users":["UBF9YRB6H","U01EF0QVAB0","UUT4VGTE2"],"subscribed":false},{"client_msg_id":"c47da9ba-196c-4df9-8d10-eeb2efe73529","type":"message","text":"I see there have been some reworks in GLM about confidence intervals, but I wanted to ask: did confidence intervals change for the vanilla linear model?","user":"U6BJ9E351","ts":"1615281578.111900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LZh5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I see there have been some reworks in GLM about confidence intervals, but I wanted to ask: did confidence intervals change for the vanilla linear model?"}]}]}],"thread_ts":"1615281578.111900","reply_count":4,"reply_users_count":2,"latest_reply":"1615281788.113900","reply_users":["U67431ELR","U6BJ9E351"],"subscribed":false},{"type":"message","subtype":"channel_join","ts":"1615367082.119500","user":"U01QB1S7C0P","text":"<@U01QB1S7C0P> has joined the channel","inviter":"U01JA0D7L56"},{"client_msg_id":"309afa8f-74ec-4bc2-9e62-cd30beb707e9","type":"message","text":"Would it be corrected to say that PCA trades covariance away in exchange for higher varience?","user":"U6A936746","ts":"1615405580.121600","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1615405583.000000"},"blocks":[{"type":"rich_text","block_id":"JGzl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Would it be corrected to say that PCA trades covariance away in exchange for higher varience?"}]}]}],"thread_ts":"1615405580.121600","reply_count":4,"reply_users_count":2,"latest_reply":"1615407564.122600","reply_users":["U6A936746","U017LQ3A59U"],"subscribed":false},{"client_msg_id":"7416f32a-0c69-4442-95da-56290b77a5e5","type":"message","text":"Does anyone know a good, short, entry-level introduction to why bayesian data analysis is cool suitable for undergrads?","user":"U73KENNG4","ts":"1615453889.123500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"58h","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know a good, short, entry-level introduction to why bayesian data analysis is cool suitable for undergrads?"}]}]}],"reactions":[{"name":"+1","users":["U7THT3TM3"],"count":1}]},{"client_msg_id":"409a4be9-6a59-4cb3-8877-27250ccaadf1","type":"message","text":"Any tips/resources on reporting bayesian stats to those who are only used to frequentist stats","user":"UCLGS1HML","ts":"1615476766.127200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"i9hgz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any tips/resources on reporting bayesian stats to those who are only used to frequentist stats"}]}]}]},{"client_msg_id":"16f51ceb-9ad0-4fae-a156-e574d6763382","type":"message","text":"Hey statistics experts,\n\nI what to draw how distribution of the average evolve and approaches gaussian in the central limit\nLet's say `X = Uniform` (or some other customary density)\nI would like to compute distribution of `y = (x1 + x2 + ... + xn) / n`  where `xi ~ X` or various n\n\nAny ideas? I have an analytic method that requires solving  `n-1`  integrals, or a brute-force pseudoexperiments, that is also not great if I want to look at the tails of `y`","user":"U01087W46CF","ts":"1615640439.136900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Em/Am","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey statistics experts,\n\nI what to draw how distribution of the average evolve and approaches gaussian in the central limit\nLet's say "},{"type":"text","text":"X = Uniform","style":{"code":true}},{"type":"text","text":" (or some other customary density)\nI would like to compute distribution of "},{"type":"text","text":"y = (x1 + x2 + ... + xn) / n","style":{"code":true}},{"type":"text","text":"  where "},{"type":"text","text":"xi ~ X","style":{"code":true}},{"type":"text","text":" or various n\n\nAny ideas? I have an analytic method that requires solving  "},{"type":"text","text":"n-1","style":{"code":true}},{"type":"text","text":"  integrals, or a brute-force pseudoexperiments, that is also not great if I want to look at the tails of "},{"type":"text","text":"y","style":{"code":true}}]}]}]},{"client_msg_id":"1e8e63f1-536f-4a02-a9e5-b4e96a7ded9c","type":"message","text":"Many thanks for many great ideas.\nNow more. I am interested in the far tail of the distribution of `y`. The integral of the tail will give me p-value.\nFrom which `n`, the `exp(-x^2)`  is a good approximation for the tail?\nAny method that would help me with the tail &gt; 5 sigma?","user":"U01087W46CF","ts":"1615753333.142300","team":"T68168MUP","edited":{"user":"U01087W46CF","ts":"1615753371.000000"},"blocks":[{"type":"rich_text","block_id":"aAw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Many thanks for many great ideas.\nNow more. I am interested in the far tail of the distribution of "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":". The integral of the tail will give me p-value.\nFrom which "},{"type":"text","text":"n","style":{"code":true}},{"type":"text","text":", the "},{"type":"text","text":"exp(-x^2)","style":{"code":true}},{"type":"text","text":"  is a good approximation for the tail?\nAny method that would help me with the tail > 5 sigma?"}]}]}]},{"client_msg_id":"1cce40ae-f293-4d76-827c-ca3a9a462c43","type":"message","text":"Hi guys, quick question on basic sequential forward selection. Does that algorithm stops when performance starts to drop? For instance, if I specify _k=5_ (5 features to look for) and by adding the 4th feature the performance (e.g. some metrics such as accuracy) drops, will it stop or move forward?","user":"UUT4VGTE2","ts":"1615866051.001500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H9H","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys, quick question on basic sequential forward selection. Does that algorithm stops when performance starts to drop? For instance, if I specify "},{"type":"text","text":"k=5","style":{"italic":true}},{"type":"text","text":" (5 features to look for) and by adding the 4th feature the performance (e.g. some metrics such as accuracy) drops, will it stop or move forward?"}]}]}]},{"client_msg_id":"8aa502fb-d26d-466a-b6be-4604e44c199b","type":"message","text":"Sorry this is not a julia question but an R question, but i don't know who else to ask and I couldn't find an answer by googling around.","user":"U69CM6160","ts":"1616362108.004000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"k7Go","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sorry this is not a julia question but an R question, but i don't know who else to ask and I couldn't find an answer by googling around."}]}]}],"thread_ts":"1616362108.004000","reply_count":2,"reply_users_count":1,"latest_reply":"1616362119.004300","reply_users":["U69CM6160"],"subscribed":false},{"client_msg_id":"5e090fc1-53f2-4956-b9ef-a5bc7e0aa3a6","type":"message","text":"Hi guys, is there any non-parametric version of ANCOVA?","user":"UUT4VGTE2","ts":"1616388812.004900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eeWC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys, is there any non-parametric version of ANCOVA?"}]}]}]},{"client_msg_id":"819e47a6-5adc-4b1f-907b-c84b4e18137a","type":"message","text":"Do we have a package for Principal Analysis by Conditional Expectation (PACE)?","user":"U6A936746","ts":"1616413728.005300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/7phj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Do we have a package for Principal Analysis by Conditional Expectation (PACE)?"}]}]}]},{"client_msg_id":"c52312c4-de85-4a60-8169-af711079ca37","type":"message","text":"I don’t entirely get what PACE is, it feels some how related to AppoxFun.jl?","user":"U6A936746","ts":"1616413788.005900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZPvWD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don’t entirely get what PACE is, it feels some how related to AppoxFun.jl?"}]}]}]},{"client_msg_id":"05fc38be-ac85-4bb7-9523-ecd022e1d03e","type":"message","text":"Matlab package <http://www.stat.ucdavis.edu/PACE/>\nR package <https://cran.r-project.org/web/packages/fdapace/vignettes/fdapaceVig.html>","user":"U6A936746","ts":"1616413854.006400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HCGdf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Matlab package "},{"type":"link","url":"http://www.stat.ucdavis.edu/PACE/"},{"type":"text","text":"\nR package "},{"type":"link","url":"https://cran.r-project.org/web/packages/fdapace/vignettes/fdapaceVig.html"}]}]}]},{"client_msg_id":"d48522fe-1959-4d58-98a4-d5bebadb5505","type":"message","text":"Maybe: <https://elasticfdajl.readthedocs.io/en/latest/index.html>?","user":"U6A936746","ts":"1616415197.006700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4KaN3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe: "},{"type":"link","url":"https://elasticfdajl.readthedocs.io/en/latest/index.html"},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"b841c344-a2dd-4df8-95d8-086656d3da4d","type":"message","text":"I've never used PACE but elastic FDA is about performing curve registration together with normal functional statistical analysis. So it looks different.","user":"U9AHT3YM7","ts":"1616416730.007800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"duP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've never used PACE but elastic FDA is about performing curve registration together with normal functional statistical analysis. So it looks different."}]}]}]},{"client_msg_id":"60c46d30-0ea1-499d-8ce0-240b91b92635","type":"message","text":"Hey folks! Pumas-AI is holding a webinar tomorrow on non-Gaussian nonlinear mixed effects models in Pumas presented by none other than <@U680T6770>. Feel free to join <https://form.jotform.com/210666635657161>. If you have further ideas after the talk in the same space, feel free to come and talk to either Andreas, me or <@UAVMYR0F4>.","user":"U85JBUGGP","ts":"1616417255.011000","team":"T68168MUP","edited":{"user":"U85JBUGGP","ts":"1616417305.000000"},"attachments":[{"title":"PUMAS 2.0 FEATURE SERIES: First order methods for non-Gaussian NLME models in Pumas","title_link":"https://form.jotform.com/210666635657161","text":"Please click the link to complete this form.","fallback":"PUMAS 2.0 FEATURE SERIES: First order methods for non-Gaussian NLME models in Pumas","from_url":"https://form.jotform.com/210666635657161","service_icon":"https://cdn.jotfor.ms/favicon.ico","service_name":"form.jotform.com","id":1,"original_url":"https://form.jotform.com/210666635657161"}],"blocks":[{"type":"rich_text","block_id":"dCjW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey folks! Pumas-AI is holding a webinar tomorrow on non-Gaussian nonlinear mixed effects models in Pumas presented by none other than "},{"type":"user","user_id":"U680T6770"},{"type":"text","text":". Feel free to join "},{"type":"link","url":"https://form.jotform.com/210666635657161"},{"type":"text","text":". If you have further ideas after the talk in the same space, feel free to come and talk to either Andreas, me or "},{"type":"user","user_id":"UAVMYR0F4"},{"type":"text","text":"."}]}]}],"reactions":[{"name":"+1","users":["U82LX4ACB"],"count":1}]},{"client_msg_id":"e23f5e36-b044-4674-a91b-54b71666b978","type":"message","text":"Is there still no way to fit a GAM in Julia? Need something like R's  `mgcv`. Wondering if anybody is working on it, would consider even implementing it myself, but the statistical theory of mgcv GAMs is quite beyond me. Even just splines would be fine for now, but I don't know what Julia package offers splines to use in glm() like s() in R splines","user":"U01EF0QVAB0","ts":"1616537377.014600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vwZzs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there still no way to fit a GAM in Julia? Need something like R's  "},{"type":"text","text":"mgcv","style":{"code":true}},{"type":"text","text":". Wondering if anybody is working on it, would consider even implementing it myself, but the statistical theory of mgcv GAMs is quite beyond me. Even just splines would be fine for now, but I don't know what Julia package offers splines to use in glm() like s() in R splines"}]}]}]},{"client_msg_id":"e05d5d8f-8424-40b7-ba61-525fa31870a2","type":"message","text":"Hi guys,\n\nI am doing a Kruskal-wallis test and am wondering which post-hoc analysis is the most suitable for this? Been reading around and saw people recommend Dunn test. I am just wondering if there is any specific reason to not choosing something like Wilcoxon as they both non-parametric?\n\nThanks!","user":"UUT4VGTE2","ts":"1616564057.017600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6Agt0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys,\n\nI am doing a Kruskal-wallis test and am wondering which post-hoc analysis is the most suitable for this? Been reading around and saw people recommend Dunn test. I am just wondering if there is any specific reason to not choosing something like Wilcoxon as they both non-parametric?\n\nThanks!"}]}]}]},{"client_msg_id":"2550201f-9348-4bea-998c-0609040c2d8d","type":"message","text":"I have a bit of an audit sampling conundrum, which isn't really my area of expertise, but one of those problems where I think I should definitely be a Bayesian so maybe someone here has ideas or pointers. I have a population of (let's say) 100,000 invoices, and want to answer the standard audit question \"which fraction of these invoices is incorrect\", for which a sample has to be audited. Now the standard approach would (probably) be to just specify some prior Beta distribution with \"success\" denoting an error found, and then work out how many samples I need (assuming a certain chance of drawing a success on each draw) to get to a posterior that gives the required confidence interval.\n\nNow the twist is that I have a small (let's say 5%) subpopulation for which I know that the error rate is higher, and I wonder how (if at all) I should incorporate this knowledge:\n\n* Just ignore it, the higher expected error rate in the subpopulation changes my expected whole population error rate and so the info is already in the sample calculation above;\n* Treat them as two separate populations, which would likely lead to a higher overall sample size (as the whole population error rate is close to zero, removing the subpopulation will not really decrease the required sample size there, but a relatively large sample size will be required for the more volatile subpopulation)\n* Something in between (I hear a lot about \"pooling\" estimators in Bayesian analysis, but it's one of these things I've never really got my traditional-econometrics-trained head around\n\nI could imagine amending point (2) above in some way to basically calculate the sample size with reference to the whole population posterior, i.e. taking into account that the posterior for the subpopulation will be much less important when estimating the population posterior (which I guess would be a mixture of the two posteriors, weighted by the whole population share of both subpopulations?)\n\nIf anyone has any ideas on how to conceptually best approach this I'd be most grateful!","user":"U7JQGPGCQ","ts":"1616583154.028200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5T3/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a bit of an audit sampling conundrum, which isn't really my area of expertise, but one of those problems where I think I should definitely be a Bayesian so maybe someone here has ideas or pointers. I have a population of (let's say) 100,000 invoices, and want to answer the standard audit question \"which fraction of these invoices is incorrect\", for which a sample has to be audited. Now the standard approach would (probably) be to just specify some prior Beta distribution with \"success\" denoting an error found, and then work out how many samples I need (assuming a certain chance of drawing a success on each draw) to get to a posterior that gives the required confidence interval.\n\nNow the twist is that I have a small (let's say 5%) subpopulation for which I know that the error rate is higher, and I wonder how (if at all) I should incorporate this knowledge:\n\n* Just ignore it, the higher expected error rate in the subpopulation changes my expected whole population error rate and so the info is already in the sample calculation above;\n* Treat them as two separate populations, which would likely lead to a higher overall sample size (as the whole population error rate is close to zero, removing the subpopulation will not really decrease the required sample size there, but a relatively large sample size will be required for the more volatile subpopulation)\n* Something in between (I hear a lot about \"pooling\" estimators in Bayesian analysis, but it's one of these things I've never really got my traditional-econometrics-trained head around\n\nI could imagine amending point (2) above in some way to basically calculate the sample size with reference to the whole population posterior, i.e. taking into account that the posterior for the subpopulation will be much less important when estimating the population posterior (which I guess would be a mixture of the two posteriors, weighted by the whole population share of both subpopulations?)\n\nIf anyone has any ideas on how to conceptually best approach this I'd be most grateful!"}]}]}],"thread_ts":"1616583154.028200","reply_count":3,"reply_users_count":1,"latest_reply":"1616584262.028900","reply_users":["U6C937ENB"],"is_locked":false,"subscribed":false},{"client_msg_id":"42b9a554-f6be-4886-9552-fb6784bed046","type":"message","text":"I have a basic stats question. So I am comparing a patient with a condition to the population of healthy. Due to only have 1 observation/patient, I am looking into the z-score, i.e. calculating that patient z-score based on healthy stats, to check how much it deviates to healthy central tendency and how significant it is (by converting it to p-value).\n\nMy questions:\n1. Can this approach be called a 'one-sample z-test'? I have been reading around and most of the example I found, the 'one-sample' refers to another sample population, not 1 observation.\n2. My follow-up question would be, is it valid to do multiple comparison correction, such as Bonferroni-Holm on top of this analysis?\nI have been browsing about this but could not find any information for this specific question. Any help would be greatly appreciated!","user":"UUT4VGTE2","ts":"1616730322.036500","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1616730379.000000"},"blocks":[{"type":"rich_text","block_id":"DRZ2X","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a basic stats question. So I am comparing a patient with a condition to the population of healthy. Due to only have 1 observation/patient, I am looking into the z-score, i.e. calculating that patient z-score based on healthy stats, to check how much it deviates to healthy central tendency and how significant it is (by converting it to p-value).\n\nMy questions:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can this approach be called a 'one-sample z-test'? I have been reading around and most of the example I found, the 'one-sample' refers to another sample population, not 1 observation."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"My follow-up question would be, is it valid to do multiple comparison correction, such as Bonferroni-Holm on top of this analysis?"}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"\nI have been browsing about this but could not find any information for this specific question. Any help would be greatly appreciated!"}]}]}]},{"client_msg_id":"040015ca-ab26-4833-8eaa-0a48e839acad","type":"message","text":"I have a question which is kind of a signal processing question. But I'm asking here because I know nothing about signal processing.\n\nLet's say you have a sequence of ones and zeros. You think that every third entry in the sequence should be a one, and the rest zeros. You want to know if your observed sequence matches that pattern.\n\nBut there is some noise, and sometimes you get two ones in a row or three zeros in a row. But the sequence should \"start back up again\" after that error. So you can't just say \"conditional on  `mod(obsnum, 3) == 0`, what is the probability of a `1`? Because if there is an errant `1` early in the sequence, your `mod(obsnum, 3)` rule is broken later on.\n\nIs there some sort of statistic that allows me to say \"on average, this one-third rule holds\"?","user":"UBF9YRB6H","ts":"1616783573.045100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/WLBX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a question which is kind of a signal processing question. But I'm asking here because I know nothing about signal processing.\n\nLet's say you have a sequence of ones and zeros. You think that every third entry in the sequence should be a one, and the rest zeros. You want to know if your observed sequence matches that pattern.\n\nBut there is some noise, and sometimes you get two ones in a row or three zeros in a row. But the sequence should \"start back up again\" after that error. So you can't just say \"conditional on  "},{"type":"text","text":"mod(obsnum, 3) == 0","style":{"code":true}},{"type":"text","text":", what is the probability of a "},{"type":"text","text":"1","style":{"code":true}},{"type":"text","text":"? Because if there is an errant "},{"type":"text","text":"1","style":{"code":true}},{"type":"text","text":" early in the sequence, your "},{"type":"text","text":"mod(obsnum, 3)","style":{"code":true}},{"type":"text","text":" rule is broken later on.\n\nIs there some sort of statistic that allows me to say \"on average, this one-third rule holds\"?"}]}]}],"thread_ts":"1616783573.045100","reply_count":1,"reply_users_count":1,"latest_reply":"1616783626.045200","reply_users":["UBF9YRB6H"],"is_locked":false,"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"Really, just. What should I google to find information on this?","user":"UBF9YRB6H","ts":"1616783626.045200","thread_ts":"1616783573.045100","root":{"client_msg_id":"040015ca-ab26-4833-8eaa-0a48e839acad","type":"message","text":"I have a question which is kind of a signal processing question. But I'm asking here because I know nothing about signal processing.\n\nLet's say you have a sequence of ones and zeros. You think that every third entry in the sequence should be a one, and the rest zeros. You want to know if your observed sequence matches that pattern.\n\nBut there is some noise, and sometimes you get two ones in a row or three zeros in a row. But the sequence should \"start back up again\" after that error. So you can't just say \"conditional on  `mod(obsnum, 3) == 0`, what is the probability of a `1`? Because if there is an errant `1` early in the sequence, your `mod(obsnum, 3)` rule is broken later on.\n\nIs there some sort of statistic that allows me to say \"on average, this one-third rule holds\"?","user":"UBF9YRB6H","ts":"1616783573.045100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/WLBX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a question which is kind of a signal processing question. But I'm asking here because I know nothing about signal processing.\n\nLet's say you have a sequence of ones and zeros. You think that every third entry in the sequence should be a one, and the rest zeros. You want to know if your observed sequence matches that pattern.\n\nBut there is some noise, and sometimes you get two ones in a row or three zeros in a row. But the sequence should \"start back up again\" after that error. So you can't just say \"conditional on  "},{"type":"text","text":"mod(obsnum, 3) == 0","style":{"code":true}},{"type":"text","text":", what is the probability of a "},{"type":"text","text":"1","style":{"code":true}},{"type":"text","text":"? Because if there is an errant "},{"type":"text","text":"1","style":{"code":true}},{"type":"text","text":" early in the sequence, your "},{"type":"text","text":"mod(obsnum, 3)","style":{"code":true}},{"type":"text","text":" rule is broken later on.\n\nIs there some sort of statistic that allows me to say \"on average, this one-third rule holds\"?"}]}]}],"thread_ts":"1616783573.045100","reply_count":1,"reply_users_count":1,"latest_reply":"1616783626.045200","reply_users":["UBF9YRB6H"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"OZ3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Really, just. What should I google to find information on this?"}]}]}],"client_msg_id":"9b3c258b-3c5d-4140-a1fb-f349de808079"},{"client_msg_id":"2054963e-9969-4171-b8c6-ba3c72a8c892","type":"message","text":"I really wish we could have these amazing stats help conversations anywhere but on slack hole. I always try to read these but knows I'll forget if/ when I need these amazing advice. It's such a shame your advice will die a lonely death here.","user":"U7PGB5DU3","ts":"1616831616.059600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jMNY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I really wish we could have these amazing stats help conversations anywhere but on slack hole. I always try to read these but knows I'll forget if/ when I need these amazing advice. It's such a shame your advice will die a lonely death here."}]}]}],"reactions":[{"name":"+1","users":["ULMSM9MAL"],"count":1}]},{"type":"message","subtype":"thread_broadcast","text":"This can get you started <https://discourse.julialang.org/t/how-to-simulate-a-random-signal-sequence-change/47964|https://discourse.julialang.org/t/how-to-simulate-a-random-signal-sequence-change/47964>","user":"U6C937ENB","ts":"1616836013.060100","thread_ts":"1616783573.045100","root":{"client_msg_id":"040015ca-ab26-4833-8eaa-0a48e839acad","type":"message","text":"I have a question which is kind of a signal processing question. But I'm asking here because I know nothing about signal processing.\n\nLet's say you have a sequence of ones and zeros. You think that every third entry in the sequence should be a one, and the rest zeros. You want to know if your observed sequence matches that pattern.\n\nBut there is some noise, and sometimes you get two ones in a row or three zeros in a row. But the sequence should \"start back up again\" after that error. So you can't just say \"conditional on  `mod(obsnum, 3) == 0`, what is the probability of a `1`? Because if there is an errant `1` early in the sequence, your `mod(obsnum, 3)` rule is broken later on.\n\nIs there some sort of statistic that allows me to say \"on average, this one-third rule holds\"?","user":"UBF9YRB6H","ts":"1616783573.045100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/WLBX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a question which is kind of a signal processing question. But I'm asking here because I know nothing about signal processing.\n\nLet's say you have a sequence of ones and zeros. You think that every third entry in the sequence should be a one, and the rest zeros. You want to know if your observed sequence matches that pattern.\n\nBut there is some noise, and sometimes you get two ones in a row or three zeros in a row. But the sequence should \"start back up again\" after that error. So you can't just say \"conditional on  "},{"type":"text","text":"mod(obsnum, 3) == 0","style":{"code":true}},{"type":"text","text":", what is the probability of a "},{"type":"text","text":"1","style":{"code":true}},{"type":"text","text":"? Because if there is an errant "},{"type":"text","text":"1","style":{"code":true}},{"type":"text","text":" early in the sequence, your "},{"type":"text","text":"mod(obsnum, 3)","style":{"code":true}},{"type":"text","text":" rule is broken later on.\n\nIs there some sort of statistic that allows me to say \"on average, this one-third rule holds\"?"}]}]}],"thread_ts":"1616783573.045100","reply_count":27,"reply_users_count":5,"latest_reply":"1616836013.060100","reply_users":["UBF9YRB6H","U8JAMQGQY","U66M57AN4","U6A936746","U6C937ENB"],"is_locked":false,"subscribed":false},"attachments":[{"service_name":"JuliaLang","title":"How to simulate a random signal sequence change","title_link":"https://discourse.julialang.org/t/how-to-simulate-a-random-signal-sequence-change/47964","text":"I have got a simple problem to calculate Posterior after some signal disturbances. Say the input signal is a sequence of 0 and 1 with 70% of chance is 1. And somehow we know that after the transmission, the output have 0 an 1 of equal chance. I want to calculate what the probability when we get 1 in output and it is truly 1 in the input. I write the following code to implement the simulation. I want to randomly set seeds and see what happened to my simulation. using Random, StatsBase k = rand...","fallback":"JuliaLang: How to simulate a random signal sequence change","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","fields":[{"title":"Reading time","value":"1 mins :clock2:","short":true},{"title":"Likes","value":"2 :heart:","short":true}],"ts":1602128529,"from_url":"https://discourse.julialang.org/t/how-to-simulate-a-random-signal-sequence-change/47964","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/how-to-simulate-a-random-signal-sequence-change/47964"}],"blocks":[{"type":"rich_text","block_id":"FKd1j","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This can get you started "},{"type":"link","url":"https://discourse.julialang.org/t/how-to-simulate-a-random-signal-sequence-change/47964","text":"https://discourse.julialang.org/t/how-to-simulate-a-random-signal-sequence-change/47964"}]}]}],"client_msg_id":"FCA3B761-E2CA-4827-8A4D-743FE0BB7E66","edited":{"user":"U6C937ENB","ts":"1616836025.000000"}},{"type":"message","subtype":"thread_broadcast","text":"I posted on StackExchange too!\n\n<https://dsp.stackexchange.com/questions/74078/hypothesis-testing-with-binary-pattern>\n\nIt's a surprisingly interesting question. I didn't realize that in signal processing, noise comes in the form of flipped bits, not added ones and zeros. So heuristics from those problems don't apply easily.","user":"UBF9YRB6H","ts":"1616859556.079700","thread_ts":"1616831616.059600","root":{"client_msg_id":"2054963e-9969-4171-b8c6-ba3c72a8c892","type":"message","text":"I really wish we could have these amazing stats help conversations anywhere but on slack hole. I always try to read these but knows I'll forget if/ when I need these amazing advice. It's such a shame your advice will die a lonely death here.","user":"U7PGB5DU3","ts":"1616831616.059600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jMNY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I really wish we could have these amazing stats help conversations anywhere but on slack hole. I always try to read these but knows I'll forget if/ when I need these amazing advice. It's such a shame your advice will die a lonely death here."}]}]}],"thread_ts":"1616831616.059600","reply_count":1,"reply_users_count":1,"latest_reply":"1616859556.079700","reply_users":["UBF9YRB6H"],"is_locked":false,"subscribed":false},"attachments":[{"service_name":"Signal Processing Stack Exchange","title":"Hypothesis testing with binary pattern","title_link":"https://dsp.stackexchange.com/questions/74078/hypothesis-testing-with-binary-pattern","text":"Let's say you have a sequence $\\{x_i\\}_{i = 1}^N$ of ones and zeros. You know that $P(x_i = 1) = \\frac{1}{3}$. You want to test two hypotheses $H_0$: The sequence is $iid$ with $P(x_i = 1) \\ \\foral...","fallback":"Signal Processing Stack Exchange: Hypothesis testing with binary pattern","thumb_url":"https://cdn.sstatic.net/Sites/dsp/Img/apple-touch-icon@2.png?v=e0439310c223","from_url":"https://dsp.stackexchange.com/questions/74078/hypothesis-testing-with-binary-pattern","thumb_width":316,"thumb_height":316,"service_icon":"https://cdn.sstatic.net/Sites/dsp/Img/apple-touch-icon.png?v=966f090a2019","id":1,"original_url":"https://dsp.stackexchange.com/questions/74078/hypothesis-testing-with-binary-pattern"}],"blocks":[{"type":"rich_text","block_id":"yUX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I posted on StackExchange too!\n\n"},{"type":"link","url":"https://dsp.stackexchange.com/questions/74078/hypothesis-testing-with-binary-pattern"},{"type":"text","text":"\n\nIt's a surprisingly interesting question. I didn't realize that in signal processing, noise comes in the form of flipped bits, not added ones and zeros. So heuristics from those problems don't apply easily."}]}]}],"client_msg_id":"4ef60561-6317-4393-b7b5-d8e2f8e6f480"},{"type":"message","text":"<@UBF9YRB6H> I implemented  a rather complete solution because I want to add discrete models like this to <https://github.com/mschauer/Mitosis.jl> and this is a good start… sorry, that’s perhaps more than you asked for ;-)\n\n<https://gist.github.com/mschauer/db187e9a3822e45740801ff1bc1b056c>","files":[{"id":"F01T0E3SU8H","created":1616926874,"timestamp":1616926874,"name":"hidden.png","title":"hidden.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U6C937ENB","editable":false,"size":203329,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01T0E3SU8H/hidden.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01T0E3SU8H/download/hidden.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01T0E3SU8H-26c968ae71/hidden_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01T0E3SU8H-26c968ae71/hidden_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01T0E3SU8H-26c968ae71/hidden_360.png","thumb_360_w":360,"thumb_360_h":180,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01T0E3SU8H-26c968ae71/hidden_480.png","thumb_480_w":480,"thumb_480_h":240,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01T0E3SU8H-26c968ae71/hidden_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01T0E3SU8H-26c968ae71/hidden_720.png","thumb_720_w":720,"thumb_720_h":360,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01T0E3SU8H-26c968ae71/hidden_800.png","thumb_800_w":800,"thumb_800_h":400,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01T0E3SU8H-26c968ae71/hidden_960.png","thumb_960_w":960,"thumb_960_h":480,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01T0E3SU8H-26c968ae71/hidden_1024.png","thumb_1024_w":1024,"thumb_1024_h":512,"original_w":1600,"original_h":800,"thumb_tiny":"AwAYADDSoo+lFABRnjiige9ABRRRQAjb8fKFz70397/dT8zUlFAEf730T8zR+99E/M1JRQBH+9/up+ZpV35+YLj2p9FAH//Z","permalink":"https://julialang.slack.com/files/U6C937ENB/F01T0E3SU8H/hidden.png","permalink_public":"https://slack-files.com/T68168MUP-F01T0E3SU8H-2a3d177398","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"X28W","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UBF9YRB6H"},{"type":"text","text":" I implemented  a rather complete solution because I want to add discrete models like this to "},{"type":"link","url":"https://github.com/mschauer/Mitosis.jl"},{"type":"text","text":" and this is a good start… sorry, that’s perhaps more than you asked for ;-)\n\n"},{"type":"link","url":"https://gist.github.com/mschauer/db187e9a3822e45740801ff1bc1b056c"}]}]}],"user":"U6C937ENB","display_as_bot":false,"ts":"1616926879.082200","thread_ts":"1616783573.045100","parent_user_id":"UBF9YRB6H","subtype":"thread_broadcast","root":{"client_msg_id":"040015ca-ab26-4833-8eaa-0a48e839acad","type":"message","text":"I have a question which is kind of a signal processing question. But I'm asking here because I know nothing about signal processing.\n\nLet's say you have a sequence of ones and zeros. You think that every third entry in the sequence should be a one, and the rest zeros. You want to know if your observed sequence matches that pattern.\n\nBut there is some noise, and sometimes you get two ones in a row or three zeros in a row. But the sequence should \"start back up again\" after that error. So you can't just say \"conditional on  `mod(obsnum, 3) == 0`, what is the probability of a `1`? Because if there is an errant `1` early in the sequence, your `mod(obsnum, 3)` rule is broken later on.\n\nIs there some sort of statistic that allows me to say \"on average, this one-third rule holds\"?","user":"UBF9YRB6H","ts":"1616783573.045100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/WLBX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a question which is kind of a signal processing question. But I'm asking here because I know nothing about signal processing.\n\nLet's say you have a sequence of ones and zeros. You think that every third entry in the sequence should be a one, and the rest zeros. You want to know if your observed sequence matches that pattern.\n\nBut there is some noise, and sometimes you get two ones in a row or three zeros in a row. But the sequence should \"start back up again\" after that error. So you can't just say \"conditional on  "},{"type":"text","text":"mod(obsnum, 3) == 0","style":{"code":true}},{"type":"text","text":", what is the probability of a "},{"type":"text","text":"1","style":{"code":true}},{"type":"text","text":"? Because if there is an errant "},{"type":"text","text":"1","style":{"code":true}},{"type":"text","text":" early in the sequence, your "},{"type":"text","text":"mod(obsnum, 3)","style":{"code":true}},{"type":"text","text":" rule is broken later on.\n\nIs there some sort of statistic that allows me to say \"on average, this one-third rule holds\"?"}]}]}],"thread_ts":"1616783573.045100","reply_count":31,"reply_users_count":5,"latest_reply":"1616926879.082200","reply_users":["UBF9YRB6H","U8JAMQGQY","U66M57AN4","U6A936746","U6C937ENB"],"is_locked":false,"subscribed":false}},{"type":"message","text":"","files":[{"id":"F01TBKL37S4","created":1616926846,"timestamp":1616926846,"name":"hiddenmarkov.jl","title":"hiddenmarkov.jl","mimetype":"application/octet-stream","filetype":"binary","pretty_type":"Binary","user":"U6C937ENB","editable":false,"size":3695,"mode":"external","is_external":true,"external_type":"unknown","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://gist.github.com/db187e9a3822e45740801ff1bc1b056c#file-hiddenmarkov-jl","permalink":"https://julialang.slack.com/files/U6C937ENB/F01TBKL37S4/hiddenmarkov.jl","is_starred":false,"has_rich_preview":false}],"upload":false,"user":"U6C937ENB","display_as_bot":false,"ts":"1616926881.082600"},{"client_msg_id":"3872cb6f-e395-4680-a179-f067636573df","type":"message","text":"so when I see problem statements like this... I always get curious as to what the application actually is. something about this looks and feels like an XY problem.","user":"UPUBAM63X","ts":"1616941976.084100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7e1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so when I see problem statements like this... I always get curious as to what the application actually is. something about this looks and feels like an XY problem."}]}]}]},{"client_msg_id":"68b88ffa-42e2-48d8-bbd3-80c4b39eed56","type":"message","text":"The motivation is not what you expect, at all!","user":"UBF9YRB6H","ts":"1616943996.086200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"33ubI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The motivation is not what you expect, at all!"}]}]}]},{"client_msg_id":"9EDE304C-740F-4101-9620-FDB0AF5A6D3A","type":"message","text":"XYZ Problem! I certainly didn’t answer Y either :sweat_smile:","user":"U6C937ENB","ts":"1616944051.087100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5wGp+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"XYZ Problem! I certainly didn’t answer Y either "},{"type":"emoji","name":"sweat_smile"}]}]}]},{"client_msg_id":"623d531b-0750-466b-9e42-59139eee94ca","type":"message","text":"The motivation is that there is a government agency that assigns \"every third\" person to a certain benefit. We want to know how well this rule is enforced or if we are really observing benefit eligibility in the right order, or if we are observing excess people or excess assignments. We think the \"true\" pattern is in our data set, but we also have junk in it. There is also uncertainty about which population this \"every third rule\" really applies to.\n\nAs we try to reverse engineer the exact workings of this \"every third\" rule, we need some metric to know how close we are to the ideal process.","user":"UBF9YRB6H","ts":"1616944268.090400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yxK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The motivation is that there is a government agency that assigns \"every third\" person to a certain benefit. We want to know how well this rule is enforced or if we are really observing benefit eligibility in the right order, or if we are observing excess people or excess assignments. We think the \"true\" pattern is in our data set, but we also have junk in it. There is also uncertainty about which population this \"every third rule\" really applies to.\n\nAs we try to reverse engineer the exact workings of this \"every third\" rule, we need some metric to know how close we are to the ideal process."}]}]}]},{"client_msg_id":"35946d86-3c2d-404a-af87-97c9f06c35d2","type":"message","text":"Ohhhh Jeese this makes way more sense to me now. I was going to say, sure there's bit read noise and stuff, but I don't even understand what kind of item makes this kind of signal.","user":"UPUBAM63X","ts":"1616947393.092500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ywD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ohhhh Jeese this makes way more sense to me now. I was going to say, sure there's bit read noise and stuff, but I don't even understand what kind of item makes this kind of signal."}]}]}]},{"client_msg_id":"1474536d-3532-4bea-af30-d7a7e5551dd9","type":"message","text":"so I would probably approach this differently...I don't know enough about the origin of the data, and won't ask more due to it being a gov't agency... But I'd treat this as a possible data quality issue. First I'd want to know things like \"given a sample of 100 people who did/did not attend a benefit, how accurate is my data\". Because there's multiple sources of error, there's reporting error and then there's the phenomena you actually care to investigate.","user":"UPUBAM63X","ts":"1616947642.094700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bj+U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so I would probably approach this differently...I don't know enough about the origin of the data, and won't ask more due to it being a gov't agency... But I'd treat this as a possible data quality issue. First I'd want to know things like \"given a sample of 100 people who did/did not attend a benefit, how accurate is my data\". Because there's multiple sources of error, there's reporting error and then there's the phenomena you actually care to investigate."}]}]}]},{"client_msg_id":"9a7081b8-6505-4434-aedb-927ec11cede2","type":"message","text":"it might turn out that the error rate is actually 5% or something and then boom all of the bad signal you're contending with fall under an umbrella of reporting/recording error.","user":"UPUBAM63X","ts":"1616947696.095500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/zq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it might turn out that the error rate is actually 5% or something and then boom all of the bad signal you're contending with fall under an umbrella of reporting/recording error."}]}]}]},{"client_msg_id":"893985b7-74f7-4997-8f06-650d2c6da836","type":"message","text":"then if there's unaccounted for variation I'd begin things like segmenting sources, etc.","user":"UPUBAM63X","ts":"1616947753.096000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Go+LH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"then if there's unaccounted for variation I'd begin things like segmenting sources, etc."}]}]}]},{"client_msg_id":"f34d051a-8ad3-4a0e-a521-e77c1ec95aac","type":"message","text":"But really you can look at this a number of ways, my mind jumps straight to metrics like levenshtein distance, dynamic time warping, etc. But might need to twist this around a bit to fit your specific problem I guess","user":"UPUBAM63X","ts":"1616947802.097000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jj0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But really you can look at this a number of ways, my mind jumps straight to metrics like levenshtein distance, dynamic time warping, etc. But might need to twist this around a bit to fit your specific problem I guess"}]}]}]},{"client_msg_id":"3e075e10-fd37-4c97-9b1f-6356aca93050","type":"message","text":"oooo okay I won't get nerd sniped on this but entropy could be your friend here. Maybe try measuring the overall entropy, and comparing it to the expected ideal sequences. Then sliding a window around to find \"hot spots\" where the entropy spikes drastically, and drilling down on those. Its interesting because you have degeneracy in your case for compliance.\nMaybe this will provide inspiration for more rigor: <https://ieeexplore.ieee.org/document/4090616>","user":"UPUBAM63X","ts":"1616948676.100200","team":"T68168MUP","edited":{"user":"UPUBAM63X","ts":"1616948683.000000"},"blocks":[{"type":"rich_text","block_id":"DbcL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oooo okay I won't get nerd sniped on this but entropy could be your friend here. Maybe try measuring the overall entropy, and comparing it to the expected ideal sequences. Then sliding a window around to find \"hot spots\" where the entropy spikes drastically, and drilling down on those. Its interesting because you have degeneracy in your case for compliance.\nMaybe this will provide inspiration for more rigor: "},{"type":"link","url":"https://ieeexplore.ieee.org/document/4090616"}]}]}]},{"client_msg_id":"e75d8932-ec3f-4897-aa3d-f7db0bff5f88","type":"message","text":"If that's for an IV, wouldn't you just be happy if it was avidly a third and the third that was picked looks fine in terms of the distribution of observed covariates? I would buy that as an instrument (but then I don't sit in seminars anymore so I'm not the guy you need to convince :joy:)","user":"U7JQGPGCQ","ts":"1616948687.100500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8+6Vz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If that's for an IV, wouldn't you just be happy if it was avidly a third and the third that was picked looks fine in terms of the distribution of observed covariates? I would buy that as an instrument (but then I don't sit in seminars anymore so I'm not the guy you need to convince "},{"type":"emoji","name":"joy"},{"type":"text","text":")"}]}]}]},{"client_msg_id":"6dbf962e-55c5-48dc-923f-15d18fd46937","type":"message","text":"Does anyone here have pointers on how to compare fixed effects between different generalized linear mixed effects models? I am planning to run two experiments that differ in one parameter, and I would like to fit a GLMM on each dataset. Then I want to compare if one or two fixed effects are significantly smaller in one model than in the other. The model specification should be the same for both models, but it will be two different sets of participants.","user":"UK1BNFHFV","ts":"1617031930.106400","team":"T68168MUP","edited":{"user":"UK1BNFHFV","ts":"1617032010.000000"},"blocks":[{"type":"rich_text","block_id":"XN=eO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone here have pointers on how to compare fixed effects between different generalized linear mixed effects models? I am planning to run two experiments that differ in one parameter, and I would like to fit a GLMM on each dataset. Then I want to compare if one or two fixed effects are significantly smaller in one model than in the other. The model specification should be the same for both models, but it will be two different sets of participants."}]}]}],"thread_ts":"1617031930.106400","reply_count":22,"reply_users_count":2,"latest_reply":"1617032807.110800","reply_users":["U66M57AN4","UK1BNFHFV"],"is_locked":false,"subscribed":false},{"client_msg_id":"794fcceb-6451-46e9-adf3-dcde2705c247","type":"message","text":"Hadley is a speaker at our series today… Really nice presentation on decoupling backends and the dplyr case study.","user":"U82LX4ACB","ts":"1617221424.117200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Kcp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hadley is a speaker at our series today… Really nice presentation on decoupling backends and the dplyr case study."}]}]}]}]}