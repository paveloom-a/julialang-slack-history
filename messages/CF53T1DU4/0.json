{"cursor": 2, "messages": [{"client_msg_id":"58ebbfb1-37ed-4237-b082-940f95585a9a","type":"message","text":"I'll keep an eye on the new version then","user":"U7PD3M3L5","ts":"1613045744.236500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"q7o","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'll keep an eye on the new version then"}]}]}]},{"client_msg_id":"60165e23-d31a-40d4-9bea-4c8903403f6e","type":"message","text":"but I'm actually very impressed by the loop speed here","user":"U7PD3M3L5","ts":"1613045752.236800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TXtZ+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but I'm actually very impressed by the loop speed here"}]}]}],"reactions":[{"name":"sonic","users":["UH24GRBLL"],"count":1}]},{"client_msg_id":"05de277b-c2f9-4c03-906d-8ac50a8c8eb7","type":"message","text":"and the easiness of adding `@avx`  whatever it does","user":"U7PD3M3L5","ts":"1613045768.237100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"g45","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and the easiness of adding "},{"type":"text","text":"@avx","style":{"code":true}},{"type":"text","text":"  whatever it does"}]}]}]},{"client_msg_id":"1a807543-008a-4a51-83d8-1b04935bc9a2","type":"message","text":"That’s some real black magic.","user":"UD0NS8PDF","ts":"1613045800.237500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"z9Nz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That’s some real black magic."}]}]}]},{"client_msg_id":"fb55657d-429b-4869-aaa6-96067eda334a","type":"message","text":"it (on one hand) does loop reordering, on the other it merges loads (almost) optimally, such that the arithmetic unit in your CPU is always busy","user":"UH24GRBLL","ts":"1613045836.238300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VWL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it (on one hand) does loop reordering, on the other it merges loads (almost) optimally, such that the arithmetic unit in your CPU is always busy"}]}]}]},{"client_msg_id":"1a6bec46-b759-41c5-957e-f19631212747","type":"message","text":"you have to be careful though - if you don't respect its rules, it can wreck your computation","user":"UH24GRBLL","ts":"1613045872.238700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"spa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you have to be careful though - if you don't respect its rules, it can wreck your computation"}]}]}]},{"client_msg_id":"25a8487e-9226-4438-95b6-105cbd62938f","type":"message","text":"Always respect the warning! :) <https://juliahub.com/ui/Packages/LoopVectorization/4TogI/0.11.2#Warning>","user":"UH24GRBLL","ts":"1613045882.238900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EjZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Always respect the warning! :) "},{"type":"link","url":"https://juliahub.com/ui/Packages/LoopVectorization/4TogI/0.11.2#Warning"}]}]}]},{"client_msg_id":"abd12932-fcee-4a62-899b-c5b030b05b47","type":"message","text":"haha ok thanks","user":"U7PD3M3L5","ts":"1613046602.239100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"P0M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"haha ok thanks"}]}]}]},{"client_msg_id":"3bc06c81-cd6b-4c6b-860a-1cf31bdd37a3","type":"message","text":"actually I just copied it from your code, did not read the docs or the warning","user":"U7PD3M3L5","ts":"1613046613.239600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+tgr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"actually I just copied it from your code, did not read the docs or the warning"}]}]}]},{"client_msg_id":"3b54ac71-1390-45be-95c6-e5f2a4147bab","type":"message","text":"the not iterating `1:2:N`  could have gotten me at some point","user":"U7PD3M3L5","ts":"1613046624.239900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SV404","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the not iterating "},{"type":"text","text":"1:2:N","style":{"code":true}},{"type":"text","text":"  could have gotten me at some point"}]}]}]},{"client_msg_id":"3cb2ca98-a2d6-4048-bb05-a09393974124","type":"message","text":"I'll probably remove the `1:2:N` limitation fairly soon.","user":"UAUPJLBQX","ts":"1613076272.241000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jLN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'll probably remove the "},{"type":"text","text":"1:2:N","style":{"code":true}},{"type":"text","text":" limitation fairly soon."}]}]}]},{"client_msg_id":"e073d807-a592-4178-98a0-1c70cd67c63a","type":"message","text":"what package is @cast in?","user":"U01GRS159T8","ts":"1613175525.241800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yABHt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what package is @cast in?"}]}]}],"thread_ts":"1613175525.241800","reply_count":1,"reply_users_count":1,"latest_reply":"1613175558.241900","reply_users":["U0179G7FG4F"],"subscribed":false},{"client_msg_id":"ab3f7a05-3711-42d3-b97d-9de42916424e","type":"message","text":"Does anyone have experience benchmarking code in CI? I have manual benchmarks and I would like to add performance tests, but this feels like a terrible idea due to how inconsistent the benchmarks may be. The median time per sample is about 11 microseconds and CI would be GitHub actions. I would want to write a test that verifies the median sample time is 11 +/- 1 uS and fails if it falls outside that range.","user":"U01537M2E9W","ts":"1613596642.245300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SBs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone have experience benchmarking code in CI? I have manual benchmarks and I would like to add performance tests, but this feels like a terrible idea due to how inconsistent the benchmarks may be. The median time per sample is about 11 microseconds and CI would be GitHub actions. I would want to write a test that verifies the median sample time is 11 +/- 1 uS and fails if it falls outside that range."}]}]}],"thread_ts":"1613596642.245300","reply_count":1,"reply_users_count":1,"latest_reply":"1613597124.245400","reply_users":["UCZ7VBGUD"],"subscribed":false},{"client_msg_id":"e6b257d3-cf7e-4737-b274-9511bd567a2b","type":"message","text":"I need to numerically integrate a slightly complicated function many times, so I'm trying to find a fast way to do it. I don't necessarily need super high precision (ideally beyond 1e-5 but I could make do with less)\n\nI'm currently trying the following with `FastGaussQuadrature` . Might anyone have a suggestion for how to improve performance?\n```function fastgq(f, a, b)\n    nodes, weights = gausslegendre( 10000 );\n    \n    x = 0.5*((b .- a).*nodes .+ (b.+a))\n    \n    out = 0.5*(b.-a)*dot( weights, f.(x) )\n    \n    return(out)\nend```","user":"U91Q3595Y","ts":"1613615785.248800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+0fn9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I need to numerically integrate a slightly complicated function many times, so I'm trying to find a fast way to do it. I don't necessarily need super high precision (ideally beyond 1e-5 but I could make do with less)\n\nI'm currently trying the following with "},{"type":"text","text":"FastGaussQuadrature","style":{"code":true}},{"type":"text","text":" . Might anyone have a suggestion for how to improve performance?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function fastgq(f, a, b)\n    nodes, weights = gausslegendre( 10000 );\n    \n    x = 0.5*((b .- a).*nodes .+ (b.+a))\n    \n    out = 0.5*(b.-a)*dot( weights, f.(x) )\n    \n    return(out)\nend"}]}]}],"thread_ts":"1613615785.248800","reply_count":9,"reply_users_count":2,"latest_reply":"1613616936.250500","reply_users":["U0179G7FG4F","U91Q3595Y"],"subscribed":false},{"client_msg_id":"826e815f-b75c-4389-be99-72a8fba07e21","type":"message","text":"When you return an array from a function, it always allocates, correct? Is there a way to just return a pointer/reference to that array? Wrap it in `Ref` maybe?","user":"U01H36BUDJB","ts":"1613733455.261300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"y84x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"When you return an array from a function, it always allocates, correct? Is there a way to just return a pointer/reference to that array? Wrap it in "},{"type":"text","text":"Ref","style":{"code":true}},{"type":"text","text":" maybe?"}]}]}],"thread_ts":"1613733455.261300","reply_count":1,"reply_users_count":1,"latest_reply":"1613733532.261400","reply_users":["UD0NS8PDF"],"subscribed":false},{"client_msg_id":"e54b6091-4f3d-4635-af2a-2d0f41b6350c","type":"message","text":"Could anyone familiar with ComponentArrays explain why this line seems to be type-unstable with `@code_warntype` despite all of the present variables (i.e. `values` ,`start` ,`stop`) being fully known? It's really perplexing me.\n```newvalues = ComponentArray(values,(Axis{(edges=start:2:stop,cells=start+1:2:stop-1)}(),))```","user":"U01H36BUDJB","ts":"1613749045.266000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OpeP3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Could anyone familiar with ComponentArrays explain why this line seems to be type-unstable with "},{"type":"text","text":"@code_warntype","style":{"code":true}},{"type":"text","text":" despite all of the present variables (i.e. "},{"type":"text","text":"values","style":{"code":true}},{"type":"text","text":" ,"},{"type":"text","text":"start","style":{"code":true}},{"type":"text","text":" ,"},{"type":"text","text":"stop","style":{"code":true}},{"type":"text","text":") being fully known? It's really perplexing me.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"newvalues = ComponentArray(values,(Axis{(edges=start:2:stop,cells=start+1:2:stop-1)}(),))"}]}]}],"thread_ts":"1613749045.266000","reply_count":1,"reply_users_count":1,"latest_reply":"1613749075.266100","reply_users":["U01H36BUDJB"],"subscribed":false},{"type":"message","subtype":"channel_join","ts":"1613754988.266600","user":"US4A6G6B0","text":"<@US4A6G6B0> has joined the channel","inviter":"U69BL50BF"},{"client_msg_id":"17b57b98-42b8-4788-82fd-dc8f71819b25","type":"message","text":"What's the best way to debug long compilation times for a function? i.e. I want to figure out what's slowing it down.","user":"U01H36BUDJB","ts":"1613832812.000700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F8a4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What's the best way to debug long compilation times for a function? i.e. I want to figure out what's slowing it down."}]}]}]},{"client_msg_id":"5181e65a-5662-48ab-962a-bfc6a60373d2","type":"message","text":"Hey","user":"U01MG0TN079","ts":"1613894462.015400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"d1p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey"}]}]}]},{"client_msg_id":"5c3c9cbd-b681-420a-b1b9-4ff9ba57ef9f","type":"message","text":"Say I'm working with rational numbers, with a known bound on the denominator (i.e. all can be written as n/K for some known integer K), how much slower is it to work with Rational{Int} rather than Int ?","user":"U01MG0TN079","ts":"1613894514.016400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lYt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Say I'm working with rational numbers, with a known bound on the denominator (i.e. all can be written as n/K for some known integer K), how much slower is it to work with Rational{Int} rather than Int ?"}]}]}]},{"client_msg_id":"0378c30a-b2c0-4b0a-8144-d9fe520b1c8c","type":"message","text":"Another question: What would be the best way to type a vector of collections whose types depend on their index in the vector","user":"U01MG0TN079","ts":"1613910244.018000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/8QL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Another question: What would be the best way to type a vector of collections whose types depend on their index in the vector"}]}]}]},{"client_msg_id":"d0161884-6800-4511-b9db-e1f06161fb68","type":"message","text":"`[Vector{SVector{1}},Vector{SVector{2}},…]`","user":"U01MG0TN079","ts":"1613910283.018800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xOEC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"[Vector{SVector{1}},Vector{SVector{2}},…]","style":{"code":true}}]}]}]},{"client_msg_id":"c49b7c69-850b-403b-87f1-253c9649d246","type":"message","text":"Since the length of such a vector of collection is bounded in my case, by around 20, I wonder if I should just define 20 custom types, or do it with a macro?","user":"U01MG0TN079","ts":"1613910458.019700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xJl9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Since the length of such a vector of collection is bounded in my case, by around 20, I wonder if I should just define 20 custom types, or do it with a macro?"}]}]}],"thread_ts":"1613910458.019700","reply_count":2,"reply_users_count":2,"latest_reply":"1613911670.020000","reply_users":["U7HAYKY9X","U01MG0TN079"],"subscribed":false},{"client_msg_id":"71d5d8c1-a106-4932-95c4-b34190f1f523","type":"message","text":"Is accessing nested named tuples supposed to allocate? Like for example, if I do `a.b.c.X` where `a`,`b`,`c` are all nested `NamedTuple` s, and `X` is the name of an array stored in `c` this shouldn't allocate right?","user":"U01H36BUDJB","ts":"1613999608.023300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5Vp5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is accessing nested named tuples supposed to allocate? Like for example, if I do "},{"type":"text","text":"a.b.c.X","style":{"code":true}},{"type":"text","text":" where "},{"type":"text","text":"a","style":{"code":true}},{"type":"text","text":","},{"type":"text","text":"b","style":{"code":true}},{"type":"text","text":","},{"type":"text","text":"c","style":{"code":true}},{"type":"text","text":" are all nested "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" s, and "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" is the name of an array stored in "},{"type":"text","text":"c","style":{"code":true}},{"type":"text","text":" this shouldn't allocate right?"}]}]}],"thread_ts":"1613999608.023300","reply_count":1,"reply_users_count":1,"latest_reply":"1613999699.023400","reply_users":["U7HAYKY9X"],"subscribed":false},{"client_msg_id":"d6813445-8124-4ede-8951-47178b0c4ee9","type":"message","text":"<@UAUPJLBQX> thoughts on <https://github.com/dzhang314/EFTBase.jl/pull/2>? specifically, whether `fast_two_sum` or `two_sum` is likely to be faster in practice.","user":"U0179G7FG4F","ts":"1614028162.024800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pGDzI","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":" thoughts on "},{"type":"link","url":"https://github.com/dzhang314/EFTBase.jl/pull/2"},{"type":"text","text":"? specifically, whether "},{"type":"text","text":"fast_two_sum","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"two_sum","style":{"code":true}},{"type":"text","text":" is likely to be faster in practice."}]}]}]},{"client_msg_id":"dc93d659-140f-42ff-8693-4c7e2b268b9c","type":"message","text":"not Chris, but as the comments say - it's highly dependent on what happens in the CPU/microcode","user":"UH24GRBLL","ts":"1614028521.025300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dB0F","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"not Chris, but as the comments say - it's highly dependent on what happens in the CPU/microcode"}]}]}]},{"client_msg_id":"72e55605-a2fd-4c97-a9c3-f9c2e523a946","type":"message","text":"Is there a way we could automatically (at build time) pick the best one?","user":"U0179G7FG4F","ts":"1614028619.025800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ArUN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a way we could automatically (at build time) pick the best one?"}]}]}]},{"client_msg_id":"67c3a264-36a1-4ee0-9dfc-d649310b1660","type":"message","text":"have a large lookup table checking which is faster on which specific architecture and `@static` which method you define","user":"UH24GRBLL","ts":"1614028652.026400","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1614028661.000000"},"blocks":[{"type":"rich_text","block_id":"5bnE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"have a large lookup table checking which is faster on which specific architecture and "},{"type":"text","text":"@static","style":{"code":true}},{"type":"text","text":" which method you define"}]}]}]},{"client_msg_id":"aa49fb2d-e16c-4e20-aee1-61c75727742c","type":"message","text":"Do you think that's actually feasible? Would an approach where you benchmark both during pre-compile work?","user":"U0179G7FG4F","ts":"1614028872.027300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"it2D","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Do you think that's actually feasible? Would an approach where you benchmark both during pre-compile work?"}]}]}]},{"client_msg_id":"9bb70c70-ab4f-497d-aaf2-2355c83d580f","type":"message","text":"You'd have to benchmark after compilation","user":"UH24GRBLL","ts":"1614030207.027800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VO2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You'd have to benchmark after compilation"}]}]}]},{"client_msg_id":"425e1a78-d9ea-4373-9f39-16e603927b5b","type":"message","text":"As I understand it, that's how all the smart optimizations in LLVM and gcc are compared - benchmark it and find out which is faster, then emit that code.","user":"UH24GRBLL","ts":"1614030283.028600","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1614030312.000000"},"blocks":[{"type":"rich_text","block_id":"XAJa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"As I understand it, that's how all the smart optimizations in LLVM and gcc are compared - benchmark it and find out which is faster, then emit that code."}]}]}]},{"client_msg_id":"33cde73e-7c55-41f6-bce7-6ce31c8d5735","type":"message","text":"Maybe we could use Preferences.jl","user":"UAUPJLBQX","ts":"1614034597.029000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HuL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe we could use Preferences.jl"}]}]}]},{"client_msg_id":"75f9fccb-c758-472b-b439-2bb8bdbc7a16","type":"message","text":"pick a default (`two_sum`), and have a function `tune!` where it runs benchmarks, and then sets preferences accordingly?","user":"UAUPJLBQX","ts":"1614034615.029500","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1614034632.000000"},"blocks":[{"type":"rich_text","block_id":"WiC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"pick a default ("},{"type":"text","text":"two_sum","style":{"code":true}},{"type":"text","text":"), and have a function "},{"type":"text","text":"tune!","style":{"code":true}},{"type":"text","text":" where it runs benchmarks, and then sets preferences accordingly?"}]}]}]},{"client_msg_id":"50137ac0-dc9b-4bad-be53-aea0b4cffdb0","type":"message","text":"You'd have to take care not to fall into benchmarking artifacts due to other programs running at the same time - could very well mess with the branching version","user":"UH24GRBLL","ts":"1614062149.030900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OxE7P","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You'd have to take care not to fall into benchmarking artifacts due to other programs running at the same time - could very well mess with the branching version"}]}]}]},{"client_msg_id":"c5dbdcbb-84e1-46f3-b1c1-ce09e7246032","type":"message","text":"Does anyone have a good way of making a struct use a memory arena? <https://github.com/tonyrubak/MemoryArena.jl> Looks unmaintained, and it would be nice to have a go-to idiom for this","user":"U0179G7FG4F","ts":"1614393044.032100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LpmUQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone have a good way of making a struct use a memory arena? "},{"type":"link","url":"https://github.com/tonyrubak/MemoryArena.jl"},{"type":"text","text":" Looks unmaintained, and it would be nice to have a go-to idiom for this"}]}]}]},{"client_msg_id":"25c54e4e-8987-4d0b-93f8-16ac41f953f0","type":"message","text":"Hi there! I am stuck with a perf comparison with C code which is almost twice as fast as my julia version (I gain 10% if call julia with fastmath mode, but it still is far from C). Of course I can use threads easily, but that is kind of not the point. Any obvious improvement from the following julia code?\n```using BenchmarkTools\n\ncx(x, side, scale) = x / side * 2 * scale - scale\ncy(y...) = cx(y...) * 1im\n\nfunction solvePixel(i, i_n, side, center, scale)\n    y, x = divrem(i, side)\n    c = cx(x, side, scale) + cy(y, side, scale) + center\n    z = 0im\n    k = 0\n    while (k &lt; i_n)\n        z = z * z + c\n        abs(z) &lt;= 2 ? k += 1 : break \n    end\n    return 1 - k / i_n\nend\n\nfunction res_(idx, i_n, side, center, scale)\n    return UInt8(floor(solvePixel(idx, i_n, side, center, scale) * 255))\nend\n\nfunction main(; i_n=512, side=2048, center=0.4 + 0.4im, scale=0.3)\n    open(\"out.ppm\", \"w\") do io\n        write(io, \"P6 $side $side 255 \")\n        buffer = Matrix{UInt8}(undef, side, side * 3)\n        for i in 0:side - 1\n            tmp = i * side\n            for j in 1:side\n                idx = tmp + j\n                res = res_(idx, i_n, side, center, scale)\n                @inbounds buffer[i + 1,j * 3 - 2:j * 3] .= res\n            end\n        end                     \n        write(io, buffer)       \n    end\nend\n\n@benchmark main()```","user":"U01FR2HFJ7M","ts":"1614914041.036100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"K5nyJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi there! I am stuck with a perf comparison with C code which is almost twice as fast as my julia version (I gain 10% if call julia with fastmath mode, but it still is far from C). Of course I can use threads easily, but that is kind of not the point. Any obvious improvement from the following julia code?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using BenchmarkTools\n\ncx(x, side, scale) = x / side * 2 * scale - scale\ncy(y...) = cx(y...) * 1im\n\nfunction solvePixel(i, i_n, side, center, scale)\n    y, x = divrem(i, side)\n    c = cx(x, side, scale) + cy(y, side, scale) + center\n    z = 0im\n    k = 0\n    while (k < i_n)\n        z = z * z + c\n        abs(z) <= 2 ? k += 1 : break \n    end\n    return 1 - k / i_n\nend\n\nfunction res_(idx, i_n, side, center, scale)\n    return UInt8(floor(solvePixel(idx, i_n, side, center, scale) * 255))\nend\n\nfunction main(; i_n=512, side=2048, center=0.4 + 0.4im, scale=0.3)\n    open(\"out.ppm\", \"w\") do io\n        write(io, \"P6 $side $side 255 \")\n        buffer = Matrix{UInt8}(undef, side, side * 3)\n        for i in 0:side - 1\n            tmp = i * side\n            for j in 1:side\n                idx = tmp + j\n                res = res_(idx, i_n, side, center, scale)\n                @inbounds buffer[i + 1,j * 3 - 2:j * 3] .= res\n            end\n        end                     \n        write(io, buffer)       \n    end\nend\n\n@benchmark main()"}]}]}]},{"client_msg_id":"e78c4329-9240-4895-9759-d32c8c900699","type":"message","text":"Is there a way to speed up this calculate this function faster? `x` and `y` are vectors `W` and `W_in` are matrices and activation is `tanh`\n```function foo(activation,W, W_in, x, y)\n    return activation.((W*x)+(W_in*y))\nend```","user":"U01C3624SGJ","ts":"1614956001.041400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lBLx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a way to speed up this calculate this function faster? "},{"type":"text","text":"x","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":" are vectors "},{"type":"text","text":"W","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"W_in","style":{"code":true}},{"type":"text","text":" are matrices and activation is "},{"type":"text","text":"tanh","style":{"code":true}},{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function foo(activation,W, W_in, x, y)\n    return activation.((W*x)+(W_in*y))\nend"}]}]}],"thread_ts":"1614956001.041400","reply_count":3,"reply_users_count":3,"latest_reply":"1614956755.041900","reply_users":["U7HAYKY9X","U0179G7FG4F","U01C3624SGJ"],"subscribed":false},{"client_msg_id":"6603f50a-416b-4553-a5c4-5325513394d8","type":"message","text":"I would greatly appreciate if someone experienced with threading design commented in <https://github.com/JuliaData/DataFrames.jl/pull/2647> what conditions we should use in DataFrames.jl to turn-on using multi-threading (I can do it by trial and error, but maybe there are some concrete recommendations about conditions when one can expect to get speedup from using `Threads.@threads` - essentially the question is what is the cost of setting up and handling task switching). Thank you! CC <@U67431ELR>","user":"U8JAMQGQY","ts":"1615212213.050700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"syM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I would greatly appreciate if someone experienced with threading design commented in "},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/pull/2647"},{"type":"text","text":" what conditions we should use in DataFrames.jl to turn-on using multi-threading (I can do it by trial and error, but maybe there are some concrete recommendations about conditions when one can expect to get speedup from using "},{"type":"text","text":"Threads.@threads","style":{"code":true}},{"type":"text","text":" - essentially the question is what is the cost of setting up and handling task switching). Thank you! CC "},{"type":"user","user_id":"U67431ELR"}]}]}],"thread_ts":"1615212213.050700","reply_count":5,"reply_users_count":2,"latest_reply":"1615213067.051600","reply_users":["U67431ELR","U8JAMQGQY"],"subscribed":false},{"client_msg_id":"7c432943-a5bc-429c-ad3c-32fbb3a2f18b","type":"message","text":"If I have an immutable isbits struct, and I create a Vector of them, is there any way (unsafe, hacky) to modify a single field of an element? Similar to what I could do with a reference in c++.","user":"UCNPT22MQ","ts":"1615324052.056100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6sN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If I have an immutable isbits struct, and I create a Vector of them, is there any way (unsafe, hacky) to modify a single field of an element? Similar to what I could do with a reference in c++."}]}]}]},{"client_msg_id":"e1e271c2-52e8-4f22-a15b-e2a682590320","type":"message","text":"if you have a function that returns a new instance of that immutable type with that field set differently, the compiler will probably just write that for you since you're semantically unable to observe whether the element changed to a new instance","user":"UH24GRBLL","ts":"1615324245.057100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7WwM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if you have a function that returns a new instance of that immutable type with that field set differently, the compiler will probably just write that for you since you're semantically unable to observe whether the element changed to a new instance"}]}]}]},{"client_msg_id":"eb89ae35-b4cb-403d-9f84-fdc8b4d83a7e","type":"message","text":"that's the whole point of immutability","user":"UH24GRBLL","ts":"1615324261.057400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8GuGr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's the whole point of immutability"}]}]}]},{"client_msg_id":"d95e40be-91b2-45c0-90f6-fbc45ce1ba35","type":"message","text":"Hmm, interesting, thanks. It does look like the assembly only modifies the single value, though there is no SIMD happening (unlike the C++ version which generates interesting scatter / strided ops)","user":"UCNPT22MQ","ts":"1615324655.061600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kHy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hmm, interesting, thanks. It does look like the assembly only modifies the single value, though there is no SIMD happening (unlike the C++ version which generates interesting scatter / strided ops)"}]}]}]},{"client_msg_id":"07b79084-1407-4810-8ac7-0840867c1129","type":"message","text":"Not sure if the fact that the llvm is far more complex and indirect for the Julia version prevents it from seeing it","user":"UCNPT22MQ","ts":"1615324678.062400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fQic","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not sure if the fact that the llvm is far more complex and indirect for the Julia version prevents it from seeing it"}]}]}]},{"client_msg_id":"10557393-6712-46e7-a0d4-a8c913bd04ba","type":"message","text":"I'm just doing something like:\n```for i in 1:length(vals)\n    old = vals[i]\n    vals[i] = MyStruct(old.a, old.b, old.c + 10)\nend```","user":"UCNPT22MQ","ts":"1615324721.063200","team":"T68168MUP","edited":{"user":"UCNPT22MQ","ts":"1615324757.000000"},"blocks":[{"type":"rich_text","block_id":"yLLr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm just doing something like:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"for i in 1:length(vals)\n    old = vals[i]\n    vals[i] = MyStruct(old.a, old.b, old.c + 10)\nend"}]}]}]},{"client_msg_id":"7b5140e3-d9e6-4736-ab14-0ebb6a253c74","type":"message","text":"Does anyone know whats wrong with this:\n`@reduce expectation[i] := @sum(n) 1/ensemble_size * κ(Θ[:, n], Φ[:, i])`?\n`Tensorcast` gives me\n```LoadError: don't know what to do with $(Expr(:(:=), :(expectation[i]), :(#= In[37]:7 =# @sum n))) \n    @reduce expectation[i] := #= In[37]:7 =# @sum n  (1 / ensemble_size) * κ(Θ[:, n], Φ[:, i])\nin expression starting at In[37]:7```","user":"U7PD3M3L5","ts":"1615886346.000700","team":"T68168MUP","edited":{"user":"U7PD3M3L5","ts":"1615886360.000000"},"blocks":[{"type":"rich_text","block_id":"+Hga","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know whats wrong with this:\n`@reduce expectation[i] := @sum(n) 1/ensemble_size * κ(Θ[:, n], Φ[:, i])`?\n"},{"type":"text","text":"Tensorcast","style":{"code":true}},{"type":"text","text":" gives me\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"LoadError: don't know what to do with $(Expr(:(:=), :(expectation[i]), :(#= In[37]:7 =# @sum n))) \n    @reduce expectation[i] := #= In[37]:7 =# @sum n  (1 / ensemble_size) * κ(Θ[:, n], Φ[:, i])\nin expression starting at In[37]:7"}]}]}]},{"client_msg_id":"16cd862c-b805-4ab0-8a35-d21ca6e6c1d2","type":"message","text":"If I have a function that needs _some_ arguments from a struct but not all, is it quicker to pass arguments individually or is there no performance penalty for passing the whole struct (assuming it is fully typed, doesn't generate type instability etc.)?\n\nFrom tests some small tests it appears that there is a performance penalty. Is this something that can be improved by inlining?\n\nIdeally I'd like to pass the full struct to keep the code neat (lots of arguments required). Cheers!","user":"U017FUJDBT7","ts":"1615949804.002300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QOZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If I have a function that needs "},{"type":"text","text":"some","style":{"italic":true}},{"type":"text","text":" arguments from a struct but not all, is it quicker to pass arguments individually or is there no performance penalty for passing the whole struct (assuming it is fully typed, doesn't generate type instability etc.)?\n\nFrom tests some small tests it appears that there is a performance penalty. Is this something that can be improved by inlining?\n\nIdeally I'd like to pass the full struct to keep the code neat (lots of arguments required). Cheers!"}]}]}],"thread_ts":"1615949804.002300","reply_count":4,"reply_users_count":3,"latest_reply":"1615951001.004000","reply_users":["U017FUJDBT7","U0179G7FG4F","UDD5Z7FLZ"],"subscribed":false},{"type":"message","text":"I have many parametric structs like:\n```\nstruct GeneralConstraint{IndexType,WeightType,N} &lt;: AbstractClause\n    Lb::WeightType\n    Ub::WeightType\n    Weight::SVector{N,WeightType}\n    Literals::SVector{N,Literal{IndexType}}\nend\n```\nwhere the N differs in general. IndexType and WeightType are always the same.\nHow do i best store them, order does not matter but i should be able to iterate all of them and append.","user":"U9MD78Z9N","ts":"1616041467.005300","team":"T68168MUP"},{"type":"message","text":"Next step question, is there something more performant i can do if i have a collection that stays unchanged and i can sort as i want and am in control how to access it?","user":"U9MD78Z9N","ts":"1616043494.005400","team":"T68168MUP","edited":{"user":"U9MD78Z9N","ts":"1616043532.000000"}},{"client_msg_id":"5d00fb9c-6248-42de-9814-a861f0f6707d","type":"message","text":"<@U9MD78Z9N> Maybe <https://github.com/tkoolen/TypeSortedCollections.jl|https://github.com/tkoolen/TypeSortedCollections.jl>?","user":"U67G3QRJM","ts":"1616074141.006100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"s0L","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U9MD78Z9N"},{"type":"text","text":" Maybe "},{"type":"link","url":"https://github.com/tkoolen/TypeSortedCollections.jl","text":"https://github.com/tkoolen/TypeSortedCollections.jl"},{"type":"text","text":"?"}]}]}]},{"type":"message","text":"What does it mean when my flamegraph looks like this?","files":[{"id":"F01RMMU7L5B","created":1616083745,"timestamp":1616083745,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U7PD3M3L5","editable":false,"size":19930,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01RMMU7L5B/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01RMMU7L5B/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01RMMU7L5B-50d3870fc0/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01RMMU7L5B-50d3870fc0/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01RMMU7L5B-50d3870fc0/image_360.png","thumb_360_w":360,"thumb_360_h":353,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01RMMU7L5B-50d3870fc0/image_480.png","thumb_480_w":480,"thumb_480_h":470,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01RMMU7L5B-50d3870fc0/image_160.png","original_w":530,"original_h":519,"thumb_tiny":"AwAvADCnRQOlApiDFGKWigBMUGlpDQADpQKB0ooAWikzRmgBaQ0ZooAB0pKXNJQAUUUUDCiiigD/2Q==","permalink":"https://julialang.slack.com/files/U7PD3M3L5/F01RMMU7L5B/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01RMMU7L5B-51547f65c8","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"UcS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What does it mean when my flamegraph looks like this?"}]}]}],"user":"U7PD3M3L5","display_as_bot":false,"ts":"1616083748.006500"},{"client_msg_id":"e4e5bcae-4f54-4b64-9f0c-a0cfbd3e08b6","type":"message","text":"Only on the left side one of the bottom things is the actual function which is running all the time. All the big bars on the right are C functions, the topmost being `clone`","user":"U7PD3M3L5","ts":"1616083784.007400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3BBod","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Only on the left side one of the bottom things is the actual function which is running all the time. All the big bars on the right are C functions, the topmost being "},{"type":"text","text":"clone","style":{"code":true}}]}]}]},{"client_msg_id":"87307027-c794-430d-ac8d-b9b31af6f3a0","type":"message","text":"Could it be that Julia performs\nA*B*v\nas\n(A*B)*v ? seems very much like it from a performance test","user":"U7PD3M3L5","ts":"1616084234.008100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cYy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Could it be that Julia performs\nA*B*v\nas\n(A*B)*v ? seems very much like it from a performance test"}]}]}],"thread_ts":"1616084234.008100","reply_count":2,"reply_users_count":2,"latest_reply":"1616084879.008400","reply_users":["U0179G7FG4F","U67D54KS8"],"subscribed":false},{"client_msg_id":"b4d5e37c-e945-4bf5-ac03-fcd0ab0aae59","type":"message","text":"Is it possible to copy an arbitrary pixel in an file (png) without loading the entire image? I'm trying to speed up the simplified code below where the png image is one in a collection with a total size of 25GB+. I'm open to preprocessing the collection to make it easier to access the pixels\n```for frame = 1:Ntotalframes\n    newimg = copy(preloaded_img)\n    for j = 1:ysize\n        for i = 1:xsize\n            fname, pixelcoords = getDesiredFilenameAndPixelIndex(i, j, frame)\n            newimg[i, j] = load(fname)[pixelcoords[1], pixelcoords[2]]\n        end\n    end\n    newimg_file_name = @sprintf(\"%04d.png\", frame);\n    save(newimg_file_name, newimg)\nend```","user":"U0138UTB7A4","ts":"1616196756.012000","team":"T68168MUP","edited":{"user":"U0138UTB7A4","ts":"1616197210.000000"},"blocks":[{"type":"rich_text","block_id":"M+Dn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it possible to copy an arbitrary pixel in an file (png) without loading the entire image? I'm trying to speed up the simplified code below where the png image is one in a collection with a total size of 25GB+. I'm open to preprocessing the collection to make it easier to access the pixels\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"for frame = 1:Ntotalframes\n    newimg = copy(preloaded_img)\n    for j = 1:ysize\n        for i = 1:xsize\n            fname, pixelcoords = getDesiredFilenameAndPixelIndex(i, j, frame)\n            newimg[i, j] = load(fname)[pixelcoords[1], pixelcoords[2]]\n        end\n    end\n    newimg_file_name = @sprintf(\"%04d.png\", frame);\n    save(newimg_file_name, newimg)\nend"}]}]}],"thread_ts":"1616196756.012000","reply_count":10,"reply_users_count":2,"latest_reply":"1616198230.015200","reply_users":["U0179G7FG4F","U0138UTB7A4"],"subscribed":false},{"client_msg_id":"dc994942-070f-4568-80c2-9200e38e0767","type":"message","text":"`@avx` is equivalent to something like `@inbounds @simd` if the loop is only 1D, right?","user":"U011V2YN59N","ts":"1616735350.019000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uPi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"@avx","style":{"code":true}},{"type":"text","text":" is equivalent to something like "},{"type":"text","text":"@inbounds @simd","style":{"code":true}},{"type":"text","text":" if the loop is only 1D, right?"}]}]}],"thread_ts":"1616735350.019000","reply_count":2,"reply_users_count":1,"latest_reply":"1616735951.019900","reply_users":["U0179G7FG4F"],"is_locked":false,"subscribed":false},{"client_msg_id":"013325f4-7684-4d59-a775-b08637e7d21e","type":"message","text":"Hello. Running some code of mine with `@time` , I get :`7821.040149 seconds (23.55 G allocations: 1.653 TiB, 21.28% gc time)` . The code essentially consists in iterating over lots of small vectors constructed during the runtime. There is no big data that is read from disk or streamed from outside. The 1.6TiB makes me think I allocate way too much. How extreme are those numbers?","user":"U01MG0TN079","ts":"1616739073.022700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ab7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello. Running some code of mine with "},{"type":"text","text":"@time","style":{"code":true}},{"type":"text","text":" , I get :"},{"type":"text","text":"7821.040149 seconds (23.55 G allocations: 1.653 TiB, 21.28% gc time)","style":{"code":true}},{"type":"text","text":" . The code essentially consists in iterating over lots of small vectors constructed during the runtime. There is no big data that is read from disk or streamed from outside. The 1.6TiB makes me think I allocate way too much. How extreme are those numbers?"}]}]}]},{"client_msg_id":"6283876b-c698-47fd-a24d-dbedd61ea696","type":"message","text":"perhaps slightly off-topic, but does somebody know why `SLEEF.jl` got forked into `SLEEFPirates.jl` ? ... just wondering ...","user":"U013V2CFZAN","ts":"1616754077.030200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+o423","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"perhaps slightly off-topic, but does somebody know why "},{"type":"text","text":"SLEEF.jl","style":{"code":true}},{"type":"text","text":" got forked into "},{"type":"text","text":"SLEEFPirates.jl","style":{"code":true}},{"type":"text","text":" ? ... just wondering ..."}]}]}]},{"client_msg_id":"5effe515-275e-45ef-90e7-55196ac40b59","type":"message","text":"Is there a clever way to get a loop with a conditional `break` to vectorize? If I convert it to a while loop, then it's slower.","user":"U011V2YN59N","ts":"1616774934.039300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RdRTQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a clever way to get a loop with a conditional "},{"type":"text","text":"break","style":{"code":true}},{"type":"text","text":" to vectorize? If I convert it to a while loop, then it's slower."}]}]}],"thread_ts":"1616774934.039300","reply_count":18,"reply_users_count":3,"latest_reply":"1616775429.043100","reply_users":["U6QGE7S86","U011V2YN59N","U67BJLYCS"],"is_locked":false,"subscribed":false},{"client_msg_id":"37ef2864-5b02-45e8-8e77-c167154ac38e","type":"message","text":"where `needles` and `hay` are relatively small (0..32) tuples of symbols, to find the symbols in hay that are *not* in needles:\nCan I do better in performance (more important) / memory use than:\n```not_occurs_in(needles, hay) = \nhay[[foldl(.&amp;,map(.!,[n .== hay for n in needles]))...]]```","user":"U68QW0PUZ","ts":"1616792336.045700","team":"T68168MUP","edited":{"user":"U68QW0PUZ","ts":"1616792441.000000"},"blocks":[{"type":"rich_text","block_id":"JDfxR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"where "},{"type":"text","text":"needles","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"hay","style":{"code":true}},{"type":"text","text":" are relatively small (0..32) tuples of symbols, to find the symbols in hay that are "},{"type":"text","text":"not","style":{"bold":true}},{"type":"text","text":" in needles:\nCan I do better in performance (more important) / memory use than:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"not_occurs_in(needles, hay) = \nhay[[foldl(.&,map(.!,[n .== hay for n in needles]))...]]"}]}]}]},{"client_msg_id":"58798804-012e-410e-9c53-1e9f5b515ec3","type":"message","text":"Does anyone see why the following\n```function g_eps(theta, theta_, Σ_inv)\n    exp(-0.25 * (theta - theta_)' * Σ_inv * (theta-theta_))\nend\n\nfunction calc_T(Theta)\n    @cast g[i,j] := g_eps(Theta[:, i], Theta[:, j], I)\n    g\nend\n\nTheta = randn(3, 10)\ncalc_T(Theta)```\nerrors with\n```julia&gt; calc_T(Theta)\nERROR: MethodError: no method matching length(::UniformScaling{Bool})```\n?","user":"U7PD3M3L5","ts":"1617019352.052400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2gCk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone see why the following\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function g_eps(theta, theta_, Σ_inv)\n    exp(-0.25 * (theta - theta_)' * Σ_inv * (theta-theta_))\nend\n\nfunction calc_T(Theta)\n    @cast g[i,j] := g_eps(Theta[:, i], Theta[:, j], I)\n    g\nend\n\nTheta = randn(3, 10)\ncalc_T(Theta)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"errors with\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> calc_T(Theta)\nERROR: MethodError: no method matching length(::UniformScaling{Bool})"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"?"}]}]}]},{"client_msg_id":"df512ee5-9c53-4abd-8b66-e1bfac21ac6f","type":"message","text":"where does it error?","user":"UH24GRBLL","ts":"1617019788.052700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aPWaS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"where does it error?"}]}]}]},{"client_msg_id":"d2921370-1d80-4194-ae5c-3f7fde778149","type":"message","text":"In the `cast`  from tensorcast:\n```MethodError: no method matching length(::UniformScaling{Bool})\nClosest candidates are:\n  length(!Matched::DataStructures.IntSet) at /home/*/.julia/packages/DataStructures/DLSxi/src/int_set.jl:197\n  length(!Matched::LaTeXStrings.LaTeXString) at /home/*/.julia/packages/LaTeXStrings/anRaX/src/LaTeXStrings.jl:115\n  length(!Matched::Base.EnvDict) at env.jl:132\n  ...\n_similar_for(::UnitRange{Int64}, ::Type{Bool}, ::UniformScaling{Bool}, ::Base.HasLength) at array.jl:597\n_collect(::UnitRange{Int64}, ::UniformScaling{Bool}, ::Base.HasEltype, ::Base.HasLength) at array.jl:630\ncollect(::UniformScaling{Bool}) at array.jl:624\nbroadcastable(::UniformScaling{Bool}) at broadcast.jl:682\nmap(::typeof(Base.Broadcast.broadcastable), ::Tuple{UniformScaling{Bool}}) at tuple.jl:157\nbroadcasted at broadcast.jl:1262 [inlined]\nmacro expansion at macro.jl:214 [inlined]\ncalc_T(::Array{Float64,2}) at example_2.jl:45\ntop-level scope at example_2.jl:49```","user":"U7PD3M3L5","ts":"1617019884.053500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9Y6YB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In the "},{"type":"text","text":"cast","style":{"code":true}},{"type":"text","text":"  from tensorcast:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"MethodError: no method matching length(::UniformScaling{Bool})\nClosest candidates are:\n  length(!Matched::DataStructures.IntSet) at /home/*/.julia/packages/DataStructures/DLSxi/src/int_set.jl:197\n  length(!Matched::LaTeXStrings.LaTeXString) at /home/*/.julia/packages/LaTeXStrings/anRaX/src/LaTeXStrings.jl:115\n  length(!Matched::Base.EnvDict) at env.jl:132\n  ...\n_similar_for(::UnitRange{Int64}, ::Type{Bool}, ::UniformScaling{Bool}, ::Base.HasLength) at array.jl:597\n_collect(::UnitRange{Int64}, ::UniformScaling{Bool}, ::Base.HasEltype, ::Base.HasLength) at array.jl:630\ncollect(::UniformScaling{Bool}) at array.jl:624\nbroadcastable(::UniformScaling{Bool}) at broadcast.jl:682\nmap(::typeof(Base.Broadcast.broadcastable), ::Tuple{UniformScaling{Bool}}) at tuple.jl:157\nbroadcasted at broadcast.jl:1262 [inlined]\nmacro expansion at macro.jl:214 [inlined]\ncalc_T(::Array{Float64,2}) at example_2.jl:45\ntop-level scope at example_2.jl:49"}]}]}]},{"client_msg_id":"bd0c1542-5706-42c3-9d6a-7fc44d5e6688","type":"message","text":"it ends up trying to broadcast over `I`, which doesn't have a length","user":"UH24GRBLL","ts":"1617020166.053900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ALmB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it ends up trying to broadcast over "},{"type":"text","text":"I","style":{"code":true}},{"type":"text","text":", which doesn't have a length"}]}]}],"reactions":[{"name":"pray","users":["U7PD3M3L5"],"count":1}]},{"client_msg_id":"2757b67c-298c-4286-a2f2-5adf67736e70","type":"message","text":"It will work with Ref, i.e. `@cast g[i,j] := g_eps(Theta[:, i], Theta[:, j], Ref(I))`.","user":"UD0NS8PDF","ts":"1617031122.055100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XeZ3Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It will work with Ref, i.e. "},{"type":"text","text":"@cast g[i,j] := g_eps(Theta[:, i], Theta[:, j], Ref(I))","style":{"code":true}},{"type":"text","text":"."}]}]}]},{"client_msg_id":"519a811e-865d-4eb0-9957-9634627c220f","type":"message","text":"although perhaps ideally it would figure out that you only intend broadcasting to happen over the things you mark with indices?","user":"UD0NS8PDF","ts":"1617031204.056300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KaO5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"although perhaps ideally it would figure out that you only intend broadcasting to happen over the things you mark with indices?"}]}]}]},{"client_msg_id":"2df9cd5d-9491-4e36-becb-d039a656a289","type":"message","text":"(There might be more efficient ways of doing this, too.)","user":"UD0NS8PDF","ts":"1617031208.056500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1154a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(There might be more efficient ways of doing this, too.)"}]}]}]}]}