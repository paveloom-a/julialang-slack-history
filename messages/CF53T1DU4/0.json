{"cursor": 0, "messages": [{"client_msg_id":"2d884b8f-de6c-48ac-bdea-871c4ef24636","type":"message","text":"Is appropriate to mention ~6% performance loss on nightly (as compared to 1.5.3), even if so, it might be hard to strip it down to a small metric. Or is this something to do once there's an alpha, etc.","user":"ULTB7E6UW","ts":"1607980182.098000","team":"T68168MUP","edited":{"user":"ULTB7E6UW","ts":"1607980205.000000"},"blocks":[{"type":"rich_text","block_id":"6WM9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is appropriate to mention ~6% performance loss on nightly (as compared to 1.5.3), even if so, it might be hard to strip it down to a small metric. Or is this something to do once there's an alpha, etc."}]}]}]},{"client_msg_id":"b2731467-5773-4ea5-86f8-db55eb37a958","type":"message","text":"If you have a reproducible example (best small and self-contained)","user":"U67BJLYCS","ts":"1607980532.098700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1tC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you have a reproducible example (best small and self-contained)"}]}]}],"thread_ts":"1607980532.098700","reply_count":27,"reply_users_count":2,"latest_reply":"1607994990.104300","reply_users":["ULTB7E6UW","U67BJLYCS"],"subscribed":false},{"client_msg_id":"3f97b8d5-4090-4cd7-ac5b-0f304ad1781e","type":"message","text":"then yes, please open an issue","user":"U67BJLYCS","ts":"1607980542.099000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+ZcN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"then yes, please open an issue"}]}]}],"thread_ts":"1607980542.099000","reply_count":1,"reply_users_count":1,"latest_reply":"1608154024.115800","reply_users":["ULTB7E6UW"],"subscribed":false},{"client_msg_id":"778dd2d1-9a9e-4be9-bead-dc77d9bc01a0","type":"message","text":"I posted the following in <#C6A044SQH|helpdesk>, but someone mentioned this channel, so I'll just paste it below:\n\nI coded up 3 solutions to Day 15 of Advent of Code (spoilers), and got the following timings:\n<https://github.com/lojic/LearningRacket/blob/master/advent-of-code-2020/day15-unsafe-vector.rkt|Racket w/ unsafe vector/arithmetic> =&gt; 0.68 seconds\n<https://github.com/lojic/LearningRacket/blob/master/advent-of-code-2020/day15.c|C version> =&gt; 0.47 seconds\n<https://github.com/lojic/LearningRacket/blob/master/advent-of-code-2020/day15.jl|Julia w/ mutable vector> =&gt; 0.41 seconds\nI was impressed that Julia was faster than C. On the one hand, I haven't coded C seriously since 1996, but on the other, I'm very much a Julia newbie.\n\nI'm just curious if an experienced Julia coder can spot any obvious inefficiencies in the <https://github.com/lojic/LearningRacket/blob/master/advent-of-code-2020/day15.jl|little Julia program> - even though it came in faster than C, that doesn't mean I wouldn't like it to be faster :slightly_smiling_face:","user":"U014ATN949F","ts":"1608079617.105300","team":"T68168MUP","edited":{"user":"U014ATN949F","ts":"1608133861.000000"},"blocks":[{"type":"rich_text","block_id":"DvIU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I posted the following in "},{"type":"channel","channel_id":"C6A044SQH"},{"type":"text","text":", but someone mentioned this channel, so I'll just paste it below:\n\nI coded up 3 solutions to Day 15 of Advent of Code (spoilers), and got the following timings:\n"},{"type":"link","url":"https://github.com/lojic/LearningRacket/blob/master/advent-of-code-2020/day15-unsafe-vector.rkt","text":"Racket w/ unsafe vector/arithmetic"},{"type":"text","text":" => 0.68 seconds\n"},{"type":"link","url":"https://github.com/lojic/LearningRacket/blob/master/advent-of-code-2020/day15.c","text":"C version"},{"type":"text","text":" => 0.47 seconds\n"},{"type":"link","url":"https://github.com/lojic/LearningRacket/blob/master/advent-of-code-2020/day15.jl","text":"Julia w/ mutable vector"},{"type":"text","text":" => 0.41 seconds\nI was impressed that Julia was faster than C. On the one hand, I haven't coded C seriously since 1996, but on the other, I'm very much a Julia newbie.\n\nI'm just curious if an experienced Julia coder can spot any obvious inefficiencies in the "},{"type":"link","url":"https://github.com/lojic/LearningRacket/blob/master/advent-of-code-2020/day15.jl","text":"little Julia program"},{"type":"text","text":" - even though it came in faster than C, that doesn't mean I wouldn't like it to be faster "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"thread_ts":"1608079617.105300","reply_count":33,"reply_users_count":6,"latest_reply":"1608400503.142400","reply_users":["UD0NS8PDF","U014ATN949F","U0179G7FG4F","U7HAYKY9X","UH24GRBLL","UB7JS9CHF"],"subscribed":false},{"client_msg_id":"21ba142e-6d2e-4446-aae1-07ab427f9059","type":"message","text":"So, I'm looking at the Julia  <https://github.com/JuliaLang/julia/issues/29841|#29841>, where I learned that `HTML` and `Text` are errors and would be removed from Julia 2.0.   So, I've been looking to replace them with local code as advised (since <https://github.com/JuliaLang/julia/pull/38892|pull #38892> was denied).   Here is the code in question.\n```mutable struct Text{T}\n    content::T\nend\n\nBase.print(io::IO, t::Text) = print(io, t.content)\nBase.print(io::IO, t::Text{&lt;:Function}) = t.content(io)\nBase.show(io::IO, t::Text) = print(io, t)```\nWhen I do a straight-up replacement, calling this type `Reprint` (let's say), it seems to work.  At first I thought it was slower; but I think that's a sampling error on an imperfect laptop.  I have a question.\n\n1. When I drop \"mutable\" things get slower, almost 40% slower.\n2. If I replace `content::T` with `content::Function` things also get much slower.\nI'm using this in a `Text() do io ... end` style, so I was seeing if it could be improved or simplified.  I guess not?  What are the impacts of using `{T}`?\nSorry for the multiple edits (slack UI is frustrating).","user":"ULTB7E6UW","ts":"1608159461.119200","team":"T68168MUP","edited":{"user":"ULTB7E6UW","ts":"1608160314.000000"},"blocks":[{"type":"rich_text","block_id":"/dQf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So, I'm looking at the Julia  "},{"type":"link","url":"https://github.com/JuliaLang/julia/issues/29841","text":"#29841"},{"type":"text","text":", where I learned that "},{"type":"text","text":"HTML","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"Text","style":{"code":true}},{"type":"text","text":" are errors and would be removed from Julia 2.0.   So, I've been looking to replace them with local code as advised (since "},{"type":"link","url":"https://github.com/JuliaLang/julia/pull/38892","text":"pull #38892"},{"type":"text","text":" was denied).   Here is the code in question.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"mutable struct Text{T}\n    content::T\nend\n\nBase.print(io::IO, t::Text) = print(io, t.content)\nBase.print(io::IO, t::Text{<:Function}) = t.content(io)\nBase.show(io::IO, t::Text) = print(io, t)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"When I do a straight-up replacement, calling this type "},{"type":"text","text":"Reprint","style":{"code":true}},{"type":"text","text":" (let's say), it seems to work.  At first I thought it was slower; but I think that's a sampling error on an imperfect laptop.  I have a question.\n\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"When I drop \"mutable\" things get slower, almost 40% slower."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"If I replace "},{"type":"text","text":"content::T","style":{"code":true}},{"type":"text","text":" with "},{"type":"text","text":"content::Function","style":{"code":true}},{"type":"text","text":" things also get much slower."}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"\nI'm using this in a "},{"type":"text","text":"Text() do io ... end","style":{"code":true}},{"type":"text","text":" style, so I was seeing if it could be improved or simplified.  I guess not?  What are the impacts of using "},{"type":"text","text":"{T}","style":{"code":true}},{"type":"text","text":"?\nSorry for the multiple edits (slack UI is frustrating)."}]}]}],"thread_ts":"1608159461.119200","reply_count":70,"reply_users_count":2,"latest_reply":"1608164821.136600","reply_users":["ULTB7E6UW","U0179G7FG4F"],"subscribed":false},{"client_msg_id":"8fbf43e1-574f-4e16-97ec-71fb6c3218ea","type":"message","text":"Are there usually issues with type inference when shadowing local variables? Consider this relatively nonsensical example:\n```module Stuff\nfunction solve_b(filename)\n    your = Vector{Int}()\n    _nearby = Vector{Vector{Int}}()\n    ruledict = Dict{String, Vector{UnitRange}}()\n    nearby = filter(true, _nearby)\n    Dict(\n        rulename =&gt; Set(filter(_ -&gt; all(true, nearby), 1:length(your)))\n        for rulename in ruledict\n    )\nend\nend```\nThere are no issues when you run `@code_warntype Stuff.solve_b(\"a\")`, but if `_nearby` is changed to `nearby`, then it infers `nearby@_6::Core.Box` and `nearby@_8::Union{}` instead of `Vector{Vector{Int64}}` as it's supposed to.","user":"UC81ESVH6","ts":"1608159805.120800","team":"T68168MUP","edited":{"user":"UC81ESVH6","ts":"1608161244.000000"},"blocks":[{"type":"rich_text","block_id":"FuXcB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there usually issues with type inference when shadowing local variables? Consider this relatively nonsensical example:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"module Stuff\nfunction solve_b(filename)\n    your = Vector{Int}()\n    _nearby = Vector{Vector{Int}}()\n    ruledict = Dict{String, Vector{UnitRange}}()\n    nearby = filter(true, _nearby)\n    Dict(\n        rulename => Set(filter(_ -> all(true, nearby), 1:length(your)))\n        for rulename in ruledict\n    )\nend\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"There are no issues when you run "},{"type":"text","text":"@code_warntype Stuff.solve_b(\"a\")","style":{"code":true}},{"type":"text","text":", but if "},{"type":"text","text":"_nearby","style":{"code":true}},{"type":"text","text":" is changed to "},{"type":"text","text":"nearby","style":{"code":true}},{"type":"text","text":", then it infers "},{"type":"text","text":"nearby@_6::Core.Box","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"nearby@_8::Union{}","style":{"code":true}},{"type":"text","text":" instead of "},{"type":"text","text":"Vector{Vector{Int64}}","style":{"code":true}},{"type":"text","text":" as it's supposed to."}]}]}],"thread_ts":"1608159805.120800","reply_count":3,"reply_users_count":1,"latest_reply":"1608163294.130800","reply_users":["U67BJLYCS"],"subscribed":false},{"client_msg_id":"098d0cf6-d109-41cc-a560-36f954d58aaa","type":"message","text":"TranscodingStreams.jl is the best bet we have for very fast IO buffering, right? It seems like some performance is still left on the table:\nComparing this\n```function bufferfile(path, buffer::Vector{UInt8})\n    rdr = NoopStream(open(path))\n    while !eof(rdr)\n        readbytes!(rdr, buffer)\n    end\nend```\nwith `cat my_file &gt; /dev/null` , I get 370 ms for TranscodingStreams and 240 ms for `cat` . Does anyone know if a thorough optimization has been attempted?","user":"U7HAYKY9X","ts":"1608240108.139500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3wJn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"TranscodingStreams.jl is the best bet we have for very fast IO buffering, right? It seems like some performance is still left on the table:\nComparing this\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function bufferfile(path, buffer::Vector{UInt8})\n    rdr = NoopStream(open(path))\n    while !eof(rdr)\n        readbytes!(rdr, buffer)\n    end\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"with "},{"type":"text","text":"cat my_file > /dev/null","style":{"code":true}},{"type":"text","text":" , I get 370 ms for TranscodingStreams and 240 ms for "},{"type":"text","text":"cat","style":{"code":true}},{"type":"text","text":" . Does anyone know if a thorough optimization has been attempted?"}]}]}],"thread_ts":"1608240108.139500","reply_count":12,"reply_users_count":3,"latest_reply":"1608319538.142000","reply_users":["UH24GRBLL","U7HAYKY9X","U01GRS159T8"],"subscribed":false},{"client_msg_id":"8cfdea73-ff2d-4724-b473-e38adf55faa1","type":"message","text":"In which case running `GC.gc()` manually not really run the gc in the backend ?\nI have disabled gc by running `GC.enable(false)` first and then calling GC.gc() manually","user":"U01GZQ6B0JU","ts":"1608532265.145000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xUn6X","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In which case running "},{"type":"text","text":"GC.gc()","style":{"code":true}},{"type":"text","text":" manually not really run the gc in the backend ?\nI have disabled gc by running "},{"type":"text","text":"GC.enable(false) ","style":{"code":true}},{"type":"text","text":"first and then calling GC.gc() manually"}]}]}],"thread_ts":"1608532265.145000","reply_count":3,"reply_users_count":2,"latest_reply":"1608532740.145600","reply_users":["U0179G7FG4F","U01GZQ6B0JU"],"subscribed":false},{"client_msg_id":"4baa4893-1ef7-4e55-ada9-167090e2c74f","type":"message","text":"hi","user":"UTAQ23XTR","ts":"1608559692.146000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"72q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hi"}]}]}],"reactions":[{"name":"wave","users":["U7HAYKY9X","UH24GRBLL"],"count":2}]},{"client_msg_id":"56fccb0f-dd1e-43d0-9215-60ac601c0de1","type":"message","text":"I am attempting to translate some python code to julia to speed it up. But maybe as it's almost christmas I could just give it as a puzzle.","user":"UTAQ23XTR","ts":"1608560858.146900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eXPR9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am attempting to translate some python code to julia to speed it up. But maybe as it's almost christmas I could just give it as a puzzle."}]}]}],"thread_ts":"1608560858.146900","reply_count":107,"reply_users_count":4,"latest_reply":"1608649127.172200","reply_users":["U0179G7FG4F","UTAQ23XTR","UH24GRBLL","UDD5Z7FLZ"],"subscribed":false},{"client_msg_id":"4a8f2f20-8da9-42e9-9b65-18bf8a5a0891","type":"message","text":"Here it is: Given the string aaaaaaaaaa and an alphabet of size 100, find all other strings with edit (Levenshtein) distance at most 2. Your code must run in less than 1 second.  There are 1631129 distinct such strings","user":"UTAQ23XTR","ts":"1608560908.147500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6Rg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Here it is: Given the string aaaaaaaaaa and an alphabet of size 100, find all other strings with edit (Levenshtein) distance at most 2. Your code must run in less than 1 second.  There are 1631129 distinct such strings"}]}]}]},{"client_msg_id":"49c077da-71a4-42c7-a86c-ec79d68cc2f9","type":"message","text":"Ideally the code would only output the distinct strings but that is not necessary to win the prize :slightly_smiling_face:","user":"UTAQ23XTR","ts":"1608560933.148000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VmuNC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ideally the code would only output the distinct strings but that is not necessary to win the prize "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"there are only 95 printable ASCII characters...","user":"UH24GRBLL","ts":"1608561577.149300","thread_ts":"1608560858.146900","root":{"client_msg_id":"56fccb0f-dd1e-43d0-9215-60ac601c0de1","type":"message","text":"I am attempting to translate some python code to julia to speed it up. But maybe as it's almost christmas I could just give it as a puzzle.","user":"UTAQ23XTR","ts":"1608560858.146900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eXPR9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am attempting to translate some python code to julia to speed it up. But maybe as it's almost christmas I could just give it as a puzzle."}]}]}],"thread_ts":"1608560858.146900","reply_count":107,"reply_users_count":4,"latest_reply":"1608649127.172200","reply_users":["U0179G7FG4F","UTAQ23XTR","UH24GRBLL","UDD5Z7FLZ"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"F0sjL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"there are only 95 printable ASCII characters..."}]}]}],"client_msg_id":"01f58c3d-e40c-48b2-a020-52ab028e7bc2"},{"client_msg_id":"b31b26ad-193d-47c8-8f6b-a2946097c724","type":"message","text":"My code was taking 2 hours 40 mins to run and now it takes 7 minutes :star-struck:.","user":"UDSG73JTH","ts":"1608580172.162200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wT3J","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My code was taking 2 hours 40 mins to run and now it takes 7 minutes "},{"type":"emoji","name":"star-struck"},{"type":"text","text":"."}]}]}],"thread_ts":"1608580172.162200","reply_count":2,"reply_users_count":2,"latest_reply":"1608585656.162800","reply_users":["U0179G7FG4F","UDSG73JTH"],"subscribed":false},{"client_msg_id":"a0c70155-54aa-4266-bfce-642164dc5aa1","type":"message","text":"Just out of curiosity: On the systems have access to, allocations larger than 16 KiB take two operations:\n```julia&gt; @time Vector{UInt8}(undef, 2^14 - 1);\n  0.000005 seconds (1 allocation: 16.125 KiB)\n\njulia&gt; @time Vector{UInt8}(undef, 2^14);\n  0.000006 seconds (2 allocations: 16.141 KiB)\n\njulia&gt; @time Vector{UInt8}(undef, 2^40);\n  0.008465 seconds (2 allocations: 1.000 TiB, 99.61% gc time)```\nDoes this mean that the array is no longer contiguous in memory? What sets this limit? Hardware, OS, LLVM, or julia?","user":"U01DD7Z0D89","ts":"1608742654.177700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sbMEx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just out of curiosity: On the systems have access to, allocations larger than 16 KiB take two operations:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @time Vector{UInt8}(undef, 2^14 - 1);\n  0.000005 seconds (1 allocation: 16.125 KiB)\n\njulia> @time Vector{UInt8}(undef, 2^14);\n  0.000006 seconds (2 allocations: 16.141 KiB)\n\njulia> @time Vector{UInt8}(undef, 2^40);\n  0.008465 seconds (2 allocations: 1.000 TiB, 99.61% gc time)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Does this mean that the array is no longer contiguous in memory? What sets this limit? Hardware, OS, LLVM, or julia?"}]}]}],"thread_ts":"1608742654.177700","reply_count":1,"reply_users_count":1,"latest_reply":"1608742835.177800","reply_users":["U0179G7FG4F"],"subscribed":false},{"client_msg_id":"37a19605-0c34-4710-8d56-332eaa6a2fd9","type":"message","text":"hi all","user":"UTAQ23XTR","ts":"1608998510.182200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3+Ul","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hi all"}]}]}],"thread_ts":"1608998510.182200","reply_count":1,"reply_users_count":1,"latest_reply":"1608998540.182300","reply_users":["U7HAYKY9X"],"subscribed":false},{"client_msg_id":"e1a77c61-12be-4aab-a362-3c5c96d34348","type":"message","text":"it would be great if there were more/some Julia answers on <http://codegolf.stackexchange.com|codegolf.stackexchange.com> for fastest-code questions.","user":"UTAQ23XTR","ts":"1609002646.183400","team":"T68168MUP","edited":{"user":"UTAQ23XTR","ts":"1609002661.000000"},"blocks":[{"type":"rich_text","block_id":"kx0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it would be great if there were more/some Julia answers on "},{"type":"link","url":"http://codegolf.stackexchange.com","text":"codegolf.stackexchange.com"},{"type":"text","text":" for fastest-code questions."}]}]}]},{"client_msg_id":"7f7a2c00-9ab1-4bd2-bcfd-adac86a282b6","type":"message","text":"My main issue with such questions is that it sometimes veers into the \"this-looks-like-homework\" territory, and I would be a little hesitant to help.","user":"UDD5Z7FLZ","ts":"1609014202.186300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IO8i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My main issue with such questions is that it sometimes veers into the \"this-looks-like-homework\" territory, and I would be a little hesitant to help."}]}]}]},{"client_msg_id":"7e136000-a164-491e-a412-59320db940b8","type":"message","text":"I wrote a simple function to sum integers from 1 to n as a simple test of BigInt:\n```function sum_n(n::BigInt)::BigInt\n  val = BigInt(0)\n\n  while n &gt; 0\n    val += n\n    n -=  1\n  end\n\n  val\nend\nsum_n(BigInt(10))\n@time println(sum_n(BigInt(6000000))) # 6 Million```\nIt takes roughly 2.2 seconds to sum 6M numbers. By comparison, the following Racket function can sum 1B numbers in about the same amount of time. The Julia code has 30M in allocations which seems crazy. Does the BigInt implementation allocate a new BigInt for each arithmetic operation?\n```(define (sum-n n [result 0])\n  (if (&gt; n 0) \n      (sum-n (- n 1) (+ result n))\n      result))\n\n(time (sum-n 1000000000)) ; 1 Billion```","user":"U014ATN949F","ts":"1609015995.188900","team":"T68168MUP","edited":{"user":"U014ATN949F","ts":"1609016087.000000"},"blocks":[{"type":"rich_text","block_id":"cIfOH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I wrote a simple function to sum integers from 1 to n as a simple test of BigInt:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function sum_n(n::BigInt)::BigInt\n  val = BigInt(0)\n\n  while n > 0\n    val += n\n    n -=  1\n  end\n\n  val\nend\nsum_n(BigInt(10))\n@time println(sum_n(BigInt(6000000))) # 6 Million"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"It takes roughly 2.2 seconds to sum 6M numbers. By comparison, the following Racket function can sum 1B numbers in about the same amount of time. The Julia code has 30M in allocations which seems crazy. Does the BigInt implementation allocate a new BigInt for each arithmetic operation?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"(define (sum-n n [result 0])\n  (if (> n 0) \n      (sum-n (- n 1) (+ result n))\n      result))\n\n(time (sum-n 1000000000)) ; 1 Billion"}]}]}],"thread_ts":"1609015995.188900","reply_count":46,"reply_users_count":5,"latest_reply":"1609017193.198800","reply_users":["UH24GRBLL","U014ATN949F","U7HAYKY9X","UDD5Z7FLZ","UD0NS8PDF"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"should `write(io, 1234)` allocate?","user":"UH24GRBLL","ts":"1609275144.246300","thread_ts":"1608240108.139500","root":{"client_msg_id":"098d0cf6-d109-41cc-a560-36f954d58aaa","type":"message","text":"TranscodingStreams.jl is the best bet we have for very fast IO buffering, right? It seems like some performance is still left on the table:\nComparing this\n```function bufferfile(path, buffer::Vector{UInt8})\n    rdr = NoopStream(open(path))\n    while !eof(rdr)\n        readbytes!(rdr, buffer)\n    end\nend```\nwith `cat my_file &gt; /dev/null` , I get 370 ms for TranscodingStreams and 240 ms for `cat` . Does anyone know if a thorough optimization has been attempted?","user":"U7HAYKY9X","ts":"1608240108.139500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3wJn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"TranscodingStreams.jl is the best bet we have for very fast IO buffering, right? It seems like some performance is still left on the table:\nComparing this\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function bufferfile(path, buffer::Vector{UInt8})\n    rdr = NoopStream(open(path))\n    while !eof(rdr)\n        readbytes!(rdr, buffer)\n    end\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"with "},{"type":"text","text":"cat my_file > /dev/null","style":{"code":true}},{"type":"text","text":" , I get 370 ms for TranscodingStreams and 240 ms for "},{"type":"text","text":"cat","style":{"code":true}},{"type":"text","text":" . Does anyone know if a thorough optimization has been attempted?"}]}]}],"thread_ts":"1608240108.139500","reply_count":52,"reply_users_count":3,"latest_reply":"1609275155.246600","reply_users":["UH24GRBLL","U7HAYKY9X","U01GRS159T8"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"GeR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"should "},{"type":"text","text":"write(io, 1234)","style":{"code":true}},{"type":"text","text":" allocate?"}]}]}],"client_msg_id":"1007e5bd-1825-4639-8b12-135136e5da00"},{"client_msg_id":"0a390832-7399-4f7b-9a00-c72225a5794f","type":"message","text":"I have a function like this (what it does isn't really important):\n```function stabilize(curr, tolerance, distance=maximum(size(curr)))\n    prev = nothing\n    while prev != curr\n        prev = deepcopy(curr)\n        for I in CartesianIndices(curr)\n            prev[I] == 'L' &amp;&amp; count_occupied(prev, I, distance) == 0         &amp;&amp; (curr[I] = '#')\n            prev[I] == '#' &amp;&amp; count_occupied(prev, I, distance) &gt;= tolerance &amp;&amp; (curr[I] = 'L')\n        end\n    end\n    count(==('#'), curr)\nend```\nAnd it takes this long to run:\n```julia&gt; @btime stabilize(......, 4, 1)\n  38.350 ms (720 allocations: 4.00 MiB)```\nBut the moment I replace `tolerance` and `distance` with the respective values in the function I see an improvement:\n```julia&gt; @btime stabilize(......)\n  13.499 ms (720 allocations: 4.00 MiB)```\nWhy is this the case?","user":"UC81ESVH6","ts":"1609280309.249400","team":"T68168MUP","edited":{"user":"UC81ESVH6","ts":"1609280384.000000"},"blocks":[{"type":"rich_text","block_id":"H9Z6C","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a function like this (what it does isn't really important):\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function stabilize(curr, tolerance, distance=maximum(size(curr)))\n    prev = nothing\n    while prev != curr\n        prev = deepcopy(curr)\n        for I in CartesianIndices(curr)\n            prev[I] == 'L' && count_occupied(prev, I, distance) == 0         && (curr[I] = '#')\n            prev[I] == '#' && count_occupied(prev, I, distance) >= tolerance && (curr[I] = 'L')\n        end\n    end\n    count(==('#'), curr)\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"And it takes this long to run:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @btime stabilize(......, 4, 1)\n  38.350 ms (720 allocations: 4.00 MiB)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"But the moment I replace "},{"type":"text","text":"tolerance","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"distance","style":{"code":true}},{"type":"text","text":" with the respective values in the function I see an improvement:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @btime stabilize(......)\n  13.499 ms (720 allocations: 4.00 MiB)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Why is this the case?"}]}]}],"thread_ts":"1609280309.249400","reply_count":7,"reply_users_count":3,"latest_reply":"1609282422.250900","reply_users":["UH24GRBLL","UC81ESVH6","U01GMP3HF9C"],"subscribed":false},{"client_msg_id":"964d3841-c6d5-44e7-99fe-5925b196e25e","type":"message","text":"Hello all, I'm trying to optimize the following code. Essentially, I'm want to find the minimum value from `value` for each unique combination of 2 vectors (for the purposes of this code, v1 = 1 and v2 = 2 is the same as v1 = 2 and v2 = 1, which is why I do that hacky part with `min` and `max`). I need to scale this up pretty massively, so I'm hoping to find ways to speed it up. Any suggestions? Thanks very much!!\n```using Base.Threads\n# Vector 1\nv1 = rand(collect(1:1000), 100000)\n# Vector 2\nv2 = rand(collect(1:1000), 100000)\n# Values\nvalue = rand(100000)\n\n# Get unique combos of v1 and v2\nminv = min.(v1, v2)\nmaxv = max.(v1, v2)\nunique_combos = unique(tuple.(minv, maxv))\nn_unique = length(unique_combos)\n\n# init a vector to house minimum of `value` per unique v1 and v2 combination\nvalue_mins = Vector{Float64}(undef, n_unique)\n\n# loop through to find minimum per unique group\n@threads for i in 1:n_unique\n    unique_combo = unique_combos[i]\n    min_value_for_combo_i = minimum(value[(minv .== unique_combo[1]) .&amp; (maxv .== unique_combo[2])])\n    value_mins[i] = min_value_for_combo_i\nend```","user":"U011NV8FNF7","ts":"1609287683.257400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JQpt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello all, I'm trying to optimize the following code. Essentially, I'm want to find the minimum value from "},{"type":"text","text":"value","style":{"code":true}},{"type":"text","text":" for each unique combination of 2 vectors (for the purposes of this code, v1 = 1 and v2 = 2 is the same as v1 = 2 and v2 = 1, which is why I do that hacky part with "},{"type":"text","text":"min","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"max","style":{"code":true}},{"type":"text","text":"). I need to scale this up pretty massively, so I'm hoping to find ways to speed it up. Any suggestions? Thanks very much!!\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Base.Threads\n# Vector 1\nv1 = rand(collect(1:1000), 100000)\n# Vector 2\nv2 = rand(collect(1:1000), 100000)\n# Values\nvalue = rand(100000)\n\n# Get unique combos of v1 and v2\nminv = min.(v1, v2)\nmaxv = max.(v1, v2)\nunique_combos = unique(tuple.(minv, maxv))\nn_unique = length(unique_combos)\n\n# init a vector to house minimum of `value` per unique v1 and v2 combination\nvalue_mins = Vector{Float64}(undef, n_unique)\n\n# loop through to find minimum per unique group\n@threads for i in 1:n_unique\n    unique_combo = unique_combos[i]\n    min_value_for_combo_i = minimum(value[(minv .== unique_combo[1]) .& (maxv .== unique_combo[2])])\n    value_mins[i] = min_value_for_combo_i\nend"}]}]}],"thread_ts":"1609287683.257400","reply_count":4,"reply_users_count":2,"latest_reply":"1609326180.258400","reply_users":["UDD5Z7FLZ","U01GMP3HF9C"],"subscribed":false},{"client_msg_id":"be34b342-27bf-423f-9c7f-06c335bf262b","type":"message","text":"Which types of operations is julia still lacking behind compared with C in terms of preformamce?\nAre these performance issues related to inherent issues with Julia or simply due to julias relative immaturity?","user":"U01FAHWCMFF","ts":"1609345469.261100","team":"T68168MUP","edited":{"user":"U01FAHWCMFF","ts":"1609345524.000000"},"blocks":[{"type":"rich_text","block_id":"8WzB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Which types of operations is julia still lacking behind compared with C in terms of preformamce?\nAre these performance issues related to inherent issues with Julia or simply due to julias relative immaturity?"}]}]}]},{"type":"message","text":"Come compete for a $10 starbucks gift card by being the first to solve my performance issue","user":"U01FAHWCMFF","ts":"1609366811.265400","team":"T68168MUP","edited":{"user":"U01FAHWCMFF","ts":"1609366852.000000"},"attachments":[{"fallback":"[December 30th, 2020 5:09 PM] ayman: If anyone manages to get rid of the last forloop with mapping, without using `MappedArrays.jl`  or any library that doesn't come shipped with Julia (e.g. Statistics.jl is allowed, GLM.jl isnt), *with the same performance*, I will give you a $10 starbucks gift card. First person to do so wins. Have fun all :slightly_smiling_face:\n```function pairwise_analysis2(x::Array{Int16, 2})\n    m, n = size(x)\n    mean_matrix = Matrix{Float64}(undef, (n, n))\n    @views @inbounds for i = 1:n\n        for j = 1:n\n            total::Int16 = 0\n            for k = 1:m\n                total += x[k, i] == x[k, j]\n            end\n            mean_matrix[i, j] = total / m\n        end\n    end\n    return mean_matrix\nend\n\nX = Array{Int16}(rand(0:1, (1000, 1000)));\n@btime pairwise_analysis(X)```","ts":"1609366179.234900","author_id":"U01FAHWCMFF","author_subname":"Ayman Al Baz","channel_id":"C67TK21LJ","channel_name":"gripes","is_msg_unfurl":true,"is_reply_unfurl":true,"text":"If anyone manages to get rid of the last forloop with mapping, without using `MappedArrays.jl`  or any library that doesn't come shipped with Julia (e.g. Statistics.jl is allowed, GLM.jl isnt), *with the same performance*, I will give you a $10 starbucks gift card. First person to do so wins. Have fun all :slightly_smiling_face:\n```function pairwise_analysis2(x::Array{Int16, 2})\n    m, n = size(x)\n    mean_matrix = Matrix{Float64}(undef, (n, n))\n    @views @inbounds for i = 1:n\n        for j = 1:n\n            total::Int16 = 0\n            for k = 1:m\n                total += x[k, i] == x[k, j]\n            end\n            mean_matrix[i, j] = total / m\n        end\n    end\n    return mean_matrix\nend\n\nX = Array{Int16}(rand(0:1, (1000, 1000)));\n@btime pairwise_analysis(X)```","author_name":"Ayman Al Baz","author_link":"https://julialang.slack.com/team/U01FAHWCMFF","author_icon":"https://avatars.slack-edge.com/2020-11-23/1516965530134_1cf6ed3767c34aaf6d40_48.png","mrkdwn_in":["text"],"color":"D0D0D0","from_url":"https://julialang.slack.com/archives/C67TK21LJ/p1609366179234900?thread_ts=1609362482231100&cid=C67TK21LJ","is_share":true,"footer":"From a thread in #gripes"}],"blocks":[{"type":"rich_text","block_id":"cgZ5M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Come compete for a $10 starbucks gift card by being the first to solve my performance issue"}]}]}]},{"client_msg_id":"4b492bfb-da24-4057-85b8-2a5c0239793b","type":"message","text":"<@UDD5Z7FLZ>  I guess if you answer slowly enough any homework deadline will have passed :)","user":"UTAQ23XTR","ts":"1609445310.283500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8enX=","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UDD5Z7FLZ"},{"type":"text","text":"  I guess if you answer slowly enough any homework deadline will have passed :)"}]}]}],"thread_ts":"1609445310.283500","reply_count":3,"reply_users_count":2,"latest_reply":"1609445879.284000","reply_users":["UDD5Z7FLZ","UTAQ23XTR"],"subscribed":false},{"client_msg_id":"36d87105-e9da-4cc1-b965-26d187398af0","type":"message","text":"Hi all. I have a question about getting good performance out of threading. I don't have a really minimal example, but can point you to a repo with the code (~200 lines):\n\n<https://github.com/vancleve/threading_example>\n\nOn my macbookpro, running the `@time evolve_replicates!(pop, rp)` from <https://github.com/vancleve/threading_example/blob/master/popsim.jl#L30>\nI get something like (after running once to compile)\nno threads  `3.936467 seconds (7.94 M allocations: 4.620 GiB, 14.60% gc time)`\n1 thread      `3.890999 seconds (7.94 M allocations: 4.620 GiB, 16.57% gc time)`\n2 threads    `2.340651 seconds (7.94 M allocations: 4.620 GiB, 25.03% gc time)`\n4 threads    `1.786248 seconds (7.94 M allocations: 4.620 GiB, 41.74% gc time)`\n8 threads    `1.658927 seconds (7.96 M allocations: 4.621 GiB, 58.21% gc time)`\n\nHere are flame graphs for 1 thread (left) and 8 threads (right).\n\nI know I have to reduce allocations, but was hoping to get some advice how best to do this since quite of a bit of the allocation time is coming in basic linear algebra stuff like matrix division and using `I` as identity matrix.\n\nI've also thought about using `Distributed` but I ran into world age issues when passing functions to the workers...","user":"UKFUT8N5A","ts":"1609540973.289000","team":"T68168MUP","edited":{"user":"UKFUT8N5A","ts":"1609541695.000000"},"blocks":[{"type":"rich_text","block_id":"UGvV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all. I have a question about getting good performance out of threading. I don't have a really minimal example, but can point you to a repo with the code (~200 lines):\n\n"},{"type":"link","url":"https://github.com/vancleve/threading_example"},{"type":"text","text":"\n\nOn my macbookpro, running the "},{"type":"text","text":"@time evolve_replicates!(pop, rp)","style":{"code":true}},{"type":"text","text":" from "},{"type":"link","url":"https://github.com/vancleve/threading_example/blob/master/popsim.jl#L30"},{"type":"text","text":"\nI get something like (after running once to compile)\nno threads  "},{"type":"text","text":"3.936467 seconds (7.94 M allocations: 4.620 GiB, 14.60% gc time)","style":{"code":true}},{"type":"text","text":"\n1 thread      "},{"type":"text","text":"3.890999 seconds (7.94 M allocations: 4.620 GiB, 16.57% gc time)","style":{"code":true}},{"type":"text","text":"\n2 threads    "},{"type":"text","text":"2.340651 seconds (7.94 M allocations: 4.620 GiB, 25.03% gc time)","style":{"code":true}},{"type":"text","text":"\n4 threads    "},{"type":"text","text":"1.786248 seconds (7.94 M allocations: 4.620 GiB, 41.74% gc time)","style":{"code":true}},{"type":"text","text":"\n8 threads    "},{"type":"text","text":"1.658927 seconds (7.96 M allocations: 4.621 GiB, 58.21% gc time)","style":{"code":true}},{"type":"text","text":"\n\nHere are flame graphs for 1 thread (left) and 8 threads (right).\n\nI know I have to reduce allocations, but was hoping to get some advice how best to do this since quite of a bit of the allocation time is coming in basic linear algebra stuff like matrix division and using "},{"type":"text","text":"I","style":{"code":true}},{"type":"text","text":" as identity matrix.\n\nI've also thought about using "},{"type":"text","text":"Distributed","style":{"code":true}},{"type":"text","text":" but I ran into world age issues when passing functions to the workers..."}]}]}]},{"type":"message","text":"","files":[{"id":"F01HVUH9VU3","created":1609541094,"timestamp":1609541094,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UKFUT8N5A","editable":false,"size":440298,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HVUH9VU3/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HVUH9VU3/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HVUH9VU3-66bb381d09/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HVUH9VU3-66bb381d09/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HVUH9VU3-66bb381d09/image_360.png","thumb_360_w":360,"thumb_360_h":163,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HVUH9VU3-66bb381d09/image_480.png","thumb_480_w":480,"thumb_480_h":218,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HVUH9VU3-66bb381d09/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01HVUH9VU3-66bb381d09/image_720.png","thumb_720_w":720,"thumb_720_h":326,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01HVUH9VU3-66bb381d09/image_800.png","thumb_800_w":800,"thumb_800_h":363,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01HVUH9VU3-66bb381d09/image_960.png","thumb_960_w":960,"thumb_960_h":435,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01HVUH9VU3-66bb381d09/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":464,"original_w":3238,"original_h":1468,"thumb_tiny":"AwAVADDR2L/dFVMkdRV2oZIQ3TqTUtFJkP4igcehqX7P9KaYcMAO4qbMq6GbhnGBSqQTwBT/ACh523sRmnxRgAHHUUcorktFFFaEBSY+bPtilooATaN+7vjFKBgYFFFAH//Z","permalink":"https://julialang.slack.com/files/UKFUT8N5A/F01HVUH9VU3/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HVUH9VU3-a57f3c3707","is_starred":false,"has_rich_preview":false},{"id":"F01HNV0NTFY","created":1609541122,"timestamp":1609541122,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UKFUT8N5A","editable":false,"size":415089,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HNV0NTFY/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HNV0NTFY/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HNV0NTFY-3349dbff2d/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HNV0NTFY-3349dbff2d/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HNV0NTFY-3349dbff2d/image_360.png","thumb_360_w":360,"thumb_360_h":151,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HNV0NTFY-3349dbff2d/image_480.png","thumb_480_w":480,"thumb_480_h":201,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HNV0NTFY-3349dbff2d/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01HNV0NTFY-3349dbff2d/image_720.png","thumb_720_w":720,"thumb_720_h":302,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01HNV0NTFY-3349dbff2d/image_800.png","thumb_800_w":800,"thumb_800_h":335,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01HNV0NTFY-3349dbff2d/image_960.png","thumb_960_w":960,"thumb_960_h":402,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01HNV0NTFY-3349dbff2d/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":429,"original_w":3238,"original_h":1356,"thumb_tiny":"AwAUADDRZF2n5R+VVB6EYq7VaSFmfK4xUyRUWM/KjIHXFOaAqjM2OBmkKfut3TFTYrQTcD2FKCD2FNXBYDPU1YSMAkUJXB6EtFFFaGYdaQgYxjilooATaPQUtFFAH//Z","permalink":"https://julialang.slack.com/files/UKFUT8N5A/F01HNV0NTFY/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HNV0NTFY-fb2a1c796e","is_starred":false,"has_rich_preview":false}],"upload":false,"user":"UKFUT8N5A","ts":"1609541199.289200"},{"client_msg_id":"f8cbc126-a382-4696-8a81-ba33a7553958","type":"message","text":"I have a section of a `Vector{UInt8}` which corresponds to some text. I want to get the hash of that text - stripped from any whitespace is both ends. My current solution involves copying to a string, then calling `strip` , copying the result to another string, then using `crc32c` .\nIs there a way to do this more efficiently?","user":"U7HAYKY9X","ts":"1609876769.297000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4QrWV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a section of a "},{"type":"text","text":"Vector{UInt8}","style":{"code":true}},{"type":"text","text":" which corresponds to some text. I want to get the hash of that text - stripped from any whitespace is both ends. My current solution involves copying to a string, then calling "},{"type":"text","text":"strip","style":{"code":true}},{"type":"text","text":" , copying the result to another string, then using "},{"type":"text","text":"crc32c","style":{"code":true}},{"type":"text","text":" .\nIs there a way to do this more efficiently?"}]}]}],"thread_ts":"1609876769.297000","reply_count":4,"reply_users_count":2,"latest_reply":"1609877893.297700","reply_users":["U012XER8K4M","U7HAYKY9X"],"subscribed":false},{"type":"message","text":"Is there a sparse 2d data structure that supports random insertions of x,y coordinate pairs well, or a dense matrix data structure that grows in small (maybe 8 by 8) blocks when a new block gets written to?","user":"U9MD78Z9N","ts":"1609921521.298800","team":"T68168MUP"},{"client_msg_id":"b9c1be21-656b-40e2-a4bb-0aa28567ff28","type":"message","text":"When working with gzipped files, you can make it go faster by doing the (de)compression in a separate thread from the other computation. But I can't find any good packages for easy asynchronous/parallel (de)compression. Does such a package exist?","user":"U7HAYKY9X","ts":"1609932745.302100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hpY5i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"When working with gzipped files, you can make it go faster by doing the (de)compression in a separate thread from the other computation. But I can't find any good packages for easy asynchronous/parallel (de)compression. Does such a package exist?"}]}]}],"thread_ts":"1609932745.302100","reply_count":11,"reply_users_count":2,"latest_reply":"1609936069.304700","reply_users":["U6A936746","U7HAYKY9X"],"subscribed":false},{"client_msg_id":"a88591ab-bad4-4d56-ab5a-1adf45a23704","type":"message","text":"hmmm... I wonder if we can improve this <https://github.com/zero-one-group/geni/blob/develop/docs/simple_performance_benchmark.md>","user":"U013V2CFZAN","ts":"1609948057.305400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hTO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hmmm... I wonder if we can improve this "},{"type":"link","url":"https://github.com/zero-one-group/geni/blob/develop/docs/simple_performance_benchmark.md"}]}]}],"thread_ts":"1609948057.305400","reply_count":7,"reply_users_count":2,"latest_reply":"1609951222.306900","reply_users":["U013V2CFZAN","UH24GRBLL"],"subscribed":false},{"client_msg_id":"6229696a-662f-4440-ba0c-dd8bbb60f03f","type":"message","text":"Hi guys I managed to patch together an example using the 'indirectbr' llvm instruction, which is how computed gotos might be implemented.  Does anyone know how to turn this into a macro?","user":"U01GRS159T8","ts":"1609952031.308500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AtkW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys I managed to patch together an example using the 'indirectbr' llvm instruction, which is how computed gotos might be implemented.  Does anyone know how to turn this into a macro?"}]}]}],"thread_ts":"1609952031.308500","reply_count":2,"reply_users_count":1,"latest_reply":"1609952071.308800","reply_users":["U01GRS159T8"],"subscribed":false},{"type":"message","text":"Is there a way to hint/force a particular function call to be inlined? [Inlined from the caller site.]","user":"U9MD78Z9N","ts":"1610383922.313400","team":"T68168MUP","edited":{"user":"U9MD78Z9N","ts":"1610384693.000000"},"thread_ts":"1610383922.313400","reply_count":22,"reply_users_count":4,"latest_reply":"1610385597.318000","reply_users":["UAUPJLBQX","U9MD78Z9N","U0179G7FG4F","U67BJLYCS"],"subscribed":false},{"client_msg_id":"d78dcc8f-9490-4f0f-b68a-24ac96b5cf30","type":"message","text":"are there any tricks for converting an integer which respresents a fixed point decimal into a float the fastest possible way?  Is int_val * scale_factor the best you can do?","user":"U01GRS159T8","ts":"1610394662.321100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oVA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"are there any tricks for converting an integer which respresents a fixed point decimal into a float the fastest possible way?  Is int_val * scale_factor the best you can do?"}]}]}],"thread_ts":"1610394662.321100","reply_count":9,"reply_users_count":2,"latest_reply":"1610395609.323400","reply_users":["U7HAYKY9X","U01GRS159T8"],"subscribed":false},{"client_msg_id":"a4944fd3-9bfc-4a80-9721-f923e1ff7e8b","type":"message","text":"I'm trying to write a simple ode solver (like the ones <https://perso.crans.org/besson/publis/notebooks/Runge-Kutta_methods_for_ODE_integration_in_Julia.html|here>) but with a custom adaptive stepsize. What is a good way to pre-allocate the vectors given that I don't know how many steps I'll ultimately need?","user":"U91Q3595Y","ts":"1610401442.325100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cWG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm trying to write a simple ode solver (like the ones "},{"type":"link","url":"https://perso.crans.org/besson/publis/notebooks/Runge-Kutta_methods_for_ODE_integration_in_Julia.html","text":"here"},{"type":"text","text":") but with a custom adaptive stepsize. What is a good way to pre-allocate the vectors given that I don't know how many steps I'll ultimately need?"}]}]}],"thread_ts":"1610401442.325100","reply_count":26,"reply_users_count":4,"latest_reply":"1610403185.331600","reply_users":["U91Q3595Y","U0179G7FG4F","U9MED583T","U69BL50BF"],"subscribed":false},{"type":"message","text":"Assuming Julia properly inlines and the method is type stable. Are there any advantages to use value types to encourage a partial evaluation at compile time, if you call a function again and again with some arguments kept fixed and trusting constant propagation?","user":"U9MD78Z9N","ts":"1610403841.331800","team":"T68168MUP","edited":{"user":"U9MD78Z9N","ts":"1610404139.000000"}},{"client_msg_id":"65184213-14cf-4739-87d3-98a224964999","type":"message","text":"cross-posting <https://stackoverflow.com/questions/65786407/how-to-concatenate-apache-arrow-files-with-identical-structure-in-julia> since it seems like an interesting problem","user":"U0179G7FG4F","ts":"1611040656.015000","team":"T68168MUP","attachments":[{"service_name":"Stack Overflow","title":"How to concatenate Apache Arrow files with identical structure in julia","title_link":"https://stackoverflow.com/questions/65786407/how-to-concatenate-apache-arrow-files-with-identical-structure-in-julia","text":"How can I concatenate several Arrow files with identical structure into a single Arrow file without reading each file into memory? I am using Arrow.jl and the Arrow files represent dataframes with","fallback":"Stack Overflow: How to concatenate Apache Arrow files with identical structure in julia","thumb_url":"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded","from_url":"https://stackoverflow.com/questions/65786407/how-to-concatenate-apache-arrow-files-with-identical-structure-in-julia","thumb_width":316,"thumb_height":316,"service_icon":"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a","id":1,"original_url":"https://stackoverflow.com/questions/65786407/how-to-concatenate-apache-arrow-files-with-identical-structure-in-julia"}],"blocks":[{"type":"rich_text","block_id":"P+44z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"cross-posting "},{"type":"link","url":"https://stackoverflow.com/questions/65786407/how-to-concatenate-apache-arrow-files-with-identical-structure-in-julia"},{"type":"text","text":" since it seems like an interesting problem"}]}]}]},{"client_msg_id":"b976bdce-f924-49e1-879a-4fbc2f1107b8","type":"message","text":"<https://news.ycombinator.com/item?id=25825657>","user":"UDGT4PM41","ts":"1611103586.015300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H/s3","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://news.ycombinator.com/item?id=25825657"}]}]}]},{"client_msg_id":"731d9538-9799-4f46-ad62-263e57aef28b","type":"message","text":"if anyone wants to take a crack at that","user":"UDGT4PM41","ts":"1611103592.015500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T9E","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if anyone wants to take a crack at that"}]}]}],"thread_ts":"1611103592.015500","reply_count":1,"reply_users_count":1,"latest_reply":"1611103710.015600","reply_users":["USU9FRPEU"],"subscribed":false},{"client_msg_id":"fed300f3-4e1c-408f-a8ac-57c49460a7fa","type":"message","text":"Implemented a simple agent based SIR model in julia as it's been a long time since I've written anything agent based. Here is the main function, any low hanging fruit I am missing?\n```function agents_step!(u_next,u,graph,params,t,rand_gen)\n    @unpack p, recovery_rate  = params  \n    u_next .= u\n    for (v,agent) in enumerate(u)\n        if agent == Susceptible\n            for w in LightGraphs.neighbors(graph,v)\n                if u[w] == Infected &amp;&amp; rand(rand_gen) &lt; p\n                    u_next[v] = Infected\n                end\n            end\n        elseif agent == Infected\n            if rand(rand_gen) &lt; recovery_rate\n                u_next[v] = Recovered\n            end\n        end\n    end\nend```","user":"U011V2YN59N","ts":"1611109097.016900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Jmfh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Implemented a simple agent based SIR model in julia as it's been a long time since I've written anything agent based. Here is the main function, any low hanging fruit I am missing?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function agents_step!(u_next,u,graph,params,t,rand_gen)\n    @unpack p, recovery_rate  = params  \n    u_next .= u\n    for (v,agent) in enumerate(u)\n        if agent == Susceptible\n            for w in LightGraphs.neighbors(graph,v)\n                if u[w] == Infected && rand(rand_gen) < p\n                    u_next[v] = Infected\n                end\n            end\n        elseif agent == Infected\n            if rand(rand_gen) < recovery_rate\n                u_next[v] = Recovered\n            end\n        end\n    end\nend"}]}]}],"thread_ts":"1611109097.016900","reply_count":1,"reply_users_count":1,"latest_reply":"1611109637.019400","reply_users":["U011V2YN59N"],"subscribed":false},{"client_msg_id":"a1925297-1d7f-45b0-884f-93f5f31c2446","type":"message","text":"`rand_gen` is an Xorshift RNG, it's faster but not significantly so.","user":"U011V2YN59N","ts":"1611109187.017900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qdfUt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"rand_gen","style":{"code":true}},{"type":"text","text":" is an Xorshift RNG, it's faster but not significantly so."}]}]}]},{"client_msg_id":"5e878dde-c501-4bf5-a31b-b6610ea5221b","type":"message","text":"I'm also curious if anyone has had luck running ABMs on the GPU, it seems like there's too much branching for it to be efficient but I am not sure.","user":"U011V2YN59N","ts":"1611109602.019300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dEUCM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm also curious if anyone has had luck running ABMs on the GPU, it seems like there's too much branching for it to be efficient but I am not sure."}]}]}],"thread_ts":"1611109602.019300","reply_count":4,"reply_users_count":2,"latest_reply":"1611113730.020800","reply_users":["U0179G7FG4F","U011V2YN59N"],"subscribed":false},{"client_msg_id":"84fa04c2-a72e-41cc-b66a-c4f720703ef9","type":"message","text":"You could run that on GPU in DynamicGrids.jl in only a few lines of code. But it will be faster on threaded CPUs using `SparseOpt()`.","user":"URN898S15","ts":"1611121709.028100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ca/K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You could run that on GPU in DynamicGrids.jl in only a few lines of code. But it will be faster on threaded CPUs using "},{"type":"text","text":"SparseOpt()","style":{"code":true}},{"type":"text","text":"."}]}]}],"thread_ts":"1611121709.028100","reply_count":3,"reply_users_count":2,"latest_reply":"1611199810.000100","reply_users":["U011V2YN59N","URN898S15"],"subscribed":false},{"client_msg_id":"f753a398-ad73-4cc2-bba2-8b86bcdfd0db","type":"message","text":"Although I'm only guessing thats a grid based network from your code, I don't know how lightgraphs works :joy:","user":"URN898S15","ts":"1611121837.029200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vgut","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Although I'm only guessing thats a grid based network from your code, I don't know how lightgraphs works "},{"type":"emoji","name":"joy"}]}]}]},{"client_msg_id":"07a1b69d-af1f-47e1-839b-5740dd2dd19f","type":"message","text":"How long does a task need to take before it exceeds the time taken using the threading infrastructure? (Is it ~1 ms?)","user":"UDSG73JTH","ts":"1611220149.002700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kla/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How long does a task need to take before it exceeds the time taken using the threading infrastructure? (Is it ~1 ms?)"}]}]}],"thread_ts":"1611220149.002700","reply_count":6,"reply_users_count":3,"latest_reply":"1611240505.006100","reply_users":["U7HAYKY9X","UDSG73JTH","URN898S15"],"subscribed":false},{"client_msg_id":"468584d3-ae05-40dc-bbc9-26b2ff406991","type":"message","text":"I found a quick comparison code on github that was comparing C vs Java and decided to add Julia and python to the mix. The code is not pretty, but I was wondering if people could give me some feedback. Will post the code inside the thread.","user":"U013V2CFZAN","ts":"1611227612.005500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1DZK4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I found a quick comparison code on github that was comparing C vs Java and decided to add Julia and python to the mix. The code is not pretty, but I was wondering if people could give me some feedback. Will post the code inside the thread."}]}]}],"thread_ts":"1611227612.005500","reply_count":2,"reply_users_count":1,"latest_reply":"1611227688.005800","reply_users":["U013V2CFZAN"],"subscribed":false},{"client_msg_id":"7e4b6d12-09a8-4673-98b9-a145b7b65752","type":"message","text":"Do views into matrices impact the cache behavior? I was implementing some BLIS style matrix-matrix multiplies in Julia, and expected to need to add manual packing of the data to get performance for large matrices and did not need to do this. I haven't done a deep dive yet to compare with using offsets instead of views.","user":"UCRHP2GHE","ts":"1611336765.013200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nHesu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Do views into matrices impact the cache behavior? I was implementing some BLIS style matrix-matrix multiplies in Julia, and expected to need to add manual packing of the data to get performance for large matrices and did not need to do this. I haven't done a deep dive yet to compare with using offsets instead of views."}]}]}],"thread_ts":"1611336765.013200","reply_count":3,"reply_users_count":2,"latest_reply":"1611337884.013700","reply_users":["UH24GRBLL","UCRHP2GHE"],"subscribed":false},{"client_msg_id":"61f157da-4046-4410-a607-a96c351d492c","type":"message","text":"Is there a way to do the following without manually unrolling or (pre)allocating an array? I accumulate over some scalar `Float64` variables and want to do this\n```u1,u2,u3 = 0.0, 0.0, 0.0\nfor i = 1:10\n  u1 += 1 \n  u2 += 3\n  u3 += 2\nend```\nbut for `N` variables (assuming `N` is encoded in some static type info and `N` is small, e.g., 3-10ish).\n\nI can do this with a preallocated array, but I’d like to avoid that allocation too if possible.","user":"U011LUQ182G","ts":"1611383893.021500","team":"T68168MUP","edited":{"user":"U011LUQ182G","ts":"1611384216.000000"},"blocks":[{"type":"rich_text","block_id":"Xskab","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a way to do the following without manually unrolling or (pre)allocating an array? I accumulate over some scalar "},{"type":"text","text":"Float64","style":{"code":true}},{"type":"text","text":" variables and want to do this\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"u1,u2,u3 = 0.0, 0.0, 0.0\nfor i = 1:10\n  u1 += 1 \n  u2 += 3\n  u3 += 2\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"but for "},{"type":"text","text":"N","style":{"code":true}},{"type":"text","text":" variables (assuming "},{"type":"text","text":"N","style":{"code":true}},{"type":"text","text":" is encoded in some static type info and "},{"type":"text","text":"N","style":{"code":true}},{"type":"text","text":" is small, e.g., 3-10ish).\n\nI can do this with a preallocated array, but I’d like to avoid that allocation too if possible."}]}]}],"thread_ts":"1611383893.021500","reply_count":7,"reply_users_count":3,"latest_reply":"1611437212.038500","reply_users":["U011LUQ182G","UD0NS8PDF","UAUPJLBQX"],"subscribed":false},{"client_msg_id":"9667088b-fbb9-4040-8889-7e05cb7a4180","type":"message","text":"Can anyone explain to me why this code allocates memory (looking at `@benchmark` ), and if it's possible to avoid it? i.e. I want to create a view of a struct's array and use it to construct another instance of the same struct. But even just creating a view of the struct's array field allocates memory. This does not happen if the function argument is an array rather than a struct instance.\n```struct Foo\n  vals\nend\n\nconst A = randn(100)\nfoo = Foo(A)\nfunction testalloc(X,inds)\n  view(X.vals, inds);\n  return nothing;\nend\n\nxs = 1:10\n@benchmark testalloc(foo,xs)```","user":"U01H36BUDJB","ts":"1611418280.027900","team":"T68168MUP","edited":{"user":"U01H36BUDJB","ts":"1611418333.000000"},"blocks":[{"type":"rich_text","block_id":"4I9++","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can anyone explain to me why this code allocates memory (looking at "},{"type":"text","text":"@benchmark","style":{"code":true}},{"type":"text","text":" ), and if it's possible to avoid it? i.e. I want to create a view of a struct's array and use it to construct another instance of the same struct. But even just creating a view of the struct's array field allocates memory. This does not happen if the function argument is an array rather than a struct instance.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"struct Foo\n  vals\nend\n\nconst A = randn(100)\nfoo = Foo(A)\nfunction testalloc(X,inds)\n  view(X.vals, inds);\n  return nothing;\nend\n\nxs = 1:10\n@benchmark testalloc(foo,xs)"}]}]}],"thread_ts":"1611418280.027900","reply_count":35,"reply_users_count":5,"latest_reply":"1611428030.038000","reply_users":["U7HAYKY9X","U0179G7FG4F","U01H36BUDJB","U01GRS159T8","UH24GRBLL"],"subscribed":false},{"client_msg_id":"efce8b63-3113-4f39-988e-f33158a1908f","type":"message","text":"Anyone know if `Interpolations.jl` is supposed to be allocation free? It appears that even a simple example with the interpolation object and query points fixed causes allocation inside of a function:\n```const A = randn(100);\nconst A_i = interpolate(A,BSpline(Linear()));\nfunction interpalloc(y,xs,out)\n    out .= y(xs)\nend\n@benchmark interpalloc(A_i,xs,out)\n\nBenchmarkTools.Trial: \n  memory estimate:  496 bytes\n  allocs estimate:  2\n  --------------\n  minimum time:     142.632 ns (0.00% GC)\n  median time:      146.349 ns (0.00% GC)\n  mean time:        161.094 ns (4.74% GC)\n  maximum time:     1.289 μs (84.83% GC)\n  --------------\n  samples:          10000\n  evals/sample:     846```","user":"U01H36BUDJB","ts":"1611496824.039900","team":"T68168MUP","edited":{"user":"U01H36BUDJB","ts":"1611496916.000000"},"blocks":[{"type":"rich_text","block_id":"8KC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone know if "},{"type":"text","text":"Interpolations.jl","style":{"code":true}},{"type":"text","text":" is supposed to be allocation free? It appears that even a simple example with the interpolation object and query points fixed causes allocation inside of a function:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"const A = randn(100);\nconst A_i = interpolate(A,BSpline(Linear()));\nfunction interpalloc(y,xs,out)\n    out .= y(xs)\nend\n@benchmark interpalloc(A_i,xs,out)\n\nBenchmarkTools.Trial: \n  memory estimate:  496 bytes\n  allocs estimate:  2\n  --------------\n  minimum time:     142.632 ns (0.00% GC)\n  median time:      146.349 ns (0.00% GC)\n  mean time:        161.094 ns (4.74% GC)\n  maximum time:     1.289 μs (84.83% GC)\n  --------------\n  samples:          10000\n  evals/sample:     846"}]}]}],"thread_ts":"1611496824.039900","reply_count":7,"reply_users_count":3,"latest_reply":"1611610936.041400","reply_users":["U67G3QRJM","U01H36BUDJB","USU9FRPEU"],"subscribed":false},{"client_msg_id":"90b8a123-7e58-4953-beff-e9f35ea3c0b3","type":"message","text":"So I currently am having a mini-contest between a co-worker of mine about performance.\n\nHe claims that Java is one of the fastest languages for his toy-problem.\n\nI wrote a Julia version but my code currently runs at &lt;2x the speed of his Java code.\n\nCan anyone suggest to me some ways to increase my performance? Also feel free to give any un-solicited advice about my coding style :slightly_smiling_face:\nNote this has to all follow the same structure (e.g. single threaded, must use recursion)\n\nThe toy problem is just <https://en.wikipedia.org/wiki/Peg_solitaire|peg solitaire> but on a triangular board. It involves lots and lots of array append and lots of recursion.\n\n<https://github.com/ayman-albaz/peg-performance/blob/master/src/main/julia/performance.jl>","user":"U01FAHWCMFF","ts":"1611856909.043900","team":"T68168MUP","edited":{"user":"U01FAHWCMFF","ts":"1611856973.000000"},"attachments":[{"image_url":"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/Peg_Solitaire_1687_on_Portrait_of_Princess_Soubise_by_Claude-Auguste_Berey.jpg/1200px-Peg_Solitaire_1687_on_Portrait_of_Princess_Soubise_by_Claude-Auguste_Berey.jpg","image_width":1200,"image_height":1626,"image_bytes":797938,"title":"Peg solitaire","title_link":"https://en.wikipedia.org/wiki/Peg_solitaire","from_url":"https://en.wikipedia.org/wiki/Peg_solitaire","author_name":"Wikipedia","author_link":"https://en.wikipedia.org/","text":"Peg solitaire (or Solo Noble) is a board game for one player involving movement of pegs on a board with holes.  Some sets use marbles in a board with indentations. The game is known simply as Solitaire in the United Kingdom where the card games are called Patience.  It is also referred to as Brainvita (mainly in India, where sets are sold commercially under this name).\nThe first evidence of the game can be traced back to the court of Louis XIV, and the specific date of 1697, with an engraving made ten years later by Claude Auguste Berey of Anne de Rohan-Chabot, Princess of Soubise, with the puzzle by her side.  The August 1687 edition of the French literary magazine Mercure galant contains a description of the board, rules and sample problems.  This is the first known reference to the game in print.\nThe standard game fills the entire board with pegs except for the central hole. The objective is, making valid moves, to empty the entire board except for a solitary peg in the central hole.","fallback":"wikipedia: Peg solitaire","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/wikipedia.png","id":1,"original_url":"https://en.wikipedia.org/wiki/Peg_solitaire"}],"blocks":[{"type":"rich_text","block_id":"SkErK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So I currently am having a mini-contest between a co-worker of mine about performance.\n\nHe claims that Java is one of the fastest languages for his toy-problem.\n\nI wrote a Julia version but my code currently runs at <2x the speed of his Java code.\n\nCan anyone suggest to me some ways to increase my performance? Also feel free to give any un-solicited advice about my coding style "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":"\nNote this has to all follow the same structure (e.g. single threaded, must use recursion)\n\nThe toy problem is just "},{"type":"link","url":"https://en.wikipedia.org/wiki/Peg_solitaire","text":"peg solitaire"},{"type":"text","text":" but on a triangular board. It involves lots and lots of array append and lots of recursion.\n\n"},{"type":"link","url":"https://github.com/ayman-albaz/peg-performance/blob/master/src/main/julia/performance.jl"}]}]}],"thread_ts":"1611856909.043900","reply_count":2,"reply_users_count":2,"latest_reply":"1611858024.047800","reply_users":["U01GMP3HF9C","U01FAHWCMFF"],"subscribed":false},{"client_msg_id":"756bdf61-d65d-4506-8ce7-1132b4862fd2","type":"message","text":"How long does the vectors typically get? Could you get away with tuples instead of vectors to avoid the many allocations? Alternatively, preallocate arrays and use sizehint or send the current size along","user":"UJ7DVTVQ8","ts":"1611857350.045900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"y6Y7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How long does the vectors typically get? Could you get away with tuples instead of vectors to avoid the many allocations? Alternatively, preallocate arrays and use sizehint or send the current size along"}]}]}],"thread_ts":"1611857350.045900","reply_count":2,"reply_users_count":2,"latest_reply":"1611857606.047400","reply_users":["U0179G7FG4F","UJ7DVTVQ8"],"subscribed":false},{"client_msg_id":"55e79744-8434-41ae-9418-76de876e1766","type":"message","text":"I'm not too familiar with the math behind the game, but the final size of the array i guess is determined through exhaustively iterating through every possible combination of moves.","user":"U01FAHWCMFF","ts":"1611857421.046900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5lDxf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm not too familiar with the math behind the game, but the final size of the array i guess is determined through exhaustively iterating through every possible combination of moves."}]}]}]},{"client_msg_id":"09afd3a8-6707-4ac0-a024-7edab5a1c8e6","type":"message","text":"Can you post the Java version?","user":"U0179G7FG4F","ts":"1611857534.047100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3VVXT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can you post the Java version?"}]}]}]},{"client_msg_id":"d7ba8eaf-11e9-4570-9c3d-991f59eb4e58","type":"message","text":"<https://github.com/ayman-albaz/peg-performance/tree/master/src/main/java>\nJust run the .sh file.","user":"U01FAHWCMFF","ts":"1611857557.047300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pEAbz","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/ayman-albaz/peg-performance/tree/master/src/main/java"},{"type":"text","text":"\nJust run the .sh file."}]}]}]},{"client_msg_id":"f9ac3b8d-f6b8-4d96-9611-c45788550d34","type":"message","text":"I just want to point out that data structures and models are not part of a problem but part of a solution. It seems to me that you're contest is slightly biased.\nNow I haven't look at the code or anything so ... Sorry to disrupt your thread","user":"U01FR2HFJ7M","ts":"1611880767.055400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TfJ5u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I just want to point out that data structures and models are not part of a problem but part of a solution. It seems to me that you're contest is slightly biased.\nNow I haven't look at the code or anything so ... Sorry to disrupt your thread"}]}]}]},{"client_msg_id":"f2cea381-44ee-44c0-88bf-4b6b037b1d1d","type":"message","text":"```using Distributions\nusing BenchmarkTools\nfunction sample_dist_a(n,b,a)\n    for i in 1:n, j in 1:n\n        b[i,j] = rand(a[i % 2 + 1,j % 2 + 1])\n    end\nend\nfunction sample_dist_b(n,b,a)\n\n    for i in 1:n, j in 1:n\n        b[i,j] = rand(a[i % 2 + 1][j % 2 + 1])\n    end\nend\nfunction performance_test()\n    a = [\n        Geometric(0.2) Geometric(0.2)\n        Poisson(2.0)   Poisson(2.0)\n    ]\n    b =(\n        (Geometric(0.2), Geometric(0.2)),\n        (Poisson(2.0), Poisson(2.0))\n    )\n    in = zeros(100,100)\n    @btime sample_dist_a(100,$in,$a)\n    @btime sample_dist_b(100,$in,$b)\nend```\nwhy does `sample_dist_b` allocate twice as much?","user":"U011V2YN59N","ts":"1612037626.080500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"e2G0A","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Distributions\nusing BenchmarkTools\nfunction sample_dist_a(n,b,a)\n    for i in 1:n, j in 1:n\n        b[i,j] = rand(a[i % 2 + 1,j % 2 + 1])\n    end\nend\nfunction sample_dist_b(n,b,a)\n\n    for i in 1:n, j in 1:n\n        b[i,j] = rand(a[i % 2 + 1][j % 2 + 1])\n    end\nend\nfunction performance_test()\n    a = [\n        Geometric(0.2) Geometric(0.2)\n        Poisson(2.0)   Poisson(2.0)\n    ]\n    b =(\n        (Geometric(0.2), Geometric(0.2)),\n        (Poisson(2.0), Poisson(2.0))\n    )\n    in = zeros(100,100)\n    @btime sample_dist_a(100,$in,$a)\n    @btime sample_dist_b(100,$in,$b)\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"why does "},{"type":"text","text":"sample_dist_b","style":{"code":true}},{"type":"text","text":" allocate twice as much?"}]}]}]},{"client_msg_id":"b863714f-7269-4a26-a992-a3bc8f0ccbb7","type":"message","text":"```julia&gt; performance_test()\n  2.020 ms (10000 allocations: 156.25 KiB)\n  1.300 ms (20000 allocations: 781.25 KiB)```","user":"U011V2YN59N","ts":"1612037638.080800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0uB7","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> performance_test()\n  2.020 ms (10000 allocations: 156.25 KiB)\n  1.300 ms (20000 allocations: 781.25 KiB)"}]}]}]},{"client_msg_id":"d62f3d2f-b9b7-4357-9e7d-72ca65a97127","type":"message","text":"despite being faster","user":"U011V2YN59N","ts":"1612037641.081000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"inR8e","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"despite being faster"}]}]}]},{"client_msg_id":"d70e31e6-442f-470b-b3a7-85dddf700ed7","type":"message","text":"what is this (pretty huge) difference in performance between anonymous function and normal function due to? Do anonymous functions have some extra overhead when called?\n\n```julia&gt; f = x -&gt; x+1\n#95 (generic function with 1 method)\n\njulia&gt; g(x) = x+1\ng (generic function with 1 method)\n\njulia&gt; @btime f(1)\n  20.543 ns (0 allocations: 0 bytes)\n2\n\njulia&gt; @btime g(1)\n  0.001 ns (0 allocations: 0 bytes)```","user":"U012RPHRSP3","ts":"1612037752.082300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yAs+z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what is this (pretty huge) difference in performance between anonymous function and normal function due to? Do anonymous functions have some extra overhead when called?\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> f = x -> x+1\n#95 (generic function with 1 method)\n\njulia> g(x) = x+1\ng (generic function with 1 method)\n\njulia> @btime f(1)\n  20.543 ns (0 allocations: 0 bytes)\n2\n\njulia> @btime g(1)\n  0.001 ns (0 allocations: 0 bytes)"}]}]}],"thread_ts":"1612037752.082300","reply_count":10,"reply_users_count":4,"latest_reply":"1612085760.085100","reply_users":["U7HAYKY9X","U011V2YN59N","U012RPHRSP3","U01H36BUDJB"],"subscribed":false},{"client_msg_id":"d1f937b6-5ab6-4f0f-818c-a0554d133666","type":"message","text":"Does anyone know how to make an efficient wrapper type around an Array? It seems even for simple copy operations I get a performance hit of 3-4x when using a wrapper type that subtypes `DenseArray` and provides all of the basic functions like `getindex` . Is there something I'm missing? A dispatch that needs to be added to make it more efficient?","user":"U01H36BUDJB","ts":"1612107297.086800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5Lxp6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know how to make an efficient wrapper type around an Array? It seems even for simple copy operations I get a performance hit of 3-4x when using a wrapper type that subtypes "},{"type":"text","text":"DenseArray","style":{"code":true}},{"type":"text","text":" and provides all of the basic functions like "},{"type":"text","text":"getindex","style":{"code":true}},{"type":"text","text":" . Is there something I'm missing? A dispatch that needs to be added to make it more efficient?"}]}]}]},{"client_msg_id":"1bada36f-df8f-4ce4-bd1a-b921da3be7bd","type":"message","text":"You might need `@propagate_inbounds`","user":"U67D54KS8","ts":"1612107485.087200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"A624","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You might need "},{"type":"text","text":"@propagate_inbounds","style":{"code":true}}]}]}],"thread_ts":"1612107485.087200","reply_count":4,"reply_users_count":3,"latest_reply":"1612108275.090000","reply_users":["U01H36BUDJB","UH24GRBLL","U67D54KS8"],"subscribed":false},{"client_msg_id":"7f41fd31-ff09-40d5-b60c-3461c1083feb","type":"message","text":"and make sure to forward `iterate` if `@propagate_inbounds` alone doesn't bring you up to speed","user":"UH24GRBLL","ts":"1612107617.087800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TkqY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and make sure to forward "},{"type":"text","text":"iterate","style":{"code":true}},{"type":"text","text":" if "},{"type":"text","text":"@propagate_inbounds","style":{"code":true}},{"type":"text","text":" alone doesn't bring you up to speed"}]}]}]},{"client_msg_id":"5e5ae083-e2e5-43b4-a052-39686dea1f49","type":"message","text":"just adding `@propagate_inbounds` didn't seem to do anything. I'll try forwarding `iterate`.","user":"U01H36BUDJB","ts":"1612107862.089100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yl2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"just adding "},{"type":"text","text":"@propagate_inbounds","style":{"code":true}},{"type":"text","text":" didn't seem to do anything. I'll try forwarding "},{"type":"text","text":"iterate","style":{"code":true}},{"type":"text","text":"."}]}]}]},{"client_msg_id":"9679d74b-48c5-4a18-b450-92aa8cddd4d1","type":"message","text":"overriding `iterate` improved it, but it's still about 2x slower to copy than a regular array","user":"U01H36BUDJB","ts":"1612108225.089900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yN9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"overriding "},{"type":"text","text":"iterate","style":{"code":true}},{"type":"text","text":" improved it, but it's still about 2x slower to copy than a regular array"}]}]}]},{"client_msg_id":"5e02a538-80e7-4a4e-bf1e-94a4566df5b1","type":"message","text":"The `copy!` for `Array` ends up doing a `memove` while yours probably just does an iteration. Perhaps subtyping `DenseArray` instead of `AbstractArray` could help (if it is dense).","user":"U67D54KS8","ts":"1612108541.091300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pp+=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The "},{"type":"text","text":"copy!","style":{"code":true}},{"type":"text","text":" for "},{"type":"text","text":"Array","style":{"code":true}},{"type":"text","text":" ends up doing a "},{"type":"text","text":"memove","style":{"code":true}},{"type":"text","text":" while yours probably just does an iteration. Perhaps subtyping "},{"type":"text","text":"DenseArray","style":{"code":true}},{"type":"text","text":" instead of "},{"type":"text","text":"AbstractArray","style":{"code":true}},{"type":"text","text":" could help (if it is dense)."}]}]}]},{"client_msg_id":"3c219794-f042-4f62-9ffe-c8cccd46c674","type":"message","text":"Yeah, I am subtyping `DenseArray`. And it seems that using `copy!` actually gets rid of the performance disparity. But doing a `.=` on an `Array` is 2x faster than on my array type (and interestingly also almost exactly as fast as `copy!` , which leads me to think the compiler is using `copy!` under the hood).","user":"U01H36BUDJB","ts":"1612109184.093000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PY7EV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, I am subtyping `DenseArray`. And it seems that using "},{"type":"text","text":"copy!","style":{"code":true}},{"type":"text","text":" actually gets rid of the performance disparity. But doing a "},{"type":"text","text":".=","style":{"code":true}},{"type":"text","text":" on an "},{"type":"text","text":"Array","style":{"code":true}},{"type":"text","text":" is 2x faster than on my array type (and interestingly also almost exactly as fast as "},{"type":"text","text":"copy!","style":{"code":true}},{"type":"text","text":" , which leads me to think the compiler is using "},{"type":"text","text":"copy!","style":{"code":true}},{"type":"text","text":" under the hood)."}]}]}]},{"client_msg_id":"0d35431c-c73c-4543-8776-40e41ec28c4a","type":"message","text":"Did you defined the `IndexStyle` for it? (<https://docs.julialang.org/en/v1/manual/interfaces/#man-interface-array>)","user":"U67D54KS8","ts":"1612109264.093300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/nC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Did you defined the "},{"type":"text","text":"IndexStyle","style":{"code":true}},{"type":"text","text":" for it? ("},{"type":"link","url":"https://docs.julialang.org/en/v1/manual/interfaces/#man-interface-array"},{"type":"text","text":")"}]}]}]},{"client_msg_id":"de8ab82a-77b3-4289-b33c-078891c487dd","type":"message","text":"I did not, good catch!","user":"U01H36BUDJB","ts":"1612109377.093500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eOyq7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I did not, good catch!"}]}]}]},{"client_msg_id":"829d801d-0d59-427c-8ae2-5c71e64e70b5","type":"message","text":"most of the optional methods are specialized for the Arrays in Base, so if you wrap them, it's probably a good idea to forward those as well","user":"UH24GRBLL","ts":"1612109609.094200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cXYvf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"most of the optional methods are specialized for the Arrays in Base, so if you wrap them, it's probably a good idea to forward those as well"}]}]}]},{"client_msg_id":"79ce7717-49f3-4ac5-97c1-1e2222d709c0","type":"message","text":"(unless they're not, then you may just end up in a loop)","user":"UH24GRBLL","ts":"1612109650.094800","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1612109658.000000"},"blocks":[{"type":"rich_text","block_id":"yJ1=5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(unless they're not, then you may just end up in a loop)"}]}]}]},{"client_msg_id":"096ad577-6ed3-41de-89d5-1498648286a5","type":"message","text":"I think have them all overridden, but it's still 2x slower... the performance is about the same though for `@view` , so maybe I'll just ignore it and use `copy!` instead of `.=` when I want to copy the whole array. I guess that's probably generally better anyway.","user":"U01H36BUDJB","ts":"1612110601.096200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oST","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think have them all overridden, but it's still 2x slower... the performance is about the same though for "},{"type":"text","text":"@view","style":{"code":true}},{"type":"text","text":" , so maybe I'll just ignore it and use "},{"type":"text","text":"copy!","style":{"code":true}},{"type":"text","text":" instead of "},{"type":"text","text":".=","style":{"code":true}},{"type":"text","text":" when I want to copy the whole array. I guess that's probably generally better anyway."}]}]}]},{"client_msg_id":"2008047d-12e1-4f99-a472-4f95c3b9e612","type":"message","text":"have you forwarded `setindex!(A, X, I...)` as well? that's the one that's important for multidimensional setindex","user":"UH24GRBLL","ts":"1612110787.096500","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1612110839.000000"},"blocks":[{"type":"rich_text","block_id":"0hq3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"have you forwarded "},{"type":"text","text":"setindex!(A, X, I...)","style":{"code":true}},{"type":"text","text":" as well? that's the one that's important for multidimensional setindex"}]}]}]},{"client_msg_id":"e086a2ff-44d4-481d-8a69-a43424dc36a3","type":"message","text":"That shouldn't be needed when it `IndexLinear`","user":"U67D54KS8","ts":"1612111625.097100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ISLJM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That shouldn't be needed when it "},{"type":"text","text":"IndexLinear","style":{"code":true}}]}]}]},{"client_msg_id":"4dc19964-ccd8-4a40-bb79-6c8264cf107c","type":"message","text":"I did yeah. Sadly, there is also a performance hit when doing basic broadcasted math, e.g. `@. out = 2x^3` is 2x slower with the custom array type `x` than a plain `Vector` .","user":"U01H36BUDJB","ts":"1612111872.099200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4DDK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I did yeah. Sadly, there is also a performance hit when doing basic broadcasted math, e.g. "},{"type":"text","text":"@. out = 2x^3","style":{"code":true}},{"type":"text","text":" is 2x slower with the custom array type "},{"type":"text","text":"x","style":{"code":true}},{"type":"text","text":" than a plain "},{"type":"text","text":"Vector","style":{"code":true}},{"type":"text","text":" ."}]}]}]},{"client_msg_id":"4451b0b9-e96a-4a6a-b5c0-96b19bb714fa","type":"message","text":"This seems to be an issue with `AxisArray` as well, so maybe it's just a general trade-off with custom array types? Maybe I'll just try to think of alternative solutions that just use the built-in arrays.","user":"U01H36BUDJB","ts":"1612111977.100400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hEgq1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This seems to be an issue with "},{"type":"text","text":"AxisArray","style":{"code":true}},{"type":"text","text":" as well, so maybe it's just a general trade-off with custom array types? Maybe I'll just try to think of alternative solutions that just use the built-in arrays."}]}]}]},{"client_msg_id":"7f3cb6a6-cb55-48ef-aa1a-bdcec044e751","type":"message","text":"there shouldn't be if you've forwarded everything properly and with the correct `@propagate_inbounds` annotations","user":"UH24GRBLL","ts":"1612112549.100900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"c+ol","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"there shouldn't be if you've forwarded everything properly and with the correct "},{"type":"text","text":"@propagate_inbounds","style":{"code":true}},{"type":"text","text":" annotations"}]}]}]},{"client_msg_id":"070d95c8-bbca-4395-b667-08dfb0c95ad8","type":"message","text":"I think there is a codegen bug with views and other wrappers that cause the data pointer to be loaded at every iteration","user":"U67BJLYCS","ts":"1612113330.102100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MWB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think there is a codegen bug with views and other wrappers that cause the data pointer to be loaded at every iteration"}]}]}],"thread_ts":"1612113330.102100","reply_count":1,"reply_users_count":1,"latest_reply":"1612113475.103000","reply_users":["U67BJLYCS"],"subscribed":false},{"client_msg_id":"c16da2f9-7e09-4baa-8b25-ec0f253f0361","type":"message","text":"Oh wait it works now! I restarted the REPL and added the `broadcastable` and `BroadcastStyle` forwards and now the performance difference is gone. So I guess it was broadcasting that was the culprit.","user":"U01H36BUDJB","ts":"1612113382.102900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NUA/9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh wait it works now! I restarted the REPL and added the "},{"type":"text","text":"broadcastable","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"BroadcastStyle","style":{"code":true}},{"type":"text","text":" forwards and now the performance difference is gone. So I guess it was broadcasting that was the culprit."}]}]}]},{"type":"message","text":"Do we have a cache simulator like what is discussed here: <https://www.youtube.com/watch?v=SZOr0m-K5PQ> ?\nSingle step each instruction, disasemble instruction, find memory operands, update cache simulation, re-set trap flag to keep tracing\n\nIt might be called like @cache_sim(f(x,y,z,t);model=nahlem())","user":"U9MD78Z9N","ts":"1612117132.103200","team":"T68168MUP","edited":{"user":"U9MD78Z9N","ts":"1612117583.000000"},"attachments":[{"service_name":"YouTube","service_url":"https://www.youtube.com/","title":"Cold, Hard Cache Insomniacs Cache Simulator","title_link":"https://www.youtube.com/watch?v=SZOr0m-K5PQ","author_name":"GDC","author_link":"https://www.youtube.com/c/Gdconf","thumb_url":"https://i.ytimg.com/vi/SZOr0m-K5PQ/hqdefault.jpg","thumb_width":480,"thumb_height":360,"fallback":"YouTube Video: Cold, Hard Cache Insomniacs Cache Simulator","video_html":"<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/SZOr0m-K5PQ?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","video_html_width":400,"video_html_height":225,"from_url":"https://www.youtube.com/watch?v=SZOr0m-K5PQ","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png","id":1,"original_url":"https://www.youtube.com/watch?v=SZOr0m-K5PQ"}]},{"client_msg_id":"6a288d03-023b-4e31-8b2d-de0f66aa27e3","type":"message","text":"Can anyone make the vectorized and inplace version (bottom) of the top function faster?\n```function Base.rand(rng::AbstractRNG, s::ZWDist)\n    return ifelse(Base.rand(rng) &lt; s.α, 0, Base.rand(rng,s.base_dist))\nend\n\nfunction Random.rand!(rng::AbstractRNG, s::ZWDist, l::T) where T&lt;:AbstractVector\n    Random.rand!(rng,l)\n    l[l .&lt; s.α] .= 0\n    Random.rand!(rng,s.base_dist,@view l[l .&gt;= s.α])\n    return nothing\nend```","user":"U011V2YN59N","ts":"1612132171.105000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zNl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can anyone make the vectorized and inplace version (bottom) of the top function faster?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function Base.rand(rng::AbstractRNG, s::ZWDist)\n    return ifelse(Base.rand(rng) < s.α, 0, Base.rand(rng,s.base_dist))\nend\n\nfunction Random.rand!(rng::AbstractRNG, s::ZWDist, l::T) where T<:AbstractVector\n    Random.rand!(rng,l)\n    l[l .< s.α] .= 0\n    Random.rand!(rng,s.base_dist,@view l[l .>= s.α])\n    return nothing\nend"}]}]}],"thread_ts":"1612132171.105000","reply_count":126,"reply_users_count":2,"latest_reply":"1612164953.131800","reply_users":["U011V2YN59N","UH24GRBLL"],"subscribed":false},{"client_msg_id":"ab941f89-4af2-426c-8e80-03366a3acecd","type":"message","text":"I'm a little puzzled. Here's the output from `--track-allocation=user`  on a particular snippet of mine.\n```    23984     @inbounds for t ∈ 0:Δt:T\n        0         dynamics!(dx, x, params, t)\n        - \n   112112         x[:, :, 2] .+= Δt .* dx[:, :, 2]\n   112112         x[:, :, 1] .+= Δt .* x[:, :, 2] # Symplectic Euler\n        - \n   160160         x[:, reference_idx, 1] .= reference_vals\n   128096         x[:, reference_idx, 2] .= 0\n        -     end```\n`x` and `dx` are `Array{Float64,3} (3, 355, 2)`\n\nHow can I get this code to stop allocating? Clearly I'm missing something besides the broadcasting.","user":"UMC2RHKLZ","ts":"1612488923.135200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fsL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm a little puzzled. Here's the output from "},{"type":"text","text":"--track-allocation=user","style":{"code":true}},{"type":"text","text":"  on a particular snippet of mine.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"    23984     @inbounds for t ∈ 0:Δt:T\n        0         dynamics!(dx, x, params, t)\n        - \n   112112         x[:, :, 2] .+= Δt .* dx[:, :, 2]\n   112112         x[:, :, 1] .+= Δt .* x[:, :, 2] # Symplectic Euler\n        - \n   160160         x[:, reference_idx, 1] .= reference_vals\n   128096         x[:, reference_idx, 2] .= 0\n        -     end"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"x","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"dx","style":{"code":true}},{"type":"text","text":" are "},{"type":"text","text":"Array{Float64,3} (3, 355, 2)","style":{"code":true}},{"type":"text","text":"\n\nHow can I get this code to stop allocating? Clearly I'm missing something besides the broadcasting."}]}]}]},{"client_msg_id":"bff967c1-4a2a-4f36-abbb-2b0f80ffd44d","type":"message","text":"I'm looping over a text file and pushing parsed lines to a `Dict{String, Vector{Vector}}` and I find I need a function similar to `push!`, but that creates the key in the dict if it does not already exist. I came up with\n```function push_or_add!(d::AbstractDict{K, &lt;: AbstractVector}, p::Pair) \n    haskey(d, p[1]) ? push!(d[p[1]], p[2]) : push!(d, p[1] =&gt; [p[2]])\nend```\nwhich works, but it performs the key lookup twice, once in `haskey` and once in `push!`. Is there a simple way of doing this already existing?","user":"UJ7DVTVQ8","ts":"1612550826.149800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oJf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm looping over a text file and pushing parsed lines to a "},{"type":"text","text":"Dict{String, Vector{Vector}}","style":{"code":true}},{"type":"text","text":" and I find I need a function similar to "},{"type":"text","text":"push!","style":{"code":true}},{"type":"text","text":", but that creates the key in the dict if it does not already exist. I came up with\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function push_or_add!(d::AbstractDict{K, <: AbstractVector}, p::Pair) \n    haskey(d, p[1]) ? push!(d[p[1]], p[2]) : push!(d, p[1] => [p[2]])\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"which works, but it performs the key lookup twice, once in "},{"type":"text","text":"haskey","style":{"code":true}},{"type":"text","text":" and once in "},{"type":"text","text":"push!","style":{"code":true}},{"type":"text","text":". Is there a simple way of doing this already existing?"}]}]}],"thread_ts":"1612550826.149800","reply_count":5,"reply_users_count":2,"latest_reply":"1612551494.150700","reply_users":["UH24GRBLL","UJ7DVTVQ8"],"subscribed":false},{"type":"message","text":"Assuming i have a C++ code with arbitrary x86_64 instrinsic, can i translate it to Julia?","user":"U9MD78Z9N","ts":"1612828321.153800","team":"T68168MUP","thread_ts":"1612828321.153800","reply_count":5,"reply_users_count":3,"latest_reply":"1612830234.154800","reply_users":["U9MD78Z9N","U0179G7FG4F","U67BJLYCS"],"subscribed":false},{"client_msg_id":"7fdfaccf-f3c5-467f-8fe2-c0250dbd995f","type":"message","text":"When I run joining benchmarks in DataFrames.jl I get the following timing for `llen=10^6` and `rlen=2*20^7`:\n```[ Info: sorted int duplicates many\n 34.686326 seconds (171 allocations: 2.454 GiB, 91.70% gc time)\n 34.366576 seconds (171 allocations: 2.454 GiB, 91.61% gc time)```\nwhen called from within a function. But if I call the same code (copy-pasted) in top level scope I get:\n```julia&gt; df1 = DataFrame(id = sort!(rand(1:llen ÷ 100, llen)), copycols=false);\n\njulia&gt; df2 = DataFrame(id = sort!(rand(1:rlen ÷ 100, rlen)), copycols=false);\n\njulia&gt; GC.gc()\n\njulia&gt; @time innerjoin(df1, df2, on=:id);\n  3.472643 seconds (172 allocations: 2.453 GiB, 9.72% gc time)\n\njulia&gt; GC.gc()\n\njulia&gt; @time innerjoin(df2, df1, on=:id);\n  3.269198 seconds (172 allocations: 2.453 GiB, 6.79% gc time)```\nCould someone please help me understand what is going on here? Why `GC.gc()` does not garbage collect things if it is called within a loop that is in a function but does it when called in top-level scope? (within a function only `df1` and `df2` variables get binding except for some variables controlling looping - these variables are bound to other values earlier in the function but then are rebound as in the code above) CC <@U67431ELR>","user":"U8JAMQGQY","ts":"1612968087.157100","team":"T68168MUP","edited":{"user":"U8JAMQGQY","ts":"1612968229.000000"},"blocks":[{"type":"rich_text","block_id":"yc6u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"When I run joining benchmarks in DataFrames.jl I get the following timing for "},{"type":"text","text":"llen=10^6","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"rlen=2*20^7","style":{"code":true}},{"type":"text","text":":\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"[ Info: sorted int duplicates many\n 34.686326 seconds (171 allocations: 2.454 GiB, 91.70% gc time)\n 34.366576 seconds (171 allocations: 2.454 GiB, 91.61% gc time)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"when called from within a function. But if I call the same code (copy-pasted) in top level scope I get:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> df1 = DataFrame(id = sort!(rand(1:llen ÷ 100, llen)), copycols=false);\n\njulia> df2 = DataFrame(id = sort!(rand(1:rlen ÷ 100, rlen)), copycols=false);\n\njulia> GC.gc()\n\njulia> @time innerjoin(df1, df2, on=:id);\n  3.472643 seconds (172 allocations: 2.453 GiB, 9.72% gc time)\n\njulia> GC.gc()\n\njulia> @time innerjoin(df2, df1, on=:id);\n  3.269198 seconds (172 allocations: 2.453 GiB, 6.79% gc time)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Could someone please help me understand what is going on here? Why "},{"type":"text","text":"GC.gc()","style":{"code":true}},{"type":"text","text":" does not garbage collect things if it is called within a loop that is in a function but does it when called in top-level scope? (within a function only "},{"type":"text","text":"df1","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"df2","style":{"code":true}},{"type":"text","text":" variables get binding except for some variables controlling looping - these variables are bound to other values earlier in the function but then are rebound as in the code above) CC "},{"type":"user","user_id":"U67431ELR"}]}]}],"thread_ts":"1612968087.157100","reply_count":10,"reply_users_count":4,"latest_reply":"1612970388.159400","reply_users":["U01H36BUDJB","UCZ7VBGUD","U8JAMQGQY","U67431ELR"],"subscribed":false},{"client_msg_id":"4b474e68-7f48-41d1-af6b-7925b967b931","type":"message","text":"why is multiplying `a * b`  as fast as multiplying `transpose(a)*b` . Shouldn't the latter be much faster in a language with column-major ordering?","user":"U7PD3M3L5","ts":"1613033281.161600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"99G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"why is multiplying "},{"type":"text","text":"a * b","style":{"code":true}},{"type":"text","text":"  as fast as multiplying "},{"type":"text","text":"transpose(a)*b","style":{"code":true}},{"type":"text","text":" . Shouldn't the latter be much faster in a language with column-major ordering?"}]}]}],"thread_ts":"1613033281.161600","reply_count":11,"reply_users_count":2,"latest_reply":"1613034443.163900","reply_users":["UH24GRBLL","U7PD3M3L5"],"subscribed":false},{"client_msg_id":"1b182b53-16a1-4469-83d7-2334911df9c3","type":"message","text":"Can I somehow have the operation\n```function multiply_test(a, b, c, d)\n    mul!(a, b .+ c, d)\nend\n\na = rand(500, 500)\nb = rand(500, 500)\nc = rand(500, 500)\nd = rand(500, 500)\n@btime multiply_test($a, $b, $c, $d)```\nnot allocate any space for `b.+c` ?","user":"U7PD3M3L5","ts":"1613037517.165600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/wz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can I somehow have the operation\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function multiply_test(a, b, c, d)\n    mul!(a, b .+ c, d)\nend\n\na = rand(500, 500)\nb = rand(500, 500)\nc = rand(500, 500)\nd = rand(500, 500)\n@btime multiply_test($a, $b, $c, $d)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"not allocate any space for "},{"type":"text","text":"b.+c","style":{"code":true}},{"type":"text","text":" ?"}]}]}],"thread_ts":"1613037517.165600","reply_count":4,"reply_users_count":3,"latest_reply":"1613037947.166400","reply_users":["UH24GRBLL","U7PD3M3L5","U01H36BUDJB"],"subscribed":false},{"client_msg_id":"bfc17385-c387-4ebd-81a6-22d858a191c2","type":"message","text":"Ok last question for now. Does anyone have a good idea how to, given an `d x n`  matrix `X`  (basically each column is a vector in my space), the pairwise difference matrix `d x n x n`  with entries:\n```Diff[:, i, j] = X[:, i] - X[:, j]```\nWhen taking the norm (i.e. calculating `dist[i, j] = || X[:, i] - X[:, j] ||^2`) using the `Distances.jl`  package gave me a huge speedup (16-fold) over the naive implementation of preallocating `dist`  and doing it in a loop","user":"U7PD3M3L5","ts":"1613040753.170700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"D697","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok last question for now. Does anyone have a good idea how to, given an "},{"type":"text","text":"d x n","style":{"code":true}},{"type":"text","text":"  matrix "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":"  (basically each column is a vector in my space), the pairwise difference matrix "},{"type":"text","text":"d x n x n","style":{"code":true}},{"type":"text","text":"  with entries:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Diff[:, i, j] = X[:, i] - X[:, j]"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"When taking the norm (i.e. calculating "},{"type":"text","text":"dist[i, j] = || X[:, i] - X[:, j] ||^2","style":{"code":true}},{"type":"text","text":") using the "},{"type":"text","text":"Distances.jl","style":{"code":true}},{"type":"text","text":"  package gave me a huge speedup (16-fold) over the naive implementation of preallocating "},{"type":"text","text":"dist","style":{"code":true}},{"type":"text","text":"  and doing it in a loop"}]}]}],"thread_ts":"1613040753.170700","reply_count":5,"reply_users_count":2,"latest_reply":"1613041594.176000","reply_users":["UD0NS8PDF","U7PD3M3L5"],"subscribed":false},{"client_msg_id":"a7a6ffca-ded7-4319-b3e1-dd04222997f6","type":"message","text":"`d`  and `n`  are both in the area of 100-1000, but basically I would like to be able to ttake both, (especially the dimension `d`) as large as possible","user":"U7PD3M3L5","ts":"1613040805.171800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fVrC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"d","style":{"code":true}},{"type":"text","text":"  and "},{"type":"text","text":"n","style":{"code":true}},{"type":"text","text":"  are both in the area of 100-1000, but basically I would like to be able to ttake both, (especially the dimension "},{"type":"text","text":"d","style":{"code":true}},{"type":"text","text":") as large as possible"}]}]}]},{"client_msg_id":"ef349f69-18e6-40b1-8119-50f8c88b03d5","type":"message","text":"not sure what the question is..?","user":"UH24GRBLL","ts":"1613040981.172800","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1613040983.000000"},"blocks":[{"type":"rich_text","block_id":"hhzZz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"not sure what the question is..?"}]}]}]},{"client_msg_id":"79c83e89-b41d-4964-8775-3aa058ec128e","type":"message","text":"are you asking about colwise differences?","user":"UH24GRBLL","ts":"1613041010.173200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HPVai","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"are you asking about colwise differences?"}]}]}]},{"client_msg_id":"8fca4bd7-7342-4269-bc72-4ea425feb1d2","type":"message","text":"Yes. I have currently implemented it as\n```n = 5\nd = 30\nX = rand(d, n)\n\ndiff = similar(X, n , n, d)\nfor dim=1:d\n    diff[:, :, dim] .= [X[dim, i] - X[dim, j] for i=1:n, j=1:n]\nend\ndiff```\nbut I don't think this is the most efficient way","user":"U7PD3M3L5","ts":"1613041336.174100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5ezT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes. I have currently implemented it as\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"n = 5\nd = 30\nX = rand(d, n)\n\ndiff = similar(X, n , n, d)\nfor dim=1:d\n    diff[:, :, dim] .= [X[dim, i] - X[dim, j] for i=1:n, j=1:n]\nend\ndiff"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"but I don't think this is the most efficient way"}]}]}]},{"client_msg_id":"4bec6a1f-db3f-4bfe-9c18-ec034dd3929f","type":"message","text":"you can just write out those loops","user":"UH24GRBLL","ts":"1613041480.174700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"p4e+n","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you can just write out those loops"}]}]}]},{"client_msg_id":"e21cbbbe-fffa-4453-b7fe-824a743d2def","type":"message","text":"wait how is this supposed to work? there's no sum here :thinking_face:","user":"UH24GRBLL","ts":"1613041600.176300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4Dmj9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"wait how is this supposed to work? there's no sum here "},{"type":"emoji","name":"thinking_face"}]}]}]},{"client_msg_id":"8253ce7d-eecf-4c5c-9539-fb8d3e1dbafb","type":"message","text":"ahh I see","user":"UH24GRBLL","ts":"1613041637.176500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TyLvo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ahh I see"}]}]}]},{"client_msg_id":"f5fec24c-60aa-49be-8081-751d200d2204","type":"message","text":"Calling that `d1(X)`, and comparing to just broadcasting:\n```julia&gt; d2(X) = @cast Diff[i, j, μ] := X[μ, i] - X[μ, j];\n\njulia&gt; d1(X, n, d) ≈ d2(X)\ntrue\n\njulia&gt; @btime d1($X, $n, $d);\n  3.482 μs (31 allocations: 14.44 KiB)\n\njulia&gt; @btime d2($X);\n  2.019 μs (7 allocations: 8.88 KiB)```\n","user":"UD0NS8PDF","ts":"1613041725.177400","team":"T68168MUP","edited":{"user":"UD0NS8PDF","ts":"1613041809.000000"},"blocks":[{"type":"rich_text","block_id":"LGjW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Calling that "},{"type":"text","text":"d1(X)","style":{"code":true}},{"type":"text","text":", and comparing to just broadcasting:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> d2(X) = @cast Diff[i, j, μ] := X[μ, i] - X[μ, j];\n\njulia> d1(X, n, d) ≈ d2(X)\ntrue\n\njulia> @btime d1($X, $n, $d);\n  3.482 μs (31 allocations: 14.44 KiB)\n\njulia> @btime d2($X);\n  2.019 μs (7 allocations: 8.88 KiB)"}]},{"type":"rich_text_section","elements":[]}]}]},{"client_msg_id":"303a4542-8206-4ceb-a4bf-6826a0d7fb7c","type":"message","text":"you can save all allocations by not using `[ ... ]` but `( ... )`, to not eagerly collect the generator","user":"UH24GRBLL","ts":"1613041763.178000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2Pv5d","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you can save all allocations by not using "},{"type":"text","text":"[ ... ]","style":{"code":true}},{"type":"text","text":" but "},{"type":"text","text":"( ... )","style":{"code":true}},{"type":"text","text":", to not eagerly collect the generator"}]}]}]},{"client_msg_id":"3cf2986b-c062-459f-b0b2-977c3495c69d","type":"message","text":"I think broadcasting collects anyway, but maybe copyto! would not","user":"UD0NS8PDF","ts":"1613041843.178600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"P7b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think broadcasting collects anyway, but maybe copyto! would not"}]}]}]},{"client_msg_id":"5a8f6e05-1c81-40c1-b131-79ac134ccb48","type":"message","text":"broadcasting to a matrix uses `copyto!` internally","user":"UH24GRBLL","ts":"1613041862.178900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6BU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"broadcasting to a matrix uses "},{"type":"text","text":"copyto!","style":{"code":true}},{"type":"text","text":" internally"}]}]}]},{"client_msg_id":"52508099-a5fc-45e5-b239-e6b7c599c47b","type":"message","text":"that's the multi dimensional setindex magic","user":"UH24GRBLL","ts":"1613041879.179200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/xvE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's the multi dimensional setindex magic"}]}]}]},{"client_msg_id":"06c334f5-5b1b-4311-ba08-0f929bb41af3","type":"message","text":"Yes, but broadcasting a generator usually collects it first","user":"UD0NS8PDF","ts":"1613041893.179500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lEm96","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, but broadcasting a generator usually collects it first"}]}]}]},{"client_msg_id":"94ced444-2be0-4b02-bf86-3f05cf80cdd7","type":"message","text":"yes, that's true","user":"UH24GRBLL","ts":"1613041907.179800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Xv1yE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yes, that's true"}]}]}]},{"client_msg_id":"5954e88a-f9b6-491f-b584-7a5889ca6d13","type":"message","text":"With `copyto!(@view(diff[:, :, dim]), (X[dim, i] - X[dim, j] for i=1:n, j=1:n))` it does seem faster","user":"UD0NS8PDF","ts":"1613041929.180100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2+B7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"With "},{"type":"text","text":"copyto!(@view(diff[:, :, dim]), (X[dim, i] - X[dim, j] for i=1:n, j=1:n))","style":{"code":true}},{"type":"text","text":" it does seem faster"}]}]}]},{"client_msg_id":"b23591d4-6a93-413c-b8e1-037e8cd8591e","type":"message","text":"```for i=1:n, j=1:n, dim=1:d\n        diff[i,j,dim] = X[dim,i] - X[dim,j]\nend```\niteration order may need tweaking, but this is probably just as good","user":"UH24GRBLL","ts":"1613042003.180600","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1613042008.000000"},"blocks":[{"type":"rich_text","block_id":"4Ly","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"for i=1:n, j=1:n, dim=1:d\n        diff[i,j,dim] = X[dim,i] - X[dim,j]\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"iteration order may need tweaking, but this is probably just as good"}]}]}]},{"client_msg_id":"93d49f04-e2b2-4816-ab6b-1f3c50ab249f","type":"message","text":"the resulting difference matrix is (except forthe sign) symmetric, right?","user":"UH24GRBLL","ts":"1613042068.181800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vlHpT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the resulting difference matrix is (except forthe sign) symmetric, right?"}]}]}]},{"client_msg_id":"5b5c0d81-f2cc-4fe0-a9ae-fde9a02b23ec","type":"message","text":"what is the difference between\n`copyto!(@view(diff[:, :, dim]), (X[dim, i] - X[dim, j] for i=1:n, j=1:n))`\nand\n`diff[:, :, dim] .= (X[dim, i] - X[dim, j] for i=1:n, j=1:n)` ?","user":"U7PD3M3L5","ts":"1613042068.181900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eu9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what is the difference between\n"},{"type":"text","text":"copyto!(@view(diff[:, :, dim]), (X[dim, i] - X[dim, j] for i=1:n, j=1:n))","style":{"code":true}},{"type":"text","text":"\nand\n"},{"type":"text","text":"diff[:, :, dim] .= (X[dim, i] - X[dim, j] for i=1:n, j=1:n)","style":{"code":true}},{"type":"text","text":" ?"}]}]}]},{"client_msg_id":"a8b8d12f-7c7b-40b3-b2e4-985df2c1d8c0","type":"message","text":"Simple loops:\n```julia&gt; d4(X) = @einsum Diff[i, j, μ] := X[μ, i] - X[μ, j];\n\njulia&gt; @btime d4($X);\n  827.337 ns (1 allocation: 6.00 KiB)```\nYes to the asymmetry, but not sure of a tidy way of encoding that, for a 3-array.","user":"UD0NS8PDF","ts":"1613042162.183100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5pMU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Simple loops:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> d4(X) = @einsum Diff[i, j, μ] := X[μ, i] - X[μ, j];\n\njulia> @btime d4($X);\n  827.337 ns (1 allocation: 6.00 KiB)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Yes to the asymmetry, but not sure of a tidy way of encoding that, for a 3-array."}]}]}]},{"client_msg_id":"f94d8806-1276-4f49-ac4c-ac14d6fa51e0","type":"message","text":"The difference is a quirk of broadcasting. Not every generator has a known (or even fixed) size, while broadcasting really needs to know that before starting. So it (I think always) calls `collect`, to make a matrix, before proceeding. Thus the `.= (...` version ends up exactly like the `.= [...` version.","user":"UD0NS8PDF","ts":"1613042289.185100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FRb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The difference is a quirk of broadcasting. Not every generator has a known (or even fixed) size, while broadcasting really needs to know that before starting. So it (I think always) calls "},{"type":"text","text":"collect","style":{"code":true}},{"type":"text","text":", to make a matrix, before proceeding. Thus the "},{"type":"text","text":".= (...","style":{"code":true}},{"type":"text","text":" version ends up exactly like the "},{"type":"text","text":".= [...","style":{"code":true}},{"type":"text","text":" version."}]}]}]},{"client_msg_id":"780b2470-3053-4707-9c6f-d11a50bf8c82","type":"message","text":"if you pass `Diff` into `d4`, you'll save that last allocation as well","user":"UH24GRBLL","ts":"1613042381.186200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yHn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if you pass "},{"type":"text","text":"Diff","style":{"code":true}},{"type":"text","text":" into "},{"type":"text","text":"d4","style":{"code":true}},{"type":"text","text":", you'll save that last allocation as well"}]}]}]},{"client_msg_id":"4426c382-ef78-45a0-a409-8a7d0b3ccd71","type":"message","text":"and with the `copy_to`  it inffers the generator output type from the copy destination? Why do I need the `@view` ?","user":"U7PD3M3L5","ts":"1613042401.186600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2Io","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and with the "},{"type":"text","text":"copy_to","style":{"code":true}},{"type":"text","text":"  it inffers the generator output type from the copy destination? Why do I need the "},{"type":"text","text":"@view","style":{"code":true}},{"type":"text","text":" ?"}]}]}]},{"client_msg_id":"673ae319-03f1-4ddc-b5e0-ce004c306100","type":"message","text":"in julia, slices create copies","user":"UH24GRBLL","ts":"1613042414.186900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"y3C8R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"in julia, slices create copies"}]}]}]},{"client_msg_id":"678fe260-1c55-4f02-9547-da81054ac1a3","type":"message","text":"`@view` instead creates a view into the underlying memory","user":"UH24GRBLL","ts":"1613042426.187600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QLT7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"@view","style":{"code":true}},{"type":"text","text":" instead creates a view into the underlying memory"}]}]}]},{"client_msg_id":"bb1ded95-2c84-4b11-aff9-b9ed73667690","type":"message","text":"uff really :smile:","user":"U7PD3M3L5","ts":"1613042426.187700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m7YfI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"uff really "},{"type":"emoji","name":"smile"}]}]}]},{"client_msg_id":"7a06df2b-a2e2-45cd-bbbd-5382de3a79e9","type":"message","text":"man thats a lot to keep in my head","user":"U7PD3M3L5","ts":"1613042431.188000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FGQAb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"man thats a lot to keep in my head"}]}]}]},{"client_msg_id":"8b9b2f5f-8378-4ac2-b047-afe78901f503","type":"message","text":"it's not that much :) slices copy, loops are fast (REALLY fast)","user":"UH24GRBLL","ts":"1613042471.189100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5ZR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it's not that much :) slices copy, loops are fast (REALLY fast)"}]}]}]},{"client_msg_id":"1082d601-db97-4a7b-b085-846c7ad7ecd7","type":"message","text":"Slice notation left of `=` or `.=` is special, it’s really `setindex!` or `broadcast!` (I think). But `copyto!` is an ordinary function, so its arguments get evaluated first.","user":"UD0NS8PDF","ts":"1613042496.189900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JyW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Slice notation left of "},{"type":"text","text":"=","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":".=","style":{"code":true}},{"type":"text","text":" is special, it’s really "},{"type":"text","text":"setindex!","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"broadcast!","style":{"code":true}},{"type":"text","text":" (I think). But "},{"type":"text","text":"copyto!","style":{"code":true}},{"type":"text","text":" is an ordinary function, so its arguments get evaluated first."}]}]}]},{"client_msg_id":"20d3d59f-3867-41d8-b180-d7db10b13b47","type":"message","text":"and we need the `copyto`  s.t. it can predict the output size of the generator?","user":"U7PD3M3L5","ts":"1613042537.190700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qU5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and we need the "},{"type":"text","text":"copyto","style":{"code":true}},{"type":"text","text":"  s.t. it can predict the output size of the generator?"}]}]}]},{"client_msg_id":"7b48e3b1-540c-4a94-9193-cce404568f25","type":"message","text":"yes, something like `A[:] .= B[:]` broadcasts the setindex, which (internally) calls `copyto!` since it writes to a slice","user":"UH24GRBLL","ts":"1613042559.191500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mKGLD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yes, something like "},{"type":"text","text":"A[:] .= B[:]","style":{"code":true}},{"type":"text","text":" broadcasts the setindex, which (internally) calls "},{"type":"text","text":"copyto!","style":{"code":true}},{"type":"text","text":" since it writes to a slice"}]}]}]},{"client_msg_id":"fcbaf6b3-fc25-4151-b72c-8d4ae11015df","type":"message","text":"I want to stress that you don't have to write the `copyto!(...)` manually - it was just an attempt at making the generator variant fast (looks ugly in my opionion :man-shrugging:)","user":"UH24GRBLL","ts":"1613042602.192900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UFv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I want to stress that you don't have to write the "},{"type":"text","text":"copyto!(...)","style":{"code":true}},{"type":"text","text":" manually - it was just an attempt at making the generator variant fast (looks ugly in my opionion "},{"type":"emoji","name":"man-shrugging"},{"type":"text","text":")"}]}]}],"reactions":[{"name":"+1","users":["UD0NS8PDF"],"count":1}]},{"client_msg_id":"9d2a6682-da74-4b7a-8b7f-54f02a33f4ab","type":"message","text":"I haven't benchmarked it, but I'd wager\n\n```for i=1:n, j=1:n, dim=1:d\n        diff[i,j,dim] = X[dim,i] - X[dim,j]\nend```\nis plenty fast enough - and if it isn't we can work with that to make it faster","user":"UH24GRBLL","ts":"1613042651.194000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FfBh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I haven't benchmarked it, but I'd wager\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"for i=1:n, j=1:n, dim=1:d\n        diff[i,j,dim] = X[dim,i] - X[dim,j]\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nis plenty fast enough - and if it isn't we can work with that to make it faster"}]}]}]},{"client_msg_id":"ee5e2b6e-d481-4991-9b2e-5b0a882f9057","type":"message","text":"I think `copyto!` doesn’t need to know the length, it just starts iterating and writing. But it’s a much simpler thing than broadcasting. It doesn’t try to look for size-1 dimensions of some arrays to expand…","user":"UD0NS8PDF","ts":"1613042653.194100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4fZf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think "},{"type":"text","text":"copyto!","style":{"code":true}},{"type":"text","text":" doesn’t need to know the length, it just starts iterating and writing. But it’s a much simpler thing than broadcasting. It doesn’t try to look for size-1 dimensions of some arrays to expand…"}]}]}]},{"client_msg_id":"6a20e29b-8c66-4172-978a-193b6493fd5a","type":"message","text":"These simple loops are precisely what the `@einsum` variant above times.","user":"UD0NS8PDF","ts":"1613042676.194500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+nb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"These simple loops are precisely what the "},{"type":"text","text":"@einsum","style":{"code":true}},{"type":"text","text":" variant above times."}]}]}]},{"client_msg_id":"b8f21d48-e689-4885-97e2-835945a89bc3","type":"message","text":"right - I just prefer being explicit instead of pulling in a macro :)","user":"UH24GRBLL","ts":"1613042714.194800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"51i6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"right - I just prefer being explicit instead of pulling in a macro :)"}]}]}]},{"client_msg_id":"b84aea64-d9ce-4618-b9a2-c5d5c3911879","type":"message","text":"lets me pretend that I have a clue what's going on","user":"UH24GRBLL","ts":"1613042731.195400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MKD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"lets me pretend that I have a clue what's going on"}]}]}]},{"client_msg_id":"cc72ebb5-6f85-43d9-8e62-4067ad53dc74","type":"message","text":"Sure :slightly_smiling_face:. With `@inbounds`.","user":"UD0NS8PDF","ts":"1613042736.195500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WYO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sure "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":". With "},{"type":"text","text":"@inbounds","style":{"code":true}},{"type":"text","text":"."}]}]}]},{"client_msg_id":"8b49ccfc-8fac-4119-a0b7-861af9c402dd","type":"message","text":"and `@simd`","user":"UH24GRBLL","ts":"1613042744.195900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+ig","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and "},{"type":"text","text":"@simd","style":{"code":true}}]}]}]},{"client_msg_id":"747682dc-f0ef-4e4d-a13d-7a1d49752c39","type":"message","text":"And I never remember what loop is innermost in `for i=1:n, j=1:n, dim=1:d` on one line :confused:","user":"UD0NS8PDF","ts":"1613042758.196300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IQs=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And I never remember what loop is innermost in "},{"type":"text","text":"for i=1:n, j=1:n, dim=1:d","style":{"code":true}},{"type":"text","text":" on one line "},{"type":"emoji","name":"confused"}]}]}]},{"client_msg_id":"41d2dfd9-17a6-4521-b472-027ebfc9411c","type":"message","text":"that's why I mentioned the order may need tweaking :D","user":"UH24GRBLL","ts":"1613042770.196600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eSpy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's why I mentioned the order may need tweaking :D"}]}]}],"thread_ts":"1613042770.196600","reply_count":1,"reply_users_count":1,"latest_reply":"1613042963.199200","reply_users":["UD0NS8PDF"],"subscribed":false},{"client_msg_id":"0002206d-26ed-4c88-844a-cb1dfca1b754","type":"message","text":"I think you'd want to iterate `dim` first, since that accesses `X`","user":"UH24GRBLL","ts":"1613042796.197100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"303WA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think you'd want to iterate "},{"type":"text","text":"dim","style":{"code":true}},{"type":"text","text":" first, since that accesses "},{"type":"text","text":"X","style":{"code":true}}]}]}]},{"client_msg_id":"661f8509-f4a8-403e-9e47-e2a82d43ccab","type":"message","text":"but about the loops being fast. Calculating this:\n```    dist = SqEuclidean()\n    res .= exp.(-pairwise(dist, X, X, dims=2) ./ (2*σ_squ))```\nto get an `nxn`  kernel matrix was about 15x faster than doing it in a for-loop I think","user":"U7PD3M3L5","ts":"1613042848.198200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"N1S","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but about the loops being fast. Calculating this:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"    dist = SqEuclidean()\n    res .= exp.(-pairwise(dist, X, X, dims=2) ./ (2*σ_squ))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"to get an "},{"type":"text","text":"nxn","style":{"code":true}},{"type":"text","text":"  kernel matrix was about 15x faster than doing it in a for-loop I think"}]}]}]},{"client_msg_id":"03d3b996-1397-4156-836a-825b3db05762","type":"message","text":"allthough I did maybe misuse a generator in an allocating way, I did not know about `[]`  allocating","user":"U7PD3M3L5","ts":"1613042871.198700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TSPR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"allthough I did maybe misuse a generator in an allocating way, I did not know about "},{"type":"text","text":"[]","style":{"code":true}},{"type":"text","text":"  allocating"}]}]}]},{"client_msg_id":"d9c75ca4-8453-4da0-8072-3643a65a67a1","type":"message","text":"this is the reason why I didn't want to use a loop here in the first place","user":"U7PD3M3L5","ts":"1613042888.199100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G7GO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this is the reason why I didn't want to use a loop here in the first place"}]}]}]},{"client_msg_id":"0c8d4666-9c2c-4c16-994b-18e6002461fa","type":"message","text":"Yes. Very simple loops are fast here, because the operation is something close to a copy, you iterate through the data once. But `pairwise(SqEuclidean(),` is a more complicated operation, it sums over some indices, it’s a bit like matrix multiplication.","user":"UD0NS8PDF","ts":"1613043107.201600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"R12","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes. Very simple loops are fast here, because the operation is something close to a copy, you iterate through the data once. But "},{"type":"text","text":"pairwise(SqEuclidean(),","style":{"code":true}},{"type":"text","text":" is a more complicated operation, it sums over some indices, it’s a bit like matrix multiplication."}]}]}]},{"client_msg_id":"5e30fece-58e5-4e51-9073-b718dd607018","type":"message","text":"<https://juliahub.com/ui/Packages/Distances/yuMjt/0.10.2#Pairwise-benchmark>\n\nis also of note","user":"UH24GRBLL","ts":"1613043154.202600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LzYn","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://juliahub.com/ui/Packages/Distances/yuMjt/0.10.2#Pairwise-benchmark"},{"type":"text","text":"\n\nis also of note"}]}]}]},{"client_msg_id":"f5dd6405-3682-41a5-86e6-ef7f582f844b","type":"message","text":"&gt; Generically, pairwise distances are computed using a straightforward loop implementation. For distances of which a major part of the computation is a quadratic form, however, the performance can be drastically improved by restructuring the computation and delegating the core part to GEMM in BLAS","user":"UH24GRBLL","ts":"1613043168.203000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Xmne","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"Generically, pairwise distances are computed using a straightforward loop implementation. For distances of which a major part of the computation is a quadratic form, however, the performance can be drastically improved by restructuring the computation and delegating the core part to GEMM in BLAS"}]}]}]},{"client_msg_id":"af55c7a2-5de0-4322-82e1-93cd7081a46b","type":"message","text":"And that’s something for which simple loops (even in a fast language) can be beaten by smarter code. I’m not sure what Distances does but one way of calculating this does just re-write it as matrix multiplication.","user":"UD0NS8PDF","ts":"1613043170.203200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+q/9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And that’s something for which simple loops (even in a fast language) can be beaten by smarter code. I’m not sure what Distances does but one way of calculating this does just re-write it as matrix multiplication."}]}]}]},{"client_msg_id":"362c5863-1270-425e-9a0b-6f855a6e7e6c","type":"message","text":"The beauty of it is that the loop version (if written non allocating and SIMD friendly) is still blazingly fast and the matmul is just an optimization on top of that. In some other languages, the loop version isn't even a contender, with it being more than 100x slower","user":"UH24GRBLL","ts":"1613043281.204600","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1613043284.000000"},"blocks":[{"type":"rich_text","block_id":"ZydaJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The beauty of it is that the loop version (if written non allocating and SIMD friendly) is still blazingly fast and the matmul is just an optimization on top of that. In some other languages, the loop version isn't even a contender, with it being more than 100x slower"}]}]}]},{"client_msg_id":"fc1762fa-f092-4bca-8c5c-4cc2b92ac2de","type":"message","text":"Ok I lied a bit and this is the full version of the function I am trying to calculate (it is the matrix I told you above with the differences * k a kernel matrix). These are the versions and the benchmarks:","user":"U7PD3M3L5","ts":"1613043423.205600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zUK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok I lied a bit and this is the full version of the function I am trying to calculate (it is the matrix I told you above with the differences * k a kernel matrix). These are the versions and the benchmarks:"}]}]}]},{"client_msg_id":"6bddb76e-f474-45d9-8efc-9745ac47b140","type":"message","text":"```function calc_dx_K(K, X, σ_squ, res)\n    (d, n) = size(X)\n    \n    for dim=1:d\n        res[:, :, dim] .= (-1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j] for i=1:n, j=1:n)\n    end\n    \n    res\nend```\n`2.006 ms (200 allocations: 4.89 MiB)`\n```function calc_dx_K_cast(K, X, σ_squ, res)\n    (d, n) = size(X)\n    @cast res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    res\nend```\n`  704.595 μs (8 allocations: 125.38 KiB)`\n```\nfunction calc_dx_K_loop(K, X, σ_squ, res)\n    (d, n) = size(X)\n    for i=1:n, j=1:n, dim=1:d\n        res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    end\n    res\nend```\n`  1.827 ms (0 allocations: 0 bytes)`","user":"U7PD3M3L5","ts":"1613043487.206600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JFJNQ","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function calc_dx_K(K, X, σ_squ, res)\n    (d, n) = size(X)\n    \n    for dim=1:d\n        res[:, :, dim] .= (-1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j] for i=1:n, j=1:n)\n    end\n    \n    res\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"`2.006 ms (200 allocations: 4.89 MiB)`\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function calc_dx_K_cast(K, X, σ_squ, res)\n    (d, n) = size(X)\n    @cast res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    res\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"`  704.595 μs (8 allocations: 125.38 KiB)`\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"\nfunction calc_dx_K_loop(K, X, σ_squ, res)\n    (d, n) = size(X)\n    for i=1:n, j=1:n, dim=1:d\n        res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    end\n    res\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"`  1.827 ms (0 allocations: 0 bytes)`"}]}]}]},{"client_msg_id":"010c255a-9ee0-4449-aa47-d21bcb88191a","type":"message","text":"I benchmarked them with\n```X = rand(d, n)\nK = rand(n, n)\nres = similar(X, n, n, d)\n\n@btime calc_dx_K($K, $X, 2, $res) ```","user":"U7PD3M3L5","ts":"1613043507.206800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xkku","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I benchmarked them with\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"X = rand(d, n)\nK = rand(n, n)\nres = similar(X, n, n, d)\n\n@btime calc_dx_K($K, $X, 2, $res) "}]}]}]},{"client_msg_id":"c316f969-f2ba-42d4-8208-6cf7d19da8be","type":"message","text":"put an `@inbounds` on that loop version, right in front of the `for`","user":"UH24GRBLL","ts":"1613043530.207400","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1613043535.000000"},"blocks":[{"type":"rich_text","block_id":"Oq1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"put an "},{"type":"text","text":"@inbounds","style":{"code":true}},{"type":"text","text":" on that loop version, right in front of the "},{"type":"text","text":"for","style":{"code":true}}]}]}]},{"client_msg_id":"e57abb6e-7bac-43c5-a0c4-c1e7317100f5","type":"message","text":"this is probably since the loop is doing the wrong order?","user":"U7PD3M3L5","ts":"1613043530.207500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uEuI4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this is probably since the loop is doing the wrong order?"}]}]}]},{"client_msg_id":"f6c05d3e-b7c8-4c30-b377-fff9899f838c","type":"message","text":"I'm not sure if it helps with SIMD, but you can also hoist the `-1/sigma_squ` out of the loop into its own variable - though the compiler should be able to do that on its own","user":"UH24GRBLL","ts":"1613043594.208300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/rHQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm not sure if it helps with SIMD, but you can also hoist the "},{"type":"text","text":"-1/sigma_squ","style":{"code":true}},{"type":"text","text":" out of the loop into its own variable - though the compiler should be able to do that on its own"}]}]}]},{"client_msg_id":"8105375b-128c-4c7d-b234-64b21bd8d2b9","type":"message","text":"loop version with `@inbounds` : 1.740 ms (0 allocations: 0 bytes)","user":"U7PD3M3L5","ts":"1613043623.208600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lrg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"loop version with "},{"type":"text","text":"@inbounds","style":{"code":true}},{"type":"text","text":" : 1.740 ms (0 allocations: 0 bytes)"}]}]}]},{"client_msg_id":"86d42268-7daa-47e4-886c-5d726972a5c1","type":"message","text":"```julia&gt; function calc_dx_K_loop(K, X, σ_squ, res)\n           (d, n) = size(X)\n           factor = -1/σ_squ\n           @inbounds for i=1:n, j=1:n, dim=1:d\n               res[i, j, dim] = factor * (X[dim, i] - X[dim, j]) * K[i, j]\n           end\n           res\n       end\ncalc_dx_K_loop (generic function with 1 method)\n\njulia&gt; @benchmark calc_dx_K_loop($K, $X, 2, $res)\nBenchmarkTools.Trial:\n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     744.531 ns (0.00% GC)\n  median time:      745.312 ns (0.00% GC)\n  mean time:        811.813 ns (0.00% GC)\n  maximum time:     12.431 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     128```","user":"UH24GRBLL","ts":"1613043856.209000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"csv","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> function calc_dx_K_loop(K, X, σ_squ, res)\n           (d, n) = size(X)\n           factor = -1/σ_squ\n           @inbounds for i=1:n, j=1:n, dim=1:d\n               res[i, j, dim] = factor * (X[dim, i] - X[dim, j]) * K[i, j]\n           end\n           res\n       end\ncalc_dx_K_loop (generic function with 1 method)\n\njulia> @benchmark calc_dx_K_loop($K, $X, 2, $res)\nBenchmarkTools.Trial:\n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     744.531 ns (0.00% GC)\n  median time:      745.312 ns (0.00% GC)\n  mean time:        811.813 ns (0.00% GC)\n  maximum time:     12.431 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     128"}]}]}]},{"client_msg_id":"c697c5ad-4918-4a8e-9a3f-c5396c32b463","type":"message","text":"yeah but you probably have a different computer to mine","user":"U7PD3M3L5","ts":"1613043895.209300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xjq/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah but you probably have a different computer to mine"}]}]}]},{"client_msg_id":"d0cb5099-631f-43c6-8741-9a27356aef67","type":"message","text":"so only the relative difference is of interest or not","user":"U7PD3M3L5","ts":"1613043925.210000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"55hc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so only the relative difference is of interest or not"}]}]}]},{"client_msg_id":"0b2d4cab-36df-45ee-bbdd-8242c7a45cb6","type":"message","text":"this version\n```function calc_dx_K_generator(K, X, σ_squ, res)\n    (d, n) = size(X)\n    for dim=1:d\n        copyto!(@view(res[:, :, dim]), ( -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j] for i=1:n, j=1:n))\n    end\n    res\nend```\ntakes   1.705 ms (0 allocations: 0 bytes), so pretty much the same like the loop version","user":"U7PD3M3L5","ts":"1613043949.210500","team":"T68168MUP","edited":{"user":"U7PD3M3L5","ts":"1613044018.000000"},"blocks":[{"type":"rich_text","block_id":"qLziU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this version\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function calc_dx_K_generator(K, X, σ_squ, res)\n    (d, n) = size(X)\n    for dim=1:d\n        copyto!(@view(res[:, :, dim]), ( -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j] for i=1:n, j=1:n))\n    end\n    res\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"takes   1.705 ms (0 allocations: 0 bytes), so pretty much the same like the loop version"}]}]}]},{"client_msg_id":"78c875b9-aef2-4ee1-b9c8-e4fbffc78824","type":"message","text":"if I force the target to be cold cache lines, I get it this\n```julia&gt; @benchmark calc_dx_K_loop(a, b, 2, c) setup=(a=deepcopy(K);b=deepcopy(X);c=similar(X, n, n, d)) evals=1\nBenchmarkTools.Trial:\n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.200 μs (0.00% GC)\n  median time:      2.600 μs (0.00% GC)\n  mean time:        3.190 μs (0.00% GC)\n  maximum time:     72.900 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1```","user":"UH24GRBLL","ts":"1613044022.211700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"o9/d","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if I force the target to be cold cache lines, I get it this\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @benchmark calc_dx_K_loop(a, b, 2, c) setup=(a=deepcopy(K);b=deepcopy(X);c=similar(X, n, n, d)) evals=1\nBenchmarkTools.Trial:\n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.200 μs (0.00% GC)\n  median time:      2.600 μs (0.00% GC)\n  mean time:        3.190 μs (0.00% GC)\n  maximum time:     72.900 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1"}]}]}]},{"client_msg_id":"379a432a-a708-48f3-bc68-af1f0ddc91cf","type":"message","text":"and what do you get for the cast version?","user":"U7PD3M3L5","ts":"1613044064.212200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"abq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and what do you get for the cast version?"}]}]}]},{"client_msg_id":"ce75b149-d05e-4497-b0d9-c54f4c11d204","type":"message","text":"that one is the fastest on my pc","user":"U7PD3M3L5","ts":"1613044073.212500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bm9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that one is the fastest on my pc"}]}]}]},{"client_msg_id":"0a6e5f1e-52a4-4ba9-990f-5668fa3c76f1","type":"message","text":"I don't have that macro, is it from Distances?","user":"UH24GRBLL","ts":"1613044081.212900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LSLi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't have that macro, is it from Distances?"}]}]}],"thread_ts":"1613044081.212900","reply_count":1,"reply_users_count":1,"latest_reply":"1613044119.213500","reply_users":["UD0NS8PDF"],"subscribed":false},{"client_msg_id":"45d67473-bee6-42b7-9c94-a40ccf57fbba","type":"message","text":"Oh that’s interesting. My times were:\n```julia&gt; @btime calc_dx_K_loop($K, $X, 2, $res); # without @inbounds\n  1.068 μs (0 allocations: 0 bytes)\n\njulia&gt; @btime calc_dx_K_cast($K, $X, 2, $res);\n  2.291 μs (6 allocations: 2.88 KiB)\n\njulia&gt; function calc_dx_K_loop(K, X, σ_squ, res)\n           (d, n) = size(X)\n           @inbounds for i=1:n, j=1:n, dim=1:d\n               res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n           end\n           res\n       end\ncalc_dx_K_loop (generic function with 1 method)\n\njulia&gt; @btime calc_dx_K_loop($K, $X, 2, $res);\n  692.162 ns (0 allocations: 0 bytes)\n\njulia&gt; using LoopVectorization\n\njulia&gt; function calc_dx_K_loop(K, X, σ_squ, res)\n           (d, n) = size(X)\n           pre = -1/σ_squ\n           @avx for i=1:n, j=1:n, dim=1:d\n               res[i, j, dim] = pre * (X[dim, i] - X[dim, j]) * K[i, j]\n           end\n           res\n       end\ncalc_dx_K_loop (generic function with 1 method)\n\njulia&gt; @btime calc_dx_K_loop($K, $X, 2, $res);\n  502.534 ns (0 allocations: 0 bytes)```","user":"UD0NS8PDF","ts":"1613044087.213100","team":"T68168MUP","edited":{"user":"UD0NS8PDF","ts":"1613044311.000000"},"blocks":[{"type":"rich_text","block_id":"fm9A","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh that’s interesting. My times were:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @btime calc_dx_K_loop($K, $X, 2, $res); # without @inbounds\n  1.068 μs (0 allocations: 0 bytes)\n\njulia> @btime calc_dx_K_cast($K, $X, 2, $res);\n  2.291 μs (6 allocations: 2.88 KiB)\n\njulia> function calc_dx_K_loop(K, X, σ_squ, res)\n           (d, n) = size(X)\n           @inbounds for i=1:n, j=1:n, dim=1:d\n               res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n           end\n           res\n       end\ncalc_dx_K_loop (generic function with 1 method)\n\njulia> @btime calc_dx_K_loop($K, $X, 2, $res);\n  692.162 ns (0 allocations: 0 bytes)\n\njulia> using LoopVectorization\n\njulia> function calc_dx_K_loop(K, X, σ_squ, res)\n           (d, n) = size(X)\n           pre = -1/σ_squ\n           @avx for i=1:n, j=1:n, dim=1:d\n               res[i, j, dim] = pre * (X[dim, i] - X[dim, j]) * K[i, j]\n           end\n           res\n       end\ncalc_dx_K_loop (generic function with 1 method)\n\njulia> @btime calc_dx_K_loop($K, $X, 2, $res);\n  502.534 ns (0 allocations: 0 bytes)"}]}]}]},{"client_msg_id":"05fdb668-9f6d-4e51-9c43-5885d1188a4e","type":"message","text":"My machine is\n\n```julia&gt; versioninfo()\nJulia Version 1.6.0-rc1\nCommit a58bdd9010* (2021-02-06 15:49 UTC)\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: Intel(R) Core(TM) i7-6600U CPU @ 2.60GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)\nEnvironment:\n  JULIA_PKG_SERVER =\n  JULIA_NUM_THREADS = 4```","user":"UH24GRBLL","ts":"1613044099.213300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4Kn3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My machine is\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> versioninfo()\nJulia Version 1.6.0-rc1\nCommit a58bdd9010* (2021-02-06 15:49 UTC)\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: Intel(R) Core(TM) i7-6600U CPU @ 2.60GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)\nEnvironment:\n  JULIA_PKG_SERVER =\n  JULIA_NUM_THREADS = 4"}]}]}]},{"client_msg_id":"f9a3b997-114b-4ab4-a24b-f48a87f10047","type":"message","text":"also 4 threads on BLAS","user":"UH24GRBLL","ts":"1613044127.213800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"B9VF2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"also 4 threads on BLAS"}]}]}]},{"client_msg_id":"ddaff09d-6f45-4a61-8e66-9b311d88d8e1","type":"message","text":"yeah, I'm not surprised that `@avx` kills it here","user":"UH24GRBLL","ts":"1613044184.214200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yRw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, I'm not surprised that "},{"type":"text","text":"@avx","style":{"code":true}},{"type":"text","text":" kills it here"}]}]}]},{"client_msg_id":"1c23ee25-0b48-4d3c-8180-6b547c8b2671","type":"message","text":"@cast is from tensorcast","user":"U7PD3M3L5","ts":"1613044228.214600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2sMXM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"@cast is from tensorcast"}]}]}]},{"client_msg_id":"4e783a04-7721-4954-9b3d-a12a29d6555e","type":"message","text":"what is your result with `@cast`  <@UD0NS8PDF>?","user":"U7PD3M3L5","ts":"1613044241.214900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lQAYG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what is your result with "},{"type":"text","text":"@cast","style":{"code":true}},{"type":"text","text":"  "},{"type":"user","user_id":"UD0NS8PDF"},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"92bdb68f-7eed-4546-9489-ff83614b3a4b","type":"message","text":"it is much faster on my machine allthough it allocates","user":"U7PD3M3L5","ts":"1613044256.215200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m0+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it is much faster on my machine allthough it allocates"}]}]}]},{"client_msg_id":"b51b028e-d632-44e9-b983-c0520bf9035d","type":"message","text":"oh we should also compare to Tullio","user":"UH24GRBLL","ts":"1613044293.215400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ooIO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oh we should also compare to Tullio"}]}]}]},{"client_msg_id":"a368347a-01d5-40c8-9613-f9738e50bbce","type":"message","text":"For me `@tullio` matches the `@avx` version above, i.e. it’s getting no benefit from threading.","user":"UD0NS8PDF","ts":"1613044346.216200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"P53","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For me "},{"type":"text","text":"@tullio","style":{"code":true}},{"type":"text","text":" matches the "},{"type":"text","text":"@avx","style":{"code":true}},{"type":"text","text":" version above, i.e. it’s getting no benefit from threading."}]}]}]},{"client_msg_id":"ce2400ad-7cbe-4885-b308-11fdf1a8864f","type":"message","text":"<@UD0NS8PDF> has faster RAM than I do, I'm limited to the 2µs :(","user":"UH24GRBLL","ts":"1613044364.216800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jZxsD","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UD0NS8PDF"},{"type":"text","text":" has faster RAM than I do, I'm limited to the 2µs :("}]}]}]},{"client_msg_id":"6d1f9861-81f8-41c3-b5e8-2bd1da6940db","type":"message","text":"```julia&gt; function calc_dx_K_loop(K, X, σ_squ, res)\n           (d, n) = size(X)\n           factor = -1/σ_squ\n           @avx for i=1:n, j=1:n, dim=1:d\n               res[i, j, dim] = factor * (X[dim, i] - X[dim, j]) * K[i, j]\n           end\n           res\n       end\ncalc_dx_K_loop (generic function with 1 method)\n\njulia&gt; @benchmark calc_dx_K_loop(a, b, 2, c) setup=(a=deepcopy(K);b=deepcopy(X);c=similar(X, n, n, d)) evals=1\nBenchmarkTools.Trial:\n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.000 μs (0.00% GC)\n  median time:      2.200 μs (0.00% GC)\n  mean time:        2.932 μs (0.00% GC)\n  maximum time:     29.100 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1```","user":"UH24GRBLL","ts":"1613044367.217000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=ofQC","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> function calc_dx_K_loop(K, X, σ_squ, res)\n           (d, n) = size(X)\n           factor = -1/σ_squ\n           @avx for i=1:n, j=1:n, dim=1:d\n               res[i, j, dim] = factor * (X[dim, i] - X[dim, j]) * K[i, j]\n           end\n           res\n       end\ncalc_dx_K_loop (generic function with 1 method)\n\njulia> @benchmark calc_dx_K_loop(a, b, 2, c) setup=(a=deepcopy(K);b=deepcopy(X);c=similar(X, n, n, d)) evals=1\nBenchmarkTools.Trial:\n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.000 μs (0.00% GC)\n  median time:      2.200 μs (0.00% GC)\n  mean time:        2.932 μs (0.00% GC)\n  maximum time:     29.100 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1"}]}]}]},{"client_msg_id":"44199e20-db10-4d9d-915f-bc008d19f2a7","type":"message","text":"I can't really help further with checks from my machine, since I hit memory loading bounds","user":"UH24GRBLL","ts":"1613044390.217800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vO3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can't really help further with checks from my machine, since I hit memory loading bounds"}]}]}]},{"client_msg_id":"ab53da0b-3d0e-4814-b84b-59cb2346488d","type":"message","text":"you mean the 2microseconds are the time it takes to get the stuff from RAM into the processor cache?","user":"U7PD3M3L5","ts":"1613044449.219400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FkZX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you mean the 2microseconds are the time it takes to get the stuff from RAM into the processor cache?"}]}]}]},{"client_msg_id":"43f63ceb-73f8-4666-b6d5-25d5b694627d","type":"message","text":"And `@cast` is 2.291 μs, I added it above now. I’m a little confused but think I’m on the same branch as the tagged version. The allocations are because it’s trying to avoid reshaping `X` after transposing it… a new version should avoid this.","user":"UD0NS8PDF","ts":"1613044455.219500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lyz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And "},{"type":"text","text":"@cast","style":{"code":true}},{"type":"text","text":" is 2.291 μs, I added it above now. I’m a little confused but think I’m on the same branch as the tagged version. The allocations are because it’s trying to avoid reshaping "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" after transposing it… a new version should avoid this."}]}]}]},{"client_msg_id":"2327f218-a76f-4806-824a-fc511b41a98e","type":"message","text":"if I just `@btime`, I also get 500ns, but that's because you're choosing the minimum time of a number of benchmarkruns over the same exact data to the same exact memory locations - basically measuring caching effects","user":"UH24GRBLL","ts":"1613044490.220300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1Dp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if I just "},{"type":"text","text":"@btime","style":{"code":true}},{"type":"text","text":", I also get 500ns, but that's because you're choosing the minimum time of a number of benchmarkruns over the same exact data to the same exact memory locations - basically measuring caching effects"}]}]}]},{"client_msg_id":"8bb6c2e7-64bf-4af3-b73a-3911d2d345a0","type":"message","text":"that's why I chose to go the route of providing `@benchmark` with a setup and `evals=1`, to force it to write to each location only once","user":"UH24GRBLL","ts":"1613044522.220900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"diFxc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's why I chose to go the route of providing "},{"type":"text","text":"@benchmark","style":{"code":true}},{"type":"text","text":" with a setup and "},{"type":"text","text":"evals=1","style":{"code":true}},{"type":"text","text":", to force it to write to each location only once"}]}]}]},{"client_msg_id":"8270d764-04bf-4ecc-91b2-b4bd22ffcbda","type":"message","text":"much more typical use :)","user":"UH24GRBLL","ts":"1613044540.221100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SVD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"much more typical use :)"}]}]}]},{"client_msg_id":"3febe7d3-f2a7-45d2-b001-15fb6afb5fc6","type":"message","text":"weird that on your machine looping is faster and on mine its caching?","user":"U7PD3M3L5","ts":"1613044582.221400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WCTk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"weird that on your machine looping is faster and on mine its caching?"}]}]}]},{"client_msg_id":"ad98f024-8b9e-42b9-95ec-88d0aa1a39f1","type":"message","text":"you've only measured with `@btime`, correct?","user":"UH24GRBLL","ts":"1613044618.222000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fkmaM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you've only measured with "},{"type":"text","text":"@btime","style":{"code":true}},{"type":"text","text":", correct?"}]}]}]},{"client_msg_id":"94b5b924-21d4-4715-8c8c-e82e73a5e023","type":"message","text":"it is not very unprobable that the `K`  matrix will be in cache actually","user":"U7PD3M3L5","ts":"1613044626.222500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0hq5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it is not very unprobable that the "},{"type":"text","text":"K","style":{"code":true}},{"type":"text","text":"  matrix will be in cache actually"}]}]}]},{"client_msg_id":"48dc5723-be30-4012-9ada-246eae5f1607","type":"message","text":"its pretty common in the code","user":"U7PD3M3L5","ts":"1613044631.222900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QuP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"its pretty common in the code"}]}]}]},{"client_msg_id":"1d5c5a90-8675-4078-aaa3-ae7a79f07dfc","type":"message","text":"try measuring with that `@benchmark calc_dx_K_loop(a, b, 2, c) setup(a=deepcopy(K);b=deepcopy(X);c=similar(X, n, n, d)) evals=1`","user":"UH24GRBLL","ts":"1613044641.223200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Nbkv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"try measuring with that "},{"type":"text","text":"@benchmark calc_dx_K_loop(a, b, 2, c) setup(a=deepcopy(K);b=deepcopy(X);c=similar(X, n, n, d)) evals=1","style":{"code":true}}]}]}]},{"client_msg_id":"67e59025-51b3-4bb9-b3f9-73454a2eee41","type":"message","text":"Yes, `K` will be - but will `res`?","user":"UH24GRBLL","ts":"1613044651.223700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"y6G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, "},{"type":"text","text":"K","style":{"code":true}},{"type":"text","text":" will be - but will "},{"type":"text","text":"res","style":{"code":true}},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"5030c295-7fb9-4f2e-abff-7ebe24a4c908","type":"message","text":"It is a bit weird. I’m on a 2018-ish macbook pro, the cheapest kind.","user":"UD0NS8PDF","ts":"1613044662.224100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iDV9L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It is a bit weird. I’m on a 2018-ish macbook pro, the cheapest kind."}]}]}]},{"client_msg_id":"dbd92d73-81cd-4238-ae3a-bec0c5f1ab3b","type":"message","text":"I mean res is a buffer I will be reusing all the time","user":"U7PD3M3L5","ts":"1613044669.224500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"32f","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I mean res is a buffer I will be reusing all the time"}]}]}]},{"client_msg_id":"36e44f2a-c95d-44b8-b2f7-d9063709d815","type":"message","text":"but yeah at that point its maybe not in cache anymore","user":"U7PD3M3L5","ts":"1613044678.225000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"01pgk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but yeah at that point its maybe not in cache anymore"}]}]}]},{"client_msg_id":"b2ec290c-40a5-458e-a61a-da1d0bbdb874","type":"message","text":"or at least not in the very closes caches","user":"U7PD3M3L5","ts":"1613044691.225600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AdJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"or at least not in the very closes caches"}]}]}]},{"client_msg_id":"daa93597-a3c3-4f1a-b739-41197605b7d7","type":"message","text":"For me the copy comparison looks like so, I don’t quite know what to make of these (fairly repeatable) numbers:\n```julia&gt; @btime calc_dx_K_loop($K, $X, 2, $res); # version with @avx\n  503.715 ns (0 allocations: 0 bytes)\n\njulia&gt; @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=copy($K); X_=copy($X); res_=copy($res)) evals=1;\n  527.000 ns (0 allocations: 0 bytes)\n\njulia&gt; @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=copy(K); X_=copy(X); res_=copy(res)) evals=1;\n  533.000 ns (0 allocations: 0 bytes)\n\njulia&gt; @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=deepcopy($K); X_=deepcopy($X); res_=deepcopy($res)) evals=1;\n  707.000 ns (0 allocations: 0 bytes)\n\njulia&gt; @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=deepcopy(K); X_=deepcopy(X); res_=deepcopy(res)) evals=1;\n  544.000 ns (0 allocations: 0 bytes)```","user":"UD0NS8PDF","ts":"1613044699.226000","team":"T68168MUP","edited":{"user":"UD0NS8PDF","ts":"1613044949.000000"},"blocks":[{"type":"rich_text","block_id":"8UF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For me the copy comparison looks like so, I don’t quite know what to make of these (fairly repeatable) numbers:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @btime calc_dx_K_loop($K, $X, 2, $res); # version with @avx\n  503.715 ns (0 allocations: 0 bytes)\n\njulia> @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=copy($K); X_=copy($X); res_=copy($res)) evals=1;\n  527.000 ns (0 allocations: 0 bytes)\n\njulia> @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=copy(K); X_=copy(X); res_=copy(res)) evals=1;\n  533.000 ns (0 allocations: 0 bytes)\n\njulia> @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=deepcopy($K); X_=deepcopy($X); res_=deepcopy($res)) evals=1;\n  707.000 ns (0 allocations: 0 bytes)\n\njulia> @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=deepcopy(K); X_=deepcopy(X); res_=deepcopy(res)) evals=1;\n  544.000 ns (0 allocations: 0 bytes)"}]}]}],"thread_ts":"1613044699.226000","reply_count":5,"reply_users_count":2,"latest_reply":"1613045716.236100","reply_users":["UH24GRBLL","UD0NS8PDF"],"subscribed":false},{"client_msg_id":"ac910628-a287-4507-8b63-ce61d032f9f1","type":"message","text":"I'm on a dell latitude 7490","user":"U7PD3M3L5","ts":"1613044705.226300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NMnc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm on a dell latitude 7490"}]}]}]},{"client_msg_id":"13651e86-2274-48e3-9ae3-522194d328f6","type":"message","text":"```julia&gt; @benchmark calc_dx_K_loop($K, $X, 2, c) setup=(c=similar(X, n, n, d);) evals=1\nBenchmarkTools.Trial:\n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.000 μs (0.00% GC)\n  median time:      2.200 μs (0.00% GC)\n  mean time:        3.325 μs (0.00% GC)\n  maximum time:     118.500 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1```\nmaking sure K and X are hot, it'S not enough","user":"UH24GRBLL","ts":"1613044708.226600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pxw37","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @benchmark calc_dx_K_loop($K, $X, 2, c) setup=(c=similar(X, n, n, d);) evals=1\nBenchmarkTools.Trial:\n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.000 μs (0.00% GC)\n  median time:      2.200 μs (0.00% GC)\n  mean time:        3.325 μs (0.00% GC)\n  maximum time:     118.500 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nmaking sure K and X are hot, it'S not enough"}]}]}]},{"client_msg_id":"6e878604-4fc7-49bf-a01f-4cacd42c8f19","type":"message","text":"it has 8 threads though?","user":"U7PD3M3L5","ts":"1613044710.226700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zWY0S","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it has 8 threads though?"}]}]}]},{"client_msg_id":"9b157530-d997-4faf-9a7f-e7e0740d759a","type":"message","text":"Wait I'll check again to be sure","user":"U7PD3M3L5","ts":"1613044716.226900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"g9qk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Wait I'll check again to be sure"}]}]}]},{"client_msg_id":"e81c5187-cef4-4cbe-9c3c-808161ed3670","type":"message","text":"`versioninfo()` can tell you","user":"UH24GRBLL","ts":"1613044729.227300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JaLjo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"versioninfo()","style":{"code":true}},{"type":"text","text":" can tell you"}]}]}]},{"client_msg_id":"0cca2ec6-6b9f-49c5-94e3-ec51c0cd186a","type":"message","text":"I think this is all single-threaded, `@avx` doesn’t spawn.","user":"UD0NS8PDF","ts":"1613044734.227500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PTc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think this is all single-threaded, "},{"type":"text","text":"@avx","style":{"code":true}},{"type":"text","text":" doesn’t spawn."}]}]}]},{"client_msg_id":"3f85bd5d-2270-49b0-b11f-c46c2806f3b0","type":"message","text":"yep","user":"UH24GRBLL","ts":"1613044741.227700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qnJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yep"}]}]}]},{"client_msg_id":"c190ed24-9035-4bb3-8281-0081f2b9d105","type":"message","text":"```  OS: Linux (x86_64-pc-linux-gnu)\n  CPU: Intel(R) Core(TM) i7-8650U CPU @ 1.90GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)```\n","user":"U7PD3M3L5","ts":"1613044746.228000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"c9Sb","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"  OS: Linux (x86_64-pc-linux-gnu)\n  CPU: Intel(R) Core(TM) i7-8650U CPU @ 1.90GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)"}]},{"type":"rich_text_section","elements":[]}]}]},{"client_msg_id":"b13cb57a-7c41-4adf-a378-695f39a5133d","type":"message","text":"this is what versioninfo gives me","user":"U7PD3M3L5","ts":"1613044750.228200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kKXm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this is what versioninfo gives me"}]}]}]},{"client_msg_id":"c6ba0f5f-bd41-4503-b87d-a5b2fc2596d1","type":"message","text":"Mine is:\n```Julia Version 1.7.0-DEV.406\nPlatform Info:\n  OS: macOS (x86_64-apple-darwin18.7.0)\n  CPU: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)```","user":"UD0NS8PDF","ts":"1613044801.228600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9kg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Mine is:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Julia Version 1.7.0-DEV.406\nPlatform Info:\n  OS: macOS (x86_64-apple-darwin18.7.0)\n  CPU: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)"}]}]}]},{"client_msg_id":"0734eb7c-d244-463a-8ab6-c087d6f3fed1","type":"message","text":"yeah, threads won't help here - the matrices are probably too small","user":"UH24GRBLL","ts":"1613044839.229000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aT/zw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, threads won't help here - the matrices are probably too small"}]}]}]},{"client_msg_id":"0ab2705a-b8f5-44b9-8ed9-75bd1018c1e4","type":"message","text":"```julia&gt; @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=deepcopy(K); X_=deepcopy(X); res_=deepcopy(res)) evals=1;\n  2.000 μs (0 allocations: 0 bytes)```\nMemory bandwidth :man-shrugging:","user":"UH24GRBLL","ts":"1613045001.229400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DRQMo","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @btime calc_dx_K_loop(K_, X_, 2, res_)  setup=(K_=deepcopy(K); X_=deepcopy(X); res_=deepcopy(res)) evals=1;\n  2.000 μs (0 allocations: 0 bytes)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nMemory bandwidth "},{"type":"emoji","name":"man-shrugging"}]}]}]},{"client_msg_id":"071dfaf4-3363-4f2a-a33e-7e3a2eb6920d","type":"message","text":"So\n```function calc_dx_K_cast(K, X, σ_squ, res)\n    (d, n) = size(X)\n    @cast res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    res\nend```\n`704.319 μs (8 allocations: 125.38 KiB)`\n\n```function calc_dx_K_loop(K, X, σ_squ, res)\n    (d, n) = size(X)\n    @inbounds for i=1:n, j=1:n, dim=1:d\n        res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    end\n    res\nend```\n`1.726 ms (0 allocations: 0 bytes)`\n\n```function calc_dx_K_vectorized(K, X, σ_squ, res)\n    (d, n) = size(X)\n    @avx for i=1:n, j=1:n, dim=1:d\n        res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    end\n    res\nend```\n`206.479 μs (0 allocations: 0 bytes)`","user":"U7PD3M3L5","ts":"1613045269.231100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8YSsq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function calc_dx_K_cast(K, X, σ_squ, res)\n    (d, n) = size(X)\n    @cast res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    res\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"},{"type":"text","text":"704.319 μs (8 allocations: 125.38 KiB)","style":{"code":true}},{"type":"text","text":"\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function calc_dx_K_loop(K, X, σ_squ, res)\n    (d, n) = size(X)\n    @inbounds for i=1:n, j=1:n, dim=1:d\n        res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    end\n    res\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"},{"type":"text","text":"1.726 ms (0 allocations: 0 bytes)","style":{"code":true}},{"type":"text","text":"\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function calc_dx_K_vectorized(K, X, σ_squ, res)\n    (d, n) = size(X)\n    @avx for i=1:n, j=1:n, dim=1:d\n        res[i, j, dim] = -1/σ_squ * (X[dim, i] - X[dim, j]) * K[i, j]\n    end\n    res\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"},{"type":"text","text":"206.479 μs (0 allocations: 0 bytes)","style":{"code":true}}]}]}]},{"client_msg_id":"2b8eb780-43ef-4621-8f3c-4fbe8e9f621a","type":"message","text":"Benchmarked with `@btime calc_dx_K($K, $X, 2, $res)`  since `@benchmark calc_dx_K_loop(a, b, 2, c) setup(a=deepcopy(K);b=deepcopy(X);c=similar(X, n, n, d)) evals=1`  gave me `syntax: invalid syntax ; b = deepcopy(X),; c = similar(X, n, n, d)`","user":"U7PD3M3L5","ts":"1613045305.231600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TtFs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Benchmarked with "},{"type":"text","text":"@btime calc_dx_K($K, $X, 2, $res)","style":{"code":true}},{"type":"text","text":"  since "},{"type":"text","text":"@benchmark calc_dx_K_loop(a, b, 2, c) setup(a=deepcopy(K);b=deepcopy(X);c=similar(X, n, n, d)) evals=1","style":{"code":true}},{"type":"text","text":"  gave me "},{"type":"text","text":"syntax: invalid syntax ; b = deepcopy(X),; c = similar(X, n, n, d)","style":{"code":true}}]}]}]},{"client_msg_id":"bf52078a-059b-4381-9748-ad4875f99dd5","type":"message","text":"the vectorization is the clear winner, but casting also gives pretty good results for being so easy","user":"U7PD3M3L5","ts":"1613045362.232200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BRs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the vectorization is the clear winner, but casting also gives pretty good results for being so easy"}]}]}]},{"client_msg_id":"98b86855-7cd6-4b9d-87fd-eef8eb12c56a","type":"message","text":"all of those are doing vectorization one way or another :)","user":"UH24GRBLL","ts":"1613045454.233100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cWAcf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"all of those are doing vectorization one way or another :)"}]}]}]},{"client_msg_id":"15685d0c-9974-4ba7-a5c6-b709a78e7ed2","type":"message","text":"they are all using simd instructions?","user":"U7PD3M3L5","ts":"1613045469.233600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qdAF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"they are all using simd instructions?"}]}]}]},{"client_msg_id":"65cb22f8-3740-421e-8019-b32f51fa72ee","type":"message","text":"I'd just be aware that `@cast` allocates the result, which may slow things down","user":"UH24GRBLL","ts":"1613045472.233700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uY7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd just be aware that "},{"type":"text","text":"@cast","style":{"code":true}},{"type":"text","text":" allocates the result, which may slow things down"}]}]}]},{"client_msg_id":"0b644638-0a45-4842-82f3-2b445a511012","type":"message","text":"you can check yourself with `@code_llvm` - if there's some `broadcast` in there, it vectorizes at least some part","user":"UH24GRBLL","ts":"1613045492.234200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cO1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you can check yourself with "},{"type":"text","text":"@code_llvm","style":{"code":true}},{"type":"text","text":" - if there's some "},{"type":"text","text":"broadcast","style":{"code":true}},{"type":"text","text":" in there, it vectorizes at least some part"}]}]}]},{"client_msg_id":"64aab638-cec5-449b-8a89-443244549773","type":"message","text":"`@cast res[i, j, dim] = ` with = not `:=` isn’t allocating `res`. What it’s doing is transposing `X[dim, j]` and then, when it wants to reshape that to put `dims` last, it makes a copy because `reshape(transpose(...` is dog-slow. It’s an implementation quirk which the new version should remove.","user":"UD0NS8PDF","ts":"1613045643.236000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QOzvR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"`@cast res[i, j, dim] = ` with = not "},{"type":"text","text":":=","style":{"code":true}},{"type":"text","text":" isn’t allocating "},{"type":"text","text":"res","style":{"code":true}},{"type":"text","text":". What it’s doing is transposing "},{"type":"text","text":"X[dim, j]","style":{"code":true}},{"type":"text","text":" and then, when it wants to reshape that to put "},{"type":"text","text":"dims","style":{"code":true}},{"type":"text","text":" last, it makes a copy because "},{"type":"text","text":"reshape(transpose(...","style":{"code":true}},{"type":"text","text":" is dog-slow. It’s an implementation quirk which the new version should remove."}]}]}]},{"client_msg_id":"58ebbfb1-37ed-4237-b082-940f95585a9a","type":"message","text":"I'll keep an eye on the new version then","user":"U7PD3M3L5","ts":"1613045744.236500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"q7o","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'll keep an eye on the new version then"}]}]}]},{"client_msg_id":"60165e23-d31a-40d4-9bea-4c8903403f6e","type":"message","text":"but I'm actually very impressed by the loop speed here","user":"U7PD3M3L5","ts":"1613045752.236800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TXtZ+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but I'm actually very impressed by the loop speed here"}]}]}],"reactions":[{"name":"sonic","users":["UH24GRBLL"],"count":1}]},{"client_msg_id":"05de277b-c2f9-4c03-906d-8ac50a8c8eb7","type":"message","text":"and the easiness of adding `@avx`  whatever it does","user":"U7PD3M3L5","ts":"1613045768.237100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"g45","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and the easiness of adding "},{"type":"text","text":"@avx","style":{"code":true}},{"type":"text","text":"  whatever it does"}]}]}]},{"client_msg_id":"1a807543-008a-4a51-83d8-1b04935bc9a2","type":"message","text":"That’s some real black magic.","user":"UD0NS8PDF","ts":"1613045800.237500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"z9Nz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That’s some real black magic."}]}]}]},{"client_msg_id":"fb55657d-429b-4869-aaa6-96067eda334a","type":"message","text":"it (on one hand) does loop reordering, on the other it merges loads (almost) optimally, such that the arithmetic unit in your CPU is always busy","user":"UH24GRBLL","ts":"1613045836.238300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VWL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it (on one hand) does loop reordering, on the other it merges loads (almost) optimally, such that the arithmetic unit in your CPU is always busy"}]}]}]},{"client_msg_id":"1a6bec46-b759-41c5-957e-f19631212747","type":"message","text":"you have to be careful though - if you don't respect its rules, it can wreck your computation","user":"UH24GRBLL","ts":"1613045872.238700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"spa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you have to be careful though - if you don't respect its rules, it can wreck your computation"}]}]}]},{"client_msg_id":"25a8487e-9226-4438-95b6-105cbd62938f","type":"message","text":"Always respect the warning! :) <https://juliahub.com/ui/Packages/LoopVectorization/4TogI/0.11.2#Warning>","user":"UH24GRBLL","ts":"1613045882.238900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EjZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Always respect the warning! :) "},{"type":"link","url":"https://juliahub.com/ui/Packages/LoopVectorization/4TogI/0.11.2#Warning"}]}]}]},{"client_msg_id":"abd12932-fcee-4a62-899b-c5b030b05b47","type":"message","text":"haha ok thanks","user":"U7PD3M3L5","ts":"1613046602.239100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"P0M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"haha ok thanks"}]}]}]},{"client_msg_id":"3bc06c81-cd6b-4c6b-860a-1cf31bdd37a3","type":"message","text":"actually I just copied it from your code, did not read the docs or the warning","user":"U7PD3M3L5","ts":"1613046613.239600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+tgr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"actually I just copied it from your code, did not read the docs or the warning"}]}]}]},{"client_msg_id":"3b54ac71-1390-45be-95c6-e5f2a4147bab","type":"message","text":"the not iterating `1:2:N`  could have gotten me at some point","user":"U7PD3M3L5","ts":"1613046624.239900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SV404","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the not iterating "},{"type":"text","text":"1:2:N","style":{"code":true}},{"type":"text","text":"  could have gotten me at some point"}]}]}]},{"client_msg_id":"3cb2ca98-a2d6-4048-bb05-a09393974124","type":"message","text":"I'll probably remove the `1:2:N` limitation fairly soon.","user":"UAUPJLBQX","ts":"1613076272.241000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jLN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'll probably remove the "},{"type":"text","text":"1:2:N","style":{"code":true}},{"type":"text","text":" limitation fairly soon."}]}]}]},{"client_msg_id":"e073d807-a592-4178-98a0-1c70cd67c63a","type":"message","text":"what package is @cast in?","user":"U01GRS159T8","ts":"1613175525.241800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yABHt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what package is @cast in?"}]}]}],"thread_ts":"1613175525.241800","reply_count":1,"reply_users_count":1,"latest_reply":"1613175558.241900","reply_users":["U0179G7FG4F"],"subscribed":false},{"client_msg_id":"ab3f7a05-3711-42d3-b97d-9de42916424e","type":"message","text":"Does anyone have experience benchmarking code in CI? I have manual benchmarks and I would like to add performance tests, but this feels like a terrible idea due to how inconsistent the benchmarks may be. The median time per sample is about 11 microseconds and CI would be GitHub actions. I would want to write a test that verifies the median sample time is 11 +/- 1 uS and fails if it falls outside that range.","user":"U01537M2E9W","ts":"1613596642.245300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SBs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone have experience benchmarking code in CI? I have manual benchmarks and I would like to add performance tests, but this feels like a terrible idea due to how inconsistent the benchmarks may be. The median time per sample is about 11 microseconds and CI would be GitHub actions. I would want to write a test that verifies the median sample time is 11 +/- 1 uS and fails if it falls outside that range."}]}]}],"thread_ts":"1613596642.245300","reply_count":1,"reply_users_count":1,"latest_reply":"1613597124.245400","reply_users":["UCZ7VBGUD"],"subscribed":false},{"client_msg_id":"e6b257d3-cf7e-4737-b274-9511bd567a2b","type":"message","text":"I need to numerically integrate a slightly complicated function many times, so I'm trying to find a fast way to do it. I don't necessarily need super high precision (ideally beyond 1e-5 but I could make do with less)\n\nI'm currently trying the following with `FastGaussQuadrature` . Might anyone have a suggestion for how to improve performance?\n```function fastgq(f, a, b)\n    nodes, weights = gausslegendre( 10000 );\n    \n    x = 0.5*((b .- a).*nodes .+ (b.+a))\n    \n    out = 0.5*(b.-a)*dot( weights, f.(x) )\n    \n    return(out)\nend```","user":"U91Q3595Y","ts":"1613615785.248800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+0fn9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I need to numerically integrate a slightly complicated function many times, so I'm trying to find a fast way to do it. I don't necessarily need super high precision (ideally beyond 1e-5 but I could make do with less)\n\nI'm currently trying the following with "},{"type":"text","text":"FastGaussQuadrature","style":{"code":true}},{"type":"text","text":" . Might anyone have a suggestion for how to improve performance?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function fastgq(f, a, b)\n    nodes, weights = gausslegendre( 10000 );\n    \n    x = 0.5*((b .- a).*nodes .+ (b.+a))\n    \n    out = 0.5*(b.-a)*dot( weights, f.(x) )\n    \n    return(out)\nend"}]}]}],"thread_ts":"1613615785.248800","reply_count":9,"reply_users_count":2,"latest_reply":"1613616936.250500","reply_users":["U0179G7FG4F","U91Q3595Y"],"subscribed":false},{"client_msg_id":"826e815f-b75c-4389-be99-72a8fba07e21","type":"message","text":"When you return an array from a function, it always allocates, correct? Is there a way to just return a pointer/reference to that array? Wrap it in `Ref` maybe?","user":"U01H36BUDJB","ts":"1613733455.261300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"y84x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"When you return an array from a function, it always allocates, correct? Is there a way to just return a pointer/reference to that array? Wrap it in "},{"type":"text","text":"Ref","style":{"code":true}},{"type":"text","text":" maybe?"}]}]}],"thread_ts":"1613733455.261300","reply_count":1,"reply_users_count":1,"latest_reply":"1613733532.261400","reply_users":["UD0NS8PDF"],"subscribed":false},{"client_msg_id":"e54b6091-4f3d-4635-af2a-2d0f41b6350c","type":"message","text":"Could anyone familiar with ComponentArrays explain why this line seems to be type-unstable with `@code_warntype` despite all of the present variables (i.e. `values` ,`start` ,`stop`) being fully known? It's really perplexing me.\n```newvalues = ComponentArray(values,(Axis{(edges=start:2:stop,cells=start+1:2:stop-1)}(),))```","user":"U01H36BUDJB","ts":"1613749045.266000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OpeP3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Could anyone familiar with ComponentArrays explain why this line seems to be type-unstable with "},{"type":"text","text":"@code_warntype","style":{"code":true}},{"type":"text","text":" despite all of the present variables (i.e. "},{"type":"text","text":"values","style":{"code":true}},{"type":"text","text":" ,"},{"type":"text","text":"start","style":{"code":true}},{"type":"text","text":" ,"},{"type":"text","text":"stop","style":{"code":true}},{"type":"text","text":") being fully known? It's really perplexing me.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"newvalues = ComponentArray(values,(Axis{(edges=start:2:stop,cells=start+1:2:stop-1)}(),))"}]}]}],"thread_ts":"1613749045.266000","reply_count":1,"reply_users_count":1,"latest_reply":"1613749075.266100","reply_users":["U01H36BUDJB"],"subscribed":false},{"type":"message","subtype":"channel_join","ts":"1613754988.266600","user":"US4A6G6B0","text":"<@US4A6G6B0> has joined the channel","inviter":"U69BL50BF"},{"client_msg_id":"17b57b98-42b8-4788-82fd-dc8f71819b25","type":"message","text":"What's the best way to debug long compilation times for a function? i.e. I want to figure out what's slowing it down.","user":"U01H36BUDJB","ts":"1613832812.000700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F8a4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What's the best way to debug long compilation times for a function? i.e. I want to figure out what's slowing it down."}]}]}]},{"client_msg_id":"5181e65a-5662-48ab-962a-bfc6a60373d2","type":"message","text":"Hey","user":"U01MG0TN079","ts":"1613894462.015400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"d1p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey"}]}]}]},{"client_msg_id":"5c3c9cbd-b681-420a-b1b9-4ff9ba57ef9f","type":"message","text":"Say I'm working with rational numbers, with a known bound on the denominator (i.e. all can be written as n/K for some known integer K), how much slower is it to work with Rational{Int} rather than Int ?","user":"U01MG0TN079","ts":"1613894514.016400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lYt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Say I'm working with rational numbers, with a known bound on the denominator (i.e. all can be written as n/K for some known integer K), how much slower is it to work with Rational{Int} rather than Int ?"}]}]}]},{"client_msg_id":"0378c30a-b2c0-4b0a-8144-d9fe520b1c8c","type":"message","text":"Another question: What would be the best way to type a vector of collections whose types depend on their index in the vector","user":"U01MG0TN079","ts":"1613910244.018000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/8QL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Another question: What would be the best way to type a vector of collections whose types depend on their index in the vector"}]}]}]},{"client_msg_id":"d0161884-6800-4511-b9db-e1f06161fb68","type":"message","text":"`[Vector{SVector{1}},Vector{SVector{2}},…]`","user":"U01MG0TN079","ts":"1613910283.018800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xOEC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"[Vector{SVector{1}},Vector{SVector{2}},…]","style":{"code":true}}]}]}]},{"client_msg_id":"c49b7c69-850b-403b-87f1-253c9649d246","type":"message","text":"Since the length of such a vector of collection is bounded in my case, by around 20, I wonder if I should just define 20 custom types, or do it with a macro?","user":"U01MG0TN079","ts":"1613910458.019700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xJl9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Since the length of such a vector of collection is bounded in my case, by around 20, I wonder if I should just define 20 custom types, or do it with a macro?"}]}]}],"thread_ts":"1613910458.019700","reply_count":2,"reply_users_count":2,"latest_reply":"1613911670.020000","reply_users":["U7HAYKY9X","U01MG0TN079"],"subscribed":false},{"client_msg_id":"71d5d8c1-a106-4932-95c4-b34190f1f523","type":"message","text":"Is accessing nested named tuples supposed to allocate? Like for example, if I do `a.b.c.X` where `a`,`b`,`c` are all nested `NamedTuple` s, and `X` is the name of an array stored in `c` this shouldn't allocate right?","user":"U01H36BUDJB","ts":"1613999608.023300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5Vp5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is accessing nested named tuples supposed to allocate? Like for example, if I do "},{"type":"text","text":"a.b.c.X","style":{"code":true}},{"type":"text","text":" where "},{"type":"text","text":"a","style":{"code":true}},{"type":"text","text":","},{"type":"text","text":"b","style":{"code":true}},{"type":"text","text":","},{"type":"text","text":"c","style":{"code":true}},{"type":"text","text":" are all nested "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" s, and "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" is the name of an array stored in "},{"type":"text","text":"c","style":{"code":true}},{"type":"text","text":" this shouldn't allocate right?"}]}]}],"thread_ts":"1613999608.023300","reply_count":1,"reply_users_count":1,"latest_reply":"1613999699.023400","reply_users":["U7HAYKY9X"],"subscribed":false},{"client_msg_id":"d6813445-8124-4ede-8951-47178b0c4ee9","type":"message","text":"<@UAUPJLBQX> thoughts on <https://github.com/dzhang314/EFTBase.jl/pull/2>? specifically, whether `fast_two_sum` or `two_sum` is likely to be faster in practice.","user":"U0179G7FG4F","ts":"1614028162.024800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pGDzI","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":" thoughts on "},{"type":"link","url":"https://github.com/dzhang314/EFTBase.jl/pull/2"},{"type":"text","text":"? specifically, whether "},{"type":"text","text":"fast_two_sum","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"two_sum","style":{"code":true}},{"type":"text","text":" is likely to be faster in practice."}]}]}]},{"client_msg_id":"dc93d659-140f-42ff-8693-4c7e2b268b9c","type":"message","text":"not Chris, but as the comments say - it's highly dependent on what happens in the CPU/microcode","user":"UH24GRBLL","ts":"1614028521.025300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dB0F","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"not Chris, but as the comments say - it's highly dependent on what happens in the CPU/microcode"}]}]}]},{"client_msg_id":"72e55605-a2fd-4c97-a9c3-f9c2e523a946","type":"message","text":"Is there a way we could automatically (at build time) pick the best one?","user":"U0179G7FG4F","ts":"1614028619.025800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ArUN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a way we could automatically (at build time) pick the best one?"}]}]}]},{"client_msg_id":"67c3a264-36a1-4ee0-9dfc-d649310b1660","type":"message","text":"have a large lookup table checking which is faster on which specific architecture and `@static` which method you define","user":"UH24GRBLL","ts":"1614028652.026400","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1614028661.000000"},"blocks":[{"type":"rich_text","block_id":"5bnE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"have a large lookup table checking which is faster on which specific architecture and "},{"type":"text","text":"@static","style":{"code":true}},{"type":"text","text":" which method you define"}]}]}]},{"client_msg_id":"aa49fb2d-e16c-4e20-aee1-61c75727742c","type":"message","text":"Do you think that's actually feasible? Would an approach where you benchmark both during pre-compile work?","user":"U0179G7FG4F","ts":"1614028872.027300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"it2D","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Do you think that's actually feasible? Would an approach where you benchmark both during pre-compile work?"}]}]}]},{"client_msg_id":"9bb70c70-ab4f-497d-aaf2-2355c83d580f","type":"message","text":"You'd have to benchmark after compilation","user":"UH24GRBLL","ts":"1614030207.027800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VO2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You'd have to benchmark after compilation"}]}]}]},{"client_msg_id":"425e1a78-d9ea-4373-9f39-16e603927b5b","type":"message","text":"As I understand it, that's how all the smart optimizations in LLVM and gcc are compared - benchmark it and find out which is faster, then emit that code.","user":"UH24GRBLL","ts":"1614030283.028600","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1614030312.000000"},"blocks":[{"type":"rich_text","block_id":"XAJa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"As I understand it, that's how all the smart optimizations in LLVM and gcc are compared - benchmark it and find out which is faster, then emit that code."}]}]}]}]}