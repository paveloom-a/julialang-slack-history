{"cursor": 1, "messages": [{"client_msg_id":"31e6bc4e-6b24-4755-8161-450af7b187b9","type":"message","text":"Suppose you’re trying to load data from multiple sources (e.g. , reddit, nyt, etc) into a SQLite DB. Would you store the date/time info in the sqlite db as text or as a number (i.e., as either the integer or real storage class in sqlite)?","user":"US8V7JSKB","ts":"1610569648.426000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1HAN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Suppose you’re trying to load data from multiple sources (e.g. , reddit, nyt, etc) into a SQLite DB. Would you store the date/time info in the sqlite db as text or as a number (i.e., as either the integer or real storage class in sqlite)?"}]}]}],"thread_ts":"1610569648.426000","reply_count":6,"reply_users_count":2,"latest_reply":"1610570546.432900","reply_users":["UH24GRBLL","US8V7JSKB"],"subscribed":false},{"client_msg_id":"673ffe2b-42b0-41f1-adef-40332cd09e83","type":"message","text":"What's the difference between the JuliaIO and JuliaData orgs?","user":"U6C1MMAAJ","ts":"1610570149.426900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FeI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What's the difference between the JuliaIO and JuliaData orgs?"}]}]}]},{"client_msg_id":"f79af1d5-981d-49d0-b4a6-9a2f7fd2fce5","type":"message","text":"Should we move HDF5.jl over to JuliaData? There seems to be overlap.","user":"U6C1MMAAJ","ts":"1610570155.427200","team":"T68168MUP","edited":{"user":"U6C1MMAAJ","ts":"1610570222.000000"},"blocks":[{"type":"rich_text","block_id":"K0/0R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Should we move HDF5.jl over to JuliaData? There seems to be overlap."}]}]}]},{"client_msg_id":"fbab8fea-06af-4f40-9bd0-0e0c72b23368","type":"message","text":"JuliaData is primarily (but not exclusively) concerned with tabular data.\nJuliaIO is concerned with loading and savings all formats.\nHDF5 is nontabular so seems no strong argument to move.\nIt could join the handful of nontabular formats in JuliaData but I don't see a reason why it should","user":"U6A936746","ts":"1610570327.430900","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1610570349.000000"},"blocks":[{"type":"rich_text","block_id":"wCSpi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"JuliaData is primarily (but not exclusively) concerned with tabular data.\nJuliaIO is concerned with loading and savings all formats.\nHDF5 is nontabular so seems no strong argument to move.\nIt could join the handful of nontabular formats in JuliaData but I don't see a reason why it should"}]}]}],"thread_ts":"1610570327.430900","reply_count":2,"reply_users_count":1,"latest_reply":"1610570375.431700","reply_users":["U6C1MMAAJ"],"subscribed":false},{"client_msg_id":"d641018a-112b-458e-9aae-09f32f4cd2e8","type":"message","text":"yeah, it’s not a strict division, but that’s the general idea.","user":"U681ELA87","ts":"1610570434.432400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xbZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, it’s not a strict division, but that’s the general idea."}]}]}]},{"client_msg_id":"17b8812c-d33f-49d7-b6ba-3b196cc63cf1","type":"message","text":"Is SQLite.jl currently mature enough that it’d be safe for users who may not be skilled enough to dive into the source code to resolve any possible issues to use it? I’ve been trying to read up on SQLite.jl on the julia discourse before committing to using julia for my ETL, and it wasn’t clear if it’s mature / well-tested enough. (This isn’t a knock on SQLite.jl or anything like that, and a lot of great and hard work has clearly gone into it; I’m just trying to get a sense for its viability for a normal user.)","user":"US8V7JSKB","ts":"1610587628.005700","team":"T68168MUP","edited":{"user":"US8V7JSKB","ts":"1610587699.000000"},"blocks":[{"type":"rich_text","block_id":"n4t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is SQLite.jl currently mature enough that it’d be safe for users who may not be skilled enough to dive into the source code to resolve any possible issues to use it? I’ve been trying to read up on SQLite.jl on the julia discourse before committing to using julia for my ETL, and it wasn’t clear if it’s mature / well-tested enough. (This isn’t a knock on SQLite.jl or anything like that, and a lot of great and hard work has clearly gone into it; I’m just trying to get a sense for its viability for a normal user.)"}]}]}],"thread_ts":"1610587628.005700","reply_count":1,"reply_users_count":1,"latest_reply":"1610591485.009400","reply_users":["U8JP5B9T2"],"subscribed":false},{"client_msg_id":"cae0266a-cc97-4a4c-a56d-4359a52eea60","type":"message","text":"I think the upgrade to DBInterface is producing an error on the execute function. DBInterface.execute statements are producing an error about an ambiguity with ODBC.execute. Downgrading to Do interface v2.2.0 fixes the error.","user":"UCAFZ51L3","ts":"1610587776.009300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"87yU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think the upgrade to DBInterface is producing an error on the execute function. DBInterface.execute statements are producing an error about an ambiguity with ODBC.execute. Downgrading to Do interface v2.2.0 fixes the error."}]}]}]},{"client_msg_id":"44f55d2c-7c8d-47c9-ab86-2adc510ecc99","type":"message","text":"I am getting an error when I try `using CSV`,\n`Failed to precompile CSV: CategoricalString not defined`","user":"UAH43TMUN","ts":"1610597930.010900","team":"T68168MUP","edited":{"user":"UAH43TMUN","ts":"1610597999.000000"},"blocks":[{"type":"rich_text","block_id":"+xW61","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am getting an error when I try "},{"type":"text","text":"using CSV","style":{"code":true}},{"type":"text","text":",\n"},{"type":"text","text":"Failed to precompile CSV: CategoricalString not defined","style":{"code":true}}]}]}]},{"client_msg_id":"fca8c4a5-2e74-49f0-afdd-cfa4c7fca580","type":"message","text":"Given where we currently are on `leftjoin` performance, should I have any hope for `leftjoin(df1, df2)` with `size(df1) == (31635463, 7)` and `size(df2) == (564537, 2)`?","user":"U7JQGPGCQ","ts":"1610634257.013200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TXUuH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Given where we currently are on "},{"type":"text","text":"leftjoin","style":{"code":true}},{"type":"text","text":" performance, should I have any hope for "},{"type":"text","text":"leftjoin(df1, df2)","style":{"code":true}},{"type":"text","text":" with "},{"type":"text","text":"size(df1) == (31635463, 7)","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"size(df2) == (564537, 2)","style":{"code":true}},{"type":"text","text":"?"}]}]}],"thread_ts":"1610634257.013200","reply_count":6,"reply_users_count":3,"latest_reply":"1610634926.014800","reply_users":["U67431ELR","U7JQGPGCQ","U6A936746"],"subscribed":false},{"client_msg_id":"d8ff4009-e0e8-464d-950d-17d70d12ae79","type":"message","text":"<@U6A936746> Can I pick your brain about a DataDeps thing?","user":"U8JP5B9T2","ts":"1610656132.017700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"d8O","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U6A936746"},{"type":"text","text":" Can I pick your brain about a DataDeps thing?"}]}]}],"thread_ts":"1610656132.017700","reply_count":7,"reply_users_count":2,"latest_reply":"1610656724.019100","reply_users":["U8JP5B9T2","U6A936746"],"subscribed":false},{"client_msg_id":"cb30e1a3-349a-4ed2-9f9e-b75ecc987ce3","type":"message","text":"It seems that matlab tables are not supported by `MAT.jl` or `MATLAB.jl`. Which do you think will be more performant/reliable:\n:one: Export matlab table as parquet and read that into julia using `Parquet.jl`\n:two: Convert matlab table to struct array and save as .mat file and read that into julia using `MAT.jl`","user":"U017JTQFNEQ","ts":"1610688541.029500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6fc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It seems that matlab tables are not supported by "},{"type":"text","text":"MAT.jl","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"MATLAB.jl","style":{"code":true}},{"type":"text","text":". Which do you think will be more performant/reliable:\n"},{"type":"emoji","name":"one"},{"type":"text","text":" Export matlab table as parquet and read that into julia using "},{"type":"text","text":"Parquet.jl","style":{"code":true}},{"type":"text","text":"\n"},{"type":"emoji","name":"two"},{"type":"text","text":" Convert matlab table to struct array and save as .mat file and read that into julia using "},{"type":"text","text":"MAT.jl","style":{"code":true}}]}]}]},{"client_msg_id":"76b1900a-c3ad-4bd9-a963-1b27cf37b2e4","type":"message","text":"Guten Morgen <#C674VR0HH|data>, does this snippet emit SIMD code? Is there a way for me to verify this?\n```concatenated_col = Vector{String}(undef, df_length)\n@threads for i in 1:df_length\n    @inbounds concatenated_col[i] = @inbounds df.input[i] * @inbounds df.target[i]\nend```\nside note: I have no idea what I’m doing with @inbounds. Is this overkill or are all three instances necessary?","user":"U01GXNFKY6R","ts":"1610698227.030600","team":"T68168MUP","edited":{"user":"U01GXNFKY6R","ts":"1610698276.000000"},"blocks":[{"type":"rich_text","block_id":"r19","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Guten Morgen "},{"type":"channel","channel_id":"C674VR0HH"},{"type":"text","text":", does this snippet emit SIMD code? Is there a way for me to verify this?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"concatenated_col = Vector{String}(undef, df_length)\n@threads for i in 1:df_length\n    @inbounds concatenated_col[i] = @inbounds df.input[i] * @inbounds df.target[i]\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"side note: I have no idea what I’m doing with @inbounds. Is this overkill or are all three instances necessary?"}]}]}],"thread_ts":"1610698227.030600","reply_count":7,"reply_users_count":3,"latest_reply":"1610699924.032400","reply_users":["U8JAMQGQY","U01GXNFKY6R","U67431ELR"],"subscribed":false},{"client_msg_id":"7a9748e1-8188-48ee-88e3-a3358c5561cc","type":"message","text":"How can I get the `n` th row directly for a `Tables.jl` compliant implementation ? I want to directly get `Tables.Row(Tables.rows(table), n)` .","user":"U93U5PMH9","ts":"1610957747.050300","team":"T68168MUP","edited":{"user":"U93U5PMH9","ts":"1610958172.000000"},"blocks":[{"type":"rich_text","block_id":"R0L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How can I get the "},{"type":"text","text":"n","style":{"code":true}},{"type":"text","text":" th row directly for a "},{"type":"text","text":"Tables.jl","style":{"code":true}},{"type":"text","text":" compliant implementation ? I want to directly get "},{"type":"text","text":"Tables.Row(Tables.rows(table), n)","style":{"code":true}},{"type":"text","text":" ."}]}]}],"thread_ts":"1610957747.050300","reply_count":1,"reply_users_count":1,"latest_reply":"1610980898.055800","reply_users":["UBF9YRB6H"],"subscribed":false},{"client_msg_id":"6006fa07-b3ec-4aba-9d20-ebe08b8754c4","type":"message","text":"I have used Chain.jl for the fist time on SO :smile: (CC <@UK1BNFHFV>): <https://stackoverflow.com/questions/65789320/how-to-reshape-group-by-and-rename-julia-dataframe/65790242#65790242>","user":"U8JAMQGQY","ts":"1611054244.056000","team":"T68168MUP","attachments":[{"service_name":"Stack Overflow","title":"How to reshape, group by and rename Julia dataframe?","title_link":"https://stackoverflow.com/questions/65789320/how-to-reshape-group-by-and-rename-julia-dataframe/65790242#65790242","text":"I have the following DataFrame : Police Product PV1 PV2 PV3 PM1 PM2 PM3 0 1 AA 10 8 14 150 145 140 1 2 AB 25 4 7 700 650 620 2 3 ...","fallback":"Stack Overflow: How to reshape, group by and rename Julia dataframe?","thumb_url":"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded","from_url":"https://stackoverflow.com/questions/65789320/how-to-reshape-group-by-and-rename-julia-dataframe/65790242#65790242","thumb_width":316,"thumb_height":316,"service_icon":"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a","id":1,"original_url":"https://stackoverflow.com/questions/65789320/how-to-reshape-group-by-and-rename-julia-dataframe/65790242#65790242"}],"blocks":[{"type":"rich_text","block_id":"eT4ii","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have used Chain.jl for the fist time on SO "},{"type":"emoji","name":"smile"},{"type":"text","text":" (CC "},{"type":"user","user_id":"UK1BNFHFV"},{"type":"text","text":"): "},{"type":"link","url":"https://stackoverflow.com/questions/65789320/how-to-reshape-group-by-and-rename-julia-dataframe/65790242#65790242"}]}]}],"thread_ts":"1611054244.056000","reply_count":3,"reply_users_count":2,"latest_reply":"1611062107.062200","reply_users":["U01GXNFKY6R","UK1BNFHFV"],"subscribed":false,"reactions":[{"name":"white_check_mark","users":["U01GXNFKY6R"],"count":1},{"name":"heart","users":["UK1BNFHFV","U017JTQFNEQ","UM4TSHKF1"],"count":3},{"name":"clapping","users":["UB197FRCL","U8JP5B9T2","U8T0YV7QC"],"count":3},{"name":"chains","users":["U01GXNFKY6R","U8T0YV7QC"],"count":2}]},{"client_msg_id":"c97e6c28-309d-4a03-8d47-a3698ed8d569","type":"message","text":"<@U681ELA87> Sorry to keep bugging you - I'm having some issues writing arrow files. Details in thread.","user":"U8JP5B9T2","ts":"1611083623.072300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0OR","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U681ELA87"},{"type":"text","text":" Sorry to keep bugging you - I'm having some issues writing arrow files. Details in thread."}]}]}],"thread_ts":"1611083623.072300","reply_count":4,"reply_users_count":2,"latest_reply":"1611086939.073000","reply_users":["U8JP5B9T2","U681ELA87"],"subscribed":false},{"client_msg_id":"5e1f5f92-ea46-43fc-adb9-ac536a90c37e","type":"message","text":"Hi guys\ni am struggling to read some json file which i am not just getting right,\nthe json looks like so\n```  {\n    \"Variable\": \"Returns\",\n    \"Data\":[\n        {\n\t\t\t\t\"item 1.0\": [{\n\t\t\t\t\t\t\"Value\": 0.0127041742286751361161524501,\n\t\t\t\t\t\t\"Date\": \"2019-04-01T00:00:00\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"Value\": 0.0071684587813620071684587814,\n\t\t\t\t\t\t\"Date\": \"2019-04-02T00:00:00\"\n\t\t\t\t\t}],\n                \"item 2.0\": [\n                    {\n\t\t\t\t\t\t\"Value\": 0.0,\n\t\t\t\t\t\t\"Date\": \"2019-04-01T00:00:00\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"Value\": -0.001779359430604982206405694,\n\t\t\t\t\t\t\"Date\": \"2019-04-02T00:00:00\"\n\t\t\t\t\t}\n                ]\n        }],\n    \"DataWeights\": [\n        {\n\t\t\t\t\"item 1.0\": [{\n\t\t\t\t\t\t\"Value\": 0.0336538461538461538461538462,\n\t\t\t\t\t\t\"Date\": \"2019-04-01T00:00:00\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"Value\": 0.0,\n\t\t\t\t\t\t\"Date\": \"2019-04-02T00:00:00\"\n\t\t\t\t\t}],\n                \"item 2.0\": [\n                    {\n\t\t\t\t\t\t\"Value\": -0.0061099796334012219959266802,\n\t\t\t\t\t\t\"Date\": \"2019-04-01T00:00:00\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"Value\": 0.0143442622950819672131147541,\n\t\t\t\t\t\t\"Date\": \"2019-04-02T00:00:00\"\n\t\t\t\t\t}\n                ]\n        }]\n  }```\nand I'd like a final output like below\n```4×4 DataFrame\n Row │ Date        Name      Data      Dataweights \n     │ String      String    Float64   Float64     \n─────┼─────────────────────────────────────────────\n   1 │ 2019-04-01  item 1.0   0.0127       0.03365\n   2 │ 2019-04-01  item 2.0   0.0         -0.0061\n   3 │ 2019-04-02  item 1.0   0.0071       0.0\n   4 │ 2019-04-02  item 2.0  -0.00177      0.014\n ```\nthe challenge mostly is on how to pick it date wise from both the weights and data.\nany help or suggestions i will appreciate.","user":"UPH1M2MB2","ts":"1611137031.076500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"exoJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys\ni am struggling to read some json file which i am not just getting right,\nthe json looks like so\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"  {\n    \"Variable\": \"Returns\",\n    \"Data\":[\n        {\n\t\t\t\t\"item 1.0\": [{\n\t\t\t\t\t\t\"Value\": 0.0127041742286751361161524501,\n\t\t\t\t\t\t\"Date\": \"2019-04-01T00:00:00\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"Value\": 0.0071684587813620071684587814,\n\t\t\t\t\t\t\"Date\": \"2019-04-02T00:00:00\"\n\t\t\t\t\t}],\n                \"item 2.0\": [\n                    {\n\t\t\t\t\t\t\"Value\": 0.0,\n\t\t\t\t\t\t\"Date\": \"2019-04-01T00:00:00\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"Value\": -0.001779359430604982206405694,\n\t\t\t\t\t\t\"Date\": \"2019-04-02T00:00:00\"\n\t\t\t\t\t}\n                ]\n        }],\n    \"DataWeights\": [\n        {\n\t\t\t\t\"item 1.0\": [{\n\t\t\t\t\t\t\"Value\": 0.0336538461538461538461538462,\n\t\t\t\t\t\t\"Date\": \"2019-04-01T00:00:00\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"Value\": 0.0,\n\t\t\t\t\t\t\"Date\": \"2019-04-02T00:00:00\"\n\t\t\t\t\t}],\n                \"item 2.0\": [\n                    {\n\t\t\t\t\t\t\"Value\": -0.0061099796334012219959266802,\n\t\t\t\t\t\t\"Date\": \"2019-04-01T00:00:00\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"Value\": 0.0143442622950819672131147541,\n\t\t\t\t\t\t\"Date\": \"2019-04-02T00:00:00\"\n\t\t\t\t\t}\n                ]\n        }]\n  }"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"and I'd like a final output like below\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"4×4 DataFrame\n Row │ Date        Name      Data      Dataweights \n     │ String      String    Float64   Float64     \n─────┼─────────────────────────────────────────────\n   1 │ 2019-04-01  item 1.0   0.0127       0.03365\n   2 │ 2019-04-01  item 2.0   0.0         -0.0061\n   3 │ 2019-04-02  item 1.0   0.0071       0.0\n   4 │ 2019-04-02  item 2.0  -0.00177      0.014\n "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"the challenge mostly is on how to pick it date wise from both the weights and data.\nany help or suggestions i will appreciate."}]}]}],"thread_ts":"1611137031.076500","reply_count":2,"reply_users_count":2,"latest_reply":"1611192917.000200","reply_users":["U8JAMQGQY","UPH1M2MB2"],"subscribed":false},{"client_msg_id":"656bace2-12d8-4164-bcc0-b031f4f1ec12","type":"message","text":"Is there a version of the arrow implementation status page that has julia?\n<https://arrow.apache.org/docs/status.html>","user":"U6A936746","ts":"1611143646.076900","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1611143689.000000"},"blocks":[{"type":"rich_text","block_id":"eSuR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a version of the arrow implementation status page that has julia?\n"},{"type":"link","url":"https://arrow.apache.org/docs/status.html"}]}]}],"thread_ts":"1611143646.076900","reply_count":3,"reply_users_count":2,"latest_reply":"1611154695.078600","reply_users":["U6A936746","U681ELA87"],"subscribed":false},{"client_msg_id":"9fc6c643-91d1-4d03-9b6e-c02819949e45","type":"message","text":"I have a column with ids and i want a new column that is the ordinalrank of those ids. I can achieve it like this, but i know there must be a 1-liner (right?)\n```dd = DataFrame(a = [1 1 1 5 5 6 6 6 101 10 10 22 5 2 1][:])\ntempd = Dict( a=&gt;b for (a,b) in zip(unique(dd.a), ordinalrank(unique(dd.a))))\ntransform(dd, :a=&gt;ByRow(x -&gt; tempd[x])=&gt;:idx)```","user":"U017JTQFNEQ","ts":"1611158749.080400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"duk/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a column with ids and i want a new column that is the ordinalrank of those ids. I can achieve it like this, but i know there must be a 1-liner (right?)\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"dd = DataFrame(a = [1 1 1 5 5 6 6 6 101 10 10 22 5 2 1][:])\ntempd = Dict( a=>b for (a,b) in zip(unique(dd.a), ordinalrank(unique(dd.a))))\ntransform(dd, :a=>ByRow(x -> tempd[x])=>:idx)"}]}]}],"thread_ts":"1611158749.080400","reply_count":3,"reply_users_count":2,"latest_reply":"1611199846.000600","reply_users":["U8JAMQGQY","U017JTQFNEQ"],"subscribed":false},{"client_msg_id":"5fd056fc-1754-4ba4-b2da-5d563d198723","type":"message","text":"Anyone with access to JuliaData or YAML.jl (<@U8JP5B9T2>?), there are a few very simple PRs that could use merging:\n- <https://github.com/JuliaData/YAML.jl/pull/96> (print empty collections properly)\n- <https://github.com/JuliaData/YAML.jl/pull/109> (fix 1.0 support)\n- <https://github.com/JuliaData/YAML.jl/pull/110> (update CI badge)\n- <https://github.com/JuliaData/YAML.jl/pull/111> (fix writing of single-line strings with dollar signs)","user":"U6NFPDBV1","ts":"1611165449.082800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ukf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone with access to JuliaData or YAML.jl ("},{"type":"user","user_id":"U8JP5B9T2"},{"type":"text","text":"?), there are a few very simple PRs that could use merging:\n- "},{"type":"link","url":"https://github.com/JuliaData/YAML.jl/pull/96"},{"type":"text","text":" (print empty collections properly)\n- "},{"type":"link","url":"https://github.com/JuliaData/YAML.jl/pull/109"},{"type":"text","text":" (fix 1.0 support)\n- "},{"type":"link","url":"https://github.com/JuliaData/YAML.jl/pull/110"},{"type":"text","text":" (update CI badge)\n- "},{"type":"link","url":"https://github.com/JuliaData/YAML.jl/pull/111"},{"type":"text","text":" (fix writing of single-line strings with dollar signs)"}]}]}],"thread_ts":"1611165449.082800","reply_count":14,"reply_users_count":3,"latest_reply":"1611169212.085700","reply_users":["U6NFPDBV1","U681ELA87","U8JP5B9T2"],"subscribed":false},{"client_msg_id":"123fb093-d3b6-49be-a98d-6f4decc61f29","type":"message","text":"Is a `DataFrame` column allowed to be any abstract array or are there restrictions on what should be used as a column?","user":"U68M6ERG8","ts":"1611170052.086400","team":"T68168MUP","edited":{"user":"U68M6ERG8","ts":"1611170066.000000"},"blocks":[{"type":"rich_text","block_id":"VvKBI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is a "},{"type":"text","text":"DataFrame","style":{"code":true}},{"type":"text","text":" column allowed to be any abstract array or are there restrictions on what should be used as a column?"}]}]}],"thread_ts":"1611170052.086400","reply_count":4,"reply_users_count":3,"latest_reply":"1611175191.094000","reply_users":["U9VG1AYSG","U68M6ERG8","U8JAMQGQY"],"subscribed":false},{"client_msg_id":"97E8A79D-8123-411B-A7F2-461E57C7505E","type":"message","text":"I think the internal field is `AbstractVector[]`,","user":"U681ELA87","ts":"1611170159.087700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WYp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think the internal field is "},{"type":"text","text":"AbstractVector[]","style":{"code":true}},{"type":"text","text":","}]}]}],"reactions":[{"name":"white_check_mark","users":["U9VG1AYSG"],"count":1}]},{"client_msg_id":"f65978e8-f5eb-4c3a-80b5-71d56867b4a7","type":"message","text":"Is there a shorthand in the DataFrames mini-language for leaving missing values alone and only applying function to non-missing values? I tried eg\n\n```transform!(df, \"subject\" =&gt; ByRow(skipmissing ∘ (s-&gt; parse(Int, s))) =&gt; \"subject\")```\nbut no joy","user":"U8JP5B9T2","ts":"1611171486.089400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Jiv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a shorthand in the DataFrames mini-language for leaving missing values alone and only applying function to non-missing values? I tried eg\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"transform!(df, \"subject\" => ByRow(skipmissing ∘ (s-> parse(Int, s))) => \"subject\")"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"but no joy"}]}]}],"thread_ts":"1611171486.089400","reply_count":7,"reply_users_count":3,"latest_reply":"1611176199.094800","reply_users":["U68M6ERG8","U8JP5B9T2","U67431ELR"],"subscribed":false},{"client_msg_id":"7997d689-e041-40ab-8f6d-37d69cd9dad5","type":"message","text":"Would be nice to have something like `ByRow(fun, skipmissing=true)`","user":"U8JP5B9T2","ts":"1611171514.089900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IPYj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Would be nice to have something like "},{"type":"text","text":"ByRow(fun, skipmissing=true)","style":{"code":true}}]}]}],"thread_ts":"1611171514.089900","reply_count":5,"reply_users_count":4,"latest_reply":"1611240941.004300","reply_users":["U681ELA87","U8JAMQGQY","UBF9YRB6H","U8JP5B9T2"],"subscribed":false},{"client_msg_id":"51df6636-ee81-4898-9650-5bc091afcde5","type":"message","text":"Or `transform(... , skipmissing::Bool)` (plus things like arrays of `Bool` or `col=&gt;Bool` pairs)","user":"U8JP5B9T2","ts":"1611171644.091700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MFyH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Or "},{"type":"text","text":"transform(... , skipmissing::Bool)","style":{"code":true}},{"type":"text","text":" (plus things like arrays of "},{"type":"text","text":"Bool","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"col=>Bool","style":{"code":true}},{"type":"text","text":" pairs)"}]}]}]},{"client_msg_id":"51905396-ee1f-4062-8d7d-43320ef5c455","type":"message","text":"Are there packages similar to Query.jl but with less \"macro magic\"? I mean manipulation of table-like objects (mostly Vector{NamedTuple}) such as examples at <https://www.queryverse.org/Query.jl/stable/standalonequerycommands/>.","user":"UGTUKUHLN","ts":"1611226985.003400","team":"T68168MUP","edited":{"user":"UGTUKUHLN","ts":"1611227156.000000"},"blocks":[{"type":"rich_text","block_id":"pV0v","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there packages similar to Query.jl but with less \"macro magic\"? I mean manipulation of table-like objects (mostly Vector{NamedTuple}) such as examples at "},{"type":"link","url":"https://www.queryverse.org/Query.jl/stable/standalonequerycommands/"},{"type":"text","text":"."}]}]}],"thread_ts":"1611226985.003400","reply_count":42,"reply_users_count":8,"latest_reply":"1611349416.032200","reply_users":["UBF9YRB6H","U01GXNFKY6R","U681ELA87","UGTUKUHLN","U6A936746","UDGT4PM41","U01JRKTSL2U","U68UUUFPS"],"subscribed":false},{"client_msg_id":"643cf3cd-0aa6-43ec-871d-3eaec4899c31","type":"message","text":"DataFrames.jl 0.22.3 patch release is out. It fixes a minor bug in integration with Unitful.jl.","user":"U8JAMQGQY","ts":"1611253712.015100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jQYl/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"DataFrames.jl 0.22.3 patch release is out. It fixes a minor bug in integration with Unitful.jl."}]}]}],"reactions":[{"name":"+1","users":["U67431ELR","UBF9YRB6H","UB197FRCL","U01GXNFKY6R","U0163V6FU1H"],"count":5}]},{"client_msg_id":"3c7edfdd-8cbe-4e36-a2fd-8f6f17f52bc1","type":"message","text":"can somebody merge or comment on my PR to Tables.jl? (<https://github.com/JuliaData/Tables.jl/pull/226>).  It contains some small fixes to improve the usability of the `Tables.Columns` interface wrapper.  It's languished for a while now and it's blocking a package registration for me","user":"U9VG1AYSG","ts":"1611269434.017400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MmW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"can somebody merge or comment on my PR to Tables.jl? ("},{"type":"link","url":"https://github.com/JuliaData/Tables.jl/pull/226"},{"type":"text","text":").  It contains some small fixes to improve the usability of the "},{"type":"text","text":"Tables.Columns","style":{"code":true}},{"type":"text","text":" interface wrapper.  It's languished for a while now and it's blocking a package registration for me"}]}]}]},{"client_msg_id":"1cd32a37-f68b-458b-aefc-fc2f70ca47c6","type":"message","text":"Following the recent discussion on DataFrames.jl documentation quality this week I have posted another how-to guide in my blog: <https://bkamins.github.io/julialang/2021/01/22/transforming.html>","user":"U8JAMQGQY","ts":"1611310955.018400","team":"T68168MUP","attachments":[{"service_name":"Blog by Bogumił Kamiński","title":"Mass transformations of data frames how-to","title_link":"https://bkamins.github.io/julialang/2021/01/22/transforming.html","text":"Introduction","fallback":"Blog by Bogumił Kamiński: Mass transformations of data frames how-to","ts":1611301913,"from_url":"https://bkamins.github.io/julialang/2021/01/22/transforming.html","service_icon":"https://bkamins.github.io/favicon.ico","id":1,"original_url":"https://bkamins.github.io/julialang/2021/01/22/transforming.html"}],"blocks":[{"type":"rich_text","block_id":"K6R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Following the recent discussion on DataFrames.jl documentation quality this week I have posted another how-to guide in my blog: "},{"type":"link","url":"https://bkamins.github.io/julialang/2021/01/22/transforming.html"}]}]}],"reactions":[{"name":"+1","users":["U01GXNFKY6R","U01K3MC53LY"],"count":2}]},{"client_msg_id":"258a1456-4399-476f-94f0-926581f86e00","type":"message","text":"Next month I will be teaching a workshop with <@URFTMGLQL> on \"Julia for Data Science\".  The audience members should have experience with R or Python but probably not Julia.\n\nI have a Pluto notebook <https://github.com/crsl4/julia-workshop/blob/main/notebooks/consistency.jl> with a vignette on checking values in a data column for consistency with keys in another column.  Part of the purpose here is to show that even if you don't know the higher-level way of doing data manipulation you can write code in a lower-level approach without too much pain.\n\nPlease let me know if\n1. I have misrepresented what goes on in Tables.jl\n2. I have missed an obviously superior approach","user":"UBGRZ7FSP","ts":"1611334183.026200","team":"T68168MUP","edited":{"user":"UBGRZ7FSP","ts":"1611334502.000000"},"blocks":[{"type":"rich_text","block_id":"AmG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Next month I will be teaching a workshop with "},{"type":"user","user_id":"URFTMGLQL"},{"type":"text","text":" on \"Julia for Data Science\".  The audience members should have experience with R or Python but probably not Julia.\n\nI have a Pluto notebook "},{"type":"link","url":"https://github.com/crsl4/julia-workshop/blob/main/notebooks/consistency.jl"},{"type":"text","text":" with a vignette on checking values in a data column for consistency with keys in another column.  Part of the purpose here is to show that even if you don't know the higher-level way of doing data manipulation you can write code in a lower-level approach without too much pain.\n\nPlease let me know if\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have misrepresented what goes on in Tables.jl"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I have missed an obviously superior approach"}]}],"style":"ordered","indent":0}]}],"thread_ts":"1611334183.026200","reply_count":2,"reply_users_count":2,"latest_reply":"1611336121.027600","reply_users":["U681ELA87","UBGRZ7FSP"],"subscribed":false,"reactions":[{"name":"heart","users":["U680THK2S","U6795JH6H","U66M57AN4","UCAFZ51L3","U01C15GH58B","U017JTQFNEQ","U85JBUGGP","UAZP7LJLU"],"count":8}]},{"type":"message","subtype":"channel_join","ts":"1611334190.026400","user":"URFTMGLQL","text":"<@URFTMGLQL> has joined the channel","inviter":"UBGRZ7FSP"},{"client_msg_id":"32096858-f363-45b7-9b13-09ea11bea15e","type":"message","text":"dear god does DataFrames.jl have a lot of unit tests these days","user":"U9VG1AYSG","ts":"1611337585.028100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eRhe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"dear god does DataFrames.jl have a lot of unit tests these days"}]}]}]},{"client_msg_id":"0e1acbe3-f4f4-4c4e-816e-45959235f2ca","type":"message","text":"Just saw these latest benchmarks done this month and was quite surprised by how slow DataFrames.jl seems to be for joins, its ~10x slower than R dplyr: <https://h2oai.github.io/db-benchmark/>, though is faster than dplyr for groupby. I know the reason data.table wins is because multithreading but still very weird that dplyr beats DataFrames.jl for joins. Why might joins be this slow?","user":"U01EF0QVAB0","ts":"1611343078.030200","team":"T68168MUP","edited":{"user":"U01EF0QVAB0","ts":"1611343094.000000"},"blocks":[{"type":"rich_text","block_id":"GrP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just saw these latest benchmarks done this month and was quite surprised by how slow DataFrames.jl seems to be for joins, its ~10x slower than R dplyr: "},{"type":"link","url":"https://h2oai.github.io/db-benchmark/"},{"type":"text","text":", though is faster than dplyr for groupby. I know the reason data.table wins is because multithreading but still very weird that dplyr beats DataFrames.jl for joins. Why might joins be this slow?"}]}]}],"thread_ts":"1611343078.030200","reply_count":6,"reply_users_count":4,"latest_reply":"1611350141.032400","reply_users":["U7JQGPGCQ","U9VG1AYSG","U8JP5B9T2","U8JAMQGQY"],"subscribed":false},{"client_msg_id":"5b70f5bd-e1fc-4aec-a1f6-bd429dd95697","type":"message","text":"I am applying a function to a column and I want this function to return two resulting columns... something like\n```function tst_done(vec) \n    z = zeros(Bool, length(vec))\n    for (i, x) in enumerate(vec)\n        if !ismissing(x) \n           z[i] = 1 \n        else \n           z[i] = 0\n        end\n    end\n    return (z = z, v = z)\nend\n\ntransform!(a, :Antigen =&gt; tst_done)```\nwhere it takes the column `Antigen` and the function `tst_done` will theoretically return two vectors. Anyway to do this? I can always do it manually.","user":"U6Z8377N2","ts":"1611369869.033900","team":"T68168MUP","edited":{"user":"U6Z8377N2","ts":"1611369881.000000"},"blocks":[{"type":"rich_text","block_id":"Eihhy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am applying a function to a column and I want this function to return two resulting columns... something like\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function tst_done(vec) \n    z = zeros(Bool, length(vec))\n    for (i, x) in enumerate(vec)\n        if !ismissing(x) \n           z[i] = 1 \n        else \n           z[i] = 0\n        end\n    end\n    return (z = z, v = z)\nend\n\ntransform!(a, :Antigen => tst_done)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"where it takes the column "},{"type":"text","text":"Antigen","style":{"code":true}},{"type":"text","text":" and the function "},{"type":"text","text":"tst_done","style":{"code":true}},{"type":"text","text":" will theoretically return two vectors. Anyway to do this? I can always do it manually."}]}]}],"thread_ts":"1611369869.033900","reply_count":1,"reply_users_count":1,"latest_reply":"1611374854.034200","reply_users":["UBF9YRB6H"],"subscribed":false},{"client_msg_id":"7609aeec-c740-405c-b435-459a46696e0b","type":"message","text":"Happy Sunday y’all! I’m interested in implementing the C Data Interface for Apache Arrow, which should allow us to reuse pyarrow’s memory in Julia in a zero-copy way. I’ve translated the <https://arrow.apache.org/docs/format/CDataInterface.html|Structure Definitions> to Julia using Clang.jl, but I’m not sure where to go from here. Does anyone have ideas?","user":"U01GXNFKY6R","ts":"1611478490.038600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ao5ly","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Happy Sunday y’all! I’m interested in implementing the C Data Interface for Apache Arrow, which should allow us to reuse pyarrow’s memory in Julia in a zero-copy way. I’ve translated the "},{"type":"link","url":"https://arrow.apache.org/docs/format/CDataInterface.html","text":"Structure Definitions"},{"type":"text","text":" to Julia using Clang.jl, but I’m not sure where to go from here. Does anyone have ideas?"}]}]}],"thread_ts":"1611478490.038600","reply_count":2,"reply_users_count":2,"latest_reply":"1611567038.049700","reply_users":["U6A936746","U01GXNFKY6R"],"subscribed":false},{"client_msg_id":"28694823-1612-4c13-8a24-cf2c21f80eda","type":"message","text":"<@U8JAMQGQY> can you help me understand the reasoning for the following\n\n```df = DataFrame(a = [\"1\", \"2\"])\ndf[:, \"a\"]  = parse.(Int64, df[:, \"a\"])```\nthrows an error? but using `!` does not? My intuition would be the opposite: `:` means you can make *more* modifications to the data frame, not fewer, since you are copying everywhere.","user":"UBF9YRB6H","ts":"1611524015.041000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IBgi","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U8JAMQGQY"},{"type":"text","text":" can you help me understand the reasoning for the following\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"df = DataFrame(a = [\"1\", \"2\"])\ndf[:, \"a\"]  = parse.(Int64, df[:, \"a\"])"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nthrows an error? but using "},{"type":"text","text":"!","style":{"code":true}},{"type":"text","text":" does not? My intuition would be the opposite: "},{"type":"text","text":":","style":{"code":true}},{"type":"text","text":" means you can make "},{"type":"text","text":"more","style":{"bold":true}},{"type":"text","text":" modifications to the data frame, not fewer, since you are copying everywhere."}]}]}],"thread_ts":"1611524015.041000","reply_count":11,"reply_users_count":3,"latest_reply":"1611525934.044000","reply_users":["U8JAMQGQY","UBF9YRB6H","U681ELA87"],"subscribed":false},{"client_msg_id":"a1187456-5b4e-4861-ba8c-3135b0f3c594","type":"message","text":":wave: is there a straight forward way to do lag a column by something? I used to do this but `by` has been deprecated:\n```@&gt; begin\n    df\n    sort!([:category, :item, :date])\n    by([:category, :item], \n    lag_sales = :sales =&gt; Base.Fix2(ShiftedArrays.lag, 1))\nend```","user":"UUYRZ3LU8","ts":"1611538189.045900","team":"T68168MUP","edited":{"user":"UUYRZ3LU8","ts":"1611538196.000000"},"blocks":[{"type":"rich_text","block_id":"cNEL","elements":[{"type":"rich_text_section","elements":[{"type":"emoji","name":"wave"},{"type":"text","text":" is there a straight forward way to do lag a column by something? I used to do this but "},{"type":"text","text":"by","style":{"code":true}},{"type":"text","text":" has been deprecated:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"@> begin\n    df\n    sort!([:category, :item, :date])\n    by([:category, :item], \n    lag_sales = :sales => Base.Fix2(ShiftedArrays.lag, 1))\nend"}]}]}],"thread_ts":"1611538189.045900","reply_count":7,"reply_users_count":4,"latest_reply":"1611582328.050900","reply_users":["UBF9YRB6H","UUYRZ3LU8","U7JQGPGCQ","U8JAMQGQY"],"subscribed":false},{"client_msg_id":"488870c3-5e5a-4113-83f7-857da731b474","type":"message","text":"is there a way to modify a value in a json file and write back to disk?\n\nedit: `JSON` can do it `JSON3` has immutables","user":"UH8A351DJ","ts":"1611542012.046500","team":"T68168MUP","edited":{"user":"UH8A351DJ","ts":"1611542294.000000"},"blocks":[{"type":"rich_text","block_id":"d3t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a way to modify a value in a json file and write back to disk?\n\nedit: "},{"type":"text","text":"JSON","style":{"code":true}},{"type":"text","text":" can do it "},{"type":"text","text":"JSON3","style":{"code":true}},{"type":"text","text":" has immutables"}]}]}]},{"client_msg_id":"032102fd-2c76-4f74-ac64-e35e937d9cf0","type":"message","text":"I mean, json is a text format, so unless the value you're replacing has the exact same byte width, then it's not _really_ modifying in place. You can get the same \"mutability\" from JSON3 by doing `JSON3.read(json, Dict)` , modify the dict, then write it back out.","user":"U681ELA87","ts":"1611547844.048300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"frC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I mean, json is a text format, so unless the value you're replacing has the exact same byte width, then it's not "},{"type":"text","text":"really","style":{"italic":true}},{"type":"text","text":" modifying in place. You can get the same \"mutability\" from JSON3 by doing "},{"type":"text","text":"JSON3.read(json, Dict)","style":{"code":true}},{"type":"text","text":" , modify the dict, then write it back out."}]}]}],"thread_ts":"1611547844.048300","reply_count":2,"reply_users_count":2,"latest_reply":"1611601805.051300","reply_users":["U6A936746","UH8A351DJ"],"subscribed":false,"reactions":[{"name":"+1","users":["UH8A351DJ","U017JTQFNEQ"],"count":2}]},{"client_msg_id":"73c8c5be-5ea5-49d0-8e66-189f1e9e1475","type":"message","text":"finally merged my package [Shapley.jl](<https://gitlab.com/ExpandingMan/Shapley.jl>) to the general registry, in case anyone is interested.  Got stalled for a while because I needed to make a small change to Tables.jl","user":"U9VG1AYSG","ts":"1611618292.052300","team":"T68168MUP","attachments":[{"service_name":"GitLab","title":"Expanding Man / Shapley.jl","title_link":"https://gitlab.com/ExpandingMan/Shapley.jl","text":"feature importance from game theory in Julia","fallback":"GitLab: Expanding Man / Shapley.jl","thumb_url":"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png","from_url":"https://gitlab.com/ExpandingMan/Shapley.jl","thumb_width":128,"thumb_height":128,"service_icon":"https://assets.gitlab-static.net/assets/touch-icon-iphone-5a9cee0e8a51212e70b90c87c12f382c428870c0ff67d1eb034d884b78d2dae7.png","id":1,"original_url":"https://gitlab.com/ExpandingMan/Shapley.jl"}],"blocks":[{"type":"rich_text","block_id":"hbt1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"finally merged my package [Shapley.jl]("},{"type":"link","url":"https://gitlab.com/ExpandingMan/Shapley.jl"},{"type":"text","text":") to the general registry, in case anyone is interested.  Got stalled for a while because I needed to make a small change to Tables.jl"}]}]}],"reactions":[{"name":"+1","users":["U7PGB5DU3","U01GXNFKY6R","UKG4WF8PJ","U969CNQU9"],"count":4},{"name":"mask-parrot","users":["U01GXNFKY6R"],"count":1}]},{"client_msg_id":"7ac27fee-f83c-4600-a4ec-9b7d43dd481d","type":"message","text":"How does it differ from <https://juliapackages.com/p/shapml>","user":"U01FR784NSW","ts":"1611620005.052800","team":"T68168MUP","attachments":[{"service_name":"Julia Packages","title":"ShapML.jl","title_link":"https://juliapackages.com/p/shapml","text":"A Julia package for interpretable machine learning with stochastic Shapley values","fallback":"Julia Packages: ShapML.jl","thumb_url":"https://juliapackages.com/julia_share.png","from_url":"https://juliapackages.com/p/shapml","thumb_width":1200,"thumb_height":1200,"service_icon":"https://juliapackages.com/julia.ico","id":1,"original_url":"https://juliapackages.com/p/shapml"}],"blocks":[{"type":"rich_text","block_id":"TGBH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How does it differ from "},{"type":"link","url":"https://juliapackages.com/p/shapml"}]}]}]},{"client_msg_id":"35c29a37-a6df-45f9-9c38-893d945aa009","type":"message","text":"well, I had attempted to use ShapML and it didn't have very good compatibility with anything else in the ecosystem.  I was going to make a PR to that to improve this,  but found that it was almost entirely written with DataFrames operations.  So, the main advantage of my package is that it's compatible with the Tables.jl interface, so it should work seamlessly with most stuff in the data ecosystem, particularly MLJ.  It's also likely to perform better under most circumstances (much of the work that went into Shapley.jl was to make sure that I always called `predict` methods on full datasets rather than individual data points, because most such methods are designed to be more efficient this way), but I have not thoroughly benchmarked it, so I could be wrong","user":"U9VG1AYSG","ts":"1611672330.056800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TkXMs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"well, I had attempted to use ShapML and it didn't have very good compatibility with anything else in the ecosystem.  I was going to make a PR to that to improve this,  but found that it was almost entirely written with DataFrames operations.  So, the main advantage of my package is that it's compatible with the Tables.jl interface, so it should work seamlessly with most stuff in the data ecosystem, particularly MLJ.  It's also likely to perform better under most circumstances (much of the work that went into Shapley.jl was to make sure that I always called "},{"type":"text","text":"predict","style":{"code":true}},{"type":"text","text":" methods on full datasets rather than individual data points, because most such methods are designed to be more efficient this way), but I have not thoroughly benchmarked it, so I could be wrong"}]}]}],"thread_ts":"1611672330.056800","reply_count":1,"reply_users_count":1,"latest_reply":"1611768362.107100","reply_users":["U01EF0QVAB0"],"subscribed":false,"reactions":[{"name":"+1","users":["U6A936746","UDGT4PM41","U01C15GH58B","U01EF0QVAB0"],"count":4}]},{"client_msg_id":"23ab8da7-f436-46a0-84bb-1868ebb8b729","type":"message","text":"I am trying to demonstrate the use of the Arrow file format to archive a data table in one language and read it in another.  The simplest case is to write an Arrow file from R using `arrow::write_feather`.  I can read such a file using `Arrow.Table` in Julia but I get an error message from `pyarrow.feather.read_feather` in Python.  My Python is pretty rusty so I'm not sure if I misunderstood the documentation or I have an older version of the package or ...","user":"UBGRZ7FSP","ts":"1611680827.061700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fTz+P","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am trying to demonstrate the use of the Arrow file format to archive a data table in one language and read it in another.  The simplest case is to write an Arrow file from R using "},{"type":"text","text":"arrow::write_feather","style":{"code":true}},{"type":"text","text":".  I can read such a file using "},{"type":"text","text":"Arrow.Table","style":{"code":true}},{"type":"text","text":" in Julia but I get an error message from "},{"type":"text","text":"pyarrow.feather.read_feather","style":{"code":true}},{"type":"text","text":" in Python.  My Python is pretty rusty so I'm not sure if I misunderstood the documentation or I have an older version of the package or ..."}]}]}]},{"client_msg_id":"27d9d888-151f-4369-b1f3-c1455fa22aa0","type":"message","text":"Sorry for asking a Pythonish question on this forum but can anyone point me to where I might see an example of reading a file in the Arrow file format using `pyarrow.feather.read_feather?`","user":"UBGRZ7FSP","ts":"1611680901.063100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"I380","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sorry for asking a Pythonish question on this forum but can anyone point me to where I might see an example of reading a file in the Arrow file format using "},{"type":"text","text":"pyarrow.feather.read_feather?","style":{"code":true}}]}]}],"thread_ts":"1611680901.063100","reply_count":8,"reply_users_count":2,"latest_reply":"1611683673.068000","reply_users":["U681ELA87","UBGRZ7FSP"],"subscribed":false},{"client_msg_id":"20af31f2-fa7d-4c7f-b366-4801fd0c5238","type":"message","text":"speaking of arrow, has anyone ever tried to make them query-able through apache presto (aws athena)?  I've wanted to switch everything from using CSV to using Arrow, but I can't because my colleagues won't read them (and increasingly I am relying on presto/athena, so it's now a problem for me as well).  Unfortunately parquet seems to be the only binary format that's query-able with these.  Anybody do anything with this?","user":"U9VG1AYSG","ts":"1611682533.066300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3imZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"speaking of arrow, has anyone ever tried to make them query-able through apache presto (aws athena)?  I've wanted to switch everything from using CSV to using Arrow, but I can't because my colleagues won't read them (and increasingly I am relying on presto/athena, so it's now a problem for me as well).  Unfortunately parquet seems to be the only binary format that's query-able with these.  Anybody do anything with this?"}]}]}]},{"client_msg_id":"b8d14b5b-9f83-460c-b903-87029eb8cc29","type":"message","text":"Yeah, I'm not familiar enough with presto/athena to know if it's possible to query arrow files. I still would like to do a deep dive in Parquet.jl to get it up to the same amount of support it has in the c++ part of the apache/arrow project","user":"U681ELA87","ts":"1611683016.067300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F5wO7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, I'm not familiar enough with presto/athena to know if it's possible to query arrow files. I still would like to do a deep dive in Parquet.jl to get it up to the same amount of support it has in the c++ part of the apache/arrow project"}]}]}],"reactions":[{"name":"heart","users":["UDXST8ARK","U01C15GH58B","U01GXNFKY6R"],"count":3}]},{"client_msg_id":"E910EB55-AB50-48A7-96B7-ABD31187D18F","type":"message","text":"Hello, I have an array of a custom data structure representing different files with similar content. Now I want to vertically concatenate the multidimensional matrix stored in the field PP, i.e. something like dat[:].PP . I know that [dat[1].PP; dat[2].PP; dat[3].PP] works fine as only the size of the first dimension changes. What would be an efficient way to do that if the array becomes large? Can that be done in one line, or using array comprehension? I am still new to Julia programming and would appreciate a good hint. Thanks!","user":"U01GBPDL7SP","ts":"1611685208.077700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1=C","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello, I have an array of a custom data structure representing different files with similar content. Now I want to vertically concatenate the multidimensional matrix stored in the field PP, i.e. something like dat[:].PP . I know that [dat[1].PP; dat[2].PP; dat[3].PP] works fine as only the size of the first dimension changes. What would be an efficient way to do that if the array becomes large? Can that be done in one line, or using array comprehension? I am still new to Julia programming and would appreciate a good hint. Thanks!"}]}]}]},{"client_msg_id":"4095563b-f321-4d81-b4ef-0b77950a3b70","type":"message","text":"you probably want `reduce(vcat, (d.PP for d \\in dat))`","user":"U9VG1AYSG","ts":"1611685269.078300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sDO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you probably want "},{"type":"text","text":"reduce(vcat, (d.PP for d \\in dat))","style":{"code":true}}]}]}],"reactions":[{"name":"+1","users":["U01GBPDL7SP"],"count":1}]},{"client_msg_id":"EF28806A-BD27-4266-8DB6-06D0DA1278C7","type":"message","text":"Great, works like a charm. Thanks a lot, Michael","user":"U01GBPDL7SP","ts":"1611687796.079500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kMa9f","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Great, works like a charm. Thanks a lot, Michael"}]}]}]},{"client_msg_id":"2bf24142-c919-4ee6-944b-b8e46f16cbae","type":"message","text":"Blogpost about official Julia Arrow support up for consideration: <https://github.com/JuliaLang/www.julialang.org/pull/1129>. The Apache Arrow project just released 3.0.0 this morning, which is the first official release with Julia support included in the project.","user":"U681ELA87","ts":"1611690839.080600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"c28dm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Blogpost about official Julia Arrow support up for consideration: "},{"type":"link","url":"https://github.com/JuliaLang/www.julialang.org/pull/1129"},{"type":"text","text":". The Apache Arrow project just released 3.0.0 this morning, which is the first official release with Julia support included in the project."}]}]}],"reactions":[{"name":"+1","users":["U680THK2S","U6795JH6H","U67431ELR","U9VG1AYSG","UKG4WF8PJ","U6SHSF4R0","U969CNQU9","U011V2YN59N","UBGRZ7FSP","U680T6770","UDXST8ARK","U82LX4ACB","UCZ7VBGUD","U017JTQFNEQ","U01C15GH58B","U01GXNFKY6R","U66QZ3QF3"],"count":17},{"name":"tada","users":["U6795JH6H","U01FAHWCMFF","U67431ELR","U8D0QF5NZ","UCAFZ51L3","U82LX4ACB","U01CQTKB86N","U69KQT9DL","UCZ7VBGUD","U01GXNFKY6R","U66QZ3QF3"],"count":11}]},{"client_msg_id":"691f73e1-a919-49bb-8014-9cdeb1a24ebc","type":"message","text":"Does the 3.0.0 release of Arrow allow R and Pandas to use unsigned integer types as indices into a DictEncoding type?  If not we may want consider altering `PooledArrays.jl` to default to signed integer types for the ref array.","user":"UBGRZ7FSP","ts":"1611698589.085100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IRI3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does the 3.0.0 release of Arrow allow R and Pandas to use unsigned integer types as indices into a DictEncoding type?  If not we may want consider altering "},{"type":"text","text":"PooledArrays.jl","style":{"code":true}},{"type":"text","text":" to default to signed integer types for the ref array."}]}]}]},{"client_msg_id":"22ac5928-3276-49c0-9a5a-5d99df847a75","type":"message","text":"Good question. I doubt they changed things on their side; I thought in Arrow.jl we always convert to signed indices though; are you seeing issues?","user":"U681ELA87","ts":"1611699007.085600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u+1An","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Good question. I doubt they changed things on their side; I thought in Arrow.jl we always convert to signed indices though; are you seeing issues?"}]}]}]},{"client_msg_id":"84241489-ae55-40ed-8ce0-89200c85ffa5","type":"message","text":"Yes, I read a CSV file then wrote an Arrow file and it ended up with UInt32 indices in the Arrow file.  I can read it using `pyarrow.feather.read_table` which reports","user":"UBGRZ7FSP","ts":"1611700099.089100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"L/L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, I read a CSV file then wrote an Arrow file and it ended up with UInt32 indices in the Arrow file.  I can read it using "},{"type":"text","text":"pyarrow.feather.read_table","style":{"code":true}},{"type":"text","text":" which reports"}]}]}]},{"client_msg_id":"b8b0e1f4-ff4d-4247-8f2d-690a0b57ef1b","type":"message","text":"```PyObject pyarrow.Table\nlab: dictionary&lt;values=string, indices=uint32, ordered=0&gt; not null\nsubid: dictionary&lt;values=string, indices=uint32, ordered=0&gt; not null\ntrial_num: int64 not null\ntrial_type: dictionary&lt;values=string, indices=uint32, ordered=0&gt;\nstimulus_num: int64\nlooking_time: double\ntrial_error: bool not null\ntrial_error_type: dictionary&lt;values=string, indices=uint32, ordered=0&gt;\nmethod: dictionary&lt;values=string, indices=uint32, ordered=0&gt; not null\nra: dictionary&lt;values=string, indices=uint32, ordered=0&gt;```\n","user":"UBGRZ7FSP","ts":"1611700115.089300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jz0","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"PyObject pyarrow.Table\nlab: dictionary<values=string, indices=uint32, ordered=0> not null\nsubid: dictionary<values=string, indices=uint32, ordered=0> not null\ntrial_num: int64 not null\ntrial_type: dictionary<values=string, indices=uint32, ordered=0>\nstimulus_num: int64\nlooking_time: double\ntrial_error: bool not null\ntrial_error_type: dictionary<values=string, indices=uint32, ordered=0>\nmethod: dictionary<values=string, indices=uint32, ordered=0> not null\nra: dictionary<values=string, indices=uint32, ordered=0>"}]},{"type":"rich_text_section","elements":[]}]}]},{"client_msg_id":"cba027a3-a202-4c55-a84f-91351fc10450","type":"message","text":"if I remember correctly the arrow spec requires signed indices for everything, so technically I don't think anything is supposed to support that","user":"U9VG1AYSG","ts":"1611700403.090000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"E9eo9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if I remember correctly the arrow spec requires signed indices for everything, so technically I don't think anything is supposed to support that"}]}]}]},{"client_msg_id":"19bd6d27-a436-470e-8368-7f887f7d2515","type":"message","text":"I am using Arrow.jl v1.2.1","user":"UBGRZ7FSP","ts":"1611700545.090400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2m1nQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am using Arrow.jl v1.2.1"}]}]}]},{"client_msg_id":"d1eee205-90a0-43b2-a3b3-d578d583decf","type":"message","text":"In\n```julia&gt; using DBInterface, SQLite, Tables\n\njulia&gt; db = DBInterface.connect(SQLite.DB, \"db.sqlite\");\n\njulia&gt; DBInterface.execute(db, \"CREATE TABLE testtable (col1, col2);\");\n\njulia&gt; DBInterface.execute(db, \"SELECT * FROM testtable;\") |&gt; Tables.columntable\n(q = SQLite.Query[],)\n\njulia&gt; DBInterface.execute(db, \"INSERT INTO testtable VALUES (1, 2);\");\n\njulia&gt; DBInterface.execute(db, \"SELECT * FROM testtable;\") |&gt; Tables.columntable\n(col1 = [1], col2 = [2])```\nwhy do I not get `(col1 = [], col2 = [])` for the first select? The information seems to be there.","user":"U67SCG4HG","ts":"1611704667.092000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4yJp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> using DBInterface, SQLite, Tables\n\njulia> db = DBInterface.connect(SQLite.DB, \"db.sqlite\");\n\njulia> DBInterface.execute(db, \"CREATE TABLE testtable (col1, col2);\");\n\njulia> DBInterface.execute(db, \"SELECT * FROM testtable;\") |> Tables.columntable\n(q = SQLite.Query[],)\n\njulia> DBInterface.execute(db, \"INSERT INTO testtable VALUES (1, 2);\");\n\njulia> DBInterface.execute(db, \"SELECT * FROM testtable;\") |> Tables.columntable\n(col1 = [1], col2 = [2])"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"why do I not get "},{"type":"text","text":"(col1 = [], col2 = [])","style":{"code":true}},{"type":"text","text":" for the first select? The information seems to be there."}]}]}],"thread_ts":"1611704667.092000","reply_count":1,"reply_users_count":1,"latest_reply":"1611764231.099200","reply_users":["U681ELA87"],"subscribed":false},{"client_msg_id":"0af69e45-65e6-46fa-be21-01ad140e5c45","type":"message","text":"Anyone know what's going on here?","user":"U69BL50BF","ts":"1611707435.092200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GvPU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone know what's going on here?"}]}]}]},{"client_msg_id":"83a125dc-d69e-4c0d-8662-c57857afa7dc","type":"message","text":"```ERROR: LoadError: ArgumentError: Package Indexing [313cdc1a-70c2-5d6a-ae34-0150d3930a38] is required but does not seem to be installed:\n - Run `Pkg.instantiate()` to install all recorded dependencies.\n\nStacktrace:\n [1] _require(::Base.PkgId) at .\\loading.jl:999\n [2] require(::Base.PkgId) at .\\loading.jl:928\n [3] require(::Module, ::Symbol) at .\\loading.jl:923\n [4] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [5] include(::Module, ::String) at .\\Base.jl:368\n [6] top-level scope at none:2\n [7] eval at .\\boot.jl:331 [inlined]\n [8] eval(::Expr) at .\\client.jl:467\n [9] top-level scope at .\\none:3\nin expression starting at C:\\Users\\accou\\.julia\\packages\\SplitApplyCombine\\2fFYd\\src\\SplitApplyCombine.jl:4\nERROR: LoadError: Failed to precompile SplitApplyCombine [03a91e81-4c3e-53e1-a0a4-9c0c8f19dd66] to C:\\Users\\accou\\.julia\\compiled\\v1.5\\SplitApplyCombine\\vbX6o_e1Vc1.ji.\nStacktrace:\n [1] error(::String) at .\\error.jl:33\n [2] compilecache(::Base.PkgId, ::String) at .\\loading.jl:1305\n [3] _require(::Base.PkgId) at .\\loading.jl:1030\n [4] require(::Base.PkgId) at .\\loading.jl:928\n [5] require(::Module, ::Symbol) at .\\loading.jl:923\n [6] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [7] include(::Module, ::String) at .\\Base.jl:368\n [8] top-level scope at none:2\n [9] eval at .\\boot.jl:331 [inlined]\n [10] eval(::Expr) at .\\client.jl:467\n [11] top-level scope at .\\none:3\nin expression starting at C:\\Users\\accou\\.julia\\packages\\TypedTables\\ZF2b3\\src\\TypedTables.jl:5\nERROR: LoadError: LoadError: Failed to precompile TypedTables [9d95f2ec-7b3d-5a63-8d20-e2491e220bb9] to C:\\Users\\accou\\.julia\\compiled\\v1.5\\TypedTables\\NU69s_e1Vc1.ji.\nStacktrace:\n [1] error(::String) at .\\error.jl:33\n [2] compilecache(::Base.PkgId, ::String) at .\\loading.jl:1305\n [3] _require(::Base.PkgId) at .\\loading.jl:1030\n [4] require(::Base.PkgId) at .\\loading.jl:928\n [5] require(::Module, ::Symbol) at .\\loading.jl:923\n [6] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [7] include at .\\Base.jl:368 [inlined]\n [8] include(::String) at C:\\Users\\accou\\.julia\\packages\\Catlab\\yfjLt\\src\\Catlab.jl:1\n [9] top-level scope at C:\\Users\\accou\\.julia\\packages\\Catlab\\yfjLt\\src\\Catlab.jl:6\n [10] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [11] include(::Module, ::String) at .\\Base.jl:368\n [12] top-level scope at none:2\n [13] eval at .\\boot.jl:331 [inlined]\n [14] eval(::Expr) at .\\client.jl:467\n [15] top-level scope at .\\none:3\nin expression starting at C:\\Users\\accou\\.julia\\packages\\Catlab\\yfjLt\\src\\categorical_algebra\\CSetDataStructures.jl:14\nin expression starting at C:\\Users\\accou\\.julia\\packages\\Catlab\\yfjLt\\src\\Catlab.jl:6\nERROR: LoadError: Failed to precompile Catlab [134e5e36-593f-5add-ad60-77f754baafbe] to C:\\Users\\accou\\.julia\\compiled\\v1.5\\Catlab\\fBQ1G_e1Vc1.ji.\nStacktrace:\n [1] error(::String) at .\\error.jl:33\n [2] compilecache(::Base.PkgId, ::String) at .\\loading.jl:1305\n [3] _require(::Base.PkgId) at .\\loading.jl:1030\n [4] require(::Base.PkgId) at .\\loading.jl:928\n [5] require(::Module, ::Symbol) at .\\loading.jl:923\n [6] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [7] include(::Module, ::String) at .\\Base.jl:368\n [8] top-level scope at none:2\n [9] eval at .\\boot.jl:331 [inlined]\n [10] eval(::Expr) at .\\client.jl:467\n [11] top-level scope at .\\none:3\nin expression starting at C:\\Users\\accou\\.julia\\packages\\Catalyst\\cSPjT\\src\\Catalyst.jl:29```","user":"U69BL50BF","ts":"1611707436.092500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QIgZ","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ERROR: LoadError: ArgumentError: Package Indexing [313cdc1a-70c2-5d6a-ae34-0150d3930a38] is required but does not seem to be installed:\n - Run `Pkg.instantiate()` to install all recorded dependencies.\n\nStacktrace:\n [1] _require(::Base.PkgId) at .\\loading.jl:999\n [2] require(::Base.PkgId) at .\\loading.jl:928\n [3] require(::Module, ::Symbol) at .\\loading.jl:923\n [4] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [5] include(::Module, ::String) at .\\Base.jl:368\n [6] top-level scope at none:2\n [7] eval at .\\boot.jl:331 [inlined]\n [8] eval(::Expr) at .\\client.jl:467\n [9] top-level scope at .\\none:3\nin expression starting at C:\\Users\\accou\\.julia\\packages\\SplitApplyCombine\\2fFYd\\src\\SplitApplyCombine.jl:4\nERROR: LoadError: Failed to precompile SplitApplyCombine [03a91e81-4c3e-53e1-a0a4-9c0c8f19dd66] to C:\\Users\\accou\\.julia\\compiled\\v1.5\\SplitApplyCombine\\vbX6o_e1Vc1.ji.\nStacktrace:\n [1] error(::String) at .\\error.jl:33\n [2] compilecache(::Base.PkgId, ::String) at .\\loading.jl:1305\n [3] _require(::Base.PkgId) at .\\loading.jl:1030\n [4] require(::Base.PkgId) at .\\loading.jl:928\n [5] require(::Module, ::Symbol) at .\\loading.jl:923\n [6] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [7] include(::Module, ::String) at .\\Base.jl:368\n [8] top-level scope at none:2\n [9] eval at .\\boot.jl:331 [inlined]\n [10] eval(::Expr) at .\\client.jl:467\n [11] top-level scope at .\\none:3\nin expression starting at C:\\Users\\accou\\.julia\\packages\\TypedTables\\ZF2b3\\src\\TypedTables.jl:5\nERROR: LoadError: LoadError: Failed to precompile TypedTables [9d95f2ec-7b3d-5a63-8d20-e2491e220bb9] to C:\\Users\\accou\\.julia\\compiled\\v1.5\\TypedTables\\NU69s_e1Vc1.ji.\nStacktrace:\n [1] error(::String) at .\\error.jl:33\n [2] compilecache(::Base.PkgId, ::String) at .\\loading.jl:1305\n [3] _require(::Base.PkgId) at .\\loading.jl:1030\n [4] require(::Base.PkgId) at .\\loading.jl:928\n [5] require(::Module, ::Symbol) at .\\loading.jl:923\n [6] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [7] include at .\\Base.jl:368 [inlined]\n [8] include(::String) at C:\\Users\\accou\\.julia\\packages\\Catlab\\yfjLt\\src\\Catlab.jl:1\n [9] top-level scope at C:\\Users\\accou\\.julia\\packages\\Catlab\\yfjLt\\src\\Catlab.jl:6\n [10] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [11] include(::Module, ::String) at .\\Base.jl:368\n [12] top-level scope at none:2\n [13] eval at .\\boot.jl:331 [inlined]\n [14] eval(::Expr) at .\\client.jl:467\n [15] top-level scope at .\\none:3\nin expression starting at C:\\Users\\accou\\.julia\\packages\\Catlab\\yfjLt\\src\\categorical_algebra\\CSetDataStructures.jl:14\nin expression starting at C:\\Users\\accou\\.julia\\packages\\Catlab\\yfjLt\\src\\Catlab.jl:6\nERROR: LoadError: Failed to precompile Catlab [134e5e36-593f-5add-ad60-77f754baafbe] to C:\\Users\\accou\\.julia\\compiled\\v1.5\\Catlab\\fBQ1G_e1Vc1.ji.\nStacktrace:\n [1] error(::String) at .\\error.jl:33\n [2] compilecache(::Base.PkgId, ::String) at .\\loading.jl:1305\n [3] _require(::Base.PkgId) at .\\loading.jl:1030\n [4] require(::Base.PkgId) at .\\loading.jl:928\n [5] require(::Module, ::Symbol) at .\\loading.jl:923\n [6] include(::Function, ::Module, ::String) at .\\Base.jl:380\n [7] include(::Module, ::String) at .\\Base.jl:368\n [8] top-level scope at none:2\n [9] eval at .\\boot.jl:331 [inlined]\n [10] eval(::Expr) at .\\client.jl:467\n [11] top-level scope at .\\none:3\nin expression starting at C:\\Users\\accou\\.julia\\packages\\Catalyst\\cSPjT\\src\\Catalyst.jl:29"}]}]}],"thread_ts":"1611707436.092500","reply_count":2,"reply_users_count":2,"latest_reply":"1611755974.095600","reply_users":["U66QZ3QF3","U69BL50BF"],"subscribed":false},{"client_msg_id":"19c778cd-9a47-4f88-94f8-05b21a723227","type":"message","text":"it's happening even when I instantiate...","user":"U69BL50BF","ts":"1611707443.092800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/GW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it's happening even when I instantiate..."}]}]}]},{"client_msg_id":"c5cb405e-f561-41ec-aaa6-6f105f24d3b4","type":"message","text":"Hello JuliaData github org members - I was wondering if someone could make me an admin for <https://github.com/JuliaData/SplitApplyCombine.jl> ? Thanks :slightly_smiling_face:","user":"U66QZ3QF3","ts":"1611744715.094200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tK50","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello JuliaData github org members - I was wondering if someone could make me an admin for "},{"type":"link","url":"https://github.com/JuliaData/SplitApplyCombine.jl"},{"type":"text","text":" ? Thanks "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"thread_ts":"1611744715.094200","reply_count":3,"reply_users_count":2,"latest_reply":"1611744997.094900","reply_users":["U67431ELR","U66QZ3QF3"],"subscribed":false},{"client_msg_id":"00850188-741c-447b-9e56-7811370f998f","type":"message","text":"<@U681ELA87> I opened <https://github.com/JuliaData/Arrow.jl/issues/113> regarding unsigned indices in the Arrow.jl-generated DictEncoding types.  If you don't have time to look at this and can point me to the section of code where conversion to signed ints is expected to happen I can take a look.","user":"UBGRZ7FSP","ts":"1611764414.101200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bkph","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U681ELA87"},{"type":"text","text":" I opened "},{"type":"link","url":"https://github.com/JuliaData/Arrow.jl/issues/113"},{"type":"text","text":" regarding unsigned indices in the Arrow.jl-generated DictEncoding types.  If you don't have time to look at this and can point me to the section of code where conversion to signed ints is expected to happen I can take a look."}]}]}],"thread_ts":"1611764414.101200","reply_count":4,"reply_users_count":2,"latest_reply":"1611766767.103800","reply_users":["U681ELA87","UBGRZ7FSP"],"subscribed":false},{"client_msg_id":"cd02f951-1ddd-49fc-9d7f-7b909ce1c7cd","type":"message","text":"I'm trying to understand if/how the Arrow format and Parquet format can be used together.\nI see the Apache Arrow [FAQ](<https://arrow.apache.org/faq/>) says\n&gt;  Arrow and Parquet complement each other and are commonly used together in applications. Storing your data on disk using Parquet and reading it into memory in the Arrow format\nBut i'm not 100% sure what this means and i couldn't see how to do it with Parquet.jl and Arrow.jl\nIs e.g. reading Parquet files as an Arrow table possible?","user":"UDXST8ARK","ts":"1611766429.103500","team":"T68168MUP","edited":{"user":"UDXST8ARK","ts":"1611766804.000000"},"blocks":[{"type":"rich_text","block_id":"=ZUa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm trying to understand if/how the Arrow format and Parquet format can be used together.\nI see the Apache Arrow [FAQ]("},{"type":"link","url":"https://arrow.apache.org/faq/"},{"type":"text","text":") says\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":" Arrow and Parquet complement each other and are commonly used together in applications. Storing your data on disk using Parquet and reading it into memory in the Arrow format"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"But i'm not 100% sure what this means and i couldn't see how to do it with Parquet.jl and Arrow.jl\nIs e.g. reading Parquet files as an Arrow table possible?"}]}]}],"thread_ts":"1611766429.103500","reply_count":3,"reply_users_count":2,"latest_reply":"1611769002.108400","reply_users":["UDXST8ARK","U681ELA87"],"subscribed":false},{"client_msg_id":"05cecde8-0ef2-46fb-99b7-284d3ffb607c","type":"message","text":"I'm betraying my ignorance, here. But let's say I'm doing a project that is one-off, i.e. nothing else depends on it. I've been using `includet` so far, but I think it's time to make my project a module. What's the workflow again? I shouldn't use `LOAD_PATH`. Should I put it on `git`? I don't want it to be in my global environment or any other environment for that matter","user":"UBF9YRB6H","ts":"1611767280.106100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CjF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm betraying my ignorance, here. But let's say I'm doing a project that is one-off, i.e. nothing else depends on it. I've been using "},{"type":"text","text":"includet","style":{"code":true}},{"type":"text","text":" so far, but I think it's time to make my project a module. What's the workflow again? I shouldn't use "},{"type":"text","text":"LOAD_PATH","style":{"code":true}},{"type":"text","text":". Should I put it on "},{"type":"text","text":"git","style":{"code":true}},{"type":"text","text":"? I don't want it to be in my global environment or any other environment for that matter"}]}]}],"thread_ts":"1611767280.106100","reply_count":10,"reply_users_count":3,"latest_reply":"1611776930.108900","reply_users":["U6A936746","UBF9YRB6H","U01FKQQ7J0J"],"subscribed":false}]}