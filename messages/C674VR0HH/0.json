{"cursor": 5, "messages": [{"client_msg_id":"6de9b234-3c3f-40a6-bc98-fb48f3d45f15","type":"message","text":"Hi, I am trying to create a new column in my data frame. The source column is a `Date` and the target column should be a `string` with the year and the month. I have the following code\n```transform(cxvolume, :CREATED_ON =&gt; (a -&gt; Dates.format(a, \"mm yyyy\")) =&gt; :CREATED_ON_MONTH_YEAR)```\nbut i have this error message\n```MethodError: no method matching format(::SentinelArrays.ChainedVector{Dates.Date,Array{Dates.Date,1}}, ::String)```\nAny idea why?","user":"U01EZ6VN118","ts":"1616612004.222100","team":"T68168MUP","edited":{"user":"U01EZ6VN118","ts":"1616612042.000000"},"blocks":[{"type":"rich_text","block_id":"al5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I am trying to create a new column in my data frame. The source column is a "},{"type":"text","text":"Date","style":{"code":true}},{"type":"text","text":" and the target column should be a "},{"type":"text","text":"string","style":{"code":true}},{"type":"text","text":" with the year and the month. I have the following code\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"transform(cxvolume, :CREATED_ON => (a -> Dates.format(a, \"mm yyyy\")) => :CREATED_ON_MONTH_YEAR)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"but i have this error message\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"MethodError: no method matching format(::SentinelArrays.ChainedVector{Dates.Date,Array{Dates.Date,1}}, ::String)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Any idea why?"}]}]}],"thread_ts":"1616612004.222100","reply_count":4,"reply_users_count":2,"latest_reply":"1616612355.223300","reply_users":["U67SCG4HG","U680THK2S"],"is_locked":false,"subscribed":false},{"client_msg_id":"5fa97f4b-4a20-4b36-915f-5c7e995fd810","type":"message","text":"Playing around with the <https://docs.juliaplots.org/latest/|JuliaPlots> package -- which plot can I use to have bar / histogram chart with categorical x-axis? It looks like `bar` and `histogram` expect numbers in x-axis","user":"U01EZ6VN118","ts":"1616626920.225200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7EI0K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Playing around with the "},{"type":"link","url":"https://docs.juliaplots.org/latest/","text":"JuliaPlots"},{"type":"text","text":" package -- which plot can I use to have bar / histogram chart with categorical x-axis? It looks like "},{"type":"text","text":"bar","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"histogram","style":{"code":true}},{"type":"text","text":" expect numbers in x-axis"}]}]}],"thread_ts":"1616626920.225200","reply_count":8,"reply_users_count":3,"latest_reply":"1616628040.226800","reply_users":["U6A936746","U01EZ6VN118","U8JP5B9T2"],"is_locked":false,"subscribed":false},{"client_msg_id":"dc4ad704-27d5-4c5a-bedc-9ed7a8459dae","type":"message","text":"How can I rename multiple columns in my dataframe to be the same as the first row below them? In my case, I'd like to do this to every 3rd column. I'm considering using something like this if it works but not sure where to take it from here:\n\n```rename!(df,¬†[Symbol(\"col$i\")¬†for¬†i¬†in¬†2:3:94]```\n","user":"U01QJ915TFD","ts":"1616637610.236900","team":"T68168MUP","edited":{"user":"U01QJ915TFD","ts":"1616639503.000000"},"blocks":[{"type":"rich_text","block_id":"MSz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How can I rename multiple columns in my dataframe to be the same as the first row below them? In my case, I'd like to do this to every 3rd column. I'm considering using something like this if it works but not sure where to take it from here:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"rename!(df,¬†[Symbol(\"col$i\")¬†for¬†i¬†in¬†2:3:94]"}]},{"type":"rich_text_section","elements":[]}]}]},{"type":"message","text":"Here's what my df looks like","files":[{"id":"F01SJN0S868","created":1616639489,"timestamp":1616639489,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01QJ915TFD","editable":false,"size":132401,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01SJN0S868/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01SJN0S868/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01SJN0S868-da5337096b/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01SJN0S868-da5337096b/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01SJN0S868-da5337096b/image_360.png","thumb_360_w":360,"thumb_360_h":75,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01SJN0S868-da5337096b/image_480.png","thumb_480_w":480,"thumb_480_h":99,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01SJN0S868-da5337096b/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01SJN0S868-da5337096b/image_720.png","thumb_720_w":720,"thumb_720_h":149,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01SJN0S868-da5337096b/image_800.png","thumb_800_w":800,"thumb_800_h":166,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01SJN0S868-da5337096b/image_960.png","thumb_960_w":960,"thumb_960_h":199,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01SJN0S868-da5337096b/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":212,"original_w":1212,"original_h":251,"thumb_tiny":"AwAJADCorMe9IVzyTSLS9qogMfTkUg7H8KPT6UDoPrQAevTilxyRx+VJ60vf8KAP/9k=","permalink":"https://julialang.slack.com/files/U01QJ915TFD/F01SJN0S868/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01SJN0S868-d35981d2ca","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"JPp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Here's what my df looks like"}]}]}],"user":"U01QJ915TFD","display_as_bot":false,"ts":"1616639494.239000","edited":{"user":"U01QJ915TFD","ts":"1616639513.000000"}},{"client_msg_id":"a42304f2-9347-47b2-82d2-62083190bff4","type":"message","text":"If what I posted above is not really possible, something else I'd like to learn how to do would be add something to the end of all column names or to a range of them. For example, say I wanted to add the letter \"a\" to the end of all column names.","user":"U01QJ915TFD","ts":"1616640354.242100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vjN7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If what I posted above is not really possible, something else I'd like to learn how to do would be add something to the end of all column names or to a range of them. For example, say I wanted to add the letter \"a\" to the end of all column names."}]}]}]},{"client_msg_id":"94c63e73-e51f-4606-ac90-6bb4cdbc0613","type":"message","text":"Are there some established JSON serialization formats for DataFrames?","user":"UB2QSHWPN","ts":"1616669419.246700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SEZXd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there some established JSON serialization formats for DataFrames?"}]}]}]},{"client_msg_id":"4036d67a-8c3f-47e3-9eb7-f388ceb9bcca","type":"message","text":"Why can we `push!` a row into a DataFrame, but can‚Äôt `pushfirst!`? I assume there‚Äôs a reason it is not defined","user":"ULMSCCJ4C","ts":"1616675092.249600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kST","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Why can we "},{"type":"text","text":"push!","style":{"code":true}},{"type":"text","text":" a row into a DataFrame, but can‚Äôt "},{"type":"text","text":"pushfirst!","style":{"code":true}},{"type":"text","text":"? I assume there‚Äôs a reason it is not defined"}]}]}],"thread_ts":"1616675092.249600","reply_count":3,"reply_users_count":2,"latest_reply":"1616677823.252600","reply_users":["U8JAMQGQY","ULMSCCJ4C"],"is_locked":false,"subscribed":false},{"client_msg_id":"c9c1884b-1c9d-435d-ad2d-33b9ac168493","type":"message","text":"We have just made a DataFrames 0.22.6 release. Here are the release notes: <https://discourse.julialang.org/t/release-announcements-for-dataframes-jl/18258/124>","user":"U8JAMQGQY","ts":"1616676602.251900","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Release announcements for DataFrames.jl","title_link":"https://discourse.julialang.org/t/release-announcements-for-dataframes-jl/18258/124","text":"We have just made a 0.22.6 patch release. Hopefully it is the last release before 1.0 release. We have decided to make 0.22.6 release to deprecate some outstanding things that should be removed in 1.0 release, but were missed in the 0.22 release process. These functionalities are on the border of being an error, but since they worked in the past we have decided to have a release that will allow users to go through deprecation cycle (although we assume that most likely the deprecated methods are...","fallback":"JuliaLang: Release announcements for DataFrames.jl","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1616676542,"from_url":"https://discourse.julialang.org/t/release-announcements-for-dataframes-jl/18258/124","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/release-announcements-for-dataframes-jl/18258/124"}],"blocks":[{"type":"rich_text","block_id":"mf=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We have just made a DataFrames 0.22.6 release. Here are the release notes: "},{"type":"link","url":"https://discourse.julialang.org/t/release-announcements-for-dataframes-jl/18258/124"}]}]}]},{"client_msg_id":"7db74b6b-e58d-41e3-8ab0-15e4b2f2adfc","type":"message","text":"I feel kinda silly but is it possible to groupby, transform without ungrouping, and then sort by this new column?","user":"U01C2E6TYEM","ts":"1616679254.253700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nAly","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I feel kinda silly but is it possible to groupby, transform without ungrouping, and then sort by this new column?"}]}]}],"thread_ts":"1616679254.253700","reply_count":1,"reply_users_count":1,"latest_reply":"1616681554.254400","reply_users":["U8JAMQGQY"],"is_locked":false,"subscribed":false},{"client_msg_id":"32864029-da67-40de-aa9f-e3994ceea357","type":"message","text":"so just to be clear the new reworked `join` is *not* included yet, is that correct?","user":"U9VG1AYSG","ts":"1616680913.254100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SBj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so just to be clear the new reworked "},{"type":"text","text":"join","style":{"code":true}},{"type":"text","text":" is "},{"type":"text","text":"not","style":{"bold":true}},{"type":"text","text":" included yet, is that correct?"}]}]}],"thread_ts":"1616680913.254100","reply_count":1,"reply_users_count":1,"latest_reply":"1616681310.254200","reply_users":["U8JAMQGQY"],"is_locked":false,"subscribed":false},{"client_msg_id":"5997204e-5ea2-4267-9ad3-c4ac2a423007","type":"message","text":"I am using Julia 1.6 now and CategoricalArrays v0.9.3. I get this error `CategoricalArray only supports AbstractString, AbstractChar and Number element types (got element type NamedTuple{(:Arm,), Tuple{String}})` . when trying to make a dataframe where one of the columns is a NamedTuple type which is then supposed to be converted to Categorical so that it can be transferred to R for ggplot. It used to work before so what happened now? Does CategoricalArrays not support NamedTuple in a column now? The code I have was working before a few weeks ago.","user":"U01EF0QVAB0","ts":"1616711434.260700","team":"T68168MUP","edited":{"user":"U01EF0QVAB0","ts":"1616712089.000000"},"blocks":[{"type":"rich_text","block_id":"3EYrb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am using Julia 1.6 now and CategoricalArrays v0.9.3. I get this error "},{"type":"text","text":"CategoricalArray only supports AbstractString, AbstractChar and Number element types (got element type NamedTuple{(:Arm,), Tuple{String}})","style":{"code":true}},{"type":"text","text":" . when trying to make a dataframe where one of the columns is a NamedTuple type which is then supposed to be converted to Categorical so that it can be transferred to R for ggplot. It used to work before so what happened now? Does CategoricalArrays not support NamedTuple in a column now? The code I have was working before a few weeks ago."}]}]}],"thread_ts":"1616711434.260700","reply_count":2,"reply_users_count":2,"latest_reply":"1616714182.266000","reply_users":["U8JAMQGQY","U01EF0QVAB0"],"is_locked":false,"subscribed":false},{"type":"message","text":"Could you help me with an unexpected result in a DataFrame?\n\nI'm trying to extract some information from a gzip CSV file and I found out a way to extract the values this way:\n\n```a_copy = load(File(format\"CSV\", file), delim=';') |&gt; DataFrame\n\na_cols = select(a_copy, :descritivo_item, :valor_total) # 592473x2 DataFrame\n\nfiltered_copy = a_cols[ismissing.(a_cols[!, :descritivo_item]), :] # 0x2 DataFrame```\nHowever, I'm struggling to understand why the DataFrame returned with cells that has no value instead of missing (see the screenshot)\n\nAny ideas of what I may be doing wrong here?","files":[{"id":"F01T6AQNGUQ","created":1616712760,"timestamp":1616712760,"name":"Screenshot Julia.png","title":"Screenshot Julia.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U0152N9899D","editable":false,"size":63588,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01T6AQNGUQ/screenshot_julia.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01T6AQNGUQ/download/screenshot_julia.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01T6AQNGUQ-dbc58e4086/screenshot_julia_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01T6AQNGUQ-dbc58e4086/screenshot_julia_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01T6AQNGUQ-dbc58e4086/screenshot_julia_360.png","thumb_360_w":360,"thumb_360_h":253,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01T6AQNGUQ-dbc58e4086/screenshot_julia_480.png","thumb_480_w":480,"thumb_480_h":337,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01T6AQNGUQ-dbc58e4086/screenshot_julia_160.png","original_w":604,"original_h":424,"thumb_tiny":"AwAhADCoUAGeaNq+tOP3RRxn2pgM2r60bR/eFO/DNH/AaAGn0zQVwAaD1pW6CgBx+6KCfeg/do2j0oAM5H/16Q7c8ijA44pcDPSgBh9qVugpD1pW6CgBT92lpD92loAQdqB1H0oHagdR9KAGmlakNK1AH//Z","permalink":"https://julialang.slack.com/files/U0152N9899D/F01T6AQNGUQ/screenshot_julia.png","permalink_public":"https://slack-files.com/T68168MUP-F01T6AQNGUQ-2e1af0e3eb","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"pe5Z0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Could you help me with an unexpected result in a DataFrame?\n\nI'm trying to extract some information from a gzip CSV file and I found out a way to extract the values this way:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"a_copy = load(File(format\"CSV\", file), delim=';') |> DataFrame\n\na_cols = select(a_copy, :descritivo_item, :valor_total) # 592473x2 DataFrame\n\nfiltered_copy = a_cols[ismissing.(a_cols[!, :descritivo_item]), :] # 0x2 DataFrame"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nHowever, I'm struggling to understand why the DataFrame returned with cells that has no value instead of missing (see the screenshot)\n\nAny ideas of what I may be doing wrong here?"}]}]}],"user":"U0152N9899D","display_as_bot":false,"ts":"1616712789.265000","thread_ts":"1616712789.265000","reply_count":2,"reply_users_count":2,"latest_reply":"1616713981.265800","reply_users":["U8JAMQGQY","U0152N9899D"],"is_locked":false,"subscribed":false},{"client_msg_id":"da0c85b0-d279-4aba-b470-a1e5a7b5edd9","type":"message","text":"I have a grouped and sorted dataframe and want to add a column with `transform` that is just an integer from 1 to n_groups. How do I do that?\n\nThere must be something like `nrow`, maybe `igroup` . data.table has `.GRP` for example\n```DT[ , i := .GRP, by = key(DT)]```","user":"UK1BNFHFV","ts":"1616752551.272700","team":"T68168MUP","edited":{"user":"UK1BNFHFV","ts":"1616752780.000000"},"blocks":[{"type":"rich_text","block_id":"oIy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a grouped and sorted dataframe and want to add a column with "},{"type":"text","text":"transform","style":{"code":true}},{"type":"text","text":" that is just an integer from 1 to n_groups. How do I do that?\n\nThere must be something like "},{"type":"text","text":"nrow","style":{"code":true}},{"type":"text","text":", maybe "},{"type":"text","text":"igroup","style":{"code":true}},{"type":"text","text":" . data.table has "},{"type":"text","text":".GRP","style":{"code":true}},{"type":"text","text":" for example\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"DT[ , i := .GRP, by = key(DT)]"}]}]}]},{"client_msg_id":"9ff64acb-e9c2-475a-b379-d4c00bcfb103","type":"message","text":"I am using ODBC.jl (Julia x86, win10) to connect to an old MS Access DB *.mde file and query dataframes from it, but seem there are cells with Cyrillic text, and I get wrong encoding from it. Setting locale identifiers into connection string doesn't help. Can it be solved on Julia side, or should I dig into Access properties?\n```using ODBC\n\nconn_str  = \"Driver={Microsoft Access Driver (*.mdb)};Dbq=$dbfile;Uid=Admin;Pwd=;\"\n#conn_str  = \"Driver={Microsoft Access Driver (*.mdb)};Dbq=C:\\mydatabase.mde;Locale Identifier=1049;Uid=Admin;Pwd=;\" # ru-RU locales\n\nconn = ODBC.Connection(conn_str)\n\ndf = DBInterface.execute(conn, \"SELECT * from DefFil\") |&gt; DataFrame```\nI get the following data:\n```julia&gt; select(df, :text_cnp)\n22042√ó1 DataFrame\n   Row ‚îÇ text_cnp\n       ‚îÇ String?\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n     1 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     2 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     3 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     4 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     5 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     6 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     7 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     8 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶```","user":"UB2QSHWPN","ts":"1616752672.273200","team":"T68168MUP","edited":{"user":"UB2QSHWPN","ts":"1616752740.000000"},"blocks":[{"type":"rich_text","block_id":"oMP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am using ODBC.jl (Julia x86, win10) to connect to an old MS Access DB *.mde file and query dataframes from it, but seem there are cells with Cyrillic text, and I get wrong encoding from it. Setting locale identifiers into connection string doesn't help. Can it be solved on Julia side, or should I dig into Access properties?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using ODBC\n\nconn_str  = \"Driver={Microsoft Access Driver (*.mdb)};Dbq=$dbfile;Uid=Admin;Pwd=;\"\n#conn_str  = \"Driver={Microsoft Access Driver (*.mdb)};Dbq=C:\\mydatabase.mde;Locale Identifier=1049;Uid=Admin;Pwd=;\" # ru-RU locales\n\nconn = ODBC.Connection(conn_str)\n\ndf = DBInterface.execute(conn, \"SELECT * from DefFil\") |> DataFrame"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nI get the following data:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> select(df, :text_cnp)\n22042√ó1 DataFrame\n   Row ‚îÇ text_cnp\n       ‚îÇ String?\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n     1 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     2 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     3 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     4 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     5 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     6 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     7 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶\n     8 ‚îÇ \\r\\n\\r\\n   \\xc8\\xf1\\xf1\\xeb\\xe5\\‚Ä¶"}]}]}]},{"client_msg_id":"79ad86ea-6812-4122-ae1e-a1fa208fbc27","type":"message","text":"any suggestions on how can I use `|&gt;` for `select` with dataframes?\n```julia&gt; df = DataFrame(:a =&gt; [1, 2], :b =&gt; [1, 2])\n2√ó2 DataFrame\n Row ‚îÇ a      b     \n     ‚îÇ Int64  Int64 \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ     1      1\n   2 ‚îÇ     2      2\n\njulia&gt; select(df, :a)\n2√ó1 DataFrame\n Row ‚îÇ a     \n     ‚îÇ Int64 \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ     1\n   2 ‚îÇ     2\n\njulia&gt; df |&gt; select(:a)\nERROR: MethodError: no method matching select(::Symbol)\nClosest candidates are:\n  select(::AbstractDataFrame, ::Any...; copycols, renamecols) at C:\\Users\\deyan\\.julia\\packages\\DataFrames\\oQ5c7\\src\\abstractdataframe\\selection.jl:847\n  select(::Union{Function, Type}, ::AbstractDataFrame; renamecols) at C:\\Users\\deyan\\.julia\\packages\\DataFrames\\oQ5c7\\src\\abstractdataframe\\selection.jl:850\n  select(::Union{Function, Type}, ::GroupedDataFrame; copycols, keepkeys, ungroup, renamecols) at C:\\Users\\deyan\\.julia\\packages\\DataFrames\\oQ5c7\\src\\groupeddataframe\\splitapplycombine.jl:642\n  ...\nStacktrace:\n [1] top-level scope\n   @ REPL[15]:1\n\njulia&gt; ```","user":"U8WEJ293L","ts":"1616837802.287900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HjYd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"any suggestions on how can I use "},{"type":"text","text":"|>","style":{"code":true}},{"type":"text","text":" for "},{"type":"text","text":"select","style":{"code":true}},{"type":"text","text":" with dataframes?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> df = DataFrame(:a => [1, 2], :b => [1, 2])\n2√ó2 DataFrame\n Row ‚îÇ a      b     \n     ‚îÇ Int64  Int64 \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ     1      1\n   2 ‚îÇ     2      2\n\njulia> select(df, :a)\n2√ó1 DataFrame\n Row ‚îÇ a     \n     ‚îÇ Int64 \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ     1\n   2 ‚îÇ     2\n\njulia> df |> select(:a)\nERROR: MethodError: no method matching select(::Symbol)\nClosest candidates are:\n  select(::AbstractDataFrame, ::Any...; copycols, renamecols) at C:\\Users\\deyan\\.julia\\packages\\DataFrames\\oQ5c7\\src\\abstractdataframe\\selection.jl:847\n  select(::Union{Function, Type}, ::AbstractDataFrame; renamecols) at C:\\Users\\deyan\\.julia\\packages\\DataFrames\\oQ5c7\\src\\abstractdataframe\\selection.jl:850\n  select(::Union{Function, Type}, ::GroupedDataFrame; copycols, keepkeys, ungroup, renamecols) at C:\\Users\\deyan\\.julia\\packages\\DataFrames\\oQ5c7\\src\\groupeddataframe\\splitapplycombine.jl:642\n  ...\nStacktrace:\n [1] top-level scope\n   @ REPL[15]:1\n\njulia> "}]}]}],"thread_ts":"1616837802.287900","reply_count":3,"reply_users_count":2,"latest_reply":"1616838876.288400","reply_users":["U017J1FHTSA","U8WEJ293L"],"is_locked":false,"subscribed":false},{"client_msg_id":"ed99a910-496c-4cb9-847c-7fee6c47bca7","type":"message","text":"Has anyone tried using deepnote? Their free version looks good","user":"U01GXNFKY6R","ts":"1616840664.289200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RRX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Has anyone tried using deepnote? Their free version looks good"}]}]}]},{"client_msg_id":"82c5fee4-f9c3-4971-81e2-252b05521e2d","type":"message","text":"They have support for a Julia kernel too <https://docs.deepnote.com/environment/custom-environments/running-your-own-kernel#julia-kernel>","user":"U01GXNFKY6R","ts":"1616842321.289700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6Lz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"They have support for a Julia kernel too "},{"type":"link","url":"https://docs.deepnote.com/environment/custom-environments/running-your-own-kernel#julia-kernel"}]}]}]},{"client_msg_id":"015b4958-e704-46f2-af9a-34047a6ae901","type":"message","text":"I have a Dataframe with these column types:\n```eltype.(eachcol(planets))\n\n4-element Vector{DataType}:\n String\n Quantity{Float64, ùêå, Unitful.FreeUnits{(kg,), ùêå, nothing}}\n Quantity{Int64, ùêã, Unitful.FreeUnits{(km,), ùêã, nothing}}\n Quantity{Float64, ùêì, Unitful.FreeUnits{(d,), ùêì, nothing}}```\nI want to save this to disk, and read it to another Julia program while retaining the units.\nI can save it to CSV:\n```planet,mass,diameter,orbital_period\nMercury,3.3000000000000004e24 kg,4879 km,88.0 d\nVenus,4.8700000000000005e25 kg,12104 km,224.7 d\n...```\nBut when I read it in, it‚Äôs all strings.  This is not surprising, but I‚Äôd like to fix it.\nSuggestions? Just ‚Äòremember‚Äô the types and don‚Äôt store them in CSV, or somehow parse the ‚Äú4879 km‚Äù back to unitful, which I didn‚Äôt notice in the docs for that package.","user":"U01CQTKB86N","ts":"1617013731.294200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WCvJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a Dataframe with these column types:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"eltype.(eachcol(planets))\n\n4-element Vector{DataType}:\n String\n Quantity{Float64, ùêå, Unitful.FreeUnits{(kg,), ùêå, nothing}}\n Quantity{Int64, ùêã, Unitful.FreeUnits{(km,), ùêã, nothing}}\n Quantity{Float64, ùêì, Unitful.FreeUnits{(d,), ùêì, nothing}}"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I want to save this to disk, and read it to another Julia program while retaining the units.\nI can save it to CSV:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"planet,mass,diameter,orbital_period\nMercury,3.3000000000000004e24 kg,4879 km,88.0 d\nVenus,4.8700000000000005e25 kg,12104 km,224.7 d\n..."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"But when I read it in, it‚Äôs all strings.  This is not surprising, but I‚Äôd like to fix it.\nSuggestions? Just ‚Äòremember‚Äô the types and don‚Äôt store them in CSV, or somehow parse the ‚Äú4879 km‚Äù back to unitful, which I didn‚Äôt notice in the docs for that package."}]}]}]},{"client_msg_id":"0B86897B-7DE4-4ACE-BFF4-3444F93538AC","type":"message","text":"Haven‚Äôt gotten an answer over on discourse, so thought I‚Äôd see if anyone here has any thoughts on using JSONTable to turn a json with multiple nesting levels into a dataframe (sample code in the post): <https://discourse.julialang.org/t/parsing-nested-json-into-dataframe-using-jsontable/58127|https://discourse.julialang.org/t/parsing-nested-json-into-dataframe-using-jsontable/58127>","user":"U01399SPFT5","ts":"1617018621.296800","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Parsing Nested JSON into DataFrame using JSONTable","title_link":"https://discourse.julialang.org/t/parsing-nested-json-into-dataframe-using-jsontable/58127","text":"I‚Äôm trying to parse academic publication data from Open Academic Graph, which stores the data in JSON format, but am running into an issue with parsing the below sample JSON they provide on the website because it is nested. I‚Äôm fairly new to working with JSON and could use some help. Any tips for how to parse it? using JSONTables, DataFrames, CSV, JSON3 js_string = \"{ \\\"id\\\":\\\"53e9ab9eb7602d970354a97e\\\", \\\"title\\\":\\\"Data mining: concepts and techniques\\\", \\\"authors\\\":[ { ...","fallback":"JuliaLang: Parsing Nested JSON into DataFrame using JSONTable","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1616953539,"from_url":"https://discourse.julialang.org/t/parsing-nested-json-into-dataframe-using-jsontable/58127","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/parsing-nested-json-into-dataframe-using-jsontable/58127"}],"blocks":[{"type":"rich_text","block_id":"1dT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Haven‚Äôt gotten an answer over on discourse, so thought I‚Äôd see if anyone here has any thoughts on using JSONTable to turn a json with multiple nesting levels into a dataframe (sample code in the post): "},{"type":"link","url":"https://discourse.julialang.org/t/parsing-nested-json-into-dataframe-using-jsontable/58127","text":"https://discourse.julialang.org/t/parsing-nested-json-into-dataframe-using-jsontable/58127"}]}]}]},{"client_msg_id":"fe3f5ea0-079c-4181-a27e-f7effacc0497","type":"message","text":"<@U674T0Y9Z> <@UCZ7VBGUD>, <@U679T6QF7> and anyone else; now that <https://github.com/JuliaData/Arrow.jl/pull/156> is merged/tagged, I‚Äôve had the additional idea of splitting out the `ArrowTypes` module as a stand-alone package. Taking `ArrowTypes` as a dependency would be basically ‚Äúfree‚Äù, and allow defining the necessary overloads for custom types, then Arrow.jl would also take the dependency and use it internally. Is that of interest to folks? I know I saw somewhere that they were going to add Arrow.jl as a dependency via Requires.jl, which I‚Äôd rather avoid because I like being able to go to JuliaHub and see Arrow.jl‚Äôs full list of dependents in case I want to see how everyone is using the package.","user":"U681ELA87","ts":"1617035587.302000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HB1","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U674T0Y9Z"},{"type":"text","text":" "},{"type":"user","user_id":"UCZ7VBGUD"},{"type":"text","text":", "},{"type":"user","user_id":"U679T6QF7"},{"type":"text","text":" and anyone else; now that "},{"type":"link","url":"https://github.com/JuliaData/Arrow.jl/pull/156"},{"type":"text","text":" is merged/tagged, I‚Äôve had the additional idea of splitting out the "},{"type":"text","text":"ArrowTypes","style":{"code":true}},{"type":"text","text":" module as a stand-alone package. Taking "},{"type":"text","text":"ArrowTypes","style":{"code":true}},{"type":"text","text":" as a dependency would be basically ‚Äúfree‚Äù, and allow defining the necessary overloads for custom types, then Arrow.jl would also take the dependency and use it internally. Is that of interest to folks? I know I saw somewhere that they were going to add Arrow.jl as a dependency via Requires.jl, which I‚Äôd rather avoid because I like being able to go to JuliaHub and see Arrow.jl‚Äôs full list of dependents in case I want to see how everyone is using the package."}]}]}],"reactions":[{"name":"+1","users":["UCZ7VBGUD"],"count":1}]},{"type":"message","subtype":"channel_join","ts":"1617047535.303300","user":"U0197EJTSSX","text":"<@U0197EJTSSX> has joined the channel","inviter":"U6A936746"},{"client_msg_id":"cda05851-ceef-47b0-92d1-ea575070f605","type":"message","text":"I just got burned by my own stupidity, but my god did it take a long time to figure out what I had done.  Consider the following\n```julia&gt; using DataFrames\n\njulia&gt; df = DataFrame(A=rand(5))\n5√ó1 DataFrame\n Row ‚îÇ A\n     ‚îÇ Float64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ 0.899862\n   2 ‚îÇ 0.309756\n   3 ‚îÇ 0.905428\n   4 ‚îÇ 0.986047\n   5 ‚îÇ 0.219594\n\njulia&gt; df[!, :B] = df.A;\n\njulia&gt; filter!(:A=&gt;(‚â•)(0.9), df)\nERROR: BoundsError\nStacktrace:\n [1] _deleteat!(a::Vector{Float64}, inds::Vector{Int64}, dltd::Base.Nowhere)\n   @ Base ./array.jl:1398\n [2] _deleteat!\n   @ ./array.jl:1383 [inlined]\n [3] deleteat!\n   @ ./array.jl:1377 [inlined]\n [4] (::DataFrames.var\"#184#185\"{Vector{Int64}})(col::Vector{Float64})\n   @ DataFrames ~/.julia/packages/DataFrames/zXEKU/src/dataframe/dataframe.jl:885\n [5] foreach(f::DataFrames.var\"#184#185\"{Vector{Int64}}, itr::Vector{AbstractVector{T} where T})\n   @ Base ./abstractarray.jl:2141\n [6] delete!\n   @ ~/.julia/packages/DataFrames/zXEKU/src/dataframe/dataframe.jl:885 [inlined]\n [7] _filter!_helper(df::DataFrame, f::Base.Fix2{typeof(&gt;=), Float64}, cols::Vector{Float64})\n   @ DataFrames ~/.julia/packages/DataFrames/zXEKU/src/abstractdataframe/abstractdataframe.jl:1126\n [8] filter!(::Pair{Symbol, Base.Fix2{typeof(&gt;=), Float64}}, df::DataFrame)\n   @ DataFrames ~/.julia/packages/DataFrames/zXEKU/src/abstractdataframe/abstractdataframe.jl:1109\n [9] top-level scope\n   @ REPL[4]:1```\nI had enough code that it wasn't obvious to me that I had assigned columns this way without copying.  I don't think there's anything to be done here, but man did I get myself confused","user":"U9VG1AYSG","ts":"1617049706.305900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"h2e","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I just got burned by my own stupidity, but my god did it take a long time to figure out what I had done.  Consider the following\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> using DataFrames\n\njulia> df = DataFrame(A=rand(5))\n5√ó1 DataFrame\n Row ‚îÇ A\n     ‚îÇ Float64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ 0.899862\n   2 ‚îÇ 0.309756\n   3 ‚îÇ 0.905428\n   4 ‚îÇ 0.986047\n   5 ‚îÇ 0.219594\n\njulia> df[!, :B] = df.A;\n\njulia> filter!(:A=>(‚â•)(0.9), df)\nERROR: BoundsError\nStacktrace:\n [1] _deleteat!(a::Vector{Float64}, inds::Vector{Int64}, dltd::Base.Nowhere)\n   @ Base ./array.jl:1398\n [2] _deleteat!\n   @ ./array.jl:1383 [inlined]\n [3] deleteat!\n   @ ./array.jl:1377 [inlined]\n [4] (::DataFrames.var\"#184#185\"{Vector{Int64}})(col::Vector{Float64})\n   @ DataFrames ~/.julia/packages/DataFrames/zXEKU/src/dataframe/dataframe.jl:885\n [5] foreach(f::DataFrames.var\"#184#185\"{Vector{Int64}}, itr::Vector{AbstractVector{T} where T})\n   @ Base ./abstractarray.jl:2141\n [6] delete!\n   @ ~/.julia/packages/DataFrames/zXEKU/src/dataframe/dataframe.jl:885 [inlined]\n [7] _filter!_helper(df::DataFrame, f::Base.Fix2{typeof(>=), Float64}, cols::Vector{Float64})\n   @ DataFrames ~/.julia/packages/DataFrames/zXEKU/src/abstractdataframe/abstractdataframe.jl:1126\n [8] filter!(::Pair{Symbol, Base.Fix2{typeof(>=), Float64}}, df::DataFrame)\n   @ DataFrames ~/.julia/packages/DataFrames/zXEKU/src/abstractdataframe/abstractdataframe.jl:1109\n [9] top-level scope\n   @ REPL[4]:1"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I had enough code that it wasn't obvious to me that I had assigned columns this way without copying.  I don't think there's anything to be done here, but man did I get myself confused"}]}]}],"thread_ts":"1617049706.305900","reply_count":1,"reply_users_count":1,"latest_reply":"1617050594.306000","reply_users":["U8JAMQGQY"],"is_locked":false,"subscribed":false,"reactions":[{"name":"exclamation","users":["U8JAMQGQY"],"count":1}]},{"client_msg_id":"15db4a17-9dd8-46dd-a0b7-b2edef111cb8","type":"message","text":"<@U681ELA87> regarding my question yesterday, it seems that JSONSchema.jl and JSON3.jl don't jam well","user":"U67BJLYCS","ts":"1617124727.313400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"USPu","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U681ELA87"},{"type":"text","text":" regarding my question yesterday, it seems that JSONSchema.jl and JSON3.jl don't jam well"}]}]}]},{"client_msg_id":"bace00d3-e20c-4b78-ab68-7a45b2ed0fd2","type":"message","text":"```‚îå Error: Jobspec validation failed\n‚îÇ   result =\n‚îÇ    Validation failed:\n‚îÇ    path:         [resources]\n‚îÇ    instance:     JSON3.Object[{\n‚îÇ        \"type\": \"node\",\n‚îÇ       \"count\": 1,\n‚îÇ       \"label\": \"default\",\n‚îÇ        \"with\": [\n‚îÇ                  {\n‚îÇ                      \"type\": \"slot\",\n‚îÇ                     \"label\": \"mylabel\",\n‚îÇ                     \"count\": 4,\n‚îÇ                      \"with\": [\n‚îÇ                                {\n‚îÇ                                    \"type\": \"core\",\n‚îÇ                                   \"count\": 1\n‚îÇ                                }\n‚îÇ                              ]\n‚îÇ                  }\n‚îÇ                ]\n‚îÇ    }]\n‚îÇ    schema key:   type\n‚îÇ    schema value: array\n‚îÇ\n‚îî @ Main ~/src/FluxRM/playground.jl:75```","user":"U67BJLYCS","ts":"1617124750.313600","team":"T68168MUP","edited":{"user":"U67BJLYCS","ts":"1617124752.000000"},"blocks":[{"type":"rich_text","block_id":"EnD","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"‚îå Error: Jobspec validation failed\n‚îÇ   result =\n‚îÇ    Validation failed:\n‚îÇ    path:         [resources]\n‚îÇ    instance:     JSON3.Object[{\n‚îÇ        \"type\": \"node\",\n‚îÇ       \"count\": 1,\n‚îÇ       \"label\": \"default\",\n‚îÇ        \"with\": [\n‚îÇ                  {\n‚îÇ                      \"type\": \"slot\",\n‚îÇ                     \"label\": \"mylabel\",\n‚îÇ                     \"count\": 4,\n‚îÇ                      \"with\": [\n‚îÇ                                {\n‚îÇ                                    \"type\": \"core\",\n‚îÇ                                   \"count\": 1\n‚îÇ                                }\n‚îÇ                              ]\n‚îÇ                  }\n‚îÇ                ]\n‚îÇ    }]\n‚îÇ    schema key:   type\n‚îÇ    schema value: array\n‚îÇ\n‚îî @ Main ~/src/FluxRM/playground.jl:75"}]}]}]},{"client_msg_id":"f22cd930-b617-4373-83eb-0818a62d2fc7","type":"message","text":"if I read that right it expected a `array` but didn't interpret the `JSON3.Object` as such","user":"U67BJLYCS","ts":"1617124785.314400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Al1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if I read that right it expected a "},{"type":"text","text":"array","style":{"code":true}},{"type":"text","text":" but didn't interpret the "},{"type":"text","text":"JSON3.Object","style":{"code":true}},{"type":"text","text":" as such"}]}]}]},{"client_msg_id":"ccf563f1-53d8-4d32-8baf-82dcf1f237e6","type":"message","text":"and <https://github.com/fredo-dedup/JSONSchema.jl/blob/master/src/validation.jl> has dispatch on `Vector`","user":"U67BJLYCS","ts":"1617124856.314700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=r+x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and "},{"type":"link","url":"https://github.com/fredo-dedup/JSONSchema.jl/blob/master/src/validation.jl"},{"type":"text","text":" has dispatch on "},{"type":"text","text":"Vector","style":{"code":true}}]}]}]},{"client_msg_id":"11c3bad7-2585-4c20-8cef-2403621d1c15","type":"message","text":"Yeah, it seems that JSONSchema.jl is expecting to work with JSON.jl. Not sure how much it would take to allow JSON3.jl to work too.","user":"U681ELA87","ts":"1617125732.315300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qUAf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, it seems that JSONSchema.jl is expecting to work with JSON.jl. Not sure how much it would take to allow JSON3.jl to work too."}]}]}]},{"client_msg_id":"2ba1fb7f-d27f-4097-b1dd-c434dd663e86","type":"message","text":"Thanks! I think I will punt on autogenerating my types from the schema then.","user":"U67BJLYCS","ts":"1617136821.316400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7=I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks! I think I will punt on autogenerating my types from the schema then."}]}]}]},{"client_msg_id":"b1a845c3-bcb1-448b-a973-b1be2dc8e2ce","type":"message","text":"If I want to express optionality, is a `struct` type with `a::Union{Nothing, String}` the right choice","user":"U67BJLYCS","ts":"1617136857.317200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7Fg5U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If I want to express optionality, is a "},{"type":"text","text":"struct","style":{"code":true}},{"type":"text","text":" type with "},{"type":"text","text":"a::Union{Nothing, String}","style":{"code":true}},{"type":"text","text":" the right choice"}]}]}]},{"client_msg_id":"2ac362f5-8914-4d58-adc1-bb89b55a6ca1","type":"message","text":"or should I use `mutable struct`?","user":"U67BJLYCS","ts":"1617136866.317500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LxDA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"or should I use "},{"type":"text","text":"mutable struct","style":{"code":true}},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"f18684e8-973b-4aa6-9536-9681f854d60f","type":"message","text":"```struct System\n    duration::Real\n    cwd::Union{Nothing, String}\n    environment::Union{Nothing, Dict}\nend\nStructTypes.StructType(::Type{System}) = StructTypes.Struct()\n\nlet system = \"\"\"\n    {    \n        \"duration\": 3600\n    }\n    \"\"\"\n\n    sys = JSON3.read(system, System)\n    @test sys.duration == 3600\nend```","user":"U67BJLYCS","ts":"1617136887.317700","team":"T68168MUP","edited":{"user":"U67BJLYCS","ts":"1617137492.000000"},"blocks":[{"type":"rich_text","block_id":"LN+Ug","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"struct System\n    duration::Real\n    cwd::Union{Nothing, String}\n    environment::Union{Nothing, Dict}\nend\nStructTypes.StructType(::Type{System}) = StructTypes.Struct()\n\nlet system = \"\"\"\n    {    \n        \"duration\": 3600\n    }\n    \"\"\"\n\n    sys = JSON3.read(system, System)\n    @test sys.duration == 3600\nend"}]}]}]},{"client_msg_id":"50007881-b820-4439-b938-f1c094fad5f7","type":"message","text":"fails with:","user":"U67BJLYCS","ts":"1617136967.318300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EIr0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"fails with:"}]}]}]},{"client_msg_id":"4e368dc0-a389-4e2f-8fb2-b137b4f0e40f","type":"message","text":"```ERROR: LoadError: UndefRefError: access to undefined reference\nStacktrace:\n [1] getindex at ./array.jl:809 [inlined]\n [2] construct at /home/vchuravy/.julia/packages/StructTypes/MF8bN/src/StructTypes.jl:860 [inlined]\n [3] #read#42 at /home/vchuravy/.julia/packages/JSON3/IvnMR/src/structs.jl:572 [inlined]\n [4] read at /home/vchuravy/.julia/packages/JSON3/IvnMR/src/structs.jl:494 [inlined]\n [5] read(::String, ::Type{FluxRM.System}; kw::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/vchuravy/.julia/packages/JSON3/IvnMR/src/structs.jl:34\n [6] read(::String, ::Type{FluxRM.System}) at /home/vchuravy/.julia/packages/JSON3/IvnMR/src/structs.jl:33```","user":"U67BJLYCS","ts":"1617136970.318500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"k/bq","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ERROR: LoadError: UndefRefError: access to undefined reference\nStacktrace:\n [1] getindex at ./array.jl:809 [inlined]\n [2] construct at /home/vchuravy/.julia/packages/StructTypes/MF8bN/src/StructTypes.jl:860 [inlined]\n [3] #read#42 at /home/vchuravy/.julia/packages/JSON3/IvnMR/src/structs.jl:572 [inlined]\n [4] read at /home/vchuravy/.julia/packages/JSON3/IvnMR/src/structs.jl:494 [inlined]\n [5] read(::String, ::Type{FluxRM.System}; kw::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/vchuravy/.julia/packages/JSON3/IvnMR/src/structs.jl:34\n [6] read(::String, ::Type{FluxRM.System}) at /home/vchuravy/.julia/packages/JSON3/IvnMR/src/structs.jl:33"}]}]}],"thread_ts":"1617136970.318500","reply_count":1,"reply_users_count":1,"latest_reply":"1617138723.322700","reply_users":["U681ELA87"],"is_locked":false,"subscribed":false},{"client_msg_id":"08c5c0f8-15a3-4ea7-96e7-cfca6f25f0fd","type":"message","text":"```mutable struct System\n    duration::Real\n    cwd::String\n    environment::Dict\n    System() = new()\nend\nStructTypes.StructType(::Type{System}) = StructTypes.Mutable()```","user":"U67BJLYCS","ts":"1617137108.318800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ev6","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"mutable struct System\n    duration::Real\n    cwd::String\n    environment::Dict\n    System() = new()\nend\nStructTypes.StructType(::Type{System}) = StructTypes.Mutable()"}]}]}]},{"client_msg_id":"399eb0ee-18c8-4745-8639-bf2aa379ff05","type":"message","text":"works, but I lose the property that `duration` is required","user":"U67BJLYCS","ts":"1617137122.319200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Rb5R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"works, but I lose the property that "},{"type":"text","text":"duration","style":{"code":true}},{"type":"text","text":" is required"}]}]}]},{"client_msg_id":"18a9c99c-7969-4b3f-be4a-cd56b670cac9","type":"message","text":"and I can't tell Julia that, since that would require `System(duration) = new(duration)`","user":"U67BJLYCS","ts":"1617137149.319800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XcRvm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and I can't tell Julia that, since that would require "},{"type":"text","text":"System(duration) = new(duration)","style":{"code":true}}]}]}]},{"client_msg_id":"549d632f-464a-4b80-9c28-7ce0e76722cd","type":"message","text":"which changes the layout internally to assume that `duration` can't be undef","user":"U67BJLYCS","ts":"1617137167.320200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"alaR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"which changes the layout internally to assume that "},{"type":"text","text":"duration","style":{"code":true}},{"type":"text","text":" can't be undef"}]}]}],"thread_ts":"1617137167.320200","reply_count":1,"reply_users_count":1,"latest_reply":"1617138590.322100","reply_users":["U681ELA87"],"is_locked":false,"subscribed":false},{"client_msg_id":"f2816c9c-ea5b-46b9-8613-9cb0f3efbf49","type":"message","text":"Is there a way to validate that a CSV is properly readable without actually materializing the result as some kind of Julia object?","user":"U680THK2S","ts":"1617137574.321000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"acnx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a way to validate that a CSV is properly readable without actually materializing the result as some kind of Julia object?"}]}]}]},{"client_msg_id":"2e3088bc-3624-4b12-b956-b6f27f3afb84","type":"message","text":"While I can just `CSV.File` it, it seems potentially computationally wasteful","user":"U680THK2S","ts":"1617137620.321600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kQr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"While I can just "},{"type":"text","text":"CSV.File","style":{"code":true}},{"type":"text","text":" it, it seems potentially computationally wasteful"}]}]}]},{"client_msg_id":"5ecd6216-70ab-4d47-a585-9d6a06eff575","type":"message","text":"depends on what you mean by \"properly readable\"","user":"UH24GRBLL","ts":"1617138302.321900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jOlqW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"depends on what you mean by \"properly readable\""}]}]}]},{"client_msg_id":"46d82120-b7e7-4317-802c-143ef2c91198","type":"message","text":"Basically, \"will this error if I call `CSV.File` on it later\"","user":"U680THK2S","ts":"1617138610.322600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"h0rb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Basically, \"will this error if I call "},{"type":"text","text":"CSV.File","style":{"code":true}},{"type":"text","text":" on it later\""}]}]}]},{"client_msg_id":"e9f4e5e7-60fc-4df9-afd7-bc9efe49eac3","type":"message","text":"Not currently. The closest would be to iterate over the file using `CSV.Rows(file; resusebuffer=true)`, which is pretty efficient and doesn‚Äôt involve allocating more than just hte one current row buffer.","user":"U681ELA87","ts":"1617138793.323700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GgV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not currently. The closest would be to iterate over the file using "},{"type":"text","text":"CSV.Rows(file; resusebuffer=true)","style":{"code":true}},{"type":"text","text":", which is pretty efficient and doesn‚Äôt involve allocating more than just hte one current row buffer."}]}]}]},{"client_msg_id":"569e3ae4-8017-4157-a830-ae6a4fd22fd5","type":"message","text":"I migrated from Stata to R/Python/Julia and there is a bit of natural data management syntax which I have not been able to find in these languages. That is the end of line `if` within a DataFrame. For example lets say you have variables (columns) `:X` and `:Y`  and you want to create a new column `:Z` but only if `:X` if greater than `:Y` the rest will get `missing` values. In Stata I could write `gen Z = X + Y if X &gt; Y`. Is there something equivalent I could do in Julia. Say `@where!(df, :X &gt; :Y, Z = :X + :Y)` ?\nThis would leave the DataFrame unchanged except in creating the new column `Z`.\nIn Stata such a rule would typically be followed by a rule on how to manage other values such as ``replace Z = X - Y if X &lt; Y``","user":"ULNHYTCJC","ts":"1617168626.332500","team":"T68168MUP","edited":{"user":"ULNHYTCJC","ts":"1617168849.000000"},"blocks":[{"type":"rich_text","block_id":"dcTsM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I migrated from Stata to R/Python/Julia and there is a bit of natural data management syntax which I have not been able to find in these languages. That is the end of line "},{"type":"text","text":"if","style":{"code":true}},{"type":"text","text":" within a DataFrame. For example lets say you have variables (columns) "},{"type":"text","text":":X","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":":Y","style":{"code":true}},{"type":"text","text":"  and you want to create a new column "},{"type":"text","text":":Z","style":{"code":true}},{"type":"text","text":" but only if "},{"type":"text","text":":X","style":{"code":true}},{"type":"text","text":" if greater than "},{"type":"text","text":":Y","style":{"code":true}},{"type":"text","text":" the rest will get "},{"type":"text","text":"missing","style":{"code":true}},{"type":"text","text":" values. In Stata I could write "},{"type":"text","text":"gen Z = X + Y if X > Y","style":{"code":true}},{"type":"text","text":". Is there something equivalent I could do in Julia. Say "},{"type":"text","text":"@where!(df, :X > :Y, Z = :X + :Y)","style":{"code":true}},{"type":"text","text":" ?\nThis would leave the DataFrame unchanged except in creating the new column "},{"type":"text","text":"Z","style":{"code":true}},{"type":"text","text":".\nIn Stata such a rule would typically be followed by a rule on how to manage other values such as `"},{"type":"text","text":"replace Z = X - Y if X < Y`","style":{"code":true}}]}]}],"thread_ts":"1617168626.332500","reply_count":2,"reply_users_count":2,"latest_reply":"1617171602.333000","reply_users":["ULNHYTCJC","US8V7JSKB"],"is_locked":false,"subscribed":false},{"type":"message","text":"","user":"U82LX4ACB","ts":"1617221459.339900","team":"T68168MUP","attachments":[{"fallback":"[March 31st, 2021 4:10 PM] naoyabpr: Hadley is a speaker at our series today‚Ä¶ Really nice presentation on decoupling backends and the dplyr case study.","ts":"1617221424.117200","author_id":"U82LX4ACB","author_subname":"Jos√© Bayo√°n Santiago Calder√≥n","channel_id":"C6821M4KE","channel_name":"statistics","is_msg_unfurl":true,"text":"Hadley is a speaker at our series today‚Ä¶ Really nice presentation on decoupling backends and the dplyr case study.","author_name":"Jos√© Bayo√°n Santiago Calder√≥n","author_link":"https://julialang.slack.com/team/U82LX4ACB","author_icon":"https://secure.gravatar.com/avatar/a8070ca24f919e30e60dce8a763c8177.jpg?s=48&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0025-48.png","mrkdwn_in":["text"],"color":"D0D0D0","from_url":"https://julialang.slack.com/archives/C6821M4KE/p1617221424117200","is_share":true,"footer":"Posted in #statistics"}]},{"client_msg_id":"61403db5-f9ff-45ce-a0a1-af4be07f1c7d","type":"message","text":"I'm trying to serialize a table with a column of `AbstractPath`s (e.g. `S3Path` or `PosixPath`) to an arrow file, and I'm seeing errors like this:\n\n```ArgumentError: type does not have a definite number of fields\n\nStacktrace:\n  [1] fieldcount\n    @ ./reflection.jl:729 [inlined]\n  [2] arrowvector(::Arrow.ArrowTypes.StructType, x::Arrow.ToStruct{Tuple{Vararg{String, N} where N}, 1, Vector{PosixPath}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Dict{String, String}; kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{5, Symbol}, NamedTuple{(:dictencode, :compression, :largelists, :denseunions, :dictencodenested), Tuple{Bool, Nothing, Bool, Bool, Bool}}})\n    @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/struct.jl:89\n  [3] arrowvector(::Type{Tuple{Vararg{String, N} where N}}, x::Arrow.ToStruct{Tuple{Vararg{String, N} where N}, 1, Vector{PosixPath}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{5, Symbol}, NamedTuple{(:dictencode, :compression, :largelists, :denseunions, :dictencodenested), Tuple{Bool, Nothing, Bool, Bool, Bool}}})\n    @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:85\n  [4] arrowvector(x::Arrow.ToStruct{Tuple{Vararg{String, N} where N}, 1, Vector{PosixPath}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; dictencoding::Bool, dictencode::Bool, kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{4, Symbol}, NamedTuple{(:compression, :largelists, :denseunions, :dictencodenested), Tuple{Nothing, Bool, Bool, Bool}}})\n    @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:58```\nThis is on 1.6, Arrow 1.2.4, FilePathBase 0.9.10...","user":"U66M57AN4","ts":"1617288119.353100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"k+b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm trying to serialize a table with a column of `AbstractPath`s (e.g. "},{"type":"text","text":"S3Path","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"PosixPath","style":{"code":true}},{"type":"text","text":") to an arrow file, and I'm seeing errors like this:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ArgumentError: type does not have a definite number of fields\n\nStacktrace:\n  [1] fieldcount\n    @ ./reflection.jl:729 [inlined]\n  [2] arrowvector(::Arrow.ArrowTypes.StructType, x::Arrow.ToStruct{Tuple{Vararg{String, N} where N}, 1, Vector{PosixPath}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Dict{String, String}; kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{5, Symbol}, NamedTuple{(:dictencode, :compression, :largelists, :denseunions, :dictencodenested), Tuple{Bool, Nothing, Bool, Bool, Bool}}})\n    @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/struct.jl:89\n  [3] arrowvector(::Type{Tuple{Vararg{String, N} where N}}, x::Arrow.ToStruct{Tuple{Vararg{String, N} where N}, 1, Vector{PosixPath}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{5, Symbol}, NamedTuple{(:dictencode, :compression, :largelists, :denseunions, :dictencodenested), Tuple{Bool, Nothing, Bool, Bool, Bool}}})\n    @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:85\n  [4] arrowvector(x::Arrow.ToStruct{Tuple{Vararg{String, N} where N}, 1, Vector{PosixPath}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; dictencoding::Bool, dictencode::Bool, kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{4, Symbol}, NamedTuple{(:compression, :largelists, :denseunions, :dictencodenested), Tuple{Nothing, Bool, Bool, Bool}}})\n    @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:58"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nThis is on 1.6, Arrow 1.2.4, FilePathBase 0.9.10..."}]}]}]},{"client_msg_id":"9b7f0345-37e5-4d75-bdd5-1199903309b7","type":"message","text":"I gues maybe that's because the PosixPath type is like this:\n```PosixPath\n  segments: Tuple{String, String}\n    1: String \"tmp\"\n    2: String \"jl_o5s7rM\"\n  root: String \"/\"```","user":"U66M57AN4","ts":"1617288172.354200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"i4h","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I gues maybe that's because the PosixPath type is like this:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"PosixPath\n  segments: Tuple{String, String}\n    1: String \"tmp\"\n    2: String \"jl_o5s7rM\"\n  root: String \"/\""}]}]}]},{"client_msg_id":"13bb825f-4ca0-4948-aac3-a0bda05394b1","type":"message","text":"I vaguely recall that there's some functionality for using a custom serializer for Arrow but I don't recall how...","user":"U66M57AN4","ts":"1617288249.355800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5r1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I vaguely recall that there's some functionality for using a custom serializer for Arrow but I don't recall how..."}]}]}]},{"client_msg_id":"919b46ec-224a-4290-adce-873c73f42ad9","type":"message","text":"The new 1.3 release introduced a more powerful/flexible/well-documented custom serialization functionality","user":"U681ELA87","ts":"1617288294.356900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dz6t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The new 1.3 release introduced a more powerful/flexible/well-documented custom serialization functionality"}]}]}]},{"client_msg_id":"9e705cd3-5740-40ee-97b8-a38792aec9dc","type":"message","text":"Well shoot, it looks like the docs didn't get updated quite right for \"stable\"; but in the \"dev\" docs, there's a new section on custom types: <https://arrow.juliadata.org/dev/manual/#Custom-types>","user":"U681ELA87","ts":"1617288369.358500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QDWw2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Well shoot, it looks like the docs didn't get updated quite right for \"stable\"; but in the \"dev\" docs, there's a new section on custom types: "},{"type":"link","url":"https://arrow.juliadata.org/dev/manual/#Custom-types"}]}]}]},{"client_msg_id":"200b8ab3-bae7-4f04-a280-eb4edd2e9c49","type":"message","text":"One thing to note, however, is that `Arrow.write` will now throw an error if a column doesn't have a concrete element type. It's a strict requirement of the format.","user":"U681ELA87","ts":"1617288412.359600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SCZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One thing to note, however, is that "},{"type":"text","text":"Arrow.write","style":{"code":true}},{"type":"text","text":" will now throw an error if a column doesn't have a concrete element type. It's a strict requirement of the format."}]}]}]},{"client_msg_id":"a92ba145-d94a-4a36-9bc9-b0813b2286ad","type":"message","text":"It will try to coerce a column type to a small union if possible and serialize accordingly. Otherwise, it will throw an error","user":"U681ELA87","ts":"1617288430.360000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aT/a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It will try to coerce a column type to a small union if possible and serialize accordingly. Otherwise, it will throw an error"}]}]}]},{"client_msg_id":"cef0f989-4022-49aa-84b3-d84f41afdbe1","type":"message","text":"Posted a somewhat more conceptual question to discourse. Anyone mind taking a look here: <https://discourse.julialang.org/t/best-practices-for-harmonizing-datasets/58364> ? Thank you!","user":"US64J0NPQ","ts":"1617288871.360700","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Best Practices for Harmonizing Datasets","title_link":"https://discourse.julialang.org/t/best-practices-for-harmonizing-datasets/58364","text":"Hi everyone! I have a question about data manipulation that is more on the conceptual side: Say you have multiple datasets that you are trying to harmonize. Each dataset requires their own amount of processing to get it into a form for merging together. How should I best structure my project for harmonizing? Right now I have been using DrWatson.jl to organize everything (i.e. data, scripts, packages, constants) which works really well at a high level. However, right now my processing pipeline...","fallback":"JuliaLang: Best Practices for Harmonizing Datasets","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1617288727,"from_url":"https://discourse.julialang.org/t/best-practices-for-harmonizing-datasets/58364","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/best-practices-for-harmonizing-datasets/58364"}],"blocks":[{"type":"rich_text","block_id":"+FvO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Posted a somewhat more conceptual question to discourse. Anyone mind taking a look here: "},{"type":"link","url":"https://discourse.julialang.org/t/best-practices-for-harmonizing-datasets/58364"},{"type":"text","text":" ? Thank you!"}]}]}]},{"client_msg_id":"9a1b5598-9acb-4d97-aa38-0935a431c217","type":"message","text":"What is the best way to combine two data frames? I was examining joins from the DataFrames.jl docs and, based on my data which is two datasets having the same columns but uniquely valued rows, I was thinking about applying an `innerjoin` or `crossjoin`. But, in this case, how is the efficiency different from say `vcat(df_1, df_2)`?","user":"US64J0NPQ","ts":"1617297798.365200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ru7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is the best way to combine two data frames? I was examining joins from the DataFrames.jl docs and, based on my data which is two datasets having the same columns but uniquely valued rows, I was thinking about applying an "},{"type":"text","text":"innerjoin","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"crossjoin","style":{"code":true}},{"type":"text","text":". But, in this case, how is the efficiency different from say "},{"type":"text","text":"vcat(df_1, df_2)","style":{"code":true}},{"type":"text","text":"?"}]}]}],"thread_ts":"1617297798.365200","reply_count":4,"reply_users_count":2,"latest_reply":"1617299249.366200","reply_users":["U67431ELR","US64J0NPQ"],"is_locked":false,"subscribed":false},{"client_msg_id":"ced0cae2-0616-4d2c-b4fa-02cda7a48b63","type":"message","text":"Thanks!","user":"US64J0NPQ","ts":"1617297804.365400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bkTjo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks!"}]}]}]},{"client_msg_id":"86ae3fc9-a89a-4168-aad5-a21eae06fae7","type":"message","text":"We are very close to DataFrames.jl 1.0 release. This post summarizes the state of the the last big hurdle we have to pass before making it: <https://bkamins.github.io/julialang/2021/04/02/despecialization.html>","user":"U8JAMQGQY","ts":"1617382571.372100","team":"T68168MUP","attachments":[{"service_name":"Blog by Bogumi≈Ç Kami≈Ñski","title":"Poor man‚Äôs guide to despecialization","title_link":"https://bkamins.github.io/julialang/2021/04/02/despecialization.html","text":"Introduction","fallback":"Blog by Bogumi≈Ç Kami≈Ñski: Poor man‚Äôs guide to despecialization","ts":1617355069,"from_url":"https://bkamins.github.io/julialang/2021/04/02/despecialization.html","service_icon":"https://bkamins.github.io/favicon.ico","id":1,"original_url":"https://bkamins.github.io/julialang/2021/04/02/despecialization.html"}],"blocks":[{"type":"rich_text","block_id":"1Y+b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We are very close to DataFrames.jl 1.0 release. This post summarizes the state of the the last big hurdle we have to pass before making it: "},{"type":"link","url":"https://bkamins.github.io/julialang/2021/04/02/despecialization.html"}]}]}],"reactions":[{"name":"+1","users":["UBF9YRB6H","US8V7JSKB"],"count":2}]},{"client_msg_id":"452a5f52-016b-4cab-97ae-1696d69b95ad","type":"message","text":"I have a CSV where missing fields have spaces and some of the fields are padded:\n```sec, nsec, nread, count, capture, direction, T2, tau_x, V, per_tau_l, per_T2_l, per_tau_r, per_T2_r\n1617332387, 424246145, 16,        37839302,        37839298,  LEFT,        36135831,        36654715, 14.76475357, 18446744070676686135, 5263255935999163155,                ,\n1617332390, 816882774, 16,        71765556,        71765552, , , , , , , ,\n1617332390, 965988748, 16,        73256731,        73256726, RIGHT,        70561951,        71577245, 14.75320841,                ,                , 18446744069486161565, 5263251812864987215```\nI would like to read this into a DataFrame `CSV.read(\"file.csv\", DataFrame)` but this results in most columns being parsed as `String` rather than `Union{Missing, Int64}`. Specifying the type with `types=Dict(7=&gt;Union{Missing, Int64})` results in a warning for each line with no number. Is there a way to tell CSV to ignore spaces between delimiters?","user":"U011D7LMFJP","ts":"1617382870.372600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wciu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a CSV where missing fields have spaces and some of the fields are padded:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"sec, nsec, nread, count, capture, direction, T2, tau_x, V, per_tau_l, per_T2_l, per_tau_r, per_T2_r\n1617332387, 424246145, 16,        37839302,        37839298,  LEFT,        36135831,        36654715, 14.76475357, 18446744070676686135, 5263255935999163155,                ,\n1617332390, 816882774, 16,        71765556,        71765552, , , , , , , ,\n1617332390, 965988748, 16,        73256731,        73256726, RIGHT,        70561951,        71577245, 14.75320841,                ,                , 18446744069486161565, 5263251812864987215"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I would like to read this into a DataFrame "},{"type":"text","text":"CSV.read(\"file.csv\", DataFrame)","style":{"code":true}},{"type":"text","text":" but this results in most columns being parsed as "},{"type":"text","text":"String","style":{"code":true}},{"type":"text","text":" rather than "},{"type":"text","text":"Union{Missing, Int64}","style":{"code":true}},{"type":"text","text":". Specifying the type with "},{"type":"text","text":"types=Dict(7=>Union{Missing, Int64})","style":{"code":true}},{"type":"text","text":" results in a warning for each line with no number. Is there a way to tell CSV to ignore spaces between delimiters?"}]}]}]},{"client_msg_id":"df72b3f6-dc90-4b20-85d3-5f2c8a586f4d","type":"message","text":"Alright, here‚Äôs a little of what‚Äôs going on:\n‚Ä¢ By default, whitespace _is_ ignored before/after parsing numbers\n‚Ä¢ Also by default, an ‚Äúempty‚Äù field is considered `missing`, so for a comma-delimited file, this would be `,,`\n‚Ä¢ So the parser is getting confused here because it wants to try and parse a number, so whitespace is ignored, but then there‚Äôs no number to parse, _BUT_, it‚Äôs also not an empty field, so it gets worried that this should instead be a String column in case we‚Äôre trying to coerce a column type just based on an initial number being able to be parsed\nBy providing the type in your example, you actually get the desired behavior because it coerces the column to the provided type, and any cells that can‚Äôt be parsed as such are replaced with `missing`. By default, we also show the warning when this happens, as you‚Äôve pointed out. You can turn off these warnings by passing `silencewarnings=true`.\n\nWe could perhaps make the parsers a tad smarter however for this case; the logic would be that empty _or whitespace only_ fields would be considered `missing` by default. I don‚Äôt think that‚Äôs too controversial.","user":"U681ELA87","ts":"1617383868.377400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gaU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Alright, here‚Äôs a little of what‚Äôs going on:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"By default, whitespace "},{"type":"text","text":"is","style":{"italic":true}},{"type":"text","text":" ignored before/after parsing numbers"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Also by default, an ‚Äúempty‚Äù field is considered "},{"type":"text","text":"missing","style":{"code":true}},{"type":"text","text":", so for a comma-delimited file, this would be "},{"type":"text","text":",,","style":{"code":true}}]},{"type":"rich_text_section","elements":[{"type":"text","text":"So the parser is getting confused here because it wants to try and parse a number, so whitespace is ignored, but then there‚Äôs no number to parse, "},{"type":"text","text":"BUT","style":{"italic":true}},{"type":"text","text":", it‚Äôs also not an empty field, so it gets worried that this should instead be a String column in case we‚Äôre trying to coerce a column type just based on an initial number being able to be parsed"}]}],"style":"bullet","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"By providing the type in your example, you actually get the desired behavior because it coerces the column to the provided type, and any cells that can‚Äôt be parsed as such are replaced with "},{"type":"text","text":"missing","style":{"code":true}},{"type":"text","text":". By default, we also show the warning when this happens, as you‚Äôve pointed out. You can turn off these warnings by passing "},{"type":"text","text":"silencewarnings=true","style":{"code":true}},{"type":"text","text":".\n\nWe could perhaps make the parsers a tad smarter however for this case; the logic would be that empty "},{"type":"text","text":"or whitespace only","style":{"italic":true}},{"type":"text","text":" fields would be considered "},{"type":"text","text":"missing","style":{"code":true}},{"type":"text","text":" by default. I don‚Äôt think that‚Äôs too controversial."}]}]}]},{"client_msg_id":"31d6f679-2323-4bca-883a-4154c0dba0c2","type":"message","text":"Ah, I see. Perhaps rather than making it default and breaking some other oddball file, a keyword argument like `stripspaces=true` could be created to mean \"before deciding if this field is empty, remove all the spaces\". Disabling the warnings works fine for now, thank you!","user":"U011D7LMFJP","ts":"1617384113.379500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hrRe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah, I see. Perhaps rather than making it default and breaking some other oddball file, a keyword argument like "},{"type":"text","text":"stripspaces=true","style":{"code":true}},{"type":"text","text":" could be created to mean \"before deciding if this field is empty, remove all the spaces\". Disabling the warnings works fine for now, thank you!"}]}]}]},{"client_msg_id":"65cb92a6-fb8e-4175-ba93-87f353e86a54","type":"message","text":"One other thing I've done, although I'm not sure how advisable it is, it's to pass something like `[\" \"^i for i in 1:10]` as the missing string kwarg","user":"U7JQGPGCQ","ts":"1617392803.381300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AWpF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One other thing I've done, although I'm not sure how advisable it is, it's to pass something like "},{"type":"text","text":"[\" \"^i for i in 1:10]","style":{"code":true}},{"type":"text","text":" as the missing string kwarg"}]}]}]},{"client_msg_id":"2789844f-83aa-4516-8d8e-030650699a42","type":"message","text":"is there a way to apply a `transform` to all columns that don't match some pattern?  `Not([:x, :y]) .=&gt; my_f .=&gt; Not([:x, :y])` doesn't work...","user":"U66M57AN4","ts":"1617402142.382200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Wlu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a way to apply a "},{"type":"text","text":"transform","style":{"code":true}},{"type":"text","text":" to all columns that don't match some pattern?  "},{"type":"text","text":"Not([:x, :y]) .=> my_f .=> Not([:x, :y])","style":{"code":true}},{"type":"text","text":" doesn't work..."}]}]}],"thread_ts":"1617402142.382200","reply_count":1,"reply_users_count":1,"latest_reply":"1617402603.383300","reply_users":["UBF9YRB6H"],"is_locked":false,"subscribed":false},{"client_msg_id":"e27b4a7b-40f3-45fb-8467-2199d2c0005b","type":"message","text":"orrrr is there a way to use a value other than `missing` in `unstack` for combinations that don't occur in the data?","user":"U66M57AN4","ts":"1617402276.382700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"56i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"orrrr is there a way to use a value other than "},{"type":"text","text":"missing","style":{"code":true}},{"type":"text","text":" in "},{"type":"text","text":"unstack","style":{"code":true}},{"type":"text","text":" for combinations that don't occur in the data?"}]}]}],"thread_ts":"1617402276.382700","reply_count":3,"reply_users_count":2,"latest_reply":"1617402614.383600","reply_users":["U8JAMQGQY","U66M57AN4"],"is_locked":false,"subscribed":false},{"client_msg_id":"843fbc8e-e1b2-4d2d-a76a-6ac54dfc45c1","type":"message","text":"what's a good slack channel to ask about `RDKafka`? I'm interested in handling errors","user":"U8WEJ293L","ts":"1617443867.385100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AJG6z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what's a good slack channel to ask about "},{"type":"text","text":"RDKafka","style":{"code":true}},{"type":"text","text":"? I'm interested in handling errors"}]}]}]},{"client_msg_id":"8d7cb74f-29a8-49ff-9846-fc5dd247bd61","type":"message","text":"I think I have a DataFrames feature request, but I want to make sure I'm not missing something obvious before creating an issue.  The use case is creating a DataFrame from `Vector{AbstractDict}`, where the `AbstractDict` elements have mostly overlapping keys, but not exactly the same set.  Here is an example:\n```julia&gt; dicts=[Dict(:a=&gt;1, :b=&gt;2), Dict(:b=&gt;3, :c=&gt;4)]\n2-element Vector{Dict{Symbol, Int64}}:\n Dict(:a =&gt; 1, :b =&gt; 2)\n Dict(:b =&gt; 3, :c =&gt; 4)\n\njulia&gt; DataFrame(dicts)\nERROR: KeyError: key :a not found```\nIt would be great if the `DataFrame` constructor supported the `cols` keyword so the caller could get the same `cols=:union` behavior as `push!`.  My work around so far is:\n```julia&gt; reduce((df,d)-&gt;push!(df,d,cols=:union), dicts, init=DataFrame())\n2√ó3 DataFrame\n Row ‚îÇ a        b      c       \n     ‚îÇ Int64?   Int64  Int64?  \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ       1      2  missing \n   2 ‚îÇ missing      3        4```\nIs there a better way to do this already or is this a feature request?","user":"U01FKQQ7J0J","ts":"1617481494.392600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jWRiH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think I have a DataFrames feature request, but I want to make sure I'm not missing something obvious before creating an issue.  The use case is creating a DataFrame from "},{"type":"text","text":"Vector{AbstractDict}","style":{"code":true}},{"type":"text","text":", where the "},{"type":"text","text":"AbstractDict","style":{"code":true}},{"type":"text","text":" elements have mostly overlapping keys, but not exactly the same set.  Here is an example:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> dicts=[Dict(:a=>1, :b=>2), Dict(:b=>3, :c=>4)]\n2-element Vector{Dict{Symbol, Int64}}:\n Dict(:a => 1, :b => 2)\n Dict(:b => 3, :c => 4)\n\njulia> DataFrame(dicts)\nERROR: KeyError: key :a not found"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"It would be great if the "},{"type":"text","text":"DataFrame","style":{"code":true}},{"type":"text","text":" constructor supported the "},{"type":"text","text":"cols","style":{"code":true}},{"type":"text","text":" keyword so the caller could get the same "},{"type":"text","text":"cols=:union","style":{"code":true}},{"type":"text","text":" behavior as "},{"type":"text","text":"push!","style":{"code":true}},{"type":"text","text":".  My work around so far is:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> reduce((df,d)->push!(df,d,cols=:union), dicts, init=DataFrame())\n2√ó3 DataFrame\n Row ‚îÇ a        b      c       \n     ‚îÇ Int64?   Int64  Int64?  \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ       1      2  missing \n   2 ‚îÇ missing      3        4"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a better way to do this already or is this a feature request?"}]}]}],"thread_ts":"1617481494.392600","reply_count":17,"reply_users_count":4,"latest_reply":"1617484480.396500","reply_users":["U8JAMQGQY","UBF9YRB6H","U01FKQQ7J0J","U681ELA87"],"is_locked":false,"subscribed":false},{"client_msg_id":"8db215d8-8ed5-4fa0-8b88-99d7b4ad2bb2","type":"message","text":"when I am performing `append!` operation on my 2 variables:\n```df1 = DataFrame(A=1:4, B=1:4)\ndf2 = DataFrame(A=4:5, B=4:5)\nappend!(df1, df2)```\nafter appending when I am finding `df1` then it's showing result of append operation rather than `df1` result, Why?\n`df1` should give\n```Row ‚îÇ A      B\n     ‚îÇ Int64  Int64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ     1      1\n   2 ‚îÇ     2      2\n   3 ‚îÇ     3      3\n   4 ‚îÇ     4      4```\nbut it's giving\n``` Row ‚îÇ A      B\n     ‚îÇ Int64  Int64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ     1      1\n   2 ‚îÇ     2      2\n   3 ‚îÇ     3      3\n   4 ‚îÇ     4      4\n   5 ‚îÇ     4      4\n   6 ‚îÇ     5      5```","user":"U01J7SER458","ts":"1617541452.397700","team":"T68168MUP","edited":{"user":"U01J7SER458","ts":"1617541575.000000"},"blocks":[{"type":"rich_text","block_id":"y4mv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"when I am performing "},{"type":"text","text":"append!","style":{"code":true}},{"type":"text","text":" operation on my 2 variables:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"df1 = DataFrame(A=1:4, B=1:4)\ndf2 = DataFrame(A=4:5, B=4:5)\nappend!(df1, df2)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"after appending when I am finding "},{"type":"text","text":"df1","style":{"code":true}},{"type":"text","text":" then it's showing result of append operation rather than "},{"type":"text","text":"df1","style":{"code":true}},{"type":"text","text":" result, Why?\n"},{"type":"text","text":"df1","style":{"code":true}},{"type":"text","text":" should give\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Row ‚îÇ A      B\n     ‚îÇ Int64  Int64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ     1      1\n   2 ‚îÇ     2      2\n   3 ‚îÇ     3      3\n   4 ‚îÇ     4      4"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"but it's giving\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":" Row ‚îÇ A      B\n     ‚îÇ Int64  Int64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ     1      1\n   2 ‚îÇ     2      2\n   3 ‚îÇ     3      3\n   4 ‚îÇ     4      4\n   5 ‚îÇ     4      4\n   6 ‚îÇ     5      5"}]}]}],"thread_ts":"1617541452.397700","reply_count":2,"reply_users_count":2,"latest_reply":"1617542444.398600","reply_users":["UH24GRBLL","U01J7SER458"],"is_locked":false,"subscribed":false},{"client_msg_id":"9ad8f87d-06a9-4ccd-be29-38b4cbbd3763","type":"message","text":"If you are writing a bunch of GraphQL queries in Julia, these tools I just published should be a big workflow improvement! <https://lauriumlabs.com/blog/julia-code-generation-with-graphql>","user":"UHRTH2R7D","ts":"1617631357.404100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0UXd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you are writing a bunch of GraphQL queries in Julia, these tools I just published should be a big workflow improvement! "},{"type":"link","url":"https://lauriumlabs.com/blog/julia-code-generation-with-graphql"}]}]}],"reactions":[{"name":"1000","users":["US64J0NPQ"],"count":1}]},{"client_msg_id":"2c6bb1df-9f06-4ca4-a128-87aca3f311b1","type":"message","text":"Hey all - could anyone point me to documentation on how to load only specific columns of a file as opposed to loading in an entire file via file reading tools? Specifically, I am working with Arrow files and I thought I read I could do that with this type of format. Or am I wishful thinking/imagining such functionality?","user":"US64J0NPQ","ts":"1617631511.406000","team":"T68168MUP","edited":{"user":"US64J0NPQ","ts":"1617631524.000000"},"blocks":[{"type":"rich_text","block_id":"FmM1i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey all - could anyone point me to documentation on how to load only specific columns of a file as opposed to loading in an entire file via file reading tools? Specifically, I am working with Arrow files and I thought I read I could do that with this type of format. Or am I wishful thinking/imagining such functionality?"}]}]}]},{"client_msg_id":"bf77aebe-62ef-4a8b-924a-71743f106ab5","type":"message","text":"There‚Äôs nothing builtin to Arrow.jl reading as of yet, but it‚Äôs on the todo list. Otherwise, you could use something like `TableOperations.select` to pick a subselection by column names or indices. You could also materialize as a DataFrame and use its plethora of indexing options. All these should be reasonably efficient since Arrow.jl is just creating ‚Äúviews‚Äù into the data, but we‚Äôll get native support at some point.","user":"U681ELA87","ts":"1617633493.408500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3wG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There‚Äôs nothing builtin to Arrow.jl reading as of yet, but it‚Äôs on the todo list. Otherwise, you could use something like "},{"type":"text","text":"TableOperations.select","style":{"code":true}},{"type":"text","text":" to pick a subselection by column names or indices. You could also materialize as a DataFrame and use its plethora of indexing options. All these should be reasonably efficient since Arrow.jl is just creating ‚Äúviews‚Äù into the data, but we‚Äôll get native support at some point."}]}]}]},{"type":"message","subtype":"thread_broadcast","text":"Btw don't the Beacon Biosignals folks use GraphQL for stuff or did I misread that somewhere","user":"U6CF3AA5Q","ts":"1617634846.409100","thread_ts":"1617631357.404100","root":{"client_msg_id":"9ad8f87d-06a9-4ccd-be29-38b4cbbd3763","type":"message","text":"If you are writing a bunch of GraphQL queries in Julia, these tools I just published should be a big workflow improvement! <https://lauriumlabs.com/blog/julia-code-generation-with-graphql>","user":"UHRTH2R7D","ts":"1617631357.404100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0UXd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you are writing a bunch of GraphQL queries in Julia, these tools I just published should be a big workflow improvement! "},{"type":"link","url":"https://lauriumlabs.com/blog/julia-code-generation-with-graphql"}]}]}],"thread_ts":"1617631357.404100","reply_count":7,"reply_users_count":3,"latest_reply":"1617635561.409600","reply_users":["U6CF3AA5Q","UHRTH2R7D","U6NFPDBV1"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"9DFm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Btw don't the Beacon Biosignals folks use GraphQL for stuff or did I misread that somewhere"}]}]}],"client_msg_id":"1a294984-33a6-4ebe-9902-4bc3c0105d59"},{"type":"message","subtype":"tombstone","text":"This message was deleted.","user":"USLACKBOT","hidden":true,"ts":"1617638150.410700","thread_ts":"1617638150.410700","reply_count":1,"reply_users_count":1,"latest_reply":"1617638193.410800","reply_users":["U6A936746"],"is_locked":false,"subscribed":false},{"type":"message","text":"Does this look like a bug in DataFrames or more in my terminal emulator? It just started happening within this past week:","files":[{"id":"F01T0SZP31V","created":1617744320,"timestamp":1617744320,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"US64J0NPQ","editable":false,"size":297478,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01T0SZP31V/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01T0SZP31V/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01T0SZP31V-15a42cf4fc/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01T0SZP31V-15a42cf4fc/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01T0SZP31V-15a42cf4fc/image_360.png","thumb_360_w":360,"thumb_360_h":297,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01T0SZP31V-15a42cf4fc/image_480.png","thumb_480_w":480,"thumb_480_h":396,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01T0SZP31V-15a42cf4fc/image_160.png","original_w":716,"original_h":590,"thumb_tiny":"AwAnADCnj3/Sjpjnt6UL97v+FIe30oAdn6flSHnv+lJRQAuP84ox/nFPXr1bp2pJM4H3vxoAaDg5pD2+lPXG3+H8aRlwituBz2HUUANooooAcGA7Hp60MwI7/nSrjjhfTmhgNucr+FACGQ5J46Y6U0nP86KKACiiigBQxGOnFKZGIIOOfam0UAf/2Q==","permalink":"https://julialang.slack.com/files/US64J0NPQ/F01T0SZP31V/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01T0SZP31V-d59075211e","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"QamkS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does this look like a bug in DataFrames or more in my terminal emulator? It just started happening within this past week:"}]}]}],"user":"US64J0NPQ","display_as_bot":false,"ts":"1617744335.416200","thread_ts":"1617744335.416200","reply_count":14,"reply_users_count":3,"latest_reply":"1617745864.419700","reply_users":["UBF9YRB6H","US64J0NPQ","U8JAMQGQY"],"is_locked":false,"subscribed":false},{"client_msg_id":"317bdca5-4c2e-433e-8d82-597f4ddfd10c","type":"message","text":"And I am referring to the `?` symbols propagating.","user":"US64J0NPQ","ts":"1617744357.416800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+Ewn7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And I am referring to the "},{"type":"text","text":"?","style":{"code":true}},{"type":"text","text":" symbols propagating."}]}]}],"reactions":[{"name":"mario-question","users":["U680THK2S","U0138UTB7A4"],"count":2}]},{"client_msg_id":"03a2a1dc-9fbb-44f0-815f-95079f43c877","type":"message","text":"Has anything changed in what `DataFrame(Arrow.Table(\"mytable.arrow\"))` does by default? I have a 5.5GB Arrow file (100 million rows, 7 columns), which I used to be able to read in in &lt;1 sec and without allocations, now I'm getting:\n```73.554109 seconds (309.11 M allocations: 14.066 GiB, 54.51% gc time, 0.06% compilation time)```","user":"U7JQGPGCQ","ts":"1617787297.424100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"g97S9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Has anything changed in what "},{"type":"text","text":"DataFrame(Arrow.Table(\"mytable.arrow\"))","style":{"code":true}},{"type":"text","text":" does by default? I have a 5.5GB Arrow file (100 million rows, 7 columns), which I used to be able to read in in <1 sec and without allocations, now I'm getting:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"73.554109 seconds (309.11 M allocations: 14.066 GiB, 54.51% gc time, 0.06% compilation time)"}]}]}]},{"client_msg_id":"6bde79f7-09df-41df-825b-e77abcd5abeb","type":"message","text":"Did the default move from `copycols = false` to `true` maybe?","user":"U7JQGPGCQ","ts":"1617787385.424500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lVB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Did the default move from "},{"type":"text","text":"copycols = false","style":{"code":true}},{"type":"text","text":" to "},{"type":"text","text":"true","style":{"code":true}},{"type":"text","text":" maybe?"}]}]}]},{"client_msg_id":"fd5585a7-4842-46a4-8266-9d01fb975136","type":"message","text":"I don't exactly spend a ton of time inside the DataFrames repo, so maybe I'm not the one who should be askign this, but I did have occasion to check it out a few times lately, and while I am glad the package is so well documented, I find the huge doc strings extremely obnoxious when looking at code.  Would you guys be open to moving the long ones to separate files?  (this is very easy and already supported by the docs system, see my comment in <#C6FGJ8REC|appreciation>)","user":"U9VG1AYSG","ts":"1617805307.428300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4+10p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't exactly spend a ton of time inside the DataFrames repo, so maybe I'm not the one who should be askign this, but I did have occasion to check it out a few times lately, and while I am glad the package is so well documented, I find the huge doc strings extremely obnoxious when looking at code.  Would you guys be open to moving the long ones to separate files?  (this is very easy and already supported by the docs system, see my comment in "},{"type":"channel","channel_id":"C6FGJ8REC"},{"type":"text","text":")"}]}]}],"thread_ts":"1617805307.428300","reply_count":1,"reply_users_count":1,"latest_reply":"1617805721.428600","reply_users":["U8JAMQGQY"],"is_locked":false,"subscribed":false},{"client_msg_id":"fb2b836b-8c78-42ab-849f-853a01cc9321","type":"message","text":"Hi  guys\nHow can you apply  multiple function to multiple columns for a grouped data frame\nsay having  some df like so\n``` data = DataFrame(reshape(1:24, 6, 4))    \n GoupingsData = hcat([\"red\",\"blue\",\"Green\",\"red\",\"blue\",\"Green\"],data,makeunique = true)\n \n\n Output = \n @pipe GoupingsData |&gt; \n     combine(groupby(_,:x1),\n                    [:x1_1,:x2,:x3,:x4]  .=&gt; [maximum,minimum] .=&gt; \n                    [:x1min,:x1max,:x2min,:x2max,:x3min,:x3max,:x4min,:x4max]) ```\nhow would i apply each function to each of the columns.\nthe above does not work.","user":"UPH1M2MB2","ts":"1617811366.433500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kDc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi  guys\nHow can you apply  multiple function to multiple columns for a grouped data frame\nsay having  some df like so\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":" data = DataFrame(reshape(1:24, 6, 4))    \n GoupingsData = hcat([\"red\",\"blue\",\"Green\",\"red\",\"blue\",\"Green\"],data,makeunique = true)\n \n\n Output = \n @pipe GoupingsData |> \n     combine(groupby(_,:x1),\n                    [:x1_1,:x2,:x3,:x4]  .=> [maximum,minimum] .=> \n                    [:x1min,:x1max,:x2min,:x2max,:x3min,:x3max,:x4min,:x4max]) "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"how would i apply each function to each of the columns.\nthe above does not work."}]}]}],"thread_ts":"1617811366.433500","reply_count":2,"reply_users_count":1,"latest_reply":"1617811701.433800","reply_users":["UBF9YRB6H"],"is_locked":false,"subscribed":false},{"client_msg_id":"b912a784-3c26-4e92-81e5-f79525da8a5f","type":"message","text":"What would be the easiest way to loop over a grouped dataframe, while also receiving a tuple with indices, where each index denotes what cell of the product of grouping factors the current iteration is from? If I enumerate, I only get numbers from 1 to n. If I enumerate in multiple for loops, I only get numbers from 1:j for each group, but there might be missing combinations that offset the count. I need this for plotting :)","user":"UK1BNFHFV","ts":"1617812584.435900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BkXs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What would be the easiest way to loop over a grouped dataframe, while also receiving a tuple with indices, where each index denotes what cell of the product of grouping factors the current iteration is from? If I enumerate, I only get numbers from 1 to n. If I enumerate in multiple for loops, I only get numbers from 1:j for each group, but there might be missing combinations that offset the count. I need this for plotting :)"}]}]}]}]}