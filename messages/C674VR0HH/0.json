{"cursor": 3, "messages": [{"client_msg_id":"579280a8-f860-41cf-beec-deca9a066441","type":"message","text":"when making a DataFrame from a vector of JSON objects, is it possible to NOT include a column? (current approach is drop! it after the fact","user":"UH8A351DJ","ts":"1614498908.105000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kWv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"when making a DataFrame from a vector of JSON objects, is it possible to NOT include a column? (current approach is drop! it after the fact"}]}]}]},{"client_msg_id":"4454cc48-3118-4fc2-b527-f1b3f9841df4","type":"message","text":"Hi guys,\n\nAny insight on this error? Is this due to weird thread issue (I'm using Julia 1.3.1).\n```[20:15:28] ERROR: LoadError: TaskFailedException:\n[20:15:28] IOError: close: i/o error (EIO)\n[20:15:28] Stacktrace:\n[20:15:28]  [1] uv_error at ./libuv.jl:97 [inlined]\n[20:15:28]  [2] close at ./filesystem.jl:107 [inlined]\n[20:15:28]  [3] sendfile(::String, ::String) at ./file.jl:814\n[20:15:28]  [4] #cp#12(::Bool, ::Bool, ::typeof(cp), ::String, ::String) at ./file.jl:344\n[20:15:28]  [5] (::Base.Filesystem.var\"#kw##cp\")(::NamedTuple{(:force,),Tuple{Bool}}, ::typeof(cp), ::String, ::String) at ./none:0\n[20:15:28]  [6] macro expansion at /home/darren/project/MRVerify/src/MRVerify.jl:856 [inlined]\n[20:15:28]  [7] (::Main.MRVerify.var\"#232#threadsfor_fun#44\"{NamedTuple{(:ses_dir, :config, :out_path, :sub, :ses, :ses_report_path, :labnotes_path, :issue_path, :anon_rda, :overwrite),Tuple{String,Dict{String,Any},String,String,String,Nothing,Nothing,Nothing,Bool,Bool}},Array{Tuple{Int64,Pair{Any,Any}},1}})(::Bool) at ./threadingconstructs.jl:61\n[20:15:28]  [8] (::Main.MRVerify.var\"#232#threadsfor_fun#44\"{NamedTuple{(:ses_dir, :config, :out_path, :sub, :ses, :ses_report_path, :labnotes_path, :issue_path, :anon_rda, :overwrite),Tuple{String,Dict{String,Any},String,String,String,Nothing,Nothing,Nothing,Bool,Bool}},Array{Tuple{Int64,Pair{Any,Any}},1}})() at ./threadingconstructs.jl:28\n[20:15:29] Stacktrace:\n[20:15:29]  [1] wait(::Task) at ./task.jl:251\n[20:15:29]  [2] macro expansion at ./threadingconstructs.jl:69 [inlined]\n[20:15:29]  [3] #process_session_data#15(::String, ::String, ::String, ::Nothing, ::Nothing, ::Nothing, ::Bool, ::Bool, ::typeof(Main.MRVerify.process_session_data), ::String, ::Dict{String,Any}) at /home/darren/project/MRVerify/src/MRVerify.jl:852\n[20:15:29]  [4] (::Main.MRVerify.var\"#kw##process_session_data\")(::NamedTuple{(:out_path, :sub, :ses, :issue_path, :ses_report_path, :labnotes_path, :anon_rda, :overwrite),Tuple{String,String,String,Nothing,Nothing,Nothing,Bool,Bool}}, ::typeof(Main.MRVerify.process_session_data), ::String, ::Dict{String,Any}) at ./none:0\n[20:15:29]  [5] top-level scope at /home/darren/project/MRVerify/src/MRVerify.jl:1329\n[20:15:29]  [6] include at ./boot.jl:328 [inlined]\n[20:15:29]  [7] include_relative(::Module, ::String) at ./loading.jl:1105\n[20:15:29]  [8] include(::Module, ::String) at ./Base.jl:31\n[20:15:29]  [9] exec_options(::Base.JLOptions) at ./client.jl:287\n[20:15:29]  [10] _start() at ./client.jl:460\n[20:15:29] in expression starting at /home/darren/project/MRVerify/src/MRVerify.jl:1326```\nMy code in Line 852 is the `Threads.@threads` , i.e.\n```Threads.@threads for (idx, (k, v)) in collect(enumerate(twix_result))```\nAny help would be appreciated!","user":"UUT4VGTE2","ts":"1614524183.106600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"q+2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys,\n\nAny insight on this error? Is this due to weird thread issue (I'm using Julia 1.3.1).\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"[20:15:28] ERROR: LoadError: TaskFailedException:\n[20:15:28] IOError: close: i/o error (EIO)\n[20:15:28] Stacktrace:\n[20:15:28]  [1] uv_error at ./libuv.jl:97 [inlined]\n[20:15:28]  [2] close at ./filesystem.jl:107 [inlined]\n[20:15:28]  [3] sendfile(::String, ::String) at ./file.jl:814\n[20:15:28]  [4] #cp#12(::Bool, ::Bool, ::typeof(cp), ::String, ::String) at ./file.jl:344\n[20:15:28]  [5] (::Base.Filesystem.var\"#kw##cp\")(::NamedTuple{(:force,),Tuple{Bool}}, ::typeof(cp), ::String, ::String) at ./none:0\n[20:15:28]  [6] macro expansion at /home/darren/project/MRVerify/src/MRVerify.jl:856 [inlined]\n[20:15:28]  [7] (::Main.MRVerify.var\"#232#threadsfor_fun#44\"{NamedTuple{(:ses_dir, :config, :out_path, :sub, :ses, :ses_report_path, :labnotes_path, :issue_path, :anon_rda, :overwrite),Tuple{String,Dict{String,Any},String,String,String,Nothing,Nothing,Nothing,Bool,Bool}},Array{Tuple{Int64,Pair{Any,Any}},1}})(::Bool) at ./threadingconstructs.jl:61\n[20:15:28]  [8] (::Main.MRVerify.var\"#232#threadsfor_fun#44\"{NamedTuple{(:ses_dir, :config, :out_path, :sub, :ses, :ses_report_path, :labnotes_path, :issue_path, :anon_rda, :overwrite),Tuple{String,Dict{String,Any},String,String,String,Nothing,Nothing,Nothing,Bool,Bool}},Array{Tuple{Int64,Pair{Any,Any}},1}})() at ./threadingconstructs.jl:28\n[20:15:29] Stacktrace:\n[20:15:29]  [1] wait(::Task) at ./task.jl:251\n[20:15:29]  [2] macro expansion at ./threadingconstructs.jl:69 [inlined]\n[20:15:29]  [3] #process_session_data#15(::String, ::String, ::String, ::Nothing, ::Nothing, ::Nothing, ::Bool, ::Bool, ::typeof(Main.MRVerify.process_session_data), ::String, ::Dict{String,Any}) at /home/darren/project/MRVerify/src/MRVerify.jl:852\n[20:15:29]  [4] (::Main.MRVerify.var\"#kw##process_session_data\")(::NamedTuple{(:out_path, :sub, :ses, :issue_path, :ses_report_path, :labnotes_path, :anon_rda, :overwrite),Tuple{String,String,String,Nothing,Nothing,Nothing,Bool,Bool}}, ::typeof(Main.MRVerify.process_session_data), ::String, ::Dict{String,Any}) at ./none:0\n[20:15:29]  [5] top-level scope at /home/darren/project/MRVerify/src/MRVerify.jl:1329\n[20:15:29]  [6] include at ./boot.jl:328 [inlined]\n[20:15:29]  [7] include_relative(::Module, ::String) at ./loading.jl:1105\n[20:15:29]  [8] include(::Module, ::String) at ./Base.jl:31\n[20:15:29]  [9] exec_options(::Base.JLOptions) at ./client.jl:287\n[20:15:29]  [10] _start() at ./client.jl:460\n[20:15:29] in expression starting at /home/darren/project/MRVerify/src/MRVerify.jl:1326"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"My code in Line 852 is the "},{"type":"text","text":"Threads.@threads","style":{"code":true}},{"type":"text","text":" , i.e.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Threads.@threads for (idx, (k, v)) in collect(enumerate(twix_result))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Any help would be appreciated!"}]}]}]},{"client_msg_id":"d36a934f-b4a3-49c3-b474-f6f1136c651a","type":"message","text":"can I select columns by eltype?","user":"U01ARRMLM7E","ts":"1614544183.109600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"S3U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"can I select columns by eltype?"}]}]}],"thread_ts":"1614544183.109600","reply_count":1,"reply_users_count":1,"latest_reply":"1614545542.112300","reply_users":["U011QC7QLPL"],"subscribed":false},{"client_msg_id":"bd1ca99a-71e9-4d97-8e45-854e07bc1d9e","type":"message","text":"I've that idealistic thought in my mind, about streamlining ProtoBuf.jl and StructTypes.jl such that the former is generating code from proto files that matches the API of the latter. But for that I rn am not entirely sure I understood it correctly. StructTypes is a valid API for both, binary as well as textual de/serialization, isn't it?","user":"UMWFZF5DW","ts":"1614544751.112000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"e0K66","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've that idealistic thought in my mind, about streamlining ProtoBuf.jl and StructTypes.jl such that the former is generating code from proto files that matches the API of the latter. But for that I rn am not entirely sure I understood it correctly. StructTypes is a valid API for both, binary as well as textual de/serialization, isn't it?"}]}]}]},{"client_msg_id":"ccd048aa-a288-4948-bea2-8cc061df944d","type":"message","text":"We could probably have `describe` on tables be it's own package that acts on tables and returns a named tuple of vectors. and then we override it for `DataFrame`s to return a DataFrame. It's a self-contained function for the most part.","user":"UBF9YRB6H","ts":"1614548440.115100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sXhi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We could probably have "},{"type":"text","text":"describe","style":{"code":true}},{"type":"text","text":" on tables be it's own package that acts on tables and returns a named tuple of vectors. and then we override it for `DataFrame`s to return a DataFrame. It's a self-contained function for the most part."}]}]}]},{"client_msg_id":"6c86d8b1-c334-4cc9-ade6-00ed68f4603f","type":"message","text":"what is the function to call on a `DataFrame` to say how big the `CSV.write` will be?","user":"UM8JUNJG7","ts":"1614549529.115900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rz4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what is the function to call on a "},{"type":"text","text":"DataFrame","style":{"code":true}},{"type":"text","text":" to say how big the "},{"type":"text","text":"CSV.write","style":{"code":true}},{"type":"text","text":" will be?"}]}]}],"thread_ts":"1614549529.115900","reply_count":7,"reply_users_count":3,"latest_reply":"1614550189.117400","reply_users":["UBF9YRB6H","UM8JUNJG7","U01ARRMLM7E"],"subscribed":false},{"client_msg_id":"ee62cb5a-9fbc-4646-ae6e-f82f8eaa4fe0","type":"message","text":"is there a version of `lag` from ShiftedArrays that doesn't include the `missing`s? Just shortens the array","user":"UBF9YRB6H","ts":"1614552197.119400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Lgv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a version of "},{"type":"text","text":"lag","style":{"code":true}},{"type":"text","text":" from ShiftedArrays that doesn't include the `missing`s? Just shortens the array"}]}]}]},{"client_msg_id":"efb4739c-95b9-48ee-b779-0ad087e0727a","type":"message","text":"Does anyone know the situation with JSONTables. It worked when I used it about a month ago, but running the same program after an update fails. in expression starting at /Users/impero/.julia/packages/JSONTables/g5bSA/src/JSONTables.jl:3 it loads JSON3, but then: WARNING: could not import StructTypes.OrderedStruct into JSON3\nERROR: LoadError: LoadError: UndefVarError: OrderedStruct not defined","user":"U01GFAJRZ44","ts":"1614617954.140200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JkOfQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone know the situation with JSONTables. It worked when I used it about a month ago, but running the same program after an update fails. in expression starting at /Users/impero/.julia/packages/JSONTables/g5bSA/src/JSONTables.jl:3 it loads JSON3, but then: WARNING: could not import StructTypes.OrderedStruct into JSON3\nERROR: LoadError: LoadError: UndefVarError: OrderedStruct not defined"}]}]}]},{"client_msg_id":"b08aef7f-1a17-462d-aec1-7f408d6fc2bc","type":"message","text":"I have got around this for now by removing JSON3 and loading JSON3@1.5.1. 1.7.1 seems to fail","user":"U01GFAJRZ44","ts":"1614618262.140800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"53vZ2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have got around this for now by removing JSON3 and loading JSON3@1.5.1. 1.7.1 seems to fail"}]}]}]},{"client_msg_id":"c4074f43-4358-4e53-824c-d78545ebe73b","type":"message","text":"Sounds like your versions are getting mismatched? JSON3 v1.7+ requires StructTypes v1.4+. If you somehow updated JSON3 without updating StructTypes (which your error makes it sound like), then things would get out of sync","user":"U681ELA87","ts":"1614618530.141900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m5U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sounds like your versions are getting mismatched? JSON3 v1.7+ requires StructTypes v1.4+. If you somehow updated JSON3 without updating StructTypes (which your error makes it sound like), then things would get out of sync"}]}]}]},{"client_msg_id":"393e9fbe-b581-45a1-b3d8-54d1c9f24b68","type":"message","text":"JSONTables.jl just depends on JSON3 “1” and StructTypes “1\", so it’s not imposing any hard requirements","user":"U681ELA87","ts":"1614618577.142400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jbA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"JSONTables.jl just depends on JSON3 “1” and StructTypes “1\", so it’s not imposing any hard requirements"}]}]}]},{"client_msg_id":"7e3a2579-b423-4a02-82af-90cbb2e79867","type":"message","text":"StructTypes.= 1.4.0. I just did an ‘update’ in the package manager, and got JSON3 1.7.1 (was 1.5.1) and StructTypes 1.4.0.","user":"U01GFAJRZ44","ts":"1614618648.143200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+Dmia","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"StructTypes.= 1.4.0. I just did an ‘update’ in the package manager, and got JSON3 1.7.1 (was 1.5.1) and StructTypes 1.4.0."}]}]}]},{"client_msg_id":"755faa4c-6faa-46fb-b7f3-84a89463f07c","type":"message","text":"so if you restart Julia and do `using JSON3`, what happens?","user":"U681ELA87","ts":"1614618989.143600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pvDtp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so if you restart Julia and do "},{"type":"text","text":"using JSON3","style":{"code":true}},{"type":"text","text":", what happens?"}]}]}]},{"client_msg_id":"08975616-7976-46e2-bef5-2874dd8c1ea3","type":"message","text":"(and are you using a plain terminal REPL or some other Juno/Atom/VSCode/Jupyter/IJulia setup?)","user":"U681ELA87","ts":"1614619019.144200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JndDe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(and are you using a plain terminal REPL or some other Juno/Atom/VSCode/Jupyter/IJulia setup?)"}]}]}]},{"client_msg_id":"50ca2c18-b93b-4543-983c-12eae6e32a83","type":"message","text":"Can I initialize a `CategoricalArray{String}` with levels from `Dict{String,Int}` and an array of encoded values `Vector{Int}`, without creating array of strings?","user":"UB2QSHWPN","ts":"1614620425.146100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TcHd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can I initialize a "},{"type":"text","text":"CategoricalArray{String}","style":{"code":true}},{"type":"text","text":" with levels from "},{"type":"text","text":"Dict{String,Int}","style":{"code":true}},{"type":"text","text":" and an array of encoded values "},{"type":"text","text":"Vector{Int}","style":{"code":true}},{"type":"text","text":", without creating array of strings?"}]}]}],"thread_ts":"1614620425.146100","reply_count":1,"reply_users_count":1,"latest_reply":"1614620528.146200","reply_users":["U67431ELR"],"subscribed":false},{"client_msg_id":"9c15a255-685e-4603-8b21-506757ddab2b","type":"message","text":"I'm confused; is the DataFrames syntax `df.a = v` deprecated or not?  becuase I could have sworn it was but I don't seem to be getting deprecation warnings anymore","user":"U9VG1AYSG","ts":"1614623444.147100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yHAx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm confused; is the DataFrames syntax "},{"type":"text","text":"df.a = v","style":{"code":true}},{"type":"text","text":" deprecated or not?  becuase I could have sworn it was but I don't seem to be getting deprecation warnings anymore"}]}]}],"thread_ts":"1614623444.147100","reply_count":4,"reply_users_count":3,"latest_reply":"1614624697.148000","reply_users":["U8JAMQGQY","U6A936746","U9VG1AYSG"],"subscribed":false},{"client_msg_id":"86e6fdea-468d-45eb-b816-f910049f34d7","type":"message","text":"I have a 3x76 Array{Any,2}. Row1 is string, rest are float64. How can I sort it according to ascending order of row2?","user":"U01NX6V5A2D","ts":"1614674539.155300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GpOT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a 3x76 Array{Any,2}. Row1 is string, rest are float64. How can I sort it according to ascending order of row2?"}]}]}],"thread_ts":"1614674539.155300","reply_count":3,"reply_users_count":2,"latest_reply":"1614675907.155800","reply_users":["U01NX6V5A2D","U6A936746"],"subscribed":false},{"client_msg_id":"0575e023-7aed-46b2-969c-67b502fbaba9","type":"message","text":"what's the best way to keep *all* columns in the result of a `combine`?  I'm surprised there seems to be no keyword argument for this","user":"U9VG1AYSG","ts":"1614699376.161300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"A7U1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what's the best way to keep "},{"type":"text","text":"all","style":{"bold":true}},{"type":"text","text":" columns in the result of a "},{"type":"text","text":"combine","style":{"code":true}},{"type":"text","text":"?  I'm surprised there seems to be no keyword argument for this"}]}]}],"thread_ts":"1614699376.161300","reply_count":5,"reply_users_count":3,"latest_reply":"1614699731.162200","reply_users":["U67431ELR","U8JAMQGQY","U9VG1AYSG"],"subscribed":false},{"client_msg_id":"0e37cc79-a383-452c-bb34-1bfb2ba9dec7","type":"message","text":"thank you <@U8JAMQGQY> and <@U67431ELR> for putting me right on using `DataFrames: transform, transform!`; somehow I had all but forgotten about their existence.  One thing that I sometimes find myself needing to do that these functions make very easy (and seemingly even very efficient?) is adding a column to a dataframe while it's split into groups.  Giant pain in the ass without `transform!`","user":"U9VG1AYSG","ts":"1614711247.164300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"utP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thank you "},{"type":"user","user_id":"U8JAMQGQY"},{"type":"text","text":" and "},{"type":"user","user_id":"U67431ELR"},{"type":"text","text":" for putting me right on using "},{"type":"text","text":"DataFrames: transform, transform!","style":{"code":true}},{"type":"text","text":"; somehow I had all but forgotten about their existence.  One thing that I sometimes find myself needing to do that these functions make very easy (and seemingly even very efficient?) is adding a column to a dataframe while it's split into groups.  Giant pain in the ass without "},{"type":"text","text":"transform!","style":{"code":true}}]}]}]},{"client_msg_id":"272b8303-8e0d-4120-9124-868ea94d856a","type":"message","text":"overall the DataFrames API is so wonderful, you guys did a really amazing job carefully thinking it through","user":"U9VG1AYSG","ts":"1614711309.164800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=gN8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"overall the DataFrames API is so wonderful, you guys did a really amazing job carefully thinking it through"}]}]}],"reactions":[{"name":"heart","users":["U681ELA87","U8JAMQGQY"],"count":2}]},{"client_msg_id":"e9ae3e13-3df4-49be-bafe-f3acd0275895","type":"message","text":"really, look at this:\n```transform!(groupby(df, :A), :A=&gt;(x -&gt; (D=x .+ 1, E=x .+ 2))=&gt;[:D, :E])```\nit's just so cool that that's trivial to do","user":"U9VG1AYSG","ts":"1614711546.165300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8z=Eb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"really, look at this:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"transform!(groupby(df, :A), :A=>(x -> (D=x .+ 1, E=x .+ 2))=>[:D, :E])"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"it's just so cool that that's trivial to do"}]}]}]},{"client_msg_id":"91b71397-80eb-4859-b765-babbde3a3304","type":"message","text":"(btw, is there a way to do that without returning a `NamedTuple` from the intermediate function? it seems redundant because it already tells it what the column names are)","user":"U9VG1AYSG","ts":"1614711575.165900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pXOfS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(btw, is there a way to do that without returning a "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" from the intermediate function? it seems redundant because it already tells it what the column names are)"}]}]}]},{"client_msg_id":"85c5e84b-5a68-4bb8-ae11-433fa7e1bad4","type":"message","text":"```transform!(groupby(df, :A), :A=&gt; ByRow(x -&gt; x .+ (1,2)) =&gt; [:D, :E])```\nshould work and be fast (I am writing it from my head so please check :smile:)","user":"U8JAMQGQY","ts":"1614711947.167200","team":"T68168MUP","edited":{"user":"U8JAMQGQY","ts":"1614712020.000000"},"blocks":[{"type":"rich_text","block_id":"Lbxn","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"transform!(groupby(df, :A), :A=> ByRow(x -> x .+ (1,2)) => [:D, :E])"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"should work and be fast (I am writing it from my head so please check "},{"type":"emoji","name":"smile"},{"type":"text","text":")"}]}]}]},{"client_msg_id":"9cb79740-b3eb-43e5-a46f-cdf8e411fd12","type":"message","text":"wait what about `=&gt; AsTable`?","user":"UBF9YRB6H","ts":"1614712001.167500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hVp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"wait what about "},{"type":"text","text":"=> AsTable","style":{"code":true}},{"type":"text","text":"?"}]}]}],"reactions":[{"name":"point_up","users":["U9VG1AYSG"],"count":1}]},{"client_msg_id":"82ba6a7c-f068-4bcd-ac07-87152947d7da","type":"message","text":"<@U9VG1AYSG> did not want to return a `NamedTuple`","user":"U8JAMQGQY","ts":"1614712032.168200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"z7n","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U9VG1AYSG"},{"type":"text","text":" did not want to return a "},{"type":"text","text":"NamedTuple","style":{"code":true}}]}]}]},{"client_msg_id":"d613be86-21de-4bc7-a362-48f114ec2c3c","type":"message","text":"thanks, I think the `AsTable` is what I was looking for...","user":"U9VG1AYSG","ts":"1614712043.168500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9q/DV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thanks, I think the "},{"type":"text","text":"AsTable","style":{"code":true}},{"type":"text","text":" is what I was looking for..."}]}]}]},{"client_msg_id":"a88b38e9-9edf-4961-bcaa-8d35dd74f2d9","type":"message","text":"well, what I relaly wanted was to elminate the redundancy of specifying table columns in two separate places, that's all","user":"U9VG1AYSG","ts":"1614712061.169000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cfb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"well, what I relaly wanted was to elminate the redundancy of specifying table columns in two separate places, that's all"}]}]}]},{"client_msg_id":"53ea8e1b-f950-4a65-a54a-1b0337cf5688","type":"message","text":"so I think dumping to `AsTable` is the easiest way to do that","user":"U9VG1AYSG","ts":"1614712074.169600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FtI9L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so I think dumping to "},{"type":"text","text":"AsTable","style":{"code":true}},{"type":"text","text":" is the easiest way to do that"}]}]}]},{"client_msg_id":"c254830a-326a-46b8-8e1f-17b625c6b312","type":"message","text":"So as you can see - you can do it in two ways :slightly_smiling_face:.","user":"U8JAMQGQY","ts":"1614712078.169700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0CDyu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So as you can see - you can do it in two ways "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":"."}]}]}],"reactions":[{"name":"+1","users":["U9VG1AYSG"],"count":1}]},{"client_msg_id":"35aa4ec7-9d80-49e8-b50d-8f31e15e51b3","type":"message","text":"it might be good if we add a section to the docs including lots of examples on the really \"fancy\" stuff one can do with the column pair syntax.  It wasn't at all obvious to me that you can do `cols=&gt;f=&gt;AsTable`","user":"U9VG1AYSG","ts":"1614712182.170900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"45dTK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"it might be good if we add a section to the docs including lots of examples on the really \"fancy\" stuff one can do with the column pair syntax.  It wasn't at all obvious to me that you can do "},{"type":"text","text":"cols=>f=>AsTable","style":{"code":true}}]}]}]},{"client_msg_id":"9cbf5403-39c2-4431-92df-6e064f0007a2","type":"message","text":"in particular, it might be really nice to have a section on the underlying magic that makes the pairs syntax work.  Right now it seems very magical to me, but I assume it's all built around a few core, primitive functions.  Understanding what those are I think would be very enlightening","user":"U9VG1AYSG","ts":"1614712356.172000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/Ur","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"in particular, it might be really nice to have a section on the underlying magic that makes the pairs syntax work.  Right now it seems very magical to me, but I assume it's all built around a few core, primitive functions.  Understanding what those are I think would be very enlightening"}]}]}]},{"client_msg_id":"e19e3b7a-fb06-41ce-91f3-c591cbacbbb1","type":"message","text":"Those would be 2 different piece of documentation.\nUnderstanding based Explination for the later.\nand either learning based tutorials, or goal based guides for the former.\nI agree though. both would be valuable\n(4 kinds of docs <https://documentation.divio.com/introduction/>)","user":"U6A936746","ts":"1614712506.173600","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1614712514.000000"},"blocks":[{"type":"rich_text","block_id":"S9ZC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Those would be 2 different piece of documentation.\nUnderstanding based Explination for the later.\nand either learning based tutorials, or goal based guides for the former.\nI agree though. both would be valuable\n(4 kinds of docs "},{"type":"link","url":"https://documentation.divio.com/introduction/"},{"type":"text","text":")"}]}]}]},{"client_msg_id":"69f67d7e-7ebc-4e8a-bf67-60c884ead749","type":"message","text":"<@U9VG1AYSG> there's this blog-post that has some of that: <https://bkamins.github.io/julialang/2020/12/24/minilanguage.html>","user":"U8JP5B9T2","ts":"1614713663.174400","team":"T68168MUP","attachments":[{"service_name":"Blog by Bogumił Kamiński","title":"DataFrames.jl minilanguage explained","title_link":"https://bkamins.github.io/julialang/2020/12/24/minilanguage.html","text":"Introduction","fallback":"Blog by Bogumił Kamiński: DataFrames.jl minilanguage explained","ts":1608785495,"from_url":"https://bkamins.github.io/julialang/2020/12/24/minilanguage.html","service_icon":"https://bkamins.github.io/favicon.ico","id":1,"original_url":"https://bkamins.github.io/julialang/2020/12/24/minilanguage.html"}],"blocks":[{"type":"rich_text","block_id":"IoLg","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U9VG1AYSG"},{"type":"text","text":" there's this blog-post that has some of that: "},{"type":"link","url":"https://bkamins.github.io/julialang/2020/12/24/minilanguage.html"}]}]}]},{"client_msg_id":"bc66637f-17d9-4263-9f37-c3b42d1d0df8","type":"message","text":"<@UL1475QDN> will soon work on a new version of DataFrames.jl documentation. However, I think we need to start with learning based tutorial part (as it is very hard to do all four kinds of docs in one shot).","user":"U8JAMQGQY","ts":"1614714018.175800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vcjc","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UL1475QDN"},{"type":"text","text":" will soon work on a new version of DataFrames.jl documentation. However, I think we need to start with learning based tutorial part (as it is very hard to do all four kinds of docs in one shot)."}]}]}]},{"client_msg_id":"4d2794e7-e24a-4a49-9c06-5b0d5fcc584b","type":"message","text":"came up on twitter that R `read_csv` can introduce missing values if extreme values of a numeric column are introduced deep in the file.  this repo has a reproducible example (I haven't checked myself but I trust the referrer...) <https://github.com/ebergelson/read_csv_issue_quickeg>  might be useful to add to our CSV tests/benchmarking","user":"U66M57AN4","ts":"1614738858.177500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0Zf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"came up on twitter that R "},{"type":"text","text":"read_csv","style":{"code":true}},{"type":"text","text":" can introduce missing values if extreme values of a numeric column are introduced deep in the file.  this repo has a reproducible example (I haven't checked myself but I trust the referrer...) "},{"type":"link","url":"https://github.com/ebergelson/read_csv_issue_quickeg"},{"type":"text","text":"  might be useful to add to our CSV tests/benchmarking"}]}]}]},{"client_msg_id":"54ac8e98-76a2-4fee-aaf2-dcacbe96f003","type":"message","text":"<https://twitter.com/bergelsonlab/status/1366866851884589056>","user":"U66M57AN4","ts":"1614738893.177700","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/bergelsonlab|@bergelsonlab>: uhoh i love the #tidyverse &amp; all the <https://twitter.com/hadleywickham|@hadleywickham> tools but danger alert, read_csv() can make a column look full of NAs when it's not if you don't use guess_max() wisely (i.e. if u let it default when u have a rare thing 10k rows down) !!! ( read.csv() doesn't do this) #rstats","ts":1614721427,"author_name":"Bergelson Lab","author_link":"https://twitter.com/bergelsonlab/status/1366866851884589056","author_icon":"https://pbs.twimg.com/profile_images/981987616148066304/CP77wY4m_normal.jpg","author_subname":"@bergelsonlab","text":"uhoh i love the #tidyverse &amp; all the <https://twitter.com/hadleywickham|@hadleywickham> tools but danger alert, read_csv() can make a column look full of NAs when it's not if you don't use guess_max() wisely (i.e. if u let it default when u have a rare thing 10k rows down) !!! ( read.csv() doesn't do this) #rstats","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/bergelsonlab/status/1366866851884589056","id":1,"original_url":"https://twitter.com/bergelsonlab/status/1366866851884589056","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"9XCu","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/bergelsonlab/status/1366866851884589056"}]}]}]},{"client_msg_id":"8fb9e664-58c6-4b21-9097-498a84b5278b","type":"message","text":"After a hiatus off in computer simulation land I am back to processing some experimental data which I have loaded into a DataFrame. When I went looking I found that most traces of categorical arrays have been removed. What is the current state of affairs for this? I don't *need* to do anything as my DataFrame isn't huge (~500k rows and 5 columns. Of which 2 are Floats and 3 are \"categorical\") And so it fits into RAM regardless but in the past I would've used the function to convert columns to categorical arrays for faster filtering and such. I also found references to PooledArrays which I'm not familiar with. Thanks in advanced.","user":"U9L5Y89H7","ts":"1614788062.183000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nxZkU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"After a hiatus off in computer simulation land I am back to processing some experimental data which I have loaded into a DataFrame. When I went looking I found that most traces of categorical arrays have been removed. What is the current state of affairs for this? I don't "},{"type":"text","text":"need","style":{"bold":true}},{"type":"text","text":" to do anything as my DataFrame isn't huge (~500k rows and 5 columns. Of which 2 are Floats and 3 are \"categorical\") And so it fits into RAM regardless but in the past I would've used the function to convert columns to categorical arrays for faster filtering and such. I also found references to PooledArrays which I'm not familiar with. Thanks in advanced."}]}]}],"thread_ts":"1614788062.183000","reply_count":2,"reply_users_count":1,"latest_reply":"1614788239.183300","reply_users":["U67431ELR"],"subscribed":false},{"client_msg_id":"f653e31a-6aab-4410-9ecb-555efd546c7a","type":"message","text":"Is there a way to use the GroupKey from a grouped dataframe in a dict? I am able to put the GroupKey from the grouped df as the key in a dict, but I am having trouble hashing it. It seems like the GroupKey from a grouped df is like its own type. I want to make it easy to hash after I have transferred stuff into a dict.\n```n = 10\nA= rand(Normal(0,1),n)\nB= rand(Normal(1,1),n)\nC = rand(Normal(-1,1),n)\nD = rand(Normal(0.5,1),n)\n\nsimdata = DataFrame(Arm = vcat(fill(\"A\",n),fill(\"B\",n),fill(\"C\",n),fill(\"D\",n)),\n                    Y = vcat(A,B,C,D))\n\n\nsimgdf = groupby(simdata,:Arm)\n\nfunction CreateBandit(data,groups,response)\n    gdf = groupby(data,groups)\n    QN = Dict(key=&gt;(Q=0,n=0) for key in keys(gdf))\n    return(QN)\nend \n\na=CreateBandit(simdata,:Arm,:Y)\na[\"A\"] #doesn't work \na[(Arm=\"A\",)] #doesn't work ```\n","user":"U01EF0QVAB0","ts":"1614792955.186300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/7KfI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a way to use the GroupKey from a grouped dataframe in a dict? I am able to put the GroupKey from the grouped df as the key in a dict, but I am having trouble hashing it. It seems like the GroupKey from a grouped df is like its own type. I want to make it easy to hash after I have transferred stuff into a dict.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"n = 10\nA= rand(Normal(0,1),n)\nB= rand(Normal(1,1),n)\nC = rand(Normal(-1,1),n)\nD = rand(Normal(0.5,1),n)\n\nsimdata = DataFrame(Arm = vcat(fill(\"A\",n),fill(\"B\",n),fill(\"C\",n),fill(\"D\",n)),\n                    Y = vcat(A,B,C,D))\n\n\nsimgdf = groupby(simdata,:Arm)\n\nfunction CreateBandit(data,groups,response)\n    gdf = groupby(data,groups)\n    QN = Dict(key=>(Q=0,n=0) for key in keys(gdf))\n    return(QN)\nend \n\na=CreateBandit(simdata,:Arm,:Y)\na[\"A\"] #doesn't work \na[(Arm=\"A\",)] #doesn't work "}]},{"type":"rich_text_section","elements":[]}]}]},{"client_msg_id":"3a76cd94-1660-4f93-87bb-bff37d2c261e","type":"message","text":"convert it to a `NamedTuple` with `NamedTuple`","user":"U9VG1AYSG","ts":"1614792999.186600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PaF6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"convert it to a "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" with "},{"type":"text","text":"NamedTuple","style":{"code":true}}]}]}],"thread_ts":"1614792999.186600","reply_count":2,"reply_users_count":1,"latest_reply":"1614793208.189600","reply_users":["U01EF0QVAB0"],"subscribed":false},{"client_msg_id":"20ffe7eb-f87f-4a0a-8cfe-523de192b786","type":"message","text":"that is, turn it into a `NamedTuple` when you construct the dict `Dict(NamedTuple(k)=&gt;(Q=0,n=0) for k \\in keys(gdf))`","user":"U9VG1AYSG","ts":"1614793047.187400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9L6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that is, turn it into a "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" when you construct the dict "},{"type":"text","text":"Dict(NamedTuple(k)=>(Q=0,n=0) for k \\in keys(gdf))","style":{"code":true}}]}]}],"reactions":[{"name":"correct_answer","users":["UBF9YRB6H","U01EF0QVAB0"],"count":2}]},{"client_msg_id":"93338f14-7974-4357-a38f-ada67a713531","type":"message","text":"yeah, `keys(gdf)` returns GroupKeys objects, which are unique to DataFrames.","user":"UBF9YRB6H","ts":"1614793136.188100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u3v6U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, "},{"type":"text","text":"keys(gdf)","style":{"code":true}},{"type":"text","text":" returns GroupKeys objects, which are unique to DataFrames."}]}]}]},{"client_msg_id":"8e8d785b-78e7-444d-8104-e381a8b8ac9a","type":"message","text":"I wonder if it would be worth it to ensure that the `hash` of the grouped dataframe key is the same as the hash of the NamedTuple.  Kind of hard to think through whether that would solve this in all cases or if it would cause something else to go wrong","user":"U9VG1AYSG","ts":"1614793198.189500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=aW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I wonder if it would be worth it to ensure that the "},{"type":"text","text":"hash","style":{"code":true}},{"type":"text","text":" of the grouped dataframe key is the same as the hash of the NamedTuple.  Kind of hard to think through whether that would solve this in all cases or if it would cause something else to go wrong"}]}]}]},{"client_msg_id":"29e79e6b-e2ea-4622-9ca0-ebffb1f4f821","type":"message","text":"We touched related issues at <https://github.com/JuliaData/DataFrames.jl/issues/2305>, but I don't see anything that says that `hash` shouldn't give the same result for `GroupKey` and `NamedTuple`. <@U8JAMQGQY>?","user":"U67431ELR","ts":"1614802744.190900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qGRNw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We touched related issues at "},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/issues/2305"},{"type":"text","text":", but I don't see anything that says that "},{"type":"text","text":"hash","style":{"code":true}},{"type":"text","text":" shouldn't give the same result for "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":". "},{"type":"user","user_id":"U8JAMQGQY"},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"00076222-a352-4b51-b947-8a3c8c6fa4fd","type":"message","text":"The crucial thing is that two `GroupKey`s that have different parents are currently not equal according to `==` nor `isequal`:\n```julia&gt; df1 = DataFrame(a=[1, 2, missing]);\n\njulia&gt; df2 = copy(df1);\n\njulia&gt; gdf1 = groupby(df1, :a);\n\njulia&gt; gdf2 = groupby(df2, :a);\n\njulia&gt; gk1 = keys(gdf1);\n\njulia&gt; gk2 = keys(gdf2);\n\njulia&gt; gk1[1] == gk2[1]\nfalse\n\njulia&gt; isequal(gk1[1], gk2[1])\nfalse```\nI am not sure what would be the use-case of making `hash` of `NamedTuple` and `GroupKey` equal (it can be done, but what would be the benefit exactly?). In particular this would increase the cost of computing hash for `GroupKey` (but this is a secondary consideration a primary one is what would we want to use it for?).","user":"U8JAMQGQY","ts":"1614812288.194900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WMUG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The crucial thing is that two "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":"s that have different parents are currently not equal according to "},{"type":"text","text":"==","style":{"code":true}},{"type":"text","text":" nor "},{"type":"text","text":"isequal","style":{"code":true}},{"type":"text","text":":\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> df1 = DataFrame(a=[1, 2, missing]);\n\njulia> df2 = copy(df1);\n\njulia> gdf1 = groupby(df1, :a);\n\njulia> gdf2 = groupby(df2, :a);\n\njulia> gk1 = keys(gdf1);\n\njulia> gk2 = keys(gdf2);\n\njulia> gk1[1] == gk2[1]\nfalse\n\njulia> isequal(gk1[1], gk2[1])\nfalse"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I am not sure what would be the use-case of making "},{"type":"text","text":"hash","style":{"code":true}},{"type":"text","text":" of "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" equal (it can be done, but what would be the benefit exactly?). In particular this would increase the cost of computing hash for "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" (but this is a secondary consideration a primary one is what would we want to use it for?)."}]}]}],"reactions":[{"name":"+1","users":["U680THK2S","UBF9YRB6H","U6A936746"],"count":3}]},{"client_msg_id":"1033b565-3c72-425c-84ba-edd3a088570c","type":"message","text":"The use is just like the example above, suppose you want to use one group key in another `GroupedDataFrame` or any other dictionary","user":"U9VG1AYSG","ts":"1614813768.198600","team":"T68168MUP","edited":{"user":"U9VG1AYSG","ts":"1614813799.000000"},"blocks":[{"type":"rich_text","block_id":"NGvc4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The use is just like the example above, suppose you want to use one group key in another "},{"type":"text","text":"GroupedDataFrame","style":{"code":true}},{"type":"text","text":" or any other dictionary"}]}]}]},{"client_msg_id":"9361d011-4db3-40b1-9741-b1585f4728d9","type":"message","text":"but since you can already do this with conversion via `NamedTuple`, I'm not necessarily asserting that it's worth changing","user":"U9VG1AYSG","ts":"1614813783.199300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"83g0r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but since you can already do this with conversion via "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":", I'm not necessarily asserting that it's worth changing"}]}]}]},{"client_msg_id":"081a481c-cd77-4b6d-9919-b493f8e7e5bd","type":"message","text":"I suppose the question is partly do we want to make different kinds of \"row-like\" datastructures to be `isequal`? We don't really have any interface or supertype for \"row-like\" things (beyond the Tables.jl definition which is extremely light weight) so this could be pretty challenging. In other parts of Julia we don't e.g. compare `(1,2,3)` and `[1,2,3]` as `isequal` even though they iterate and index the same way, so it wouldn't make sense for all kinds of `NamedTuple` and `DataFrameRow` and `Dict{Symbol, ...}` and so-on all have the same hash. (Plus, really, it can only make sense on ordered containers, meaning `Dict{Symbol, ...}` can't be as row-like as the others).","user":"U66QZ3QF3","ts":"1614813801.199600","team":"T68168MUP","edited":{"user":"U66QZ3QF3","ts":"1614813823.000000"},"blocks":[{"type":"rich_text","block_id":"XhHYL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I suppose the question is partly do we want to make different kinds of \"row-like\" datastructures to be "},{"type":"text","text":"isequal","style":{"code":true}},{"type":"text","text":"? We don't really have any interface or supertype for \"row-like\" things (beyond the Tables.jl definition which is extremely light weight) so this could be pretty challenging. In other parts of Julia we don't e.g. compare "},{"type":"text","text":"(1,2,3)","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"[1,2,3]","style":{"code":true}},{"type":"text","text":" as "},{"type":"text","text":"isequal","style":{"code":true}},{"type":"text","text":" even though they iterate and index the same way, so it wouldn't make sense for all kinds of "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"DataFrameRow","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"Dict{Symbol, ...}","style":{"code":true}},{"type":"text","text":" and so-on all have the same hash. (Plus, really, it can only make sense on ordered containers, meaning "},{"type":"text","text":"Dict{Symbol, ...}","style":{"code":true}},{"type":"text","text":" can't be as row-like as the others)."}]}]}]},{"client_msg_id":"ee2049e6-596a-43ef-a671-e9aee306e81f","type":"message","text":"this was *NOT* my suggestion, I think maybe `GroupKey` should be equal to a NamedTuple because they are so similar and more crucially because this makes `GroupKey`s comparable across different dataframes, but I don't think that concept generalizes to all rows","user":"U9VG1AYSG","ts":"1614813880.200800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3tsr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this was "},{"type":"text","text":"NOT","style":{"bold":true}},{"type":"text","text":" my suggestion, I think maybe "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" should be equal to a NamedTuple because they are so similar and more crucially because this makes `GroupKey`s comparable across different dataframes, but I don't think that concept generalizes to all rows"}]}]}]},{"client_msg_id":"cec61dea-c879-4706-bae7-fb5f0646f192","type":"message","text":"for what it's worth, I had already tried things like what <@U01EF0QVAB0> suggested above, so it may not be that rare a use case","user":"U9VG1AYSG","ts":"1614813934.201900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jgeC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"for what it's worth, I had already tried things like what "},{"type":"user","user_id":"U01EF0QVAB0"},{"type":"text","text":" suggested above, so it may not be that rare a use case"}]}]}]},{"client_msg_id":"bb37b899-cf56-4caf-aef7-f224d7ccf1b5","type":"message","text":"but again, just to emphasize, I don't see this as a serious problem, because it's so easy to just make it a `NamedTuple`.  Were that not the case it would seem like a much bigger deal","user":"U9VG1AYSG","ts":"1614813993.203200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NQDGZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but again, just to emphasize, I don't see this as a serious problem, because it's so easy to just make it a "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":".  Were that not the case it would seem like a much bigger deal"}]}]}]},{"client_msg_id":"5543d83e-0cee-4ce9-9b68-561223fe5eda","type":"message","text":"^ I don't think it's super relevant to the issue about indexing, but I would also like to see a more uniform concept of a Row. It's a tricky problem, see here: <https://github.com/JuliaData/DataFrames.jl/issues/2576>","user":"UBF9YRB6H","ts":"1614814173.204400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AvVI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"^ I don't think it's super relevant to the issue about indexing, but I would also like to see a more uniform concept of a Row. It's a tricky problem, see here: "},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/issues/2576"}]}]}]},{"client_msg_id":"d9a9db66-78bb-4b29-bc6b-d0c38cdf4d3a","type":"message","text":"to expand a bit more on my response to <@U66QZ3QF3> comment: I think the difference in `GroupKey`s case is that these objects *themselves* are *not* comparable across different dataframes.  This is *ONLY* true for `GroupKey`, even `DataFrameRow` gives the expected result:\n```julia&gt; df1 = DataFrame(A=[1,2], B=[3,4])\n2×2 DataFrame\n Row │ A      B\n     │ Int64  Int64\n─────┼──────────────\n   1 │     1      3\n   2 │     2      4\n\njulia&gt; df2 = DataFrame(A=[2,1], B=[4,3])\n2×2 DataFrame\n Row │ A      B\n     │ Int64  Int64\n─────┼──────────────\n   1 │     2      4\n   2 │     1      3\n\njulia&gt; DataFrameRow(df1, 1)\nDataFrameRow\n Row │ A      B\n     │ Int64  Int64\n─────┼──────────────\n   1 │     1      3\n\njulia&gt; DataFrameRow(df1, 1) == DataFrameRow(df2, 2)```\nSo I very much see this as a special case in which `GroupKey` isn't being quite consistent with other \"row-like\" concepts.","user":"U9VG1AYSG","ts":"1614814344.206000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6Q0Y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"to expand a bit more on my response to "},{"type":"user","user_id":"U66QZ3QF3"},{"type":"text","text":" comment: I think the difference in `GroupKey`s case is that these objects "},{"type":"text","text":"themselves","style":{"bold":true}},{"type":"text","text":" are "},{"type":"text","text":"not","style":{"bold":true}},{"type":"text","text":" comparable across different dataframes.  This is "},{"type":"text","text":"ONLY","style":{"bold":true}},{"type":"text","text":" true for "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":", even "},{"type":"text","text":"DataFrameRow","style":{"code":true}},{"type":"text","text":" gives the expected result:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> df1 = DataFrame(A=[1,2], B=[3,4])\n2×2 DataFrame\n Row │ A      B\n     │ Int64  Int64\n─────┼──────────────\n   1 │     1      3\n   2 │     2      4\n\njulia> df2 = DataFrame(A=[2,1], B=[4,3])\n2×2 DataFrame\n Row │ A      B\n     │ Int64  Int64\n─────┼──────────────\n   1 │     2      4\n   2 │     1      3\n\njulia> DataFrameRow(df1, 1)\nDataFrameRow\n Row │ A      B\n     │ Int64  Int64\n─────┼──────────────\n   1 │     1      3\n\njulia> DataFrameRow(df1, 1) == DataFrameRow(df2, 2)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"So I very much see this as a special case in which "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" isn't being quite consistent with other \"row-like\" concepts."}]}]}]},{"client_msg_id":"89cc4259-9854-4796-92bd-823d801920c3","type":"message","text":"and I therefore think maybe something should be changed for `GroupKey`, but this does not necessarily imply that `DataFrameRow`, `GroupKey` and `NamedTuple` should all be comparable to each other","user":"U9VG1AYSG","ts":"1614814384.206700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ms9A","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and I therefore think maybe something should be changed for "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":", but this does not necessarily imply that "},{"type":"text","text":"DataFrameRow","style":{"code":true}},{"type":"text","text":", "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" should all be comparable to each other"}]}]}],"reactions":[{"name":"+1","users":["UBF9YRB6H"],"count":1}]},{"client_msg_id":"3c6e8b2a-27bb-4321-aaf3-cbdf2f1d8b68","type":"message","text":"so the full implementation of this suggestion would mean that `GroupKey` would remain the same internally for sake of efficiency, but behave to everything else like a `NamedTuple`.  i.e. it's a special case because it needs the current representation for efficiency, but otherwise it's essentially just a named tuple","user":"U9VG1AYSG","ts":"1614814508.207800","team":"T68168MUP","edited":{"user":"U9VG1AYSG","ts":"1614814542.000000"},"blocks":[{"type":"rich_text","block_id":"6smc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so the full implementation of this suggestion would mean that "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" would remain the same internally for sake of efficiency, but behave to everything else like a "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":".  i.e. it's a special case because it needs the current representation for efficiency, but otherwise it's essentially just a named tuple"}]}]}]},{"client_msg_id":"ceb08099-cd79-4c17-895d-5e6dcbb05374","type":"message","text":"this is already sort of how `DataFrameRow` works (though I haven't checked hashing)","user":"U9VG1AYSG","ts":"1614814571.208300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"r9qR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this is already sort of how "},{"type":"text","text":"DataFrameRow","style":{"code":true}},{"type":"text","text":" works (though I haven't checked hashing)"}]}]}]},{"client_msg_id":"8a0e3de1-4715-4f31-af5b-412ddc3fae8e","type":"message","text":"The key question is: do we want to allow `GroupKey` from one data frame to be used in another data frame for lookup. The initial design assumed that the answer is NO for safety reasons and one should do such a process via `NamedTuple` explicitly. But - as usual - we can discuss it.","user":"U8JAMQGQY","ts":"1614814910.209800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZBjr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The key question is: do we want to allow "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" from one data frame to be used in another data frame for lookup. The initial design assumed that the answer is NO for safety reasons and one should do such a process via "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" explicitly. But - as usual - we can discuss it."}]}]}]},{"client_msg_id":"eb2fa8e4-454b-4bfd-a4f9-047cc9bedbc9","type":"message","text":"Ok, thanks, I think I understand.\n\n<@U8JAMQGQY> I suppose if the users can get at it, maybe you need to communicate that it is in fact a _token_ that is valid for a particular (grouped) data frame. Perhaps you could even have both a `GroupKey` (value-based, row-like, can be used in other data frames) and `GroupToken` (fast for internal algorithms, only valid for it's \"parent\" dataframe)?","user":"U66QZ3QF3","ts":"1614816258.213000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fvPsu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok, thanks, I think I understand.\n\n"},{"type":"user","user_id":"U8JAMQGQY"},{"type":"text","text":" I suppose if the users can get at it, maybe you need to communicate that it is in fact a "},{"type":"text","text":"token","style":{"italic":true}},{"type":"text","text":" that is valid for a particular (grouped) data frame. Perhaps you could even have both a "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" (value-based, row-like, can be used in other data frames) and "},{"type":"text","text":"GroupToken","style":{"code":true}},{"type":"text","text":" (fast for internal algorithms, only valid for it's \"parent\" dataframe)?"}]}]}]},{"client_msg_id":"f6ad7cd5-06cc-405f-a88e-d9c29cbb33a6","type":"message","text":"well that's kind of the idea, there is the possibility that instead of forbidding this we'd just do the conversion automatically, that's all","user":"U9VG1AYSG","ts":"1614816347.213700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"a15","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"well that's kind of the idea, there is the possibility that instead of forbidding this we'd just do the conversion automatically, that's all"}]}]}]},{"client_msg_id":"ed30c9b8-5659-4eb0-9e73-29d39122805e","type":"message","text":"when we started talking about this I was fairly indifferent, but as I think more about the inconsistency with other \"row-like\" objects, all of which are comparable between different dataframes, I'm increasingly thinking that yes, `GroupKey` should also be by default","user":"U9VG1AYSG","ts":"1614816417.214800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3NhQw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"when we started talking about this I was fairly indifferent, but as I think more about the inconsistency with other \"row-like\" objects, all of which are comparable between different dataframes, I'm increasingly thinking that yes, "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" should also be by default"}]}]}]},{"client_msg_id":"1e5c1d23-e2a1-4630-8d94-a76602bb7cff","type":"message","text":"I haven't looked at the implementation - but if you can afford to carry the parent reference as well as the token in `GroupKey`, and do a quick `===`  check on the parent when indexing, then that would be OK. (Sometimes you can use `@inbounds` and `@boundscheck` as a hack to elide the `===` check for e.g. internal algorithms)","user":"U66QZ3QF3","ts":"1614816534.217200","team":"T68168MUP","edited":{"user":"U66QZ3QF3","ts":"1614816568.000000"},"blocks":[{"type":"rich_text","block_id":"UHp+S","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I haven't looked at the implementation - but if you can afford to carry the parent reference as well as the token in "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":", and do a quick "},{"type":"text","text":"===","style":{"code":true}},{"type":"text","text":"  check on the parent when indexing, then that would be OK. (Sometimes you can use "},{"type":"text","text":"@inbounds","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"@boundscheck","style":{"code":true}},{"type":"text","text":" as a hack to elide the "},{"type":"text","text":"===","style":{"code":true}},{"type":"text","text":" check for e.g. internal algorithms)"}]}]}]},{"client_msg_id":"0495b4d8-cb00-4f9c-8cd1-16dce7b51eae","type":"message","text":"Could you open an issue for this please? I think it is not a problem to allow for cross-data frame usage of `GroupKey`. We simply used a more restrictive approach in the past. Also as <@U66QZ3QF3> notes - currently the design we use means that `GroupKey` is very fast (effectively it is just an integer with metadata linking it to a parent)","user":"U8JAMQGQY","ts":"1614816598.218400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rHG+v","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Could you open an issue for this please? I think it is not a problem to allow for cross-data frame usage of "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":". We simply used a more restrictive approach in the past. Also as "},{"type":"user","user_id":"U66QZ3QF3"},{"type":"text","text":" notes - currently the design we use means that "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" is very fast (effectively it is just an integer with metadata linking it to a parent)"}]}]}],"reactions":[{"name":"+1","users":["UBF9YRB6H"],"count":1}]},{"client_msg_id":"03284e19-8560-42a1-8572-cc034fed1abf","type":"message","text":"issue here: <https://github.com/JuliaData/DataFrames.jl/issues/2639>","user":"U9VG1AYSG","ts":"1614816933.218700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7ML","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"issue here: "},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/issues/2639"}]}]}]},{"client_msg_id":"ce0b3f50-978c-4c6f-a5ba-d557011ea19e","type":"message","text":"btw, what I said about hashing before was rather idiotic.  Surely the whole reason `GroupKey` exists is that it obviates the need for hashing at all.  I haven't formed an opinion yet about what the implmentation should look like, but I am coming around to the idea that all \"row-like\" objects of the same type should be comparable across dataframes","user":"U9VG1AYSG","ts":"1614817178.220000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KlAzl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"btw, what I said about hashing before was rather idiotic.  Surely the whole reason "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" exists is that it obviates the need for hashing at all.  I haven't formed an opinion yet about what the implmentation should look like, but I am coming around to the idea that all \"row-like\" objects of the same type should be comparable across dataframes"}]}]}]},{"client_msg_id":"6edd8a52-fcd4-4b19-b946-72f04ae841fe","type":"message","text":"Yeah, the row-like idea is good. But we shouldn't do anything that hurts performance of the lookup in a grouped data frame","user":"UBF9YRB6H","ts":"1614817263.220700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qBk=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, the row-like idea is good. But we shouldn't do anything that hurts performance of the lookup in a grouped data frame"}]}]}]},{"client_msg_id":"cc92d17c-f931-4ecd-967f-cdf4ca915151","type":"message","text":"Yeah, I agree with that.  Ideally I think `GroupKey` should be allowed between DataFrames, but it would be silly to make anything more than a trivial performance sacrifice for it, as the desired functionality already exists with `NamedTuple` and is extremely simple once you understand what's going on","user":"U9VG1AYSG","ts":"1614817387.222000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Eju","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, I agree with that.  Ideally I think "},{"type":"text","text":"GroupKey","style":{"code":true}},{"type":"text","text":" should be allowed between DataFrames, but it would be silly to make anything more than a trivial performance sacrifice for it, as the desired functionality already exists with "},{"type":"text","text":"NamedTuple","style":{"code":true}},{"type":"text","text":" and is extremely simple once you understand what's going on"}]}]}]},{"client_msg_id":"fd814d31-85de-4331-98dc-fbc02ff25578","type":"message","text":"So I am encountering a very strange bug while trying to implement the Multi Armed Bandit problem. My code randomly will say `ERROR: KeyError: key NamedTuple[(Arm = \"C\",)] not found`  but it breaks randomly on an iteration of the loop, and I can't figure out why that would happen considering that its clearly able to find the key in previous iterations but it can't find it all the time? This is very strange and I don't know whats going on or how to debug an error that happens randomly in an iteration but not others. Its all simulated data and basically my function Learn!(band,20) is randomly breaking. I wonder if its related to the hash <@U9VG1AYSG> mentioned before?\n\n```using Statistics, StatsBase, Distributions \nusing DataFrames\n\nmutable struct Bandit\n    QN::Dict{NamedTuple,Dict{Symbol,Real}}\n    Y::Dict{NamedTuple,Array{Float64,1}}\n    keylist::Vector{NamedTuple}\nend \n\nfunction CreateBandit(data,groups,response)\n    gdf = groupby(data,groups)\n    QN = Dict{NamedTuple,Dict{Symbol,Real}}()\n    Y = Dict{NamedTuple,Array{Float64,1}}()\n    for key in keys(gdf)\n        QN[NamedTuple(key)] = Dict(:Q=&gt;rand(Uniform(0,1e-10)),:n=&gt;0)\n        Y[NamedTuple(key)] = gdf[key][:,response]\n    end \n    return(Bandit(QN,Y,collect(keys(QN))))\nend \n\nBase.getindex(bandit::Bandit,key) = Base.getindex(bandit.QN,key)\n\nfunction Base.argmax(bandit::Bandit)\n    keylist = bandit.keylist\n    idx = argmax(getindex.(values(bandit.QN),:Q))\n    return(keylist[idx])\nend \n\nfunction Learn!(bandit::Bandit,steps;ϵ=0.05,η=nothing)\n    lrn = ifelse(isnothing(η),0,1)\n    for i=1:steps\n        u = rand(Uniform(0,1))\n        if u &lt;= ϵ\n            action = sample(bandit.keylist,1)\n        else\n            action = argmax(bandit)\n        end \n        Qcurrent = bandit[action][:Q]\n        Reward = sample(bandit.Y[action],1)[1]\n        diff = Reward - Qcurrent\n        curr = bandit[action]\n        curr[:n] += 1\n        if lrn == 0 \n            curr[:Q] += 1/curr[:n] .* diff\n        else\n            curr[:Q] += η .* diff\n        end\n    end\n    return(bandit)\nend \n\n#Simulate Data \nn = 100\nA= rand(Normal(0,1),n)\nB= rand(Normal(1,1),n)\nC = rand(Normal(-1,1),n)\nD = rand(Normal(0.5,1),n)\n\nsimdata = DataFrame(Arm = vcat(fill(\"A\",n),fill(\"B\",n),fill(\"C\",n),fill(\"D\",n)),\n                    Y = vcat(A,B,C,D))\n\n#Use Bandit \n\nband=CreateBandit(simdata,:Arm,:Y)            \nLearn!(band,20) #This breaks randomly on an iteration ```","user":"U01EF0QVAB0","ts":"1614836707.226300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"J23yu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So I am encountering a very strange bug while trying to implement the Multi Armed Bandit problem. My code randomly will say "},{"type":"text","text":"ERROR: KeyError: key NamedTuple[(Arm = \"C\",)] not found","style":{"code":true}},{"type":"text","text":"  but it breaks randomly on an iteration of the loop, and I can't figure out why that would happen considering that its clearly able to find the key in previous iterations but it can't find it all the time? This is very strange and I don't know whats going on or how to debug an error that happens randomly in an iteration but not others. Its all simulated data and basically my function Learn!(band,20) is randomly breaking. I wonder if its related to the hash "},{"type":"user","user_id":"U9VG1AYSG"},{"type":"text","text":" mentioned before?\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Statistics, StatsBase, Distributions \nusing DataFrames\n\nmutable struct Bandit\n    QN::Dict{NamedTuple,Dict{Symbol,Real}}\n    Y::Dict{NamedTuple,Array{Float64,1}}\n    keylist::Vector{NamedTuple}\nend \n\nfunction CreateBandit(data,groups,response)\n    gdf = groupby(data,groups)\n    QN = Dict{NamedTuple,Dict{Symbol,Real}}()\n    Y = Dict{NamedTuple,Array{Float64,1}}()\n    for key in keys(gdf)\n        QN[NamedTuple(key)] = Dict(:Q=>rand(Uniform(0,1e-10)),:n=>0)\n        Y[NamedTuple(key)] = gdf[key][:,response]\n    end \n    return(Bandit(QN,Y,collect(keys(QN))))\nend \n\nBase.getindex(bandit::Bandit,key) = Base.getindex(bandit.QN,key)\n\nfunction Base.argmax(bandit::Bandit)\n    keylist = bandit.keylist\n    idx = argmax(getindex.(values(bandit.QN),:Q))\n    return(keylist[idx])\nend \n\nfunction Learn!(bandit::Bandit,steps;ϵ=0.05,η=nothing)\n    lrn = ifelse(isnothing(η),0,1)\n    for i=1:steps\n        u = rand(Uniform(0,1))\n        if u <= ϵ\n            action = sample(bandit.keylist,1)\n        else\n            action = argmax(bandit)\n        end \n        Qcurrent = bandit[action][:Q]\n        Reward = sample(bandit.Y[action],1)[1]\n        diff = Reward - Qcurrent\n        curr = bandit[action]\n        curr[:n] += 1\n        if lrn == 0 \n            curr[:Q] += 1/curr[:n] .* diff\n        else\n            curr[:Q] += η .* diff\n        end\n    end\n    return(bandit)\nend \n\n#Simulate Data \nn = 100\nA= rand(Normal(0,1),n)\nB= rand(Normal(1,1),n)\nC = rand(Normal(-1,1),n)\nD = rand(Normal(0.5,1),n)\n\nsimdata = DataFrame(Arm = vcat(fill(\"A\",n),fill(\"B\",n),fill(\"C\",n),fill(\"D\",n)),\n                    Y = vcat(A,B,C,D))\n\n#Use Bandit \n\nband=CreateBandit(simdata,:Arm,:Y)            \nLearn!(band,20) #This breaks randomly on an iteration "}]}]}]}]}