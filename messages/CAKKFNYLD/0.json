{"cursor": 0, "messages": [{"client_msg_id":"276c16fe-02d9-4215-b422-1688e1eee8ce","type":"message","text":"Hi there! I will be looking for info about Automa.jl in a couple of weeks. Is that the right place ? :slightly_smiling_face:","user":"U01FR2HFJ7M","ts":"1607995590.151400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YBBG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi there! I will be looking for info about Automa.jl in a couple of weeks. Is that the right place ? "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"c47babcb-f114-4c66-91d3-b7d0d064a092","type":"message","text":"probably - if you haven't already, I recomend this as a place to start: <https://biojulia.net/post/automa1/>","user":"U8JP5B9T2","ts":"1607997392.152200","team":"T68168MUP","attachments":[{"service_name":"BioJulia","title":"Tutorial to Automa: Part 1 | BioJulia","title_link":"https://biojulia.net/post/automa1/","text":"Find this notebook at <https://github.com/jakobnissen/automa_tutorial> In bioinformatics, we have a saying: The first step of any bioinformatics project is to define a new file format, incompatible with all previous ones. The situation might not be quite as bad as the saying implies, but it is true that we have a lot of different file formats, representing the various kinds of data we work with. For that reason, creating file parsers is a central task in bioinformatics, and has almost become a craft in itself.","fallback":"BioJulia: Tutorial to Automa: Part 1 | BioJulia","thumb_url":"https://BioJulia.github.io/images/logo_huf2e28fc1e802707079b8e0ffee62f4dc_19447_300x300_fit_lanczos_2.png","ts":1598797689,"from_url":"https://biojulia.net/post/automa1/","thumb_width":300,"thumb_height":300,"service_icon":"https://biojulia.net/images/icon_huf2e28fc1e802707079b8e0ffee62f4dc_19447_192x192_fill_lanczos_center_2.png","id":1,"original_url":"https://biojulia.net/post/automa1/"}],"blocks":[{"type":"rich_text","block_id":"Q/6ZT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"probably - if you haven't already, I recomend this as a place to start: "},{"type":"link","url":"https://biojulia.net/post/automa1/"}]}]}],"reactions":[{"name":"+1","users":["U01FR2HFJ7M","U6QGE7S86","USBKT1275"],"count":3}]},{"client_msg_id":"0f994bf7-e425-4a67-9609-6640638dc8c7","type":"message","text":"Super stoked to announce that my fork of PopGen.jl will be merging into BioJulia/PopGen.jl and continue living there :smile:","user":"UM4TSHKF1","ts":"1608055262.153900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kzPUy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Super stoked to announce that my fork of PopGen.jl will be merging into BioJulia/PopGen.jl and continue living there "},{"type":"emoji","name":"smile"}]}]}],"reactions":[{"name":"clapping","users":["U69BL50BF","U7HAYKY9X","U8JP5B9T2","UCAFZ51L3","U01BR0AKMRQ","UB197FRCL","U6QGE7S86","U9TCDH0E7","ULWFF2Z8U"],"count":9},{"name":"fast_parrot","users":["U69BL50BF","U7HAYKY9X","U6QGE7S86"],"count":3}]},{"type":"message","text":"","user":"USU9FRPEU","ts":"1608072977.155100","team":"T68168MUP","attachments":[{"fallback":"[December 15th, 2020 5:53 PM] ayman: In biology we deal with alot of large compressed files.\n\nCommon file extensions include .fasta.gz and .vcf.gz\n\nCan’t seem to find a good out of the box readers that use multithreading for regular files and compressed files.","ts":"1608072815.225800","author_id":"U01FAHWCMFF","author_subname":"Ayman Al Baz","channel_id":"C6A044SQH","channel_name":"helpdesk","is_msg_unfurl":true,"is_reply_unfurl":true,"text":"In biology we deal with alot of large compressed files.\n\nCommon file extensions include .fasta.gz and .vcf.gz\n\nCan’t seem to find a good out of the box readers that use multithreading for regular files and compressed files.","author_name":"Ayman Al Baz","author_link":"https://julialang.slack.com/team/U01FAHWCMFF","author_icon":"https://avatars.slack-edge.com/2020-11-23/1516965530134_1cf6ed3767c34aaf6d40_48.png","mrkdwn_in":["text"],"color":"D0D0D0","from_url":"https://julialang.slack.com/archives/C6A044SQH/p1608072815225800?thread_ts=1608072566225200&cid=C6A044SQH","is_share":true,"footer":"From a thread in #helpdesk"}]},{"client_msg_id":"c2631a6d-006b-4bcb-8ffd-503f6b6490d1","type":"message","text":"Thanks for reposting here, ya I’m just wondering if there were any libraries that could read large .Fastq.gz and .vcf.gz (primarily this) using multithreading. I know of single threaded readers but I’m just looking for faster solutions","user":"U01FAHWCMFF","ts":"1608073307.156900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"noTy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for reposting here, ya I’m just wondering if there were any libraries that could read large .Fastq.gz and .vcf.gz (primarily this) using multithreading. I know of single threaded readers but I’m just looking for faster solutions"}]}]}]},{"client_msg_id":"a93f8535-a961-4de8-89c0-a7e1fdf7f282","type":"message","text":"<@UC2AEGPC2> is probably the one to contact about this","user":"USU9FRPEU","ts":"1608073689.158500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KtW","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UC2AEGPC2"},{"type":"text","text":" is probably the one to contact about this"}]}]}]},{"client_msg_id":"e58841cd-7840-4c6e-b982-866b4bd9d4b5","type":"message","text":"I think <@U7HAYKY9X> has also thought about how to make automa parsers multithreaded, though I don't know if any work has been done there.","user":"U8JP5B9T2","ts":"1608074164.159500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9LHkn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think "},{"type":"user","user_id":"U7HAYKY9X"},{"type":"text","text":" has also thought about how to make automa parsers multithreaded, though I don't know if any work has been done there."}]}]}]},{"client_msg_id":"f906d99d-d3fc-46f8-bf6d-a9edc549981c","type":"message","text":"There are not, unfortunately. The bottleneck in reading these files is the decompression, so perhaps you could call a binary for multithreaded decompression like pigz? If you're willing to have a slightly lower compression ratio, you can compress it in the BGZF format and read it with CodecBGZF.jl, which is quite fast (and support random access).","user":"U7HAYKY9X","ts":"1608103489.165800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Jcpj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There are not, unfortunately. The bottleneck in reading these files is the decompression, so perhaps you could call a binary for multithreaded decompression like pigz? If you're willing to have a slightly lower compression ratio, you can compress it in the BGZF format and read it with CodecBGZF.jl, which is quite fast (and support random access)."}]}]}],"thread_ts":"1608103489.165800","reply_count":2,"reply_users_count":2,"latest_reply":"1608196142.181600","reply_users":["UM4TSHKF1","U7HAYKY9X"],"subscribed":false},{"client_msg_id":"c9c60331-d5b2-47ae-bde0-055af044b0c2","type":"message","text":"Speaking more broadly, Automa (that is, parsing itself) will probably never be multithreaded since the process is inherently serial (but it can usually parse at several GB/second, do it'll basically never be the problem). So it comes down to implementing a multithreaded decompressor package in Julia. Which is probably really hard","user":"U7HAYKY9X","ts":"1608103721.169000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OSmOE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Speaking more broadly, Automa (that is, parsing itself) will probably never be multithreaded since the process is inherently serial (but it can usually parse at several GB/second, do it'll basically never be the problem). So it comes down to implementing a multithreaded decompressor package in Julia. Which is probably really hard"}]}]}]},{"client_msg_id":"fa5c99f7-868c-442b-95eb-15bf039c0f24","type":"message","text":"Hm, perhaps it would be possible to do the *parsing* in one thread, but then offload all the *work* to another thread. It would have to be done on a parser-by-parser level. Probably not needed for FASTX at least (not sure about VCF, I think that parser is a little unmaintained and rusty)","user":"U7HAYKY9X","ts":"1608106009.170600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vTtIE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hm, perhaps it would be possible to do the "},{"type":"text","text":"parsing","style":{"bold":true}},{"type":"text","text":" in one thread, but then offload all the "},{"type":"text","text":"work","style":{"bold":true}},{"type":"text","text":" to another thread. It would have to be done on a parser-by-parser level. Probably not needed for FASTX at least (not sure about VCF, I think that parser is a little unmaintained and rusty)"}]}]}]},{"client_msg_id":"b58ec672-c674-4adb-8b28-c904d705c2e0","type":"message","text":"Question (I'm quite naive on parallelization) -\n\nIs it possible to have state machines that can start somewhere in the middle, given sufficient signal? For example, in a fastq file, I could jump to the middle of the file, and start scanning until I hit a newline followed by `@` - There are a bunch of other unambiguous entry points to certain states. So I could just say \"I don't know my state until I hit some signal.\" I would imagine you'd waste a bit of time reading the same bytes twice, but it could be worth it (or maybe not it it's really multiple GB / sec)\n\nI definitely think being able to kick state information out to different threads so that the actual bytes can be processed could make a big difference","user":"U8JP5B9T2","ts":"1608130816.175800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"j3kcR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Question (I'm quite naive on parallelization) -\n\nIs it possible to have state machines that can start somewhere in the middle, given sufficient signal? For example, in a fastq file, I could jump to the middle of the file, and start scanning until I hit a newline followed by "},{"type":"text","text":"@","style":{"code":true}},{"type":"text","text":" - There are a bunch of other unambiguous entry points to certain states. So I could just say \"I don't know my state until I hit some signal.\" I would imagine you'd waste a bit of time reading the same bytes twice, but it could be worth it (or maybe not it it's really multiple GB / sec)\n\nI definitely think being able to kick state information out to different threads so that the actual bytes can be processed could make a big difference"}]}]}]},{"client_msg_id":"1b7eeb64-c6b3-40f1-a279-506bb67e2eb3","type":"message","text":"You can do that, yeah. FASTX.jl already starts and stops the state machine at each record. I suppose you could have multiple state machines running in parallel if you wanted to. This would be a question of implementing it in the packages that uses Automa, not in Automa itself","user":"U7HAYKY9X","ts":"1608137352.177300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u+Ue","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can do that, yeah. FASTX.jl already starts and stops the state machine at each record. I suppose you could have multiple state machines running in parallel if you wanted to. This would be a question of implementing it in the packages that uses Automa, not in Automa itself"}]}]}]},{"client_msg_id":"32893a03-feb5-4bcd-b2c4-c916c4aae0c2","type":"message","text":"But, I mean, my laptop reads FASTQ files using FASTX with about 1.5 GB/s (uncompressed, with <https://github.com/BioJulia/Automa.jl/pull/60>) , so it'll probably not be worth the effort. Especially if you would have to scan the file first to find the entry points (though you could do that in a pure SIMD loop). I'd much rather see\n• Multithreaded decompression\n• Use of ReadDataStores.jl","user":"U7HAYKY9X","ts":"1608137569.179100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"014pI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But, I mean, my laptop reads FASTQ files using FASTX with about 1.5 GB/s (uncompressed, with "},{"type":"link","url":"https://github.com/BioJulia/Automa.jl/pull/60"},{"type":"text","text":") , so it'll probably not be worth the effort. Especially if you would have to scan the file first to find the entry points (though you could do that in a pure SIMD loop). I'd much rather see\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Multithreaded decompression"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Use of ReadDataStores.jl"}]}],"style":"bullet","indent":0}]}],"reactions":[{"name":"100","users":["U8JP5B9T2"],"count":1}]},{"client_msg_id":"e3326d93-cf34-4f87-b266-dabc41f93600","type":"message","text":"Thanks for the replies guys. While yes FASTA/Q parsing is fast, VCF parsing remains quite slow on my machine with roughly a read rate of 20mb/s (uncompressed) using the pre-existing VCF tools in julia","user":"U01FAHWCMFF","ts":"1608164297.180800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Sqp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for the replies guys. While yes FASTA/Q parsing is fast, VCF parsing remains quite slow on my machine with roughly a read rate of 20mb/s (uncompressed) using the pre-existing VCF tools in julia"}]}]}]},{"client_msg_id":"4aeb7771-9191-4575-b280-74e1d70168c6","type":"message","text":"Motivated by nothing but contranianism and pettiness, I have now managed to improve the FASTQ parsing times on the <https://github.com/lh3/biofast/tree/master/fqcnt> benchmark quite substantially. Here is current (observed) time versus the one originally reported:\n```Observed:\nRust                   0.43 s\nC                      0.53 s\nJulia                  0.57 s\nJulia (w. compiletime) 3.39 s\nJulia 1.6 (w. c. time) 2.22 s\n\nReported:\nRust:                    0.8 s\nC                        1.4 s\nJulia:                   2.6 s\nJulia (w. compiletime): 13.6 s```\nUnfortunately, Julia 1.6 sees a time of 0.65 seconds, probably due to <https://github.com/JuliaLang/julia/issues/38947>, but if that was fixed, one could extrapolate a speed of 2.1 seconds including compile time.\nThere still seem to be some way to go. The breakdown in time spent is approximately:\n1/3 time on the underlying IO (about 6.4 GB/s)\n1/3 time spent on the actual parsing (also about 6.4 GB/s)\n1/3 time seeps between the cracks, due to inefficiencies in TranscodingStreams.jl, the Reader interface in Automa, and the constant `eof` checking. That's where to improve.","user":"U7HAYKY9X","ts":"1608393170.185800","team":"T68168MUP","edited":{"user":"U7HAYKY9X","ts":"1608456242.000000"},"blocks":[{"type":"rich_text","block_id":"m=wdS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Motivated by nothing but contranianism and pettiness, I have now managed to improve the FASTQ parsing times on the "},{"type":"link","url":"https://github.com/lh3/biofast/tree/master/fqcnt"},{"type":"text","text":" benchmark quite substantially. Here is current (observed) time versus the one originally reported:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Observed:\nRust                   0.43 s\nC                      0.53 s\nJulia                  0.57 s\nJulia (w. compiletime) 3.39 s\nJulia 1.6 (w. c. time) 2.22 s\n\nReported:\nRust:                    0.8 s\nC                        1.4 s\nJulia:                   2.6 s\nJulia (w. compiletime): 13.6 s"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Unfortunately, Julia 1.6 sees a time of 0.65 seconds, probably due to "},{"type":"link","url":"https://github.com/JuliaLang/julia/issues/38947"},{"type":"text","text":", but if that was fixed, one could extrapolate a speed of 2.1 seconds including compile time.\nThere still seem to be some way to go. The breakdown in time spent is approximately:\n1/3 time on the underlying IO (about 6.4 GB/s)\n1/3 time spent on the actual parsing (also about 6.4 GB/s)\n1/3 time seeps between the cracks, due to inefficiencies in TranscodingStreams.jl, the Reader interface in Automa, and the constant "},{"type":"text","text":"eof","style":{"code":true}},{"type":"text","text":" checking. That's where to improve."}]}]}],"reactions":[{"name":"raised_hands","users":["U01FAHWCMFF","UKG4WF8PJ","UGU761DU2","UM4TSHKF1","U01HD5VFXJM"],"count":5},{"name":"100","users":["U6C937ENB"],"count":1}]},{"client_msg_id":"361dbe45-11a4-4224-a2de-6b71c709d060","type":"message","text":"Hi there! Small quick question. I am looking for a package for Genetic Algorithms with possibly autotune of parameters. I have found Evolutionary.jl so far, but I might have missed other options. Any recommandation ?","user":"U01FR2HFJ7M","ts":"1608775090.188300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Mkv6Q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi there! Small quick question. I am looking for a package for Genetic Algorithms with possibly autotune of parameters. I have found Evolutionary.jl so far, but I might have missed other options. Any recommandation ?"}]}]}]},{"client_msg_id":"69b0273b-598a-4979-b271-9fecc75e6769","type":"message","text":"GalacticOptim has the following: <https://galacticoptim.sciml.ai/dev/global_optimizers/global/>","user":"U69BL50BF","ts":"1608775298.188500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nJyeM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"GalacticOptim has the following: "},{"type":"link","url":"https://galacticoptim.sciml.ai/dev/global_optimizers/global/"}]}]}]},{"client_msg_id":"c1d58afd-47a8-49fb-a394-2cba45c35944","type":"message","text":"This looks like a great option, as it also includes Evolutionary.jl. Thanks <@U69BL50BF>","user":"U01FR2HFJ7M","ts":"1608781976.189500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uuF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This looks like a great option, as it also includes Evolutionary.jl. Thanks "},{"type":"user","user_id":"U69BL50BF"}]}]}]},{"client_msg_id":"6e614c8e-b86f-49c8-82a3-9a79ee99fcc4","type":"message","text":"Any idea where I can chat/contact people working/using Evolutionary.jl (other than GH issues)?","user":"U01FR2HFJ7M","ts":"1609824439.191600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ttnW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any idea where I can chat/contact people working/using Evolutionary.jl (other than GH issues)?"}]}]}]},{"client_msg_id":"a26626b3-7813-4fc0-8253-e7f56f17df1d","type":"message","text":"Hi all, I had mentioned way back that I was going to make a PyCall wrapper for Hail (<http://hail.is>) and I’m finally finding time to do it. I have one quick style question for you all. In hail you can read in a vcf file into a MatrixTable, let’s call it mt, and then print out information about it with `mt.describe`, `mt.show`, and so on. Those functions all work fine on the PyObject in PyCall, but I was thinking it might be better style to wrap them in function to make them more Julia-like. For example, PyHail.describe(mt). Any thoughts?","user":"USBRJS6BU","ts":"1610257403.195800","team":"T68168MUP","attachments":[{"title":"Hail |  Index ","title_link":"http://hail.is/","text":"Hail Index Page","fallback":"Hail |  Index ","from_url":"http://hail.is/","service_icon":"https://hail.is/hail_logo_sq-sm-opt.ico","service_name":"hail.is","id":1,"original_url":"http://hail.is"}],"blocks":[{"type":"rich_text","block_id":"/TW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all, I had mentioned way back that I was going to make a PyCall wrapper for Hail ("},{"type":"link","url":"http://hail.is"},{"type":"text","text":") and I’m finally finding time to do it. I have one quick style question for you all. In hail you can read in a vcf file into a MatrixTable, let’s call it mt, and then print out information about it with "},{"type":"text","text":"mt.describe","style":{"code":true}},{"type":"text","text":", "},{"type":"text","text":"mt.show","style":{"code":true}},{"type":"text","text":", and so on. Those functions all work fine on the PyObject in PyCall, but I was thinking it might be better style to wrap them in function to make them more Julia-like. For example, PyHail.describe(mt). Any thoughts?"}]}]}]},{"client_msg_id":"22d16385-cca6-4f38-86cb-382c8643f802","type":"message","text":"ScRNAseq.jl - for single-cell RNA-seq (scRNAseq) data analysis. Ppl interested in working together, please feel free to contact.","user":"ULWFF2Z8U","ts":"1610603568.002700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4PD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ScRNAseq.jl - for single-cell RNA-seq (scRNAseq) data analysis. Ppl interested in working together, please feel free to contact."}]}]}],"reactions":[{"name":"biojulia","users":["UCAFZ51L3","U7HAYKY9X"],"count":2}]},{"client_msg_id":"6891a1b6-a759-4610-8d04-8987f9a57829","type":"message","text":"hi, yeah I have been working on BioMakie on the side. A lot has been happening regarding layouts and so I will probably rewrite it to use the newer syntax.\nAs for the other viz tools, I have thought about making the connection, but I don't know how to do it. I'd be interested in working on it though. The fact that they have python controls means that at least there could be a PyCall interop.","user":"UAH43TMUN","ts":"1610933640.019700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nrbt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hi, yeah I have been working on BioMakie on the side. A lot has been happening regarding layouts and so I will probably rewrite it to use the newer syntax.\nAs for the other viz tools, I have thought about making the connection, but I don't know how to do it. I'd be interested in working on it though. The fact that they have python controls means that at least there could be a PyCall interop."}]}]}]},{"client_msg_id":"8871b190-cdf0-4368-9ff9-82e03081e3da","type":"message","text":"I want to align a short sequence A to a long sequence B, since I know A is contained in B. However, I can't find a setting for `BioAlignments` that doesn't give obviously bad results if the last nucleotide(s) of A is a mismatch:\n• If I choose a LocalAlignment, then the alignment just stops and doesn't include the last nucleotides\n• If I pick a global or semiglobal alignment, then the alignment will insert huge massive gaps in A in order to make it fit \"globally\" with B\nWhat to do?","user":"U7HAYKY9X","ts":"1611748527.003700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Tn1j","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I want to align a short sequence A to a long sequence B, since I know A is contained in B. However, I can't find a setting for "},{"type":"text","text":"BioAlignments","style":{"code":true}},{"type":"text","text":" that doesn't give obviously bad results if the last nucleotide(s) of A is a mismatch:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If I choose a LocalAlignment, then the alignment just stops and doesn't include the last nucleotides"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"If I pick a global or semiglobal alignment, then the alignment will insert huge massive gaps in A in order to make it fit \"globally\" with B"}]}],"style":"bullet","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"What to do?"}]}]}]},{"client_msg_id":"5994f198-c4ce-4703-a93e-97c15e68406d","type":"message","text":"```run(`bowtie2 ...`)```\n:julia-troll:","user":"U8JP5B9T2","ts":"1611759654.004700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MioG","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"run(`bowtie2 ...`)"}]},{"type":"rich_text_section","elements":[{"type":"emoji","name":"julia-troll"}]}]}],"reactions":[{"name":"troll","users":["U7HAYKY9X"],"count":1}]},{"client_msg_id":"ff1cbd78-c886-4517-b396-dfa1ceb16ff8","type":"message","text":"Looks like `OverlapAlignment()` solves it.","user":"U7HAYKY9X","ts":"1611772489.005100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Z20ja","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looks like "},{"type":"text","text":"OverlapAlignment()","style":{"code":true}},{"type":"text","text":" solves it."}]}]}],"reactions":[{"name":"tada","users":["U8JP5B9T2"],"count":1}]},{"client_msg_id":"c4476097-73c4-4b9e-8afa-60d76048398f","type":"message","text":"Hi everyone, I’m putting together a small package for working with pedigree files and was wondering if anyone had any thoughts on useful features. So far I just have the ability to read and write pedigree files assuming the FamID, Proband, Father, Mother, and Gender columns are all present (I know this isn’t necessarily the case, but it’s true of every ped I’ve worked with). I am planning to optionally support the Phenotype column and add support for trio based pedigrees.","user":"USBRJS6BU","ts":"1611797539.007500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n+OKt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi everyone, I’m putting together a small package for working with pedigree files and was wondering if anyone had any thoughts on useful features. So far I just have the ability to read and write pedigree files assuming the FamID, Proband, Father, Mother, and Gender columns are all present (I know this isn’t necessarily the case, but it’s true of every ped I’ve worked with). I am planning to optionally support the Phenotype column and add support for trio based pedigrees."}]}]}]},{"client_msg_id":"034845c9-1c07-47d5-b7a2-7f7de881ec15","type":"message","text":"And for those who were interested in Hail, I’ll have something to share this weekend (I haven’t forgotten!)","user":"USBRJS6BU","ts":"1611797567.008100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PC/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And for those who were interested in Hail, I’ll have something to share this weekend (I haven’t forgotten!)"}]}]}]},{"client_msg_id":"5f31119b-a2e3-4a90-8a22-a3eec57d717b","type":"message","text":"I have created a new package, VCF.jl, for reading VCF files. It's not my work originally, because it just contains the VCF/BCF IO that exists in GeneticVariation.jl. But it makes more sense to have as a separate package:\n* Smaller package means fewer dependencies, and most people(?) only use the VCF part of GeneticVariation.jl.\n* A smaller package with a clear focus is easier to maintain. (GeneticVariation.jl is not actively maintained.)\nVCF.jl can be found here: <https://github.com/rasmushenningsson/VCF.jl>\nIt is in the process of being registered.","user":"UPNRULT51","ts":"1613294797.015800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"t0p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have created a new package, VCF.jl, for reading VCF files. It's not my work originally, because it just contains the VCF/BCF IO that exists in GeneticVariation.jl. But it makes more sense to have as a separate package:\n* Smaller package means fewer dependencies, and most people(?) only use the VCF part of GeneticVariation.jl.\n* A smaller package with a clear focus is easier to maintain. (GeneticVariation.jl is not actively maintained.)\nVCF.jl can be found here: "},{"type":"link","url":"https://github.com/rasmushenningsson/VCF.jl"},{"type":"text","text":"\nIt is in the process of being registered."}]}]}]},{"client_msg_id":"9a181f4f-2ac0-47b9-b264-4df5c039f009","type":"message","text":"I hope this will be useful to others!","user":"UPNRULT51","ts":"1613295046.016300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ssVFW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I hope this will be useful to others!"}]}]}]},{"client_msg_id":"e7f32a06-fb72-4145-b2a8-bc5c146e8e8d","type":"message","text":"If anyone wants me to *keep* the name `VCF.jl` instead of changing to `VariantCallFormat.jl`, please say so. :) Otherwise I will go ahead with the change. (There's a thread in <#C6M4DQA5P|pkg-registration> if you want arguments for/against.)","user":"UPNRULT51","ts":"1613378287.021500","team":"T68168MUP","edited":{"user":"UPNRULT51","ts":"1613378302.000000"},"blocks":[{"type":"rich_text","block_id":"zQul","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If anyone wants me to "},{"type":"text","text":"keep","style":{"bold":true}},{"type":"text","text":" the name "},{"type":"text","text":"VCF.jl","style":{"code":true}},{"type":"text","text":" instead of changing to "},{"type":"text","text":"VariantCallFormat.jl","style":{"code":true}},{"type":"text","text":", please say so. :) Otherwise I will go ahead with the change. (There's a thread in "},{"type":"channel","channel_id":"C6M4DQA5P"},{"type":"text","text":" if you want arguments for/against.)"}]}]}]},{"client_msg_id":"0ad6000a-bc5f-486d-af5b-44254158cf19","type":"message","text":"Anyone here has a good forum post/ tutorial here to find duplicated protein sequences in a fasta using Julia?","user":"UTB5MKCL8","ts":"1614000694.000600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UIxi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone here has a good forum post/ tutorial here to find duplicated protein sequences in a fasta using Julia?"}]}]}],"thread_ts":"1614000694.000600","reply_count":15,"reply_users_count":2,"latest_reply":"1614003134.005000","reply_users":["UTB5MKCL8","U7HAYKY9X"],"subscribed":false},{"client_msg_id":"c66f25ec-bd09-40cd-9c42-ea1b8bf1c94d","type":"message","text":"Any here who works with BAM files regularly and have any interest in helping improving the packages \"around\" it? Turns out there are a lot of accessory packages to XAM, and some decisions needs to be made.","user":"U7HAYKY9X","ts":"1614513122.007700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Wb9D","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any here who works with BAM files regularly and have any interest in helping improving the packages \"around\" it? Turns out there are a lot of accessory packages to XAM, and some decisions needs to be made."}]}]}]},{"client_msg_id":"8df7a1ac-9942-4e4c-8051-4683a78080e7","type":"message","text":"I have not spent much time working with BAMs, but I'm going to have to in the next 6 months. I'm happy to spitball on the issues, though probably not competent (and don't presently have time to get competent) to implement solutions","user":"U8JP5B9T2","ts":"1614513791.010200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bUU=Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have not spent much time working with BAMs, but I'm going to have to in the next 6 months. I'm happy to spitball on the issues, though probably not competent (and don't presently have time to get competent) to implement solutions"}]}]}],"thread_ts":"1614513791.010200","reply_count":2,"reply_users_count":1,"latest_reply":"1614514674.010500","reply_users":["U7HAYKY9X"],"subscribed":false},{"client_msg_id":"68d86932-1369-486e-9b13-ccee285b6992","type":"message","text":"Sorry to bother everyone, but what is metapopulation analysis? I recently stumbled across the term during some literature reviews. The paper I was reading mentioned this is a technique borrowed from biological modeling but didn't go into what this technique actually is before it was applied. Could someone either explain to me the gist of it or link me a resource where I could learn more about it? Thank you!","user":"US64J0NPQ","ts":"1614610750.014000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yA/B","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sorry to bother everyone, but what is metapopulation analysis? I recently stumbled across the term during some literature reviews. The paper I was reading mentioned this is a technique borrowed from biological modeling but didn't go into what this technique actually is before it was applied. Could someone either explain to me the gist of it or link me a resource where I could learn more about it? Thank you!"}]}]}],"thread_ts":"1614610750.014000","reply_count":1,"reply_users_count":1,"latest_reply":"1614611057.015200","reply_users":["U7HAYKY9X"],"subscribed":false},{"client_msg_id":"39553351-9788-4b4f-9890-e24ef1f1eb96","type":"message","text":"Also, for context, this was based around human populations spread out across an area (such as parts of a country or different countries).","user":"US64J0NPQ","ts":"1614610853.015100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"R+owI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also, for context, this was based around human populations spread out across an area (such as parts of a country or different countries)."}]}]}]},{"client_msg_id":"f937e6fd-5296-4b1f-a0de-0f01684424ae","type":"message","text":"What's the procedure for merging a breaking change to BioJulia (which has already been agreed should go in the next major release), e.g. <https://github.com/BioJulia/BioSymbols.jl/pull/38>? Make a new branch for the new release? Or just merge to master, and then any bugfixes should be backported to the currently tagged release?","user":"U7HAYKY9X","ts":"1614703413.023500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UhJEn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What's the procedure for merging a breaking change to BioJulia (which has already been agreed should go in the next major release), e.g. "},{"type":"link","url":"https://github.com/BioJulia/BioSymbols.jl/pull/38"},{"type":"text","text":"? Make a new branch for the new release? Or just merge to master, and then any bugfixes should be backported to the currently tagged release?"}]}]}]},{"client_msg_id":"0d98bfb8-374e-451c-9646-2ba36369112e","type":"message","text":"Some repos have listed that they follow git flow method <https://datasift.github.io/gitflow/IntroducingGitFlow.html>\n\nBut I think <@UC2AEGPC2> added that as part of the org-wide policies / docs / templates push a while back, and I don't know how many are actually doing so","user":"U8JP5B9T2","ts":"1614704277.025900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iqTJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Some repos have listed that they follow git flow method "},{"type":"link","url":"https://datasift.github.io/gitflow/IntroducingGitFlow.html"},{"type":"text","text":"\n\nBut I think "},{"type":"user","user_id":"UC2AEGPC2"},{"type":"text","text":" added that as part of the org-wide policies / docs / templates push a while back, and I don't know how many are actually doing so"}]}]}]},{"client_msg_id":"13a6573b-0ed9-46a9-83ed-ed4bfa75823d","type":"message","text":"I haven't reached 1.0 with any of the primary packages I develop though, so it hasn't really come up","user":"U8JP5B9T2","ts":"1614704341.026400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YuMAV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I haven't reached 1.0 with any of the primary packages I develop though, so it hasn't really come up"}]}]}]},{"client_msg_id":"27a4d6be-4e07-4c92-909a-00d5ecf97054","type":"message","text":"Ah okay. I've been merging to `master` this whole time (oops). Maybe it's time to make `develop` branches for all the repos, as I work on them, then?","user":"U7HAYKY9X","ts":"1614704439.027100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oFcm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah okay. I've been merging to "},{"type":"text","text":"master","style":{"code":true}},{"type":"text","text":" this whole time (oops). Maybe it's time to make "},{"type":"text","text":"develop","style":{"code":true}},{"type":"text","text":" branches for all the repos, as I work on them, then?"}]}]}]},{"client_msg_id":"27c50ffe-2e33-4347-9fcc-83035bcf9512","type":"message","text":"I've always thought git flow is a bit involved for a typical project. It might makes sense if you have a giant code base with lots of contributors and lots of parallel feature branches.\n\nBut I think it's up to the maintainers of a given project","user":"U8JP5B9T2","ts":"1614705027.028900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Rks","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've always thought git flow is a bit involved for a typical project. It might makes sense if you have a giant code base with lots of contributors and lots of parallel feature branches.\n\nBut I think it's up to the maintainers of a given project"}]}]}]},{"client_msg_id":"efc60152-63bc-4189-8811-12e72f17436f","type":"message","text":"FWIW the BioSymbols readme doesn't mention git flow","user":"U8JP5B9T2","ts":"1614705072.029300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"i62C","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"FWIW the BioSymbols readme doesn't mention git flow"}]}]}]},{"client_msg_id":"766bc834-57b0-4781-b623-01eb19c20279","type":"message","text":"<https://chanzuckerberg.com/rfa/essential-open-source-software-for-science/>","user":"USU9FRPEU","ts":"1614730903.029700","team":"T68168MUP","attachments":[{"service_name":"Chan Zuckerberg Initiative","title":"Essential Open Source Software for Science - Chan Zuckerberg Initiative","title_link":"https://chanzuckerberg.com/rfa/essential-open-source-software-for-science/","fallback":"Chan Zuckerberg Initiative: Essential Open Source Software for Science - Chan Zuckerberg Initiative","image_url":"https://chanzuckerberg.com/wp-content/uploads/2020/06/twitter-In-Stream_Wide___computer-graphic-czi-essential-open-source-software-science.png","image_width":500,"image_height":250,"from_url":"https://chanzuckerberg.com/rfa/essential-open-source-software-for-science/","image_bytes":90854,"service_icon":"https://chanzuckerberg.com/wp-content/uploads/2018/04/new-logo.png?w=108","id":1,"original_url":"https://chanzuckerberg.com/rfa/essential-open-source-software-for-science/"}],"blocks":[{"type":"rich_text","block_id":"aUmvy","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://chanzuckerberg.com/rfa/essential-open-source-software-for-science/"}]}]}]},{"client_msg_id":"85d7fd2f-d8f3-48a2-9c9d-f53299c266d0","type":"message","text":"By \"science\" they mean biomedical research","user":"USU9FRPEU","ts":"1614730913.030100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nG5l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"By \"science\" they mean biomedical research"}]}]}]},{"client_msg_id":"0fb8ed92-3101-48f8-804b-376ff5a07d62","type":"message","text":"I have some troubles going from an unzipped fasta to a zipped fasta. This line:\n`reader = FASTX.FASTA.Reader(GzipDecompressorStream(open(\"fasta.fa.gz\", \"r\")))`  gives me\n```UndefVarError: stream not defined\nin top-level scope at 02b_create_master_fasta_from_gffs.jl:47\nin FASTX.FASTA.Reader at FASTX/WREay/src/fasta/reader.jl:19\nin #Reader#5 at FASTX/WREay/src/fasta/reader.jl:27```\nAnything obvious thing I am missing?","user":"UTB5MKCL8","ts":"1614776370.031300","team":"T68168MUP","edited":{"user":"UTB5MKCL8","ts":"1614776496.000000"},"blocks":[{"type":"rich_text","block_id":"kLn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have some troubles going from an unzipped fasta to a zipped fasta. This line:\n"},{"type":"text","text":"reader = FASTX.FASTA.Reader(GzipDecompressorStream(open(\"fasta.fa.gz\", \"r\")))","style":{"code":true}},{"type":"text","text":"  gives me\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"UndefVarError: stream not defined\nin top-level scope at 02b_create_master_fasta_from_gffs.jl:47\nin FASTX.FASTA.Reader at FASTX/WREay/src/fasta/reader.jl:19\nin #Reader#5 at FASTX/WREay/src/fasta/reader.jl:27"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nAnything obvious thing I am missing?"}]}]}],"thread_ts":"1614776370.031300","reply_count":8,"reply_users_count":2,"latest_reply":"1614777401.033000","reply_users":["U7HAYKY9X","UTB5MKCL8"],"subscribed":false},{"client_msg_id":"a86d8cad-23b9-43cd-92aa-382487b0fc00","type":"message","text":"Hi, Quick question. How do I access aligned sequence and aligned query from the alignment(..) ?","user":"UE0Q72VV0","ts":"1615148648.041600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4rO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, Quick question. How do I access aligned sequence and aligned query from the alignment(..) ?"}]}]}],"thread_ts":"1615148648.041600","reply_count":2,"reply_users_count":1,"latest_reply":"1615149385.041900","reply_users":["U7HAYKY9X"],"subscribed":false},{"client_msg_id":"5c807997-f2a1-4ee3-bc3b-648efb88ac1f","type":"message","text":"What is the BioJulia policy on Julia compatibility of future releases? It's going to get harder and harder to guarantee Julia v1.0 compatibility. Wait for new LTS or is it fair game to release new versions requiring e.g. Julia 1.3 or Julia 1.5?","user":"U7HAYKY9X","ts":"1615152118.043700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Zcp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is the BioJulia policy on Julia compatibility of future releases? It's going to get harder and harder to guarantee Julia v1.0 compatibility. Wait for new LTS or is it fair game to release new versions requiring e.g. Julia 1.3 or Julia 1.5?"}]}]}]},{"client_msg_id":"5ea61f86-ae92-4152-8a90-23ee2099838c","type":"message","text":"Personally I think it's fine to require Julia 1.3 or 1.5 for new releases with recently developed features.\nThe old versions still work on Julia 1.0, and anyone still on Julia 1.0 must appreciate they can't get every new feature.\nI also don't think we should make a general BioJulia policy on it, since Julia 1.0 compatibility is  easy for some packages and difficult for others.","user":"U9TCDH0E7","ts":"1615298434.047100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vIE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Personally I think it's fine to require Julia 1.3 or 1.5 for new releases with recently developed features.\nThe old versions still work on Julia 1.0, and anyone still on Julia 1.0 must appreciate they can't get every new feature.\nI also don't think we should make a general BioJulia policy on it, since Julia 1.0 compatibility is  easy for some packages and difficult for others."}]}]}]},{"client_msg_id":"4d7483ae-af19-44ae-a688-78fa12e45229","type":"message","text":"That makes sense, I agree with that. However, if there's not at least some informal agreement, it may lead to some grief if some package authors feel forced to abandon Julia 1.0 compatibility because their dependencies do.\nUpgrade-readiness is just so much a culturally specific phenomenon. Some people run their code on university servers where they have to make a ticket to the IT department if they want a new Julia installed - we can't expect these people to be on the newest Julia. These people might be annoyed if their packages just randomly stop working. As developers, we are almost 100% biased towards very high upgrade readiness.\nOn the other hand, there is just so much happening in Julia these years, it's getting to be a real bummer to guarantee v 1.0 support (and even v 1.2 support!)","user":"U7HAYKY9X","ts":"1615299320.050100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"702","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That makes sense, I agree with that. However, if there's not at least some informal agreement, it may lead to some grief if some package authors feel forced to abandon Julia 1.0 compatibility because their dependencies do.\nUpgrade-readiness is just so much a culturally specific phenomenon. Some people run their code on university servers where they have to make a ticket to the IT department if they want a new Julia installed - we can't expect these people to be on the newest Julia. These people might be annoyed if their packages just randomly stop working. As developers, we are almost 100% biased towards very high upgrade readiness.\nOn the other hand, there is just so much happening in Julia these years, it's getting to be a real bummer to guarantee v 1.0 support (and even v 1.2 support!)"}]}]}]},{"client_msg_id":"041fd2be-53bd-46ed-bc4f-58d32bb0cf69","type":"message","text":"Yeah, it's a tradeoff for sure.\nI have felt the dependency issue a bit with depending on CUDA.jl for another project, and consequently having to drop support for Julia below 1.5, but it's a price I'm happy to pay for low-level features that weren't going to work on Julia 1.0.\nPeople's packages shouldn't break though, provided we set up the Compat bounds correctly to prevent installing new versions on old Julias, though I guess if we fail to backport bugfixes to older versions compatible with Julia 1.0 that could be a problem.","user":"U9TCDH0E7","ts":"1615300166.053600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SBBX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, it's a tradeoff for sure.\nI have felt the dependency issue a bit with depending on CUDA.jl for another project, and consequently having to drop support for Julia below 1.5, but it's a price I'm happy to pay for low-level features that weren't going to work on Julia 1.0.\nPeople's packages shouldn't break though, provided we set up the Compat bounds correctly to prevent installing new versions on old Julias, though I guess if we fail to backport bugfixes to older versions compatible with Julia 1.0 that could be a problem."}]}]}]},{"client_msg_id":"6a3404e1-c74d-4740-861a-09804e1752e1","type":"message","text":"Their packages won't randomly stop working though. They will stop getting upgrades, sure, but if you do the versioning right, they will not be able to install broken versions. If someone is interested, you can always try to backport bug fixes.","user":"U8JP5B9T2","ts":"1615302828.055200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kOVS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Their packages won't randomly stop working though. They will stop getting upgrades, sure, but if you do the versioning right, they will not be able to install broken versions. If someone is interested, you can always try to backport bug fixes."}]}]}]},{"client_msg_id":"53a1d819-d52e-4c15-8b0f-6b76be7aff1a","type":"message","text":"That's true, they just won't get bugfixes","user":"U7HAYKY9X","ts":"1615303237.055600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"p4Gc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's true, they just won't get bugfixes"}]}]}]},{"client_msg_id":"5302F3E4-A121-4E19-85E7-509E6A1724A3","type":"message","text":"Are there any good Julia resources or guides for biology? I am kinda stumped. Thanks in advance &lt;3","user":"U01QUMZP9MF","ts":"1615304092.057000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2Zjs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any good Julia resources or guides for biology? I am kinda stumped. Thanks in advance <3"}]}]}],"thread_ts":"1615304092.057000","reply_count":3,"reply_users_count":3,"latest_reply":"1615306911.066300","reply_users":["U8JP5B9T2","U01QUMZP9MF","U69BL50BF"],"subscribed":false},{"client_msg_id":"57a57677-b115-4e3a-ad62-5df988e2d157","type":"message","text":"Small brag (because I'm so excited!):\nLast night I finished writing pairwise FST calculations in PopGen.jl and benchmarked it against the same implementation in R's `hierfstat`. On the mid-sized SNP dataset I use (212 samples x 2209 loci), my version is 170x faster on a single thread, 248x faster on 4 threads :raised_hands::skin-tone-4:","user":"UM4TSHKF1","ts":"1615304901.059100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KoJCK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Small brag (because I'm so excited!):\nLast night I finished writing pairwise FST calculations in PopGen.jl and benchmarked it against the same implementation in R's "},{"type":"text","text":"hierfstat","style":{"code":true}},{"type":"text","text":". On the mid-sized SNP dataset I use (212 samples x 2209 loci), my version is 170x faster on a single thread, 248x faster on 4 threads "},{"type":"emoji","name":"raised_hands","skin_tone":4}]}]}],"thread_ts":"1615304901.059100","reply_count":16,"reply_users_count":3,"latest_reply":"1615306310.065900","reply_users":["U7HAYKY9X","U8JP5B9T2","UM4TSHKF1"],"subscribed":false,"reactions":[{"name":"fast_parrot","users":["U7HAYKY9X","U8JP5B9T2","UCAFZ51L3","U01QUMZP9MF"],"count":4},{"name":"tada","users":["U7HAYKY9X","U8JP5B9T2","U01QUMZP9MF"],"count":3}]},{"type":"message","subtype":"thread_broadcast","text":"<https://www.youtube.com/watch?v=5p1PJE5A5Jw&amp;list=PLP8iPy9hna6TxktMt-IzdU2vQpGp3bwDn&amp;index=8> is a good introduction to biomodeling. And there's a few other bio talks in the symposium.","user":"U69BL50BF","ts":"1615306911.066300","thread_ts":"1615304092.057000","root":{"client_msg_id":"5302F3E4-A121-4E19-85E7-509E6A1724A3","type":"message","text":"Are there any good Julia resources or guides for biology? I am kinda stumped. Thanks in advance &lt;3","user":"U01QUMZP9MF","ts":"1615304092.057000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2Zjs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any good Julia resources or guides for biology? I am kinda stumped. Thanks in advance <3"}]}]}],"thread_ts":"1615304092.057000","reply_count":3,"reply_users_count":3,"latest_reply":"1615306911.066300","reply_users":["U8JP5B9T2","U01QUMZP9MF","U69BL50BF"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"/Rl","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://www.youtube.com/watch?v=5p1PJE5A5Jw&list=PLP8iPy9hna6TxktMt-IzdU2vQpGp3bwDn&index=8"},{"type":"text","text":" is a good introduction to biomodeling. And there's a few other bio talks in the symposium."}]}]}],"client_msg_id":"08fca22a-cc9c-43e1-8f2a-d09ce6f5452e"},{"client_msg_id":"6cfd748e-96f3-48e2-b7f5-94d03ab32bd3","type":"message","text":"Just got bit by the Nth time by software that SILENTLY clips the input FASTA header at the first whitespace. Oh my God, why can't we all just agree on what a FASTA file actually is?","user":"U7HAYKY9X","ts":"1615392075.078100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"huHF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just got bit by the Nth time by software that SILENTLY clips the input FASTA header at the first whitespace. Oh my God, why can't we all just agree on what a FASTA file actually is?"}]}]}]},{"client_msg_id":"2c94a531-ef8d-4246-b887-ba841e8a4840","type":"message","text":"Because early bioinformaticians were all guys that taught themselves perl in the 80s?","user":"U8JP5B9T2","ts":"1615392200.078900","team":"T68168MUP","edited":{"user":"U8JP5B9T2","ts":"1615392215.000000"},"blocks":[{"type":"rich_text","block_id":"9sM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Because early bioinformaticians were all guys that taught themselves perl in the 80s?"}]}]}]},{"client_msg_id":"ee9f0030-48d4-4635-8312-294f607c17f2","type":"message","text":"Yesterday when you talked about the ~GFF3~ GBFF format, I was amused that the *official* \"definition\" of the format is a webpage that goes:\n&gt; It look like this. Look. That be the format\nAnd then shows this massively complicated document. With no grammar or formal definition. :wat:","user":"U7HAYKY9X","ts":"1615392429.080600","team":"T68168MUP","edited":{"user":"U7HAYKY9X","ts":"1615392592.000000"},"blocks":[{"type":"rich_text","block_id":"QEvKL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yesterday when you talked about the "},{"type":"text","text":"GFF3","style":{"strike":true}},{"type":"text","text":" GBFF format, I was amused that the "},{"type":"text","text":"official","style":{"bold":true}},{"type":"text","text":" \"definition\" of the format is a webpage that goes:\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"It look like this. Look. That be the format"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"And then shows this massively complicated document. With no grammar or formal definition. "},{"type":"emoji","name":"wat"}]}]}]},{"client_msg_id":"9815cd60-8fce-42a9-826d-2807f667984a","type":"message","text":"Fine for human consumption of course, except that's the actual format the data is stored in in the database. :face_palm:","user":"U7HAYKY9X","ts":"1615392461.081200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FKa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Fine for human consumption of course, except that's the actual format the data is stored in in the database. "},{"type":"emoji","name":"face_palm"}]}]}]},{"client_msg_id":"68d75e37-1ef7-4880-b96e-c70822c980de","type":"message","text":"Why are they doing this to us? What have we done to deserve it?","user":"U7HAYKY9X","ts":"1615392475.081500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fjWb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Why are they doing this to us? What have we done to deserve it?"}]}]}]},{"client_msg_id":"70517083-1b57-4114-b574-c48f7c5350b7","type":"message","text":"Yeah... It gets worse. I went looking for what can go in \"molecule type.\" So I clicked the link, which takes you <https://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html#MoleculeTypeB|here>. OK, but the link in\n\n&gt; The various <http://www.ncbi.nlm.nih.gov/Sequin/sequin.hlp.html#Molecule|molecule types> are described in the Sequin documentation...\nredirects you to a submission page. There's a flash of a page that says\n\n```{code}\nPlease follow this link\n{code} ```\nBut I haven't been able to actually click the link, it flies by too fast","user":"U8JP5B9T2","ts":"1615393076.085300","team":"T68168MUP","attachments":[{"title":"GenBank Sample Record","title_link":"https://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html#MoleculeTypeB","text":"detailed description of each field in a GenBank record","fallback":"GenBank Sample Record","from_url":"https://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html#MoleculeTypeB","service_icon":"https://www.ncbi.nlm.nih.gov/favicon.ico","service_name":"ncbi.nlm.nih.gov","id":1,"original_url":"https://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html#MoleculeTypeB"}],"blocks":[{"type":"rich_text","block_id":"wbAFV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah... It gets worse. I went looking for what can go in \"molecule type.\" So I clicked the link, which takes you "},{"type":"link","url":"https://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html#MoleculeTypeB","text":"here"},{"type":"text","text":". OK, but the link in\n\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"The various "},{"type":"link","url":"http://www.ncbi.nlm.nih.gov/Sequin/sequin.hlp.html#Molecule","text":"molecule types"},{"type":"text","text":" are described in the Sequin documentation..."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"redirects you to a submission page. There's a flash of a page that says\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"{code}\nPlease follow this link\n{code} "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"But I haven't been able to actually click the link, it flies by too fast"}]}]}]},{"type":"message","text":"This link does the same thing","files":[{"id":"F01QTJ1PCLA","created":1615393136,"timestamp":1615393136,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U8JP5B9T2","editable":false,"size":45244,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01QTJ1PCLA/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01QTJ1PCLA/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01QTJ1PCLA-5721ac2144/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01QTJ1PCLA-5721ac2144/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01QTJ1PCLA-5721ac2144/image_360.png","thumb_360_w":360,"thumb_360_h":158,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01QTJ1PCLA-5721ac2144/image_480.png","thumb_480_w":480,"thumb_480_h":211,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01QTJ1PCLA-5721ac2144/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01QTJ1PCLA-5721ac2144/image_720.png","thumb_720_w":720,"thumb_720_h":316,"original_w":741,"original_h":325,"thumb_tiny":"AwAVADDRxgdT19aP89aU9KTJ9aAFz9PzopMn1oyaAHc0lG4Uo5oACM0m0UtFACbRRtFLRQAm0UtFFAH/2Q==","permalink":"https://julialang.slack.com/files/U8JP5B9T2/F01QTJ1PCLA/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01QTJ1PCLA-671be192ca","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"8kHua","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This link does the same thing"}]}]}],"user":"U8JP5B9T2","display_as_bot":false,"ts":"1615393143.085600","reactions":[{"name":"fearful","users":["U7HAYKY9X"],"count":1}]},{"client_msg_id":"5e432da8-1cd3-4775-a6f4-6055d49402be","type":"message","text":"It's the final revenge from all the time bioinformaticians have given the \"learn 2 code\" attitude. \"Learn to code? Okay, let's see you code a parser for this\" :smiling_imp:\nThe insanity would be funny, except *i'm* the guy having to work with it :P","user":"U7HAYKY9X","ts":"1615393340.087400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"f90r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's the final revenge from all the time bioinformaticians have given the \"learn 2 code\" attitude. \"Learn to code? Okay, let's see you code a parser for this\" "},{"type":"emoji","name":"smiling_imp"},{"type":"text","text":"\nThe insanity would be funny, except "},{"type":"text","text":"i'm","style":{"bold":true}},{"type":"text","text":" the guy having to work with it :P"}]}]}]},{"bot_id":"BUQUB8RBN","type":"message","text":"preach","user":"U8JP5B9T2","ts":"1615393461.087900","team":"T68168MUP","bot_profile":{"id":"BUQUB8RBN","deleted":false,"name":"giphy","updated":1583162249,"app_id":"A0F827J2C","icons":{"image_36":"https://a.slack-edge.com/dc483/img/plugins/giphy/service_72.png","image_48":"https://a.slack-edge.com/dc483/img/plugins/giphy/service_48.png","image_72":"https://a.slack-edge.com/dc483/img/plugins/giphy/service_72.png"},"team_id":"T68168MUP"},"blocks":[{"type":"image","block_id":"6Iv9","image_url":"https://media2.giphy.com/media/WSvYuKhLwaxuE/giphy.gif?cid=6104955e8af53ae4afd044c70afbb69c2efc0b0c7fe3f880&rid=giphy.gif","alt_text":"preach","title":{"type":"plain_text","text":"preach","emoji":true},"fallback":"397x284px image","image_width":397,"image_height":284,"image_bytes":1238115,"is_animated":true},{"type":"context","block_id":"n0/q","elements":[{"type":"image","image_url":"https://a.slack-edge.com/dc483/img/plugins/giphy/service_32.png","alt_text":"giphy logo"},{"type":"mrkdwn","text":"Posted using /giphy","verbatim":false}]}]},{"client_msg_id":"01e01103-9be2-45f6-a2da-e912cbc9a2bf","type":"message","text":"Anyone have an opinion about what to do with the state of k-mer analysis in BioJulia? Right now, we have\n• Base K-mer types in BioSequences\n• K-mer composition in BioSequences\n• K-mer minhashing in BioSequences\n• K-mer counting in KmerAnalysis.jl\n• K-mer specra in KmerAnalysis.jl\nAs well as some things scattered around in MinHash.jl, Kash.jl, Kmerminhash.jl, and Kmers.jl.\n\nKmerAnalysis seems most ambitious, by far, but it seems to have stopped in development before any releases (cc <@UC2AEGPC2>). Should we keep the base types in BioSequences, but move the other stuff into a single package, perhaps KmerAnalysis?","user":"U7HAYKY9X","ts":"1615566036.092000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"92O0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone have an opinion about what to do with the state of k-mer analysis in BioJulia? Right now, we have\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Base K-mer types in BioSequences"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"K-mer composition in BioSequences"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"K-mer minhashing in BioSequences"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"K-mer counting in KmerAnalysis.jl"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"K-mer specra in KmerAnalysis.jl"}]}],"style":"bullet","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"As well as some things scattered around in MinHash.jl, Kash.jl, Kmerminhash.jl, and Kmers.jl.\n\nKmerAnalysis seems most ambitious, by far, but it seems to have stopped in development before any releases (cc "},{"type":"user","user_id":"UC2AEGPC2"},{"type":"text","text":"). Should we keep the base types in BioSequences, but move the other stuff into a single package, perhaps KmerAnalysis?"}]}]}]},{"client_msg_id":"7fad8e50-c4a3-4b86-aeee-50951d56b357","type":"message","text":"That was my intention. So KmerAnalysis has usable stuff in it, including counting and projection etc. but because it was used as a base for the assembly package as well, I didn't bother doing releases as it moved fast enough that tagging would have been annoying.","user":"UC2AEGPC2","ts":"1615566182.093300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u/1i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That was my intention. So KmerAnalysis has usable stuff in it, including counting and projection etc. but because it was used as a base for the assembly package as well, I didn't bother doing releases as it moved fast enough that tagging would have been annoying."}]}]}],"thread_ts":"1615566182.093300","reply_count":1,"reply_users_count":1,"latest_reply":"1615566260.093400","reply_users":["U7HAYKY9X"],"subscribed":false},{"client_msg_id":"87c38019-f00d-4050-8197-36c7611d49e4","type":"message","text":"Hi!\nI have a question regarding the usage of Automa.jl (but not with regards to biology). Is this the right place to ask?","user":"U9MED583T","ts":"1615905095.001300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YyV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi!\nI have a question regarding the usage of Automa.jl (but not with regards to biology). Is this the right place to ask?"}]}]}],"thread_ts":"1615905095.001300","reply_count":4,"reply_users_count":2,"latest_reply":"1615908011.002900","reply_users":["U8JP5B9T2","U9MED583T"],"subscribed":false},{"client_msg_id":"f7ca3551-0791-4523-8c28-ca8f53a5dbe3","type":"message","text":"Is there a tutorial for BioJulia? I want to see how much from the bioinformatics class I'm taking that I can do in it.\n\nMy first thought was \"Can I ask it to load one or more GenBank sequences?\" But I'm not seeing anything, not even sure which package it would be in.\n\nI'd be happy to document my exploration and compile a tutorial based on it.","user":"U01HD5VFXJM","ts":"1616550821.003800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SxYv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a tutorial for BioJulia? I want to see how much from the bioinformatics class I'm taking that I can do in it.\n\nMy first thought was \"Can I ask it to load one or more GenBank sequences?\" But I'm not seeing anything, not even sure which package it would be in.\n\nI'd be happy to document my exploration and compile a tutorial based on it."}]}]}],"thread_ts":"1616550821.003800","reply_count":1,"reply_users_count":1,"latest_reply":"1616551912.003900","reply_users":["U8JP5B9T2"],"is_locked":false,"subscribed":false},{"client_msg_id":"e17c2bde-8439-4bb6-9a89-0e72e578a44d","type":"message","text":"To avoid derailing the other thread: how would I go about adding my packages to BioJulia?","user":"U01JE9F1NER","ts":"1616575769.006200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"D38Vu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"To avoid derailing the other thread: how would I go about adding my packages to BioJulia?"}]}]}],"thread_ts":"1616575769.006200","reply_count":1,"reply_users_count":1,"latest_reply":"1616578239.006300","reply_users":["U7HAYKY9X"],"is_locked":false,"subscribed":false},{"client_msg_id":"917d243f-3ad4-46fb-b252-083fe73f356b","type":"message","text":"Also to avoid derailing the other thread: Is there a (discover-able?) wish list/to-do for BioJulia? I'm not there yet with this language but it might be nice to have and I'd be curious about what needs there were once I'm more up-to-speed","user":"U01S2EGKB7V","ts":"1616622075.010600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YkIX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also to avoid derailing the other thread: Is there a (discover-able?) wish list/to-do for BioJulia? I'm not there yet with this language but it might be nice to have and I'd be curious about what needs there were once I'm more up-to-speed"}]}]}]},{"client_msg_id":"aaf08ec0-0d3f-4f40-add3-9d414e780fad","type":"message","text":"High-level projects are here: <https://github.com/orgs/BioJulia/projects>\nBut there is a lot of smaller-scale issues on the package level.","user":"U7HAYKY9X","ts":"1616622231.011300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0kZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"High-level projects are here: "},{"type":"link","url":"https://github.com/orgs/BioJulia/projects"},{"type":"text","text":"\nBut there is a lot of smaller-scale issues on the package level."}]}]}]},{"client_msg_id":"97a6112b-a142-4759-a142-621ba88a7019","type":"message","text":"Thanks!","user":"U01S2EGKB7V","ts":"1616623669.011500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"r/nX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks!"}]}]}]},{"client_msg_id":"63daeea6-602f-4ad2-8a05-d11c2a297269","type":"message","text":"Depending on your discipline, there are all sorts of BioJulia packages that could use extra hands and clever minds. File IO stuff like XAM.jl, VariantCall.jl. Any of the Kmer packages. PopGen.jl if that's your discipline, etc.","user":"UM4TSHKF1","ts":"1616627529.014000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Msz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Depending on your discipline, there are all sorts of BioJulia packages that could use extra hands and clever minds. File IO stuff like XAM.jl, VariantCall.jl. Any of the Kmer packages. PopGen.jl if that's your discipline, etc."}]}]}]},{"client_msg_id":"c8cc61ef-b116-4089-971a-7aa1e7f3a4c4","type":"message","text":"It might be worth codifying some of this - I'm completely slammed at work at the moment, and realistically won't have a ton of spare time to contribute until the end of summer, but it would be nice to have some of this stuff formalized as projects or goals.\n\n+1 for File IO, and I think uniform interface for all sequence-like objects from readers/writers would be good. Last time I checked (though it was admittedly a while ago), I had to do `FASTA.sequence(record)` to get a sequence from a fasta reader and `FASTQ.sequence(record)` to get it from fastq reader.\n\nThe biggest thing on my wishlist is the afore mentioned cookbook/tutorial. That's not really a do-it-and-its-done type thing, more of an ongoing effort, but getting something off the ground would be huge","user":"U8JP5B9T2","ts":"1616627919.021800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"92/Q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It might be worth codifying some of this - I'm completely slammed at work at the moment, and realistically won't have a ton of spare time to contribute until the end of summer, but it would be nice to have some of this stuff formalized as projects or goals.\n\n+1 for File IO, and I think uniform interface for all sequence-like objects from readers/writers would be good. Last time I checked (though it was admittedly a while ago), I had to do "},{"type":"text","text":"FASTA.sequence(record)","style":{"code":true}},{"type":"text","text":" to get a sequence from a fasta reader and "},{"type":"text","text":"FASTQ.sequence(record)","style":{"code":true}},{"type":"text","text":" to get it from fastq reader.\n\nThe biggest thing on my wishlist is the afore mentioned cookbook/tutorial. That's not really a do-it-and-its-done type thing, more of an ongoing effort, but getting something off the ground would be huge"}]}]}]},{"client_msg_id":"6132391c-465e-4759-bda1-eb1f5a353ad6","type":"message","text":"If you have ideas for improvements that reach across packages - e.g. reviewing file IO, please do make a new BioJulia \"Project\", so it doesn't go down the slack hole","user":"U7HAYKY9X","ts":"1616628116.022700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aoix2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you have ideas for improvements that reach across packages - e.g. reviewing file IO, please do make a new BioJulia \"Project\", so it doesn't go down the slack hole"}]}]}]},{"client_msg_id":"b537b4cc-55d1-486c-8f16-b359a1a0016a","type":"message","text":"Is there any reason why I shouldn’t define `Base.broadcastable(w::GenBank.Writer) = Ref(w)` ? It would be convenient to be able to type `write.(w, chrs)`  instead of iterating over `chrs`, but I noticed it isn’t defined for other Writers","user":"U01JE9F1NER","ts":"1616666664.025700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"z/C","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there any reason why I shouldn’t define "},{"type":"text","text":"Base.broadcastable(w::GenBank.Writer) = Ref(w)","style":{"code":true}},{"type":"text","text":" ? It would be convenient to be able to type "},{"type":"text","text":"write.(w, chrs)","style":{"code":true}},{"type":"text","text":"  instead of iterating over "},{"type":"text","text":"chrs","style":{"code":true}},{"type":"text","text":", but I noticed it isn’t defined for other Writers"}]}]}],"thread_ts":"1616666664.025700","reply_count":1,"reply_users_count":1,"latest_reply":"1616667571.025800","reply_users":["U7HAYKY9X"],"is_locked":false,"subscribed":false},{"client_msg_id":"1fb5c192-91f8-45e6-9871-d7dc455ad822","type":"message","text":"Hey everyone, I know the benefits of Automa.jl, but I'm finding that there are significant performance penalties using it.\n\nFor example in VCFtools.jl the parser uses automa in the backend and takes 6.5 seconds to parse a file I have.\n\nI wrote albeit a very bad parser without Automa (not really a parser but a function and a forloop), but its fast and gets the job done. It finishes the task in 0.6 seconds. I achieved this by reading each line of the file as UInt8[] and parsing that.\n\nI benchmarked with a mature, highly optimized C-based parser (plink.exe) and my bad parser seems to match the speed of a basic file read.\n\nMy question is mainly concerning library creation. I get that BioJulia modules use Automa for their parsers, but if we can save ~10x the time not using it, would that be worth it?","user":"U01FAHWCMFF","ts":"1616947032.032600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pd5km","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey everyone, I know the benefits of Automa.jl, but I'm finding that there are significant performance penalties using it.\n\nFor example in VCFtools.jl the parser uses automa in the backend and takes 6.5 seconds to parse a file I have.\n\nI wrote albeit a very bad parser without Automa (not really a parser but a function and a forloop), but its fast and gets the job done. It finishes the task in 0.6 seconds. I achieved this by reading each line of the file as UInt8[] and parsing that.\n\nI benchmarked with a mature, highly optimized C-based parser (plink.exe) and my bad parser seems to match the speed of a basic file read.\n\nMy question is mainly concerning library creation. I get that BioJulia modules use Automa for their parsers, but if we can save ~10x the time not using it, would that be worth it?"}]}]}],"thread_ts":"1616947032.032600","reply_count":15,"reply_users_count":2,"latest_reply":"1616949128.035600","reply_users":["U7HAYKY9X","U01FAHWCMFF"],"is_locked":false,"subscribed":false},{"client_msg_id":"ab73310b-04e6-4926-88b9-3ea4ceb33fdd","type":"message","text":"Does Julia have something which can generate .gff3 files from .gb (genebank) files?","user":"UC6B1TT7B","ts":"1617391539.037700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"S1aOc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does Julia have something which can generate .gff3 files from .gb (genebank) files?"}]}]}],"thread_ts":"1617391539.037700","reply_count":2,"reply_users_count":2,"latest_reply":"1617393485.038100","reply_users":["U8JP5B9T2","UC6B1TT7B"],"is_locked":false,"subscribed":false}]}