{"cursor": 0, "messages": [{"client_msg_id":"276c16fe-02d9-4215-b422-1688e1eee8ce","type":"message","text":"Hi there! I will be looking for info about Automa.jl in a couple of weeks. Is that the right place ? :slightly_smiling_face:","user":"U01FR2HFJ7M","ts":"1607995590.151400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YBBG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi there! I will be looking for info about Automa.jl in a couple of weeks. Is that the right place ? "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"c47babcb-f114-4c66-91d3-b7d0d064a092","type":"message","text":"probably - if you haven't already, I recomend this as a place to start: <https://biojulia.net/post/automa1/>","user":"U8JP5B9T2","ts":"1607997392.152200","team":"T68168MUP","attachments":[{"service_name":"BioJulia","title":"Tutorial to Automa: Part 1 | BioJulia","title_link":"https://biojulia.net/post/automa1/","text":"Find this notebook at <https://github.com/jakobnissen/automa_tutorial> In bioinformatics, we have a saying: The first step of any bioinformatics project is to define a new file format, incompatible with all previous ones. The situation might not be quite as bad as the saying implies, but it is true that we have a lot of different file formats, representing the various kinds of data we work with. For that reason, creating file parsers is a central task in bioinformatics, and has almost become a craft in itself.","fallback":"BioJulia: Tutorial to Automa: Part 1 | BioJulia","thumb_url":"https://BioJulia.github.io/images/logo_huf2e28fc1e802707079b8e0ffee62f4dc_19447_300x300_fit_lanczos_2.png","ts":1598797689,"from_url":"https://biojulia.net/post/automa1/","thumb_width":300,"thumb_height":300,"service_icon":"https://biojulia.net/images/icon_huf2e28fc1e802707079b8e0ffee62f4dc_19447_192x192_fill_lanczos_center_2.png","id":1,"original_url":"https://biojulia.net/post/automa1/"}],"blocks":[{"type":"rich_text","block_id":"Q/6ZT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"probably - if you haven't already, I recomend this as a place to start: "},{"type":"link","url":"https://biojulia.net/post/automa1/"}]}]}],"reactions":[{"name":"+1","users":["U01FR2HFJ7M","U6QGE7S86","USBKT1275"],"count":3}]},{"client_msg_id":"0f994bf7-e425-4a67-9609-6640638dc8c7","type":"message","text":"Super stoked to announce that my fork of PopGen.jl will be merging into BioJulia/PopGen.jl and continue living there :smile:","user":"UM4TSHKF1","ts":"1608055262.153900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kzPUy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Super stoked to announce that my fork of PopGen.jl will be merging into BioJulia/PopGen.jl and continue living there "},{"type":"emoji","name":"smile"}]}]}],"reactions":[{"name":"clapping","users":["U69BL50BF","U7HAYKY9X","U8JP5B9T2","UCAFZ51L3","U01BR0AKMRQ","UB197FRCL","U6QGE7S86","U9TCDH0E7","ULWFF2Z8U"],"count":9},{"name":"fast_parrot","users":["U69BL50BF","U7HAYKY9X","U6QGE7S86"],"count":3}]},{"type":"message","text":"","user":"USU9FRPEU","ts":"1608072977.155100","team":"T68168MUP","attachments":[{"fallback":"[December 15th, 2020 5:53 PM] ayman: In biology we deal with alot of large compressed files.\n\nCommon file extensions include .fasta.gz and .vcf.gz\n\nCan’t seem to find a good out of the box readers that use multithreading for regular files and compressed files.","ts":"1608072815.225800","author_id":"U01FAHWCMFF","author_subname":"Ayman Al Baz","channel_id":"C6A044SQH","channel_name":"helpdesk","is_msg_unfurl":true,"is_reply_unfurl":true,"text":"In biology we deal with alot of large compressed files.\n\nCommon file extensions include .fasta.gz and .vcf.gz\n\nCan’t seem to find a good out of the box readers that use multithreading for regular files and compressed files.","author_name":"Ayman Al Baz","author_link":"https://julialang.slack.com/team/U01FAHWCMFF","author_icon":"https://avatars.slack-edge.com/2020-11-23/1516965530134_1cf6ed3767c34aaf6d40_48.png","mrkdwn_in":["text"],"color":"D0D0D0","from_url":"https://julialang.slack.com/archives/C6A044SQH/p1608072815225800?thread_ts=1608072566225200&cid=C6A044SQH","is_share":true,"footer":"From a thread in #helpdesk"}]},{"client_msg_id":"c2631a6d-006b-4bcb-8ffd-503f6b6490d1","type":"message","text":"Thanks for reposting here, ya I’m just wondering if there were any libraries that could read large .Fastq.gz and .vcf.gz (primarily this) using multithreading. I know of single threaded readers but I’m just looking for faster solutions","user":"U01FAHWCMFF","ts":"1608073307.156900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"noTy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for reposting here, ya I’m just wondering if there were any libraries that could read large .Fastq.gz and .vcf.gz (primarily this) using multithreading. I know of single threaded readers but I’m just looking for faster solutions"}]}]}]},{"client_msg_id":"a93f8535-a961-4de8-89c0-a7e1fdf7f282","type":"message","text":"<@UC2AEGPC2> is probably the one to contact about this","user":"USU9FRPEU","ts":"1608073689.158500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KtW","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UC2AEGPC2"},{"type":"text","text":" is probably the one to contact about this"}]}]}]},{"client_msg_id":"e58841cd-7840-4c6e-b982-866b4bd9d4b5","type":"message","text":"I think <@U7HAYKY9X> has also thought about how to make automa parsers multithreaded, though I don't know if any work has been done there.","user":"U8JP5B9T2","ts":"1608074164.159500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9LHkn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think "},{"type":"user","user_id":"U7HAYKY9X"},{"type":"text","text":" has also thought about how to make automa parsers multithreaded, though I don't know if any work has been done there."}]}]}]},{"client_msg_id":"f906d99d-d3fc-46f8-bf6d-a9edc549981c","type":"message","text":"There are not, unfortunately. The bottleneck in reading these files is the decompression, so perhaps you could call a binary for multithreaded decompression like pigz? If you're willing to have a slightly lower compression ratio, you can compress it in the BGZF format and read it with CodecBGZF.jl, which is quite fast (and support random access).","user":"U7HAYKY9X","ts":"1608103489.165800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Jcpj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There are not, unfortunately. The bottleneck in reading these files is the decompression, so perhaps you could call a binary for multithreaded decompression like pigz? If you're willing to have a slightly lower compression ratio, you can compress it in the BGZF format and read it with CodecBGZF.jl, which is quite fast (and support random access)."}]}]}],"thread_ts":"1608103489.165800","reply_count":2,"reply_users_count":2,"latest_reply":"1608196142.181600","reply_users":["UM4TSHKF1","U7HAYKY9X"],"subscribed":false},{"client_msg_id":"c9c60331-d5b2-47ae-bde0-055af044b0c2","type":"message","text":"Speaking more broadly, Automa (that is, parsing itself) will probably never be multithreaded since the process is inherently serial (but it can usually parse at several GB/second, do it'll basically never be the problem). So it comes down to implementing a multithreaded decompressor package in Julia. Which is probably really hard","user":"U7HAYKY9X","ts":"1608103721.169000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OSmOE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Speaking more broadly, Automa (that is, parsing itself) will probably never be multithreaded since the process is inherently serial (but it can usually parse at several GB/second, do it'll basically never be the problem). So it comes down to implementing a multithreaded decompressor package in Julia. Which is probably really hard"}]}]}]},{"client_msg_id":"fa5c99f7-868c-442b-95eb-15bf039c0f24","type":"message","text":"Hm, perhaps it would be possible to do the *parsing* in one thread, but then offload all the *work* to another thread. It would have to be done on a parser-by-parser level. Probably not needed for FASTX at least (not sure about VCF, I think that parser is a little unmaintained and rusty)","user":"U7HAYKY9X","ts":"1608106009.170600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vTtIE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hm, perhaps it would be possible to do the "},{"type":"text","text":"parsing","style":{"bold":true}},{"type":"text","text":" in one thread, but then offload all the "},{"type":"text","text":"work","style":{"bold":true}},{"type":"text","text":" to another thread. It would have to be done on a parser-by-parser level. Probably not needed for FASTX at least (not sure about VCF, I think that parser is a little unmaintained and rusty)"}]}]}]},{"client_msg_id":"b58ec672-c674-4adb-8b28-c904d705c2e0","type":"message","text":"Question (I'm quite naive on parallelization) -\n\nIs it possible to have state machines that can start somewhere in the middle, given sufficient signal? For example, in a fastq file, I could jump to the middle of the file, and start scanning until I hit a newline followed by `@` - There are a bunch of other unambiguous entry points to certain states. So I could just say \"I don't know my state until I hit some signal.\" I would imagine you'd waste a bit of time reading the same bytes twice, but it could be worth it (or maybe not it it's really multiple GB / sec)\n\nI definitely think being able to kick state information out to different threads so that the actual bytes can be processed could make a big difference","user":"U8JP5B9T2","ts":"1608130816.175800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"j3kcR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Question (I'm quite naive on parallelization) -\n\nIs it possible to have state machines that can start somewhere in the middle, given sufficient signal? For example, in a fastq file, I could jump to the middle of the file, and start scanning until I hit a newline followed by "},{"type":"text","text":"@","style":{"code":true}},{"type":"text","text":" - There are a bunch of other unambiguous entry points to certain states. So I could just say \"I don't know my state until I hit some signal.\" I would imagine you'd waste a bit of time reading the same bytes twice, but it could be worth it (or maybe not it it's really multiple GB / sec)\n\nI definitely think being able to kick state information out to different threads so that the actual bytes can be processed could make a big difference"}]}]}]},{"client_msg_id":"1b7eeb64-c6b3-40f1-a279-506bb67e2eb3","type":"message","text":"You can do that, yeah. FASTX.jl already starts and stops the state machine at each record. I suppose you could have multiple state machines running in parallel if you wanted to. This would be a question of implementing it in the packages that uses Automa, not in Automa itself","user":"U7HAYKY9X","ts":"1608137352.177300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u+Ue","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can do that, yeah. FASTX.jl already starts and stops the state machine at each record. I suppose you could have multiple state machines running in parallel if you wanted to. This would be a question of implementing it in the packages that uses Automa, not in Automa itself"}]}]}]},{"client_msg_id":"32893a03-feb5-4bcd-b2c4-c916c4aae0c2","type":"message","text":"But, I mean, my laptop reads FASTQ files using FASTX with about 1.5 GB/s (uncompressed, with <https://github.com/BioJulia/Automa.jl/pull/60>) , so it'll probably not be worth the effort. Especially if you would have to scan the file first to find the entry points (though you could do that in a pure SIMD loop). I'd much rather see\n• Multithreaded decompression\n• Use of ReadDataStores.jl","user":"U7HAYKY9X","ts":"1608137569.179100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"014pI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But, I mean, my laptop reads FASTQ files using FASTX with about 1.5 GB/s (uncompressed, with "},{"type":"link","url":"https://github.com/BioJulia/Automa.jl/pull/60"},{"type":"text","text":") , so it'll probably not be worth the effort. Especially if you would have to scan the file first to find the entry points (though you could do that in a pure SIMD loop). I'd much rather see\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Multithreaded decompression"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Use of ReadDataStores.jl"}]}],"style":"bullet","indent":0}]}],"reactions":[{"name":"100","users":["U8JP5B9T2"],"count":1}]},{"client_msg_id":"e3326d93-cf34-4f87-b266-dabc41f93600","type":"message","text":"Thanks for the replies guys. While yes FASTA/Q parsing is fast, VCF parsing remains quite slow on my machine with roughly a read rate of 20mb/s (uncompressed) using the pre-existing VCF tools in julia","user":"U01FAHWCMFF","ts":"1608164297.180800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Sqp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for the replies guys. While yes FASTA/Q parsing is fast, VCF parsing remains quite slow on my machine with roughly a read rate of 20mb/s (uncompressed) using the pre-existing VCF tools in julia"}]}]}]},{"client_msg_id":"4aeb7771-9191-4575-b280-74e1d70168c6","type":"message","text":"Motivated by nothing but contranianism and pettiness, I have now managed to improve the FASTQ parsing times on the <https://github.com/lh3/biofast/tree/master/fqcnt> benchmark quite substantially. Here is current (observed) time versus the one originally reported:\n```Observed:\nRust                   0.43 s\nC                      0.53 s\nJulia                  0.57 s\nJulia (w. compiletime) 3.39 s\nJulia 1.6 (w. c. time) 2.22 s\n\nReported:\nRust:                    0.8 s\nC                        1.4 s\nJulia:                   2.6 s\nJulia (w. compiletime): 13.6 s```\nUnfortunately, Julia 1.6 sees a time of 0.65 seconds, probably due to <https://github.com/JuliaLang/julia/issues/38947>, but if that was fixed, one could extrapolate a speed of 2.1 seconds including compile time.\nThere still seem to be some way to go. The breakdown in time spent is approximately:\n1/3 time on the underlying IO (about 6.4 GB/s)\n1/3 time spent on the actual parsing (also about 6.4 GB/s)\n1/3 time seeps between the cracks, due to inefficiencies in TranscodingStreams.jl, the Reader interface in Automa, and the constant `eof` checking. That's where to improve.","user":"U7HAYKY9X","ts":"1608393170.185800","team":"T68168MUP","edited":{"user":"U7HAYKY9X","ts":"1608456242.000000"},"blocks":[{"type":"rich_text","block_id":"m=wdS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Motivated by nothing but contranianism and pettiness, I have now managed to improve the FASTQ parsing times on the "},{"type":"link","url":"https://github.com/lh3/biofast/tree/master/fqcnt"},{"type":"text","text":" benchmark quite substantially. Here is current (observed) time versus the one originally reported:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Observed:\nRust                   0.43 s\nC                      0.53 s\nJulia                  0.57 s\nJulia (w. compiletime) 3.39 s\nJulia 1.6 (w. c. time) 2.22 s\n\nReported:\nRust:                    0.8 s\nC                        1.4 s\nJulia:                   2.6 s\nJulia (w. compiletime): 13.6 s"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Unfortunately, Julia 1.6 sees a time of 0.65 seconds, probably due to "},{"type":"link","url":"https://github.com/JuliaLang/julia/issues/38947"},{"type":"text","text":", but if that was fixed, one could extrapolate a speed of 2.1 seconds including compile time.\nThere still seem to be some way to go. The breakdown in time spent is approximately:\n1/3 time on the underlying IO (about 6.4 GB/s)\n1/3 time spent on the actual parsing (also about 6.4 GB/s)\n1/3 time seeps between the cracks, due to inefficiencies in TranscodingStreams.jl, the Reader interface in Automa, and the constant "},{"type":"text","text":"eof","style":{"code":true}},{"type":"text","text":" checking. That's where to improve."}]}]}],"reactions":[{"name":"raised_hands","users":["U01FAHWCMFF","UKG4WF8PJ","UGU761DU2","UM4TSHKF1","U01HD5VFXJM"],"count":5},{"name":"100","users":["U6C937ENB"],"count":1}]},{"client_msg_id":"361dbe45-11a4-4224-a2de-6b71c709d060","type":"message","text":"Hi there! Small quick question. I am looking for a package for Genetic Algorithms with possibly autotune of parameters. I have found Evolutionary.jl so far, but I might have missed other options. Any recommandation ?","user":"U01FR2HFJ7M","ts":"1608775090.188300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Mkv6Q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi there! Small quick question. I am looking for a package for Genetic Algorithms with possibly autotune of parameters. I have found Evolutionary.jl so far, but I might have missed other options. Any recommandation ?"}]}]}]},{"client_msg_id":"69b0273b-598a-4979-b271-9fecc75e6769","type":"message","text":"GalacticOptim has the following: <https://galacticoptim.sciml.ai/dev/global_optimizers/global/>","user":"U69BL50BF","ts":"1608775298.188500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nJyeM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"GalacticOptim has the following: "},{"type":"link","url":"https://galacticoptim.sciml.ai/dev/global_optimizers/global/"}]}]}]},{"client_msg_id":"c1d58afd-47a8-49fb-a394-2cba45c35944","type":"message","text":"This looks like a great option, as it also includes Evolutionary.jl. Thanks <@U69BL50BF>","user":"U01FR2HFJ7M","ts":"1608781976.189500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uuF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This looks like a great option, as it also includes Evolutionary.jl. Thanks "},{"type":"user","user_id":"U69BL50BF"}]}]}]},{"client_msg_id":"6e614c8e-b86f-49c8-82a3-9a79ee99fcc4","type":"message","text":"Any idea where I can chat/contact people working/using Evolutionary.jl (other than GH issues)?","user":"U01FR2HFJ7M","ts":"1609824439.191600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ttnW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any idea where I can chat/contact people working/using Evolutionary.jl (other than GH issues)?"}]}]}]},{"client_msg_id":"a26626b3-7813-4fc0-8253-e7f56f17df1d","type":"message","text":"Hi all, I had mentioned way back that I was going to make a PyCall wrapper for Hail (<http://hail.is>) and I’m finally finding time to do it. I have one quick style question for you all. In hail you can read in a vcf file into a MatrixTable, let’s call it mt, and then print out information about it with `mt.describe`, `mt.show`, and so on. Those functions all work fine on the PyObject in PyCall, but I was thinking it might be better style to wrap them in function to make them more Julia-like. For example, PyHail.describe(mt). Any thoughts?","user":"USBRJS6BU","ts":"1610257403.195800","team":"T68168MUP","attachments":[{"title":"Hail |  Index ","title_link":"http://hail.is/","text":"Hail Index Page","fallback":"Hail |  Index ","from_url":"http://hail.is/","service_icon":"https://hail.is/hail_logo_sq-sm-opt.ico","service_name":"hail.is","id":1,"original_url":"http://hail.is"}],"blocks":[{"type":"rich_text","block_id":"/TW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all, I had mentioned way back that I was going to make a PyCall wrapper for Hail ("},{"type":"link","url":"http://hail.is"},{"type":"text","text":") and I’m finally finding time to do it. I have one quick style question for you all. In hail you can read in a vcf file into a MatrixTable, let’s call it mt, and then print out information about it with "},{"type":"text","text":"mt.describe","style":{"code":true}},{"type":"text","text":", "},{"type":"text","text":"mt.show","style":{"code":true}},{"type":"text","text":", and so on. Those functions all work fine on the PyObject in PyCall, but I was thinking it might be better style to wrap them in function to make them more Julia-like. For example, PyHail.describe(mt). Any thoughts?"}]}]}]},{"client_msg_id":"22d16385-cca6-4f38-86cb-382c8643f802","type":"message","text":"ScRNAseq.jl - for single-cell RNA-seq (scRNAseq) data analysis. Ppl interested in working together, please feel free to contact.","user":"ULWFF2Z8U","ts":"1610603568.002700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4PD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ScRNAseq.jl - for single-cell RNA-seq (scRNAseq) data analysis. Ppl interested in working together, please feel free to contact."}]}]}],"reactions":[{"name":"biojulia","users":["UCAFZ51L3","U7HAYKY9X"],"count":2}]},{"client_msg_id":"6891a1b6-a759-4610-8d04-8987f9a57829","type":"message","text":"hi, yeah I have been working on BioMakie on the side. A lot has been happening regarding layouts and so I will probably rewrite it to use the newer syntax.\nAs for the other viz tools, I have thought about making the connection, but I don't know how to do it. I'd be interested in working on it though. The fact that they have python controls means that at least there could be a PyCall interop.","user":"UAH43TMUN","ts":"1610933640.019700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nrbt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hi, yeah I have been working on BioMakie on the side. A lot has been happening regarding layouts and so I will probably rewrite it to use the newer syntax.\nAs for the other viz tools, I have thought about making the connection, but I don't know how to do it. I'd be interested in working on it though. The fact that they have python controls means that at least there could be a PyCall interop."}]}]}]},{"client_msg_id":"8871b190-cdf0-4368-9ff9-82e03081e3da","type":"message","text":"I want to align a short sequence A to a long sequence B, since I know A is contained in B. However, I can't find a setting for `BioAlignments` that doesn't give obviously bad results if the last nucleotide(s) of A is a mismatch:\n• If I choose a LocalAlignment, then the alignment just stops and doesn't include the last nucleotides\n• If I pick a global or semiglobal alignment, then the alignment will insert huge massive gaps in A in order to make it fit \"globally\" with B\nWhat to do?","user":"U7HAYKY9X","ts":"1611748527.003700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Tn1j","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I want to align a short sequence A to a long sequence B, since I know A is contained in B. However, I can't find a setting for "},{"type":"text","text":"BioAlignments","style":{"code":true}},{"type":"text","text":" that doesn't give obviously bad results if the last nucleotide(s) of A is a mismatch:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If I choose a LocalAlignment, then the alignment just stops and doesn't include the last nucleotides"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"If I pick a global or semiglobal alignment, then the alignment will insert huge massive gaps in A in order to make it fit \"globally\" with B"}]}],"style":"bullet","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"What to do?"}]}]}]},{"client_msg_id":"5994f198-c4ce-4703-a93e-97c15e68406d","type":"message","text":"```run(`bowtie2 ...`)```\n:julia-troll:","user":"U8JP5B9T2","ts":"1611759654.004700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MioG","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"run(`bowtie2 ...`)"}]},{"type":"rich_text_section","elements":[{"type":"emoji","name":"julia-troll"}]}]}],"reactions":[{"name":"troll","users":["U7HAYKY9X"],"count":1}]},{"client_msg_id":"ff1cbd78-c886-4517-b396-dfa1ceb16ff8","type":"message","text":"Looks like `OverlapAlignment()` solves it.","user":"U7HAYKY9X","ts":"1611772489.005100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Z20ja","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looks like "},{"type":"text","text":"OverlapAlignment()","style":{"code":true}},{"type":"text","text":" solves it."}]}]}],"reactions":[{"name":"tada","users":["U8JP5B9T2"],"count":1}]},{"client_msg_id":"c4476097-73c4-4b9e-8afa-60d76048398f","type":"message","text":"Hi everyone, I’m putting together a small package for working with pedigree files and was wondering if anyone had any thoughts on useful features. So far I just have the ability to read and write pedigree files assuming the FamID, Proband, Father, Mother, and Gender columns are all present (I know this isn’t necessarily the case, but it’s true of every ped I’ve worked with). I am planning to optionally support the Phenotype column and add support for trio based pedigrees.","user":"USBRJS6BU","ts":"1611797539.007500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n+OKt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi everyone, I’m putting together a small package for working with pedigree files and was wondering if anyone had any thoughts on useful features. So far I just have the ability to read and write pedigree files assuming the FamID, Proband, Father, Mother, and Gender columns are all present (I know this isn’t necessarily the case, but it’s true of every ped I’ve worked with). I am planning to optionally support the Phenotype column and add support for trio based pedigrees."}]}]}]},{"client_msg_id":"034845c9-1c07-47d5-b7a2-7f7de881ec15","type":"message","text":"And for those who were interested in Hail, I’ll have something to share this weekend (I haven’t forgotten!)","user":"USBRJS6BU","ts":"1611797567.008100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PC/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And for those who were interested in Hail, I’ll have something to share this weekend (I haven’t forgotten!)"}]}]}]},{"client_msg_id":"5f31119b-a2e3-4a90-8a22-a3eec57d717b","type":"message","text":"I have created a new package, VCF.jl, for reading VCF files. It's not my work originally, because it just contains the VCF/BCF IO that exists in GeneticVariation.jl. But it makes more sense to have as a separate package:\n* Smaller package means fewer dependencies, and most people(?) only use the VCF part of GeneticVariation.jl.\n* A smaller package with a clear focus is easier to maintain. (GeneticVariation.jl is not actively maintained.)\nVCF.jl can be found here: <https://github.com/rasmushenningsson/VCF.jl>\nIt is in the process of being registered.","user":"UPNRULT51","ts":"1613294797.015800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"t0p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have created a new package, VCF.jl, for reading VCF files. It's not my work originally, because it just contains the VCF/BCF IO that exists in GeneticVariation.jl. But it makes more sense to have as a separate package:\n* Smaller package means fewer dependencies, and most people(?) only use the VCF part of GeneticVariation.jl.\n* A smaller package with a clear focus is easier to maintain. (GeneticVariation.jl is not actively maintained.)\nVCF.jl can be found here: "},{"type":"link","url":"https://github.com/rasmushenningsson/VCF.jl"},{"type":"text","text":"\nIt is in the process of being registered."}]}]}]},{"client_msg_id":"9a181f4f-2ac0-47b9-b264-4df5c039f009","type":"message","text":"I hope this will be useful to others!","user":"UPNRULT51","ts":"1613295046.016300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ssVFW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I hope this will be useful to others!"}]}]}]},{"client_msg_id":"e7f32a06-fb72-4145-b2a8-bc5c146e8e8d","type":"message","text":"If anyone wants me to *keep* the name `VCF.jl` instead of changing to `VariantCallFormat.jl`, please say so. :) Otherwise I will go ahead with the change. (There's a thread in <#C6M4DQA5P|pkg-registration> if you want arguments for/against.)","user":"UPNRULT51","ts":"1613378287.021500","team":"T68168MUP","edited":{"user":"UPNRULT51","ts":"1613378302.000000"},"blocks":[{"type":"rich_text","block_id":"zQul","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If anyone wants me to "},{"type":"text","text":"keep","style":{"bold":true}},{"type":"text","text":" the name "},{"type":"text","text":"VCF.jl","style":{"code":true}},{"type":"text","text":" instead of changing to "},{"type":"text","text":"VariantCallFormat.jl","style":{"code":true}},{"type":"text","text":", please say so. :) Otherwise I will go ahead with the change. (There's a thread in "},{"type":"channel","channel_id":"C6M4DQA5P"},{"type":"text","text":" if you want arguments for/against.)"}]}]}]},{"client_msg_id":"0ad6000a-bc5f-486d-af5b-44254158cf19","type":"message","text":"Anyone here has a good forum post/ tutorial here to find duplicated protein sequences in a fasta using Julia?","user":"UTB5MKCL8","ts":"1614000694.000600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UIxi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone here has a good forum post/ tutorial here to find duplicated protein sequences in a fasta using Julia?"}]}]}],"thread_ts":"1614000694.000600","reply_count":15,"reply_users_count":2,"latest_reply":"1614003134.005000","reply_users":["UTB5MKCL8","U7HAYKY9X"],"subscribed":false}]}