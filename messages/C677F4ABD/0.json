{"cursor": 1, "messages": [{"client_msg_id":"9958accb-2569-44ae-a97c-6b8922f3c2c3","type":"message","text":"What's the rationale behind `transpose` being recursive? In what common use case is it different than a non-recursive version?","user":"UENHZ1M08","ts":"1613955339.001000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n4lTx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What's the rationale behind "},{"type":"text","text":"transpose","style":{"code":true}},{"type":"text","text":" being recursive? In what common use case is it different than a non-recursive version?"}]}]}],"thread_ts":"1613955339.001000","reply_count":2,"reply_users_count":2,"latest_reply":"1613957884.001300","reply_users":["UB197FRCL","UH8A351DJ"],"subscribed":false},{"client_msg_id":"a6939957-0346-4c15-9315-2d615f67f825","type":"message","text":"Having some numerical errors, i am calculating  `S=XX^T`, which should be SPD, but the result isnt. tried `S=(S+S.T)*0.5` which often works in such cases, but still fails","user":"UEZMLSB3R","ts":"1614021001.009400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Due4b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Having some numerical errors, i am calculating  "},{"type":"text","text":"S=XX^T","style":{"code":true}},{"type":"text","text":", which should be SPD, but the result isnt. tried "},{"type":"text","text":"S=(S+S.T)*0.5","style":{"code":true}},{"type":"text","text":" which often works in such cases, but still fails"}]}]}]},{"client_msg_id":"d8c90c3e-7242-443a-9889-7f2391a0ec0f","type":"message","text":"any nice idea to solve this?","user":"UEZMLSB3R","ts":"1614021011.009700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9Pgh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"any nice idea to solve this?"}]}]}]},{"client_msg_id":"ddfac5e5-9815-406f-913b-02b5aeb1ac45","type":"message","text":"(X is an array of 64x2MIL)","user":"UEZMLSB3R","ts":"1614021056.010300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"quARw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(X is an array of 64x2MIL)"}]}]}]},{"client_msg_id":"0e7acf3b-4454-4db1-a444-901878eddec5","type":"message","text":"What do you mean by \"`S` is not SPD\" here?\nNot symmetric? Slightly negative eigenvalues? Cholesky factorization fails?\n\nSince `X` is `64 x 2_000_000`, each coefficient in `S` is a sum with 2 million terms --&gt; you're indeed likely to have some rounding errors, especially if the range of non-zero coeffs in `X` is large.\n\nThe transformation `S = (S + S') * 0.5` will only addresses symmetry, not negative eigenvalues.","user":"UCT7E536E","ts":"1614021507.014700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n=3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What do you mean by \""},{"type":"text","text":"S","style":{"code":true}},{"type":"text","text":" is not SPD\" here?\nNot symmetric? Slightly negative eigenvalues? Cholesky factorization fails?\n\nSince "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" is "},{"type":"text","text":"64 x 2_000_000","style":{"code":true}},{"type":"text","text":", each coefficient in "},{"type":"text","text":"S","style":{"code":true}},{"type":"text","text":" is a sum with 2 million terms --> you're indeed likely to have some rounding errors, especially if the range of non-zero coeffs in "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" is large.\n\nThe transformation "},{"type":"text","text":"S = (S + S') * 0.5","style":{"code":true}},{"type":"text","text":" will only addresses symmetry, not negative eigenvalues."}]}]}]},{"client_msg_id":"9a27b0c3-168e-4204-b0ae-f0e61255451b","type":"message","text":"Yes, that sometimes does the trick when i had the same problem before","user":"UEZMLSB3R","ts":"1614021555.015500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0WOLz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, that sometimes does the trick when i had the same problem before"}]}]}]},{"client_msg_id":"af220980-2479-4027-aecd-420859f7840c","type":"message","text":"Cholesky factorization fails","user":"UEZMLSB3R","ts":"1614021562.015800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XBo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Cholesky factorization fails"}]}]}]},{"client_msg_id":"d7ba22dd-1ab9-4486-85cc-eb8ac60fbec3","type":"message","text":"althou no negative eigenvalues","user":"UEZMLSB3R","ts":"1614021572.016200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0hiJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"althou no negative eigenvalues"}]}]}]},{"client_msg_id":"f4b5afde-196d-4f44-8592-28b9c6e5c315","type":"message","text":"the smallest is `6.810845f9`","user":"UEZMLSB3R","ts":"1614021587.016700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QwN6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the smallest is "},{"type":"text","text":"6.810845f9","style":{"code":true}}]}]}]},{"client_msg_id":"68582c38-1382-4df5-a278-e39e7781763a","type":"message","text":"The obvious first: have you tried `F = cholesky(Symmetric(S))`? It will ensure the input to `cholesky` is structurally symmetric.","user":"UCT7E536E","ts":"1614021672.018800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dO6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The obvious first: have you tried "},{"type":"text","text":"F = cholesky(Symmetric(S))","style":{"code":true}},{"type":"text","text":"? It will ensure the input to "},{"type":"text","text":"cholesky","style":{"code":true}},{"type":"text","text":" is structurally symmetric."}]}]}]},{"client_msg_id":"28d54197-0489-4c67-b7c2-dd5fe3f7dd27","type":"message","text":"More generally, Cholesky requires PD matrices. Here `S` is PD if and only if `X` has full row rank, which is likely to be the case since it has 2M columns.\nI would check the numerical range of coefficients in `S`:\n```extrema(S)```\nIf you have very small/large coefficients, and/or the ratio `max/min` is large, then there's a good chance you'll get numerical issues in the factorization itself (e.g. numerically small pivots).\nOne way to get rid of that is to re-scale `X` , so that `S` is better-scaled. For instance, ensure that the norm of each row/column in `X` is closed to one.","user":"UCT7E536E","ts":"1614021750.020300","team":"T68168MUP","edited":{"user":"UCT7E536E","ts":"1614021872.000000"},"blocks":[{"type":"rich_text","block_id":"tM2Lv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"More generally, Cholesky requires PD matrices. Here "},{"type":"text","text":"S","style":{"code":true}},{"type":"text","text":" is PD if and only if "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" has full row rank, which is likely to be the case since it has 2M columns.\nI would check the numerical range of coefficients in "},{"type":"text","text":"S","style":{"code":true}},{"type":"text","text":":\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"extrema(S)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nIf you have very small/large coefficients, and/or the ratio "},{"type":"text","text":"max/min","style":{"code":true}},{"type":"text","text":" is large, then there's a good chance you'll get numerical issues in the factorization itself (e.g. numerically small pivots).\nOne way to get rid of that is to re-scale "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" , so that "},{"type":"text","text":"S","style":{"code":true}},{"type":"text","text":" is better-scaled. For instance, ensure that the norm of each row/column in "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" is closed to one."}]}]}]},{"client_msg_id":"89b1c204-85f3-43fd-bfad-074fd7ca0cf5","type":"message","text":"checking","user":"UEZMLSB3R","ts":"1614021810.020600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8V/b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"checking"}]}]}]},{"client_msg_id":"004b1586-b255-4b39-a68f-d72ccb4398c1","type":"message","text":"(-4.1357558f8, 1.4033495f9)","user":"UEZMLSB3R","ts":"1614021932.021800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EQat","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(-4.1357558f8, 1.4033495f9)"}]}]}]},{"client_msg_id":"ebdbd2b2-4020-4e1e-a54b-e16dab8c3c48","type":"message","text":"You have  `Float32` data?","user":"UCT7E536E","ts":"1614021961.022500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ot80=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You have  "},{"type":"text","text":"Float32","style":{"code":true}},{"type":"text","text":" data?"}]}]}]},{"client_msg_id":"cdf610fb-cf83-4420-a040-bec1378b17c3","type":"message","text":"Yes","user":"UEZMLSB3R","ts":"1614021969.022700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jl7g","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes"}]}]}]},{"client_msg_id":"1f9ec7b6-94e6-4be6-8847-fbd8a95f01d8","type":"message","text":"Done some heavy optimizations on it before, I would prefer to keep it that way, but if there is no other solution I will swap back to 64","user":"UEZMLSB3R","ts":"1614022012.024000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EPW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Done some heavy optimizations on it before, I would prefer to keep it that way, but if there is no other solution I will swap back to 64"}]}]}]},{"client_msg_id":"6512b506-5c8d-4f66-9b3f-d31a1e881766","type":"message","text":"What's `extrema(abs.(S))`?","user":"UCT7E536E","ts":"1614022021.024100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Br7B","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What's "},{"type":"text","text":"extrema(abs.(S))","style":{"code":true}},{"type":"text","text":"?"}]}]}]},{"client_msg_id":"e9950605-d149-4afe-b8e3-ea9a378fe1c1","type":"message","text":"(5522.052001953125, 1.403349327588623e9)","user":"UEZMLSB3R","ts":"1614022081.025200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GmIMF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(5522.052001953125, 1.403349327588623e9)"}]}]}]},{"client_msg_id":"f308b372-9e45-4ac2-a879-be36c3467859","type":"message","text":"I guess, since `S` is `64x64`, it wouldn't be too expensive to convert to Float64, factorize, then convert back to Float32.","user":"UCT7E536E","ts":"1614022090.025500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3B4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I guess, since "},{"type":"text","text":"S","style":{"code":true}},{"type":"text","text":" is "},{"type":"text","text":"64x64","style":{"code":true}},{"type":"text","text":", it wouldn't be too expensive to convert to Float64, factorize, then convert back to Float32."}]}]}]},{"client_msg_id":"70d0bcfa-e71d-4c00-98e4-d523eeb0cfd4","type":"message","text":"Working on raw f64 data `isposdef(S)` was true","user":"UEZMLSB3R","ts":"1614022175.027700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CUwR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Working on raw f64 data "},{"type":"text","text":"isposdef(S)","style":{"code":true}},{"type":"text","text":" was true"}]}]}]},{"client_msg_id":"4f075f3f-fd18-46eb-8e3e-e7c013ff7e84","type":"message","text":"In any case, your `S` looks badly conditioned: the largest element is ~250_000 larger than the smallest one. That's only about ~100x the machine precision for Float32.\nSo it's highly likely the Cholesky factorization will have a lot of rounding errors.","user":"UCT7E536E","ts":"1614022241.028600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qgiq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In any case, your "},{"type":"text","text":"S","style":{"code":true}},{"type":"text","text":" looks badly conditioned: the largest element is ~250_000 larger than the smallest one. That's only about ~100x the machine precision for Float32.\nSo it's highly likely the Cholesky factorization will have a lot of rounding errors."}]}]}]},{"client_msg_id":"0051de23-8ca0-409e-97a2-63b3f74da97c","type":"message","text":"I'd look into ways to improve that conditioning first.","user":"UCT7E536E","ts":"1614022269.029600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"I/aS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd look into ways to improve that conditioning first."}]}]}]},{"client_msg_id":"059916b1-f659-4230-99bf-918ab8a00e1b","type":"message","text":"Seems like I need to convert the data back to 64 before `XX^T`","user":"UEZMLSB3R","ts":"1614022340.031800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4lx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Seems like I need to convert the data back to 64 before "},{"type":"text","text":"XX^T","style":{"code":true}}]}]}]},{"client_msg_id":"ae26d1a6-022b-4abe-8f7d-9eb7dc578700","type":"message","text":"One option is always to add some positive term to the diagonal, e.g., to factorize `S + zI` for a well-chosen `z` .\n`z` should be small enough to not perturb the system too much, but large enough to actually make the factorization more stable.","user":"UCT7E536E","ts":"1614022363.032400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8ml=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One option is always to add some positive term to the diagonal, e.g., to factorize "},{"type":"text","text":"S + zI","style":{"code":true}},{"type":"text","text":" for a well-chosen "},{"type":"text","text":"z","style":{"code":true}},{"type":"text","text":" .\n"},{"type":"text","text":"z","style":{"code":true}},{"type":"text","text":" should be small enough to not perturb the system too much, but large enough to actually make the factorization more stable."}]}]}]},{"client_msg_id":"df08f31d-b7f0-477b-9251-b3e98b04c5d0","type":"message","text":"Yes that was my previous solution","user":"UEZMLSB3R","ts":"1614022382.032800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZpU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes that was my previous solution"}]}]}]},{"client_msg_id":"769a98f2-1646-4ead-bb7b-87e0f2615878","type":"message","text":"But in this case seems like i applied it to many times, which eventually resulted in errors elsewhere","user":"UEZMLSB3R","ts":"1614022416.033600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SmU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But in this case seems like i applied it to many times, which eventually resulted in errors elsewhere"}]}]}]},{"client_msg_id":"b3f0603f-ff1f-4a1c-992c-6120395486f4","type":"message","text":"I will convert it to 64 before doing the multiplication, should not be too bad","user":"UEZMLSB3R","ts":"1614022479.034600","team":"T68168MUP","edited":{"user":"UEZMLSB3R","ts":"1614022571.000000"},"blocks":[{"type":"rich_text","block_id":"+riZb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I will convert it to 64 before doing the multiplication, should not be too bad"}]}]}]},{"client_msg_id":"a34678b8-25c0-4754-a8be-01d920f87642","type":"message","text":"Thanks!","user":"UEZMLSB3R","ts":"1614022536.034800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"J6D","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks!"}]}]}],"reactions":[{"name":"+1","users":["UCT7E536E"],"count":1}]},{"client_msg_id":"f1906b53-28f6-4176-91e1-34aee2751c98","type":"message","text":"The A \\ b operator finds the minimum-norm solution if the matrix is rectangular, but tries to solve the system as-is when A is square - and fails if it is singular. How to always get the min-norm solution, even for square matrix?","user":"UGTUKUHLN","ts":"1614089364.037200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Jpe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The A \\ b operator finds the minimum-norm solution if the matrix is rectangular, but tries to solve the system as-is when A is square - and fails if it is singular. How to always get the min-norm solution, even for square matrix?"}]}]}]},{"client_msg_id":"e27760fc-8dfe-4139-a125-fdd1b398d088","type":"message","text":"I'm implementing the real matrix square root and logarithm using the Schur decomposition and blocking (i.e. those described in Section 4.3 of <https://www.maths.manchester.ac.uk/~higham/narep/narep89.pdf> and Algorithm 6.1 of <http://eprints.maths.manchester.ac.uk/2015/1/120885991.pdf>, respectively). Is there an appropriate existing package to which I should contribute these?","user":"UHDQQ4GN6","ts":"1614283857.050800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VED2L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm implementing the real matrix square root and logarithm using the Schur decomposition and blocking (i.e. those described in Section 4.3 of "},{"type":"link","url":"https://www.maths.manchester.ac.uk/~higham/narep/narep89.pdf"},{"type":"text","text":" and Algorithm 6.1 of "},{"type":"link","url":"http://eprints.maths.manchester.ac.uk/2015/1/120885991.pdf"},{"type":"text","text":", respectively). Is there an appropriate existing package to which I should contribute these?"}]}]}],"thread_ts":"1614283857.050800","reply_count":1,"reply_users_count":1,"latest_reply":"1614283955.050900","reply_users":["UHDQQ4GN6"],"subscribed":false},{"client_msg_id":"04a6a9d2-7cbd-4501-b3af-58713cfa614f","type":"message","text":"Can folks try out: <https://github.com/JuliaLinearAlgebra/MKL.jl/pull/63>","user":"U67461GUB","ts":"1614452092.053500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2Lym","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can folks try out: "},{"type":"link","url":"https://github.com/JuliaLinearAlgebra/MKL.jl/pull/63"}]}]}]},{"client_msg_id":"6bbaaabd-1a3b-463e-bb2b-15129223c18a","type":"message","text":"Basically, build Julia from master, and check out the MKL.jl#lbt2 branch. `using MKL` should switch your BLAS to MKL.","user":"U67461GUB","ts":"1614452128.054400","team":"T68168MUP","edited":{"user":"U67461GUB","ts":"1614452143.000000"},"blocks":[{"type":"rich_text","block_id":"fl4zt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Basically, build Julia from master, and check out the MKL.jl#lbt2 branch. "},{"type":"text","text":"using MKL","style":{"code":true}},{"type":"text","text":" should switch your BLAS to MKL."}]}]}]},{"client_msg_id":"c1feced2-75be-4ed5-8023-69c28a78df71","type":"message","text":"should PDMat’s overload 3 arg `*` to perform `quad`, and `X_A_Xt` ?\n(when arguments are of right types)","user":"U6A936746","ts":"1614600894.056200","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1614600906.000000"},"blocks":[{"type":"rich_text","block_id":"yNa0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"should PDMat’s overload 3 arg "},{"type":"text","text":"*","style":{"code":true}},{"type":"text","text":" to perform "},{"type":"text","text":"quad","style":{"code":true}},{"type":"text","text":", and "},{"type":"text","text":"X_A_Xt","style":{"code":true}},{"type":"text","text":" ?\n(when arguments are of right types)"}]}]}]},{"client_msg_id":"31f1d8c0-6800-482a-a9ba-f8dfe9220c6b","type":"message","text":"I’d be in favor","user":"U680T6770","ts":"1614600991.056600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HukaO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’d be in favor"}]}]}]},{"client_msg_id":"1cb2dee4-793b-41b3-937c-3df82365d08a","type":"message","text":"I will open an issue","user":"U6A936746","ts":"1614600998.056800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9IdWv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I will open an issue"}]}]}],"thread_ts":"1614600998.056800","reply_count":1,"reply_users_count":1,"latest_reply":"1614601396.056900","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"6ef28f67-8a0b-430c-8f77-d5f2a3827b21","type":"message","text":"I have some complex code involving compound types with sparse matrices in them. To make the code a bit more cleaner and readable, I introduced these redefinitions, which allow for Matlab-like behaviour, allowing sparse right-hand sides. (I know memory is not an issue)\n```ldiv!(A::Factorization, B::AbstractSparseMatrix) = ldiv!(A, Matrix(B))\nldiv!(A::Factorization, B::AbstractSparseVector) = ldiv!(A, Vector(B))\nrdiv!(A::AbstractSparseMatrix, B::Factorization) = rdiv!(Matrix(A), B)\nrdiv!(A::AbstractSparseVector, B::Factorization) = rdiv!(Vector(A), B)\nldiv!(A::AbstractMatrix, B::AbstractSparseMatrix) = ldiv!(A, Matrix(B))\nldiv!(A::AbstractMatrix, B::AbstractSparseVector) = ldiv!(A, Vector(B))\nrdiv!(A::AbstractSparseMatrix, B::AbstractMatrix) = rdiv!(Matrix(A), B)\nrdiv!(A::AbstractSparseVector, B::AbstractMatrix) = rdiv!(Vector(A), B)```\nHowever, I get this warning: An imported function has been extended without using module defined typed arguments. Any clues on how to resolve this?","user":"U01L0RJC6FM","ts":"1614678052.060100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Sxp8y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have some complex code involving compound types with sparse matrices in them. To make the code a bit more cleaner and readable, I introduced these redefinitions, which allow for Matlab-like behaviour, allowing sparse right-hand sides. (I know memory is not an issue)\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ldiv!(A::Factorization, B::AbstractSparseMatrix) = ldiv!(A, Matrix(B))\nldiv!(A::Factorization, B::AbstractSparseVector) = ldiv!(A, Vector(B))\nrdiv!(A::AbstractSparseMatrix, B::Factorization) = rdiv!(Matrix(A), B)\nrdiv!(A::AbstractSparseVector, B::Factorization) = rdiv!(Vector(A), B)\nldiv!(A::AbstractMatrix, B::AbstractSparseMatrix) = ldiv!(A, Matrix(B))\nldiv!(A::AbstractMatrix, B::AbstractSparseVector) = ldiv!(A, Vector(B))\nrdiv!(A::AbstractSparseMatrix, B::AbstractMatrix) = rdiv!(Matrix(A), B)\nrdiv!(A::AbstractSparseVector, B::AbstractMatrix) = rdiv!(Vector(A), B)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"However, I get this warning: An imported function has been extended without using module defined typed arguments. Any clues on how to resolve this?"}]}]}],"thread_ts":"1614678052.060100","reply_count":1,"reply_users_count":1,"latest_reply":"1614679060.067000","reply_users":["UCZ7VBGUD"],"subscribed":false},{"client_msg_id":"05efa7a0-217f-4084-b5a0-117525f077b2","type":"message","text":"hi guys, I am not sure whether this is the right place to ask but maybe worth a try:\nI am using the package LowRankApprox.jl and I am trying to access a `U::LowRankMatrix` , using indices written in a vector, say  `i = [1,2,3,4]`  . Weirdly, I am getting the following error message when I try to access those indices by doing `U[i,i]`  :\n\n```debug&gt; U[[1,2,3,4],[1,2,3,4]]\nERROR: setindex! not defined for LowRankApprox.LowRankMatrix{Float64}\nStacktrace:\n [1] error(::String, ::Type{T} where T) at ./error.jl:42\n [2] error_if_canonical_setindex(::IndexCartesian, ::LowRankApprox.LowRankMatrix{Float64}, ::Int64, ::Int64) at ./abstractarray.jl:1163\n [3] setindex! at ./abstractarray.jl:1152 [inlined]\n [4] _setindex! at ./abstractarray.jl:1183 [inlined]\n [5] setindex! at ./abstractarray.jl:1153 [inlined]\n [6] macro expansion at ./multidimensional.jl:772 [inlined]\n [7] macro expansion at ./cartesian.jl:64 [inlined]\n [8] macro expansion at ./multidimensional.jl:767 [inlined]\n [9] _unsafe_getindex! at ./multidimensional.jl:762 [inlined]\n [10] _unsafe_getindex(::IndexCartesian, ::LowRankApprox.LowRankMatrix{Float64}, ::Array{Int64,1}, ::Array{Int64,1}) at ./multidimensional.jl:757\n [11] _getindex at ./multidimensional.jl:743 [inlined]\n [12] getindex(::LowRankApprox.LowRankMatrix{Float64}, ::Array{Int64,1}, ::Array{Int64,1}) at ./abstractarray.jl:1060\n [13] top-level scope at none:1```\nanyone here has a tip? thanks in advance :)","user":"U01L0RJC6FM","ts":"1614890216.080200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TYF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hi guys, I am not sure whether this is the right place to ask but maybe worth a try:\nI am using the package LowRankApprox.jl and I am trying to access a "},{"type":"text","text":"U::LowRankMatrix","style":{"code":true}},{"type":"text","text":" , using indices written in a vector, say "},{"type":"text","text":" i = [1,2,3,4] ","style":{"code":true}},{"type":"text","text":" . Weirdly, I am getting the following error message when I try to access those indices by doing "},{"type":"text","text":"U[i,i] ","style":{"code":true}},{"type":"text","text":" :\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"debug> U[[1,2,3,4],[1,2,3,4]]\nERROR: setindex! not defined for LowRankApprox.LowRankMatrix{Float64}\nStacktrace:\n [1] error(::String, ::Type{T} where T) at ./error.jl:42\n [2] error_if_canonical_setindex(::IndexCartesian, ::LowRankApprox.LowRankMatrix{Float64}, ::Int64, ::Int64) at ./abstractarray.jl:1163\n [3] setindex! at ./abstractarray.jl:1152 [inlined]\n [4] _setindex! at ./abstractarray.jl:1183 [inlined]\n [5] setindex! at ./abstractarray.jl:1153 [inlined]\n [6] macro expansion at ./multidimensional.jl:772 [inlined]\n [7] macro expansion at ./cartesian.jl:64 [inlined]\n [8] macro expansion at ./multidimensional.jl:767 [inlined]\n [9] _unsafe_getindex! at ./multidimensional.jl:762 [inlined]\n [10] _unsafe_getindex(::IndexCartesian, ::LowRankApprox.LowRankMatrix{Float64}, ::Array{Int64,1}, ::Array{Int64,1}) at ./multidimensional.jl:757\n [11] _getindex at ./multidimensional.jl:743 [inlined]\n [12] getindex(::LowRankApprox.LowRankMatrix{Float64}, ::Array{Int64,1}, ::Array{Int64,1}) at ./abstractarray.jl:1060\n [13] top-level scope at none:1"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"anyone here has a tip? thanks in advance :)"}]}]}]},{"client_msg_id":"66233c88-e3f5-4e30-9ee3-7ee5253c5f76","type":"message","text":"I'd like to tap the Julia hive-mind about something that might not be strictly related to Julia. If I have two square N x N matrices of rank M &lt; N, is there a way to do `schur(A, B)` more efficiently, perhaps working it out first on the M x M full-rank subspaces and then inflating the result to NxN somehow?\nSince `schur` is O(N^3) the benefit could be substantial...","user":"U6G4M02N4","ts":"1614929116.083100","team":"T68168MUP","edited":{"user":"U6G4M02N4","ts":"1614929230.000000"},"blocks":[{"type":"rich_text","block_id":"ACYM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd like to tap the Julia hive-mind about something that might not be strictly related to Julia. If I have two square N x N matrices of rank M < N, is there a way to do "},{"type":"text","text":"schur(A, B)","style":{"code":true}},{"type":"text","text":" more efficiently, perhaps working it out first on the M x M full-rank subspaces and then inflating the result to NxN somehow?\nSince "},{"type":"text","text":"schur","style":{"code":true}},{"type":"text","text":" is O(N^3) the benefit could be substantial..."}]}]}]},{"client_msg_id":"03f68831-4b45-4a65-807b-1c3b034315bd","type":"message","text":"Do you know the rank? You can use ARPACK for the generalized eigenvalue problem but it can be tricky for reduced rank matrices","user":"U680T6770","ts":"1614930352.084300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dpOAX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Do you know the rank? You can use ARPACK for the generalized eigenvalue problem but it can be tricky for reduced rank matrices"}]}]}]},{"client_msg_id":"274329ce-0869-45b1-b588-0c5f14d22f69","type":"message","text":"Yes, M is known, and typically much smaller than N. But I want to avoid using eigen! because of numerical stability issues. I actually did it the way you suggest first, but the numerical noise in some cases was a problem because of ill-conditioning (several eigenvectors almost parallel). The schur step of eigen, however, should not be affected by ill-conditioning, hence my question. But I'm struggling to understand how to make it work.","user":"U6G4M02N4","ts":"1614930739.087100","team":"T68168MUP","edited":{"user":"U6G4M02N4","ts":"1614931009.000000"},"blocks":[{"type":"rich_text","block_id":"ZzQR8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, M is known, and typically much smaller than N. But I want to avoid using eigen! because of numerical stability issues. I actually did it the way you suggest first, but the numerical noise in some cases was a problem because of ill-conditioning (several eigenvectors almost parallel). The schur step of eigen, however, should not be affected by ill-conditioning, hence my question. But I'm struggling to understand how to make it work."}]}]}]},{"client_msg_id":"8d8ad307-409e-478c-bdba-fb7b4be01e82","type":"message","text":"I'm looking for some paper dealing with this problem, but haven't found any yet. Maybe I'm using the wrong keywords!","user":"U6G4M02N4","ts":"1614930816.088000","team":"T68168MUP","edited":{"user":"U6G4M02N4","ts":"1614930831.000000"},"blocks":[{"type":"rich_text","block_id":"st4TI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm looking for some paper dealing with this problem, but haven't found any yet. Maybe I'm using the wrong keywords!"}]}]}]},{"client_msg_id":"5927d000-6bc6-4f82-a9c2-5ac165409c1d","type":"message","text":"Put in other words: is it possible to compute `schur(A,B)`  doing the heavy lifting only on the schur complements of A and B?","user":"U6G4M02N4","ts":"1614932011.089200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0b9G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Put in other words: is it possible to compute "},{"type":"text","text":"schur(A,B)","style":{"code":true}},{"type":"text","text":"  doing the heavy lifting only on the schur complements of A and B?"}]}]}]},{"client_msg_id":"6ee16cd5-b204-4476-8edb-6d3cdfa9ed5e","type":"message","text":"Does AMD really not have its own proprietary BLAS and wants us to use BLIS? <https://developer.amd.com/amd-aocl/blas-library/>","user":"U67461GUB","ts":"1615070655.090400","team":"T68168MUP","attachments":[{"service_name":"AMD","title":"BLAS Library - AMD","title_link":"https://developer.amd.com/amd-aocl/blas-library/","text":"BLIS BLIS is a portable software framework for instantiating high-performance BLAS-like dense linear algebra libraries. The framework was designed to isolate essential kernels of computation that, when optimized, enable optimized ...","fallback":"AMD: BLAS Library - AMD","from_url":"https://developer.amd.com/amd-aocl/blas-library/","service_icon":"https://developer.amd.com/wordpress/media/2013/12/favicon.png","id":1,"original_url":"https://developer.amd.com/amd-aocl/blas-library/"}],"blocks":[{"type":"rich_text","block_id":"s9rQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does AMD really not have its own proprietary BLAS and wants us to use BLIS? "},{"type":"link","url":"https://developer.amd.com/amd-aocl/blas-library/"}]}]}]},{"client_msg_id":"983cdefd-6ec5-4225-99fc-79a204f51204","type":"message","text":"Seems like they have made their own edits to BLIS, but BLIS is not good with threading, I thought. <@UAUPJLBQX> Do you know about this?","user":"U67461GUB","ts":"1615070710.091500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"My9W","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Seems like they have made their own edits to BLIS, but BLIS is not good with threading, I thought. "},{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":" Do you know about this?"}]}]}]},{"client_msg_id":"ac6cad4a-7c52-4fa3-8071-767916a56640","type":"message","text":"They also seem to be pushing FLAME instead of LAPACK - which is refreshing.","user":"U67461GUB","ts":"1615070734.092100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rD=6a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"They also seem to be pushing FLAME instead of LAPACK - which is refreshing."}]}]}]},{"client_msg_id":"FC7C3C09-5EBC-46E1-90C6-3202AEBA1F94","type":"message","text":"AMD doesn’t have anywhere near the manpower Intel has. I don’t see why they’d want to try and make their own proprietary BLAS","user":"U8D9768Q6","ts":"1615070960.093200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TNFj9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"AMD doesn’t have anywhere near the manpower Intel has. I don’t see why they’d want to try and make their own proprietary BLAS"}]}]}]},{"client_msg_id":"74ce14c8-c38d-4198-aedf-ac54ff6b1993","type":"message","text":"I distinctly remember there used to be one at some time.","user":"U67461GUB","ts":"1615070995.093500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Kyoe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I distinctly remember there used to be one at some time."}]}]}]},{"client_msg_id":"8ecc5764-8048-47e7-b13d-e741dc492625","type":"message","text":"Just wanted to make sure if BLIS+FLAME is what I should try out - or if I was missing something. I don’t know if AMD’s blis+flame are AMD only, or if we can make them platform agnostic.","user":"U67461GUB","ts":"1615071051.094400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Rk6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just wanted to make sure if BLIS+FLAME is what I should try out - or if I was missing something. I don’t know if AMD’s blis+flame are AMD only, or if we can make them platform agnostic."}]}]}]},{"client_msg_id":"ed2589e3-5df4-4634-9bbc-345e5da3c93c","type":"message","text":"By not good with threading, I was referring to small sizes arrays. BLIS does fine asymptotically, but both OpenBLAS and BLIS seem a fair bit behind MKL asymptotically on my Skylake-X desktops. Over the size ranges I tested, Octavian was on par with BLIS and OpenBLAS there (after tuning it for those specific marchines); I haven't been able to match MKL for large matrices with Octavian's current approach.","user":"UAUPJLBQX","ts":"1615076175.097600","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1615076223.000000"},"blocks":[{"type":"rich_text","block_id":"KRjI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"By not good with threading, I was referring to small sizes arrays. BLIS does fine asymptotically, but both OpenBLAS and BLIS seem a fair bit behind MKL asymptotically on my Skylake-X desktops. Over the size ranges I tested, Octavian was on par with BLIS and OpenBLAS there (after tuning it for those specific marchines); I haven't been able to match MKL for large matrices with Octavian's current approach."}]}]}]},{"client_msg_id":"eaf700a6-bcf7-4c6d-a647-2c4a073e5640","type":"message","text":"For small matrices, you need to do some combination of not oversubscribing threads, and changing your blocking behavior to get good utilization.","user":"UAUPJLBQX","ts":"1615076278.099000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Q/k9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For small matrices, you need to do some combination of not oversubscribing threads, and changing your blocking behavior to get good utilization."}]}]}]},{"client_msg_id":"48880657-aa3e-4c55-8757-7a10b432999b","type":"message","text":"Octavian does this, and I assume MKL does on Intel CPUs but that it acts more like OpenBLAS on AMD.","user":"UAUPJLBQX","ts":"1615076302.099600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yzh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Octavian does this, and I assume MKL does on Intel CPUs but that it acts more like OpenBLAS on AMD."}]}]}]},{"client_msg_id":"e6985f9d-95e4-4290-ba81-bfb19fd01b01","type":"message","text":"There is already <https://github.com/JuliaBinaryWrappers/blis_jll.jl|blis_jll> if you want to try regular BLIS in Julia","user":"UAUPJLBQX","ts":"1615076318.099900","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1615076453.000000"},"blocks":[{"type":"rich_text","block_id":"S+Cm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There is already "},{"type":"link","url":"https://github.com/JuliaBinaryWrappers/blis_jll.jl","text":"blis_jll"},{"type":"text","text":" if you want to try regular BLIS in Julia"}]}]}]},{"client_msg_id":"49e92a11-4a25-48a3-85cb-5977ff40fb00","type":"message","text":"`using BLASBenchmarksCPU` exports `gemmblis!` if you want to just try out `gemm!` (note it's just a three arg version)","user":"UAUPJLBQX","ts":"1615076401.100600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"q75o","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"using BLASBenchmarksCPU","style":{"code":true}},{"type":"text","text":" exports "},{"type":"text","text":"gemmblis!","style":{"code":true}},{"type":"text","text":" if you want to just try out "},{"type":"text","text":"gemm!","style":{"code":true}},{"type":"text","text":" (note it's just a three arg version)"}]}]}]},{"client_msg_id":"aaf96316-f93d-4e2a-a278-5b18db537a10","type":"message","text":"That’s great to know, thanks","user":"U67461GUB","ts":"1615076515.100900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Wj57G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That’s great to know, thanks"}]}]}]},{"client_msg_id":"04ab0b22-f313-43c0-b26e-c78ef91b862b","type":"message","text":"Let’s see if BLIS + FLAME can actually provide BLAS + LAPACK. That’s a fun next step.","user":"U67461GUB","ts":"1615076579.102000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wLC5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Let’s see if BLIS + FLAME can actually provide BLAS + LAPACK. That’s a fun next step."}]}]}]},{"client_msg_id":"45f6fc05-d686-4bd8-84ca-415f44d49fe6","type":"message","text":"It does look like amd's fork has diverged a bit, so could be worth trying.","user":"UAUPJLBQX","ts":"1615076593.102300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ndLf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It does look like amd's fork has diverged a bit, so could be worth trying."}]}]}]},{"client_msg_id":"00fae4d3-fbe2-4fe1-837c-0f861ae8f6cb","type":"message","text":"BLIS provides a BLAS API","user":"UAUPJLBQX","ts":"1615076604.103000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Abf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"BLIS provides a BLAS API"}]}]}]},{"client_msg_id":"454e4ae0-9717-4831-89d3-03cc53357ba8","type":"message","text":"that was what I was thinking. And I was wondering if it is AMD specific.","user":"U67461GUB","ts":"1615076609.103600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2KEBh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that was what I was thinking. And I was wondering if it is AMD specific."}]}]}]},{"client_msg_id":"218f03c0-ac67-4a98-ab47-fa2176701435","type":"message","text":"maybe FLAME does the same for LAPACK?","user":"UAUPJLBQX","ts":"1615076614.103900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Pba6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"maybe FLAME does the same for LAPACK?"}]}]}]},{"client_msg_id":"c84651f5-4253-40c1-8fa2-b051508b82e8","type":"message","text":"It seems like it - but I don’t know how complete it is.","user":"U67461GUB","ts":"1615076625.104300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ozfcN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It seems like it - but I don’t know how complete it is."}]}]}]},{"client_msg_id":"d21dfac1-9bab-499d-8880-33d2ee7d1eb1","type":"message","text":"Clicking around on commits, I see they tuned a multithreading threshold  for Zen: <https://github.com/flame/blis/commit/5e03ca6fc70779c31e32c93f7a7f880747222590>","user":"UAUPJLBQX","ts":"1615076642.104700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0XvBp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Clicking around on commits, I see they tuned a multithreading threshold  for Zen: "},{"type":"link","url":"https://github.com/flame/blis/commit/5e03ca6fc70779c31e32c93f7a7f880747222590"}]}]}]},{"client_msg_id":"5373633a-4797-40b1-a077-b884bbd46967","type":"message","text":"which does mean that it does at least do something / isn't totally naive","user":"UAUPJLBQX","ts":"1615076664.105200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vN6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"which does mean that it does at least do something / isn't totally naive"}]}]}]},{"client_msg_id":"eacae141-2dc5-454c-b9d4-ffb1de0483fd","type":"message","text":"There's also a (relatively young) BLIS.jl repo <https://github.com/xrq-phys/BLIS.jl>","user":"UB2QRMQPN","ts":"1615077548.105800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0HHH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's also a (relatively young) BLIS.jl repo "},{"type":"link","url":"https://github.com/xrq-phys/BLIS.jl"}]}]}]},{"client_msg_id":"ea119a83-4177-48c2-9c2b-b0ace32ced89","type":"message","text":"Ah thanks! I suppose this should be updated to using LBT.","user":"U67461GUB","ts":"1615077687.106100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PKHK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah thanks! I suppose this should be updated to using LBT."}]}]}]},{"client_msg_id":"d5b99bc7-5fe2-4907-b340-21242050546c","type":"message","text":"<https://github.com/xrq-phys/BLIS.jl/issues/3>","user":"U67461GUB","ts":"1615077887.107600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xnB8","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/xrq-phys/BLIS.jl/issues/3"}]}]}]},{"client_msg_id":"2352874a-b162-4a85-b15a-b2c612d348f7","type":"message","text":"Yes, and it's probably worth asking the author if they're comfortable moving the repo to the JuliaLinearAlgebra org both for visibility &amp; more maintainer eyeballs","user":"UB2QRMQPN","ts":"1615077940.108100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iglw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, and it's probably worth asking the author if they're comfortable moving the repo to the JuliaLinearAlgebra org both for visibility & more maintainer eyeballs"}]}]}]},{"client_msg_id":"362c875a-2f42-46f2-9e4d-51dd615bed0c","type":"message","text":"If you want to file an issue, I’ll be happy to support it.","user":"U67461GUB","ts":"1615077983.108600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dRw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you want to file an issue, I’ll be happy to support it."}]}]}]},{"client_msg_id":"1c87efa9-24b2-4ae5-88b4-f01453bc9e46","type":"message","text":"<https://github.com/xrq-phys/BLIS.jl/issues/4>","user":"UB2QRMQPN","ts":"1615078129.108900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IBcse","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/xrq-phys/BLIS.jl/issues/4"}]}]}]},{"client_msg_id":"a2d5f47b-1305-4b87-ab5e-9e07d769ef9a","type":"message","text":"I just browsed <https://raw.githubusercontent.com/flame/libflame/master/docs/libflame/libflame.pdf> and it looks like the coverage of LAPACK functionality is incomplete, e.g. there is no Schur factorization. It also doesn’t look like there are DnQ versions of the Hermitian eigensolver and SVD solver. It would be interesting to compare the bi- and tridiagonal  reduction functions to MKL, though. Intel’s version are super fast compared to vanilla LAPACK and it is often the reduction is often bottleneck for large problems.","user":"U680T6770","ts":"1615108034.113300","team":"T68168MUP","edited":{"user":"U680T6770","ts":"1615108046.000000"},"blocks":[{"type":"rich_text","block_id":"nYUR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I just browsed "},{"type":"link","url":"https://raw.githubusercontent.com/flame/libflame/master/docs/libflame/libflame.pdf"},{"type":"text","text":" and it looks like the coverage of LAPACK functionality is incomplete, e.g. there is no Schur factorization. It also doesn’t look like there are DnQ versions of the Hermitian eigensolver and SVD solver. It would be interesting to compare the bi- and tridiagonal  reduction functions to MKL, though. Intel’s version are super fast compared to vanilla LAPACK and it is often the reduction is often bottleneck for large problems."}]}]}]},{"client_msg_id":"3bfc7a22-8e58-4f9b-82b2-815317edba74","type":"message","text":"<https://github.com/JuliaPackaging/Yggdrasil/issues/2657>","user":"U67461GUB","ts":"1615140936.113700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jd6","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/JuliaPackaging/Yggdrasil/issues/2657"}]}]}]},{"client_msg_id":"16530257-87ea-4903-9dc1-5b46fcaa5e90","type":"message","text":"Anyone familiar with ReLAPACK? I don’t think we are using it inside openblas.","user":"U67461GUB","ts":"1615141358.114000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WfmNS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone familiar with ReLAPACK? I don’t think we are using it inside openblas."}]}]}]},{"client_msg_id":"4af6779f-ed85-4098-ac5a-3d06bc0f79fc","type":"message","text":"<https://github.com/xianyi/OpenBLAS/tree/develop/relapack>","user":"U67461GUB","ts":"1615141359.114200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Gz4Q","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/xianyi/OpenBLAS/tree/develop/relapack"}]}]}]},{"client_msg_id":"606490d9-1854-4e87-a618-2f7db8bbc84e","type":"message","text":"relapack paper: <https://arxiv.org/pdf/1602.06763.pdf>","user":"U67461GUB","ts":"1615158791.115000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m+3bX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"relapack paper: "},{"type":"link","url":"https://arxiv.org/pdf/1602.06763.pdf"}]}]}]},{"client_msg_id":"59f0b869-53a5-407a-b288-e87ab152ea77","type":"message","text":"Has anybody seen this: <https://www.quantamagazine.org/new-algorithm-breaks-speed-limit-for-solving-linear-equations-20210308/|New Algorithm Breaks Speed Limit for Solving Linear Equations>. Paper is here <https://arxiv.org/abs/2007.10254|arXiv:2007.10254>.\n\nIt is a new randomized algorithm that (for sparse matrices) it implements matrix multiplication faster than O(n^2.37).","user":"U01QBF4PHKP","ts":"1615394925.117500","team":"T68168MUP","attachments":[{"service_name":"Quanta Magazine","title":"New Algorithm Breaks Speed Limit for Solving Linear Equations","title_link":"https://www.quantamagazine.org/new-algorithm-breaks-speed-limit-for-solving-linear-equations-20210308/","text":"By harnessing randomness, a new algorithm achieves a fundamentally novel — and faster — way of performing one of the most basic computations in math and computer science.","fallback":"Quanta Magazine: New Algorithm Breaks Speed Limit for Solving Linear Equations","image_url":"https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/03/Forest-Matrices_1200_Social.jpg","from_url":"https://www.quantamagazine.org/new-algorithm-breaks-speed-limit-for-solving-linear-equations-20210308/","image_width":476,"image_height":250,"image_bytes":221452,"service_icon":"https://www.quantamagazine.org/favicon.png","id":1,"original_url":"https://www.quantamagazine.org/new-algorithm-breaks-speed-limit-for-solving-linear-equations-20210308/"},{"service_name":"arXiv.org","title":"Solving Sparse Linear Systems Faster than Matrix Multiplication","title_link":"https://arxiv.org/abs/2007.10254","text":"Can linear systems be solved faster than matrix multiplication? While there has been remarkable progress for the special cases of graph structured linear systems, in the general setting, the bit...","fallback":"arXiv.org: Solving Sparse Linear Systems Faster than Matrix Multiplication","from_url":"https://arxiv.org/abs/2007.10254","service_icon":"https://static.arxiv.org/static/browse/0.3.2.6/images/icons/favicon.ico","id":2,"original_url":"https://arxiv.org/abs/2007.10254"}],"blocks":[{"type":"rich_text","block_id":"WQ+8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Has anybody seen this: "},{"type":"link","url":"https://www.quantamagazine.org/new-algorithm-breaks-speed-limit-for-solving-linear-equations-20210308/","text":"New Algorithm Breaks Speed Limit for Solving Linear Equations"},{"type":"text","text":". Paper is here "},{"type":"link","url":"https://arxiv.org/abs/2007.10254","text":"arXiv:2007.10254"},{"type":"text","text":".\n\nIt is a new randomized algorithm that (for sparse matrices) it implements matrix multiplication faster than O(n^2.37)."}]}]}],"thread_ts":"1615394925.117500","reply_count":5,"reply_users_count":4,"latest_reply":"1615397089.118900","reply_users":["UCT7E536E","U012RPHRSP3","UGD4K0Z25","UDD5Z7FLZ"],"subscribed":false},{"client_msg_id":"9b1b3741-deca-4e7b-a729-74f0ea239ad4","type":"message","text":"Basic question: Do preconditioners improve the accuracy of the ultimate solution (and defeat the accuracy floor set by the condition number of the original system), or do they just allow you to get to the solution faster (but not more accurately)?","user":"UDSG73JTH","ts":"1615463203.121700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Gpy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Basic question: Do preconditioners improve the accuracy of the ultimate solution (and defeat the accuracy floor set by the condition number of the original system), or do they just allow you to get to the solution faster (but not more accurately)?"}]}]}]},{"client_msg_id":"4bcc6ca7-dfe0-45f2-8c35-b53dee766265","type":"message","text":"The latter, unless you have a clever way of computing the preconditioned residual without first computing the residual then precondition it","user":"UMDEUKM29","ts":"1615468157.123200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yQ/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The latter, unless you have a clever way of computing the preconditioned residual without first computing the residual then precondition it"}]}]}]}]}