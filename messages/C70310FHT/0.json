{"cursor": 0, "messages": [{"client_msg_id":"e97557b6-2fc2-4abe-ba0c-a311f4890519","type":"message","text":"Hey <@U679VPJ8L> - out of curiosity, what would be needed to bolster the Julia NLP ecosystem? I instead had to go over to Spacy in python for some work that I had to do with tokenization but am curious what it would take to continue building the Julia NLP ecosystem. Thoughts?","user":"US64J0NPQ","ts":"1610944993.007700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"brt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey "},{"type":"user","user_id":"U679VPJ8L"},{"type":"text","text":" - out of curiosity, what would be needed to bolster the Julia NLP ecosystem? I instead had to go over to Spacy in python for some work that I had to do with tokenization but am curious what it would take to continue building the Julia NLP ecosystem. Thoughts?"}]}]}],"thread_ts":"1610944993.007700","reply_count":10,"reply_users_count":3,"latest_reply":"1610991877.009700","reply_users":["U6A936746","US64J0NPQ","U679VPJ8L"],"subscribed":false},{"client_msg_id":"523a6a68-6fd3-4ae4-b261-8bd74e7a7817","type":"message","text":"<https://twitter.com/spacy_io/status/1356238587545575427?s=19|https://twitter.com/spacy_io/status/1356238587545575427?s=19>","user":"UDGT4PM41","ts":"1612208497.001500","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/spacy_io|@spacy_io>: Today we're releasing spaCy v3.0!\n\n:flying_saucer: Transformer-based pipelines for SOTA models\n:gear: New training and config system\nüß¨ Models using any framework\nü™ê Manage end-to-end workflows\n:fire: New and improved APIs, components &amp; more\n\n<https://github.com/explosion/spaCy/releases/tag/v3.0.0/>","ts":1612187451,"author_name":"spaCy","author_link":"https://twitter.com/spacy_io/status/1356238587545575427","author_icon":"https://pbs.twimg.com/profile_images/699256981287100416/7-7zis8f_normal.png","author_subname":"@spacy_io","text":"Today we're releasing spaCy v3.0!\n\n:flying_saucer: Transformer-based pipelines for SOTA models\n:gear: New training and config system\nüß¨ Models using any framework\nü™ê Manage end-to-end workflows\n:fire: New and improved APIs, components &amp; more\n\n<https://github.com/explosion/spaCy/releases/tag/v3.0.0/>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/spacy_io/status/1356238587545575427?s=19","id":1,"original_url":"https://twitter.com/spacy_io/status/1356238587545575427?s=19","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"x69oz","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/spacy_io/status/1356238587545575427?s=19","text":"https://twitter.com/spacy_io/status/1356238587545575427?s=19"}]}]}],"thread_ts":"1612208497.001500","reply_count":3,"reply_users_count":2,"latest_reply":"1612292467.002400","reply_users":["U013KHU2XC1","U01CCE4QQV9"],"subscribed":false},{"client_msg_id":"06eb9cb7-9e0a-4e88-a072-d9dc3b005b18","type":"message","text":"Posted potentially interesting question related to NLP in Julia here: <https://discourse.julialang.org/t/effective-text-extraction-from-documents-pdfs/54889>","user":"US64J0NPQ","ts":"1612837508.009800","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Effective Text Extraction from Documents (PDFs)","title_link":"https://discourse.julialang.org/t/effective-text-extraction-from-documents-pdfs/54889","text":"Hi all, Question for those involved with text extraction pipelines (or ETL pipelines for that matter): In Julia, what works best for you when doing text extraction from PDFs? In my case, I am simplifying the problem to look at PDFs that are single column in form and are written in English with either none or minimal images. Currently trying out both Taro.jl and PDFIO.jl - so far I have found Taro.jl a bit easier to work with to extract content. However, both packages struggle with white space...","fallback":"JuliaLang: Effective Text Extraction from Documents (PDFs)","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1612837475,"from_url":"https://discourse.julialang.org/t/effective-text-extraction-from-documents-pdfs/54889","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/effective-text-extraction-from-documents-pdfs/54889"}],"blocks":[{"type":"rich_text","block_id":"LuN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Posted potentially interesting question related to NLP in Julia here: "},{"type":"link","url":"https://discourse.julialang.org/t/effective-text-extraction-from-documents-pdfs/54889"}]}]}]},{"client_msg_id":"5f100a6f-c37d-4e3f-ac85-d3e400e461c4","type":"message","text":"Would love to hear additional thoughts on it! Please post on Discourse though so we have a record. :hugging_face: Thanks!","user":"US64J0NPQ","ts":"1612837535.010500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0Au8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Would love to hear additional thoughts on it! Please post on Discourse though so we have a record. "},{"type":"emoji","name":"hugging_face"},{"type":"text","text":" Thanks!"}]}]}],"thread_ts":"1612837535.010500","reply_count":2,"reply_users_count":1,"latest_reply":"1612839804.012200","reply_users":["U7V6YNG04"],"subscribed":false},{"client_msg_id":"92b72674-d618-408d-8e35-efa358914cb5","type":"message","text":"Hi.\nSaw an issue in Embeddings.jl\n'Lazily loading Embeddings'\n\nIt had a suggestion that rather than storing the array, some lazy array could be stored(instantiated only when accessed), might help in reducing time in packages like\nFastText since it's in text format(non-binary). \n\nI think it might be of help when using `load_embeddings`, but not in `using Embeddings`\nI would like to work on this issue. Can someone guide me?\nThanks. \n:blush:","user":"U0183KL21GS","ts":"1612965318.018400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+ScT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi.\nSaw an issue in Embeddings.jl\n'Lazily loading Embeddings'\n\nIt had a suggestion that rather than storing the array, some lazy array could be stored(instantiated only when accessed), might help in reducing time in packages like\nFastText since it's in text format(non-binary). \n\nI think it might be of help when using "},{"type":"text","text":"load_embeddings","style":{"code":true}},{"type":"text","text":", but not in "},{"type":"text","text":"using Embeddings\n","style":{"code":true}},{"type":"text","text":"I would like to work on this issue. Can someone guide me?\nThanks. \n"},{"type":"emoji","name":"blush"}]}]}]},{"client_msg_id":"22c4866c-95a1-40e2-b2b3-362112b80c80","type":"message","text":"Here's a strange post but; NLP is an area near and dear to my heart, and I know that Julia will overtake Python eventually, so if anyone is wanting to dig into expanding NLP in Julia - maybe continue on the work of integrating HuggingFace models and encoders - please give me a ping. Hopefully I will be in a position to provide some renumeration/$$. It's the one thing I always have to drop back to python for, and it jst .. irks me :slightly_smiling_face:\n\nif this is the wrong channel then feel free to scream at me, I won't take it personally :slightly_smiling_face: I don't know how this slack deals with cross postings, and I think this is a very directed bounty","user":"U01ER903N3Y","ts":"1613493367.023200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OrL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Here's a strange post but; NLP is an area near and dear to my heart, and I know that Julia will overtake Python eventually, so if anyone is wanting to dig into expanding NLP in Julia - maybe continue on the work of integrating HuggingFace models and encoders - please give me a ping. Hopefully I will be in a position to provide some renumeration/$$. It's the one thing I always have to drop back to python for, and it jst .. irks me "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":"\n\nif this is the wrong channel then feel free to scream at me, I won't take it personally "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" I don't know how this slack deals with cross postings, and I think this is a very directed bounty"}]}]}]},{"client_msg_id":"85f7eab8-fb4a-40f4-acb8-5c86e6d9fb59","type":"message","text":"Thanks, this is certainly the right channel for this.","user":"U679VPJ8L","ts":"1613493484.023600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"e/Po","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks, this is certainly the right channel for this."}]}]}],"reactions":[{"name":"heart","users":["U01ER903N3Y"],"count":1}]},{"client_msg_id":"45428eae-fd42-4816-ad74-c59ad91d352b","type":"message","text":"NLP in Julia is relatively sparse (no pun intended) right now, in that there are few active contributors. There is certainly a lot to do.","user":"U679VPJ8L","ts":"1613493556.024600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"D9/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"NLP in Julia is relatively sparse (no pun intended) right now, in that there are few active contributors. There is certainly a lot to do."}]}]}]},{"client_msg_id":"d6c50bd7-522c-4b90-bb3c-ab6c05798375","type":"message","text":"I wish I had more time and Julia knowledge, then I would be happy to contribute. Alas I only have enough knowledge to be a user, not a contributor.","user":"UPSSPPBFV","ts":"1613493740.025300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n5I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I wish I had more time and Julia knowledge, then I would be happy to contribute. Alas I only have enough knowledge to be a user, not a contributor."}]}]}]},{"client_msg_id":"58926720-e29b-401f-bc2d-2e519b58610b","type":"message","text":"<@UPSSPPBFV> I hear that. I am swamped with my normal day to day job here, I am jst grinding my teeth that I have to change from Julia to Python for using the HuggingFace part","user":"U01ER903N3Y","ts":"1613493966.026600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MMC5r","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UPSSPPBFV"},{"type":"text","text":" I hear that. I am swamped with my normal day to day job here, I am jst grinding my teeth that I have to change from Julia to Python for using the HuggingFace part"}]}]}]},{"client_msg_id":"82b4448d-2b15-4010-8ac3-05773640678b","type":"message","text":"The way I can try to drive growth at this point is to try and incentivize others to pitch in on the NLP side :slightly_smiling_face:","user":"U01ER903N3Y","ts":"1613494002.027400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kc+uO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The way I can try to drive growth at this point is to try and incentivize others to pitch in on the NLP side "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"a62ce862-30c0-4c87-9f80-3b0b24e75a59","type":"message","text":"I‚Äôm also personally interested in this, and would be down to try to help out a little (for free) over the summer if there are more experienced folks who would be willing to guide me then","user":"US8V7JSKB","ts":"1613544286.028300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2RB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I‚Äôm also personally interested in this, and would be down to try to help out a little (for free) over the summer if there are more experienced folks who would be willing to guide me then"}]}]}]}]}