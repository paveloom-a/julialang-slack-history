{"cursor": 3, "messages": [{"client_msg_id":"b4ff10d3-b670-4f39-98cc-be7baa04d4cc","type":"message","text":"I read the following in the docs:\n&gt; *ForwardDiff* is algorithmically more efficient for differentiating functions where the input dimension is less than the output dimension, while *ReverseDiff* is algorithmically more efficient for differentiating functions where the output dimension is less than the input dimension.","user":"UGTUKUHLN","ts":"1613997737.014100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZgF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I read the following in the docs:\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"ForwardDiff","style":{"bold":true}},{"type":"text","text":" is algorithmically more efficient for differentiating functions where the input dimension is less than the output dimension, while "},{"type":"text","text":"ReverseDiff","style":{"bold":true}},{"type":"text","text":" is algorithmically more efficient for differentiating functions where the output dimension is less than the input dimension."}]}]}]},{"client_msg_id":"038900f6-4344-4116-b027-de514ec58685","type":"message","text":"So for gradients it would naturally make sense to use reversediff","user":"UGTUKUHLN","ts":"1613997755.014600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ICU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So for gradients it would naturally make sense to use reversediff"}]}]}]},{"client_msg_id":"861cbcdd-ac27-4207-aab2-8ae0b0349901","type":"message","text":"But they are somehow different enough that one works and the other doesn't, for exact same function","user":"UGTUKUHLN","ts":"1613997791.015200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3zur","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But they are somehow different enough that one works and the other doesn't, for exact same function"}]}]}]},{"client_msg_id":"d6f808bc-825e-43d4-a4d1-b03cd31733d4","type":"message","text":"Yes, they work in very different ways. Reverse diff is generally more complex, since you need to build up a tape, either explicitely along with tracked variables or directly in the IR, as is the case for Zygote, and then do a backwards pass to get the gradient. Forward diff is just a fairly straightforward single pass.","user":"UM30MT6RF","ts":"1613998214.019200","team":"T68168MUP","edited":{"user":"UM30MT6RF","ts":"1613998428.000000"},"blocks":[{"type":"rich_text","block_id":"E4J","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, they work in very different ways. Reverse diff is generally more complex, since you need to build up a tape, either explicitely along with tracked variables or directly in the IR, as is the case for Zygote, and then do a backwards pass to get the gradient. Forward diff is just a fairly straightforward single pass."}]}]}]},{"client_msg_id":"35e852c2-b53f-4e39-a416-e58d71ec3f4e","type":"message","text":"There are a few reason e.g. Zygote can fail. A fairly common one is that it doesn't work with code that is mutating or that contains a `ccall`, in these cases you typically need to write a custom adjoint.","user":"UM30MT6RF","ts":"1613998390.022300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KNXFi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There are a few reason e.g. Zygote can fail. A fairly common one is that it doesn't work with code that is mutating or that contains a "},{"type":"text","text":"ccall","style":{"code":true}},{"type":"text","text":", in these cases you typically need to write a custom adjoint."}]}]}]},{"client_msg_id":"9ac39849-bc4b-4938-87af-834f3cd7ceff","type":"message","text":"Actually I mixed up a bit - ReverseDiff worked for me, but only without CompiledTape. And was very slow, ~50 times slower than ForwardDiff.","user":"UGTUKUHLN","ts":"1613998508.023700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GowUq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Actually I mixed up a bit - ReverseDiff worked for me, but only without CompiledTape. And was very slow, ~50 times slower than ForwardDiff."}]}]}]},{"client_msg_id":"eab797b2-e4f3-474b-8597-47a1e67dc84e","type":"message","text":"<@UM30MT6RF> but I assume there are cases when it is better to use ReverseDiff, right? Despite it being more complex.","user":"UGTUKUHLN","ts":"1613998601.024600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QcnF","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UM30MT6RF"},{"type":"text","text":" but I assume there are cases when it is better to use ReverseDiff, right? Despite it being more complex."}]}]}],"thread_ts":"1613998601.024600","reply_count":1,"reply_users_count":1,"latest_reply":"1613998720.027200","reply_users":["UM30MT6RF"],"subscribed":false},{"client_msg_id":"551e6be2-8c6d-45e2-ae1c-2b3a0ef100be","type":"message","text":"How many parameters?","user":"U6A936746","ts":"1613998657.024900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ShG+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How many parameters?"}]}]}]},{"client_msg_id":"82861b22-8794-4175-8439-186f939925a6","type":"message","text":"say 10, or 20","user":"UGTUKUHLN","ts":"1613998668.025400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dndE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"say 10, or 20"}]}]}]},{"client_msg_id":"187be9a1-de39-4ca1-ae28-041bd540fe8f","type":"message","text":"you need hundreds at least.","user":"U69BL50BF","ts":"1613998674.025800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F8vN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you need hundreds at least."}]}]}]},{"client_msg_id":"4c0df628-3677-4f2d-a781-3fa7d5b3240b","type":"message","text":"Yeah use ForwardDiff","user":"U6A936746","ts":"1613998679.026000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Opr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah use ForwardDiff"}]}]}]},{"client_msg_id":"37444d6e-7162-4410-98ed-b6819a81c95a","type":"message","text":"ah, so ReverseDiff is for stuff like neural nets, and not for common analytical models?","user":"UGTUKUHLN","ts":"1613998743.028400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lF+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ah, so ReverseDiff is for stuff like neural nets, and not for common analytical models?"}]}]}],"thread_ts":"1613998743.028400","reply_count":1,"reply_users_count":1,"latest_reply":"1613998845.031000","reply_users":["U6A936746"],"subscribed":false,"reactions":[{"name":"heavy_check_mark","users":["U6A936746"],"count":1}]},{"client_msg_id":"85151dd8-bb23-486a-a52a-bd4fc916db56","type":"message","text":"Reverse is faster than Forwards when number of parameters is much larger (at least 5x larger, often like 200x larger) than number of outputs.\nBecause there is a lot of overhead in reverse mode having to setup and manage the tape.\nWhich generally also means allocating and storing memory","user":"U6A936746","ts":"1613998773.029500","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1613998801.000000"},"blocks":[{"type":"rich_text","block_id":"gTSm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Reverse is faster than Forwards when number of parameters is much larger (at least 5x larger, often like 200x larger) than number of outputs.\nBecause there is a lot of overhead in reverse mode having to setup and manage the tape.\nWhich generally also means allocating and storing memory"}]}]}]},{"client_msg_id":"b37ac587-1ac2-4e7b-9233-1ffeb0382de4","type":"message","text":"I see, that's way above the scales I need now...","user":"UGTUKUHLN","ts":"1613998838.030800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"v=P","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I see, that's way above the scales I need now..."}]}]}]},{"client_msg_id":"1fb7d17e-0500-44c2-90cd-00ca73d1229d","type":"message","text":"And what about Zygote?","user":"UGTUKUHLN","ts":"1613998845.031200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"C6bFw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And what about Zygote?"}]}]}]},{"client_msg_id":"a753c6cd-d8b8-4569-b858-7bf2ea8e3a64","type":"message","text":"Zygote is also reverse mode, so same applies","user":"U6A936746","ts":"1613998875.031900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"D9g3n","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Zygote is also reverse mode, so same applies"}]}]}]},{"client_msg_id":"7b623a89-dc65-400f-b6ee-cd1a121c3bf3","type":"message","text":"Thanks!\nBtw, I'm very impressed by how easy it is to compute a gradient in julia. My model was written without even thinking about that, but ForwardDiff just works!","user":"UGTUKUHLN","ts":"1613998995.036000","team":"T68168MUP","edited":{"user":"UGTUKUHLN","ts":"1613999094.000000"},"blocks":[{"type":"rich_text","block_id":"Ksi/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks!\nBtw, I'm very impressed by how easy it is to compute a gradient in julia. My model was written without even thinking about that, but ForwardDiff just works!"}]}]}]},{"client_msg_id":"991a5357-e03f-40f4-9b9d-7ae9c4dd16b1","type":"message","text":"In theory, Zygote's approach is supposed to solve this problem, but in practice it puts a lot of strain on the compiler and often interferes with inference, so there is typically some overhead. This is something a next-gen AD should be a lot better at though.","user":"UM30MT6RF","ts":"1613999195.039000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3zsW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In theory, Zygote's approach is supposed to solve this problem, but in practice it puts a lot of strain on the compiler and often interferes with inference, so there is typically some overhead. This is something a next-gen AD should be a lot better at though."}]}]}]},{"client_msg_id":"87c41310-84d7-4ef8-8abe-148e78f750f1","type":"message","text":"It already looks like half-magic :)","user":"UGTUKUHLN","ts":"1613999292.039300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/Van","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It already looks like half-magic :)"}]}]}],"reactions":[{"name":"party_wizard","users":["UM30MT6RF"],"count":1}]},{"client_msg_id":"495869a3-5be6-47cb-9904-7961cac68103","type":"message","text":"I mean from a user's point of view","user":"UGTUKUHLN","ts":"1613999321.039600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Inb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I mean from a user's point of view"}]}]}]},{"client_msg_id":"7e3fbed6-af40-4afa-a4cc-c97dc3411b11","type":"message","text":"Probably I shoudl read more on autodiff at some point... Turns out what I thought AD is in general, is just forward mode.","user":"UGTUKUHLN","ts":"1613999589.041000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"p5jHX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Probably I shoudl read more on autodiff at some point... Turns out what I thought AD is in general, is just forward mode."}]}]}],"thread_ts":"1613999589.041000","reply_count":2,"reply_users_count":1,"latest_reply":"1614000295.043200","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"3316613f-1365-403a-8d11-64355397420b","type":"message","text":"One more question: does the number of parameters refer to the input dimension only, or to intermediates as well? E.g. suppose that f(x::Real)::Real computes a large matrix somewhere inside: should one use reverse diff then?","user":"UGTUKUHLN","ts":"1614000662.044900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=IU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One more question: does the number of parameters refer to the input dimension only, or to intermediates as well? E.g. suppose that f(x::Real)::Real computes a large matrix somewhere inside: should one use reverse diff then?"}]}]}],"thread_ts":"1614000662.044900","reply_count":3,"reply_users_count":2,"latest_reply":"1614001005.045400","reply_users":["U6A936746","UGTUKUHLN"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"I found this nice short overview video on the differences between Forward Mode and Reverse Mode and the mechanics of it. I found it really understandable for me as a beginner and even went into what Lyndon was saying with advantages of Reverse Mode when the number of input variables (the ones you want to take a derivative with respect to) is large and the video mentioned how backprop is a special case of reverse mode\n\nWhat is Automatic Differentiation? by Ari Seff\n<https://youtu.be/wG_nF1awSSY|https://youtu.be/wG_nF1awSSY>","user":"U0138UTB7A4","ts":"1614019371.047500","thread_ts":"1613999589.041000","root":{"client_msg_id":"7e3fbed6-af40-4afa-a4cc-c97dc3411b11","type":"message","text":"Probably I shoudl read more on autodiff at some point... Turns out what I thought AD is in general, is just forward mode.","user":"UGTUKUHLN","ts":"1613999589.041000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"p5jHX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Probably I shoudl read more on autodiff at some point... Turns out what I thought AD is in general, is just forward mode."}]}]}],"thread_ts":"1613999589.041000","reply_count":7,"reply_users_count":3,"latest_reply":"1614019371.047500","reply_users":["U6A936746","U01C3624SGJ","U0138UTB7A4"],"subscribed":false},"attachments":[{"service_name":"YouTube","service_url":"https://www.youtube.com/","title":"What is Automatic Differentiation?","title_link":"https://youtu.be/wG_nF1awSSY","author_name":"Ari Seff","author_link":"https://www.youtube.com/channel/UCIxertsVDip8QHpnhinkAow","thumb_url":"https://i.ytimg.com/vi/wG_nF1awSSY/hqdefault.jpg","thumb_width":480,"thumb_height":360,"fallback":"YouTube Video: What is Automatic Differentiation?","video_html":"<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/wG_nF1awSSY?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","video_html_width":400,"video_html_height":225,"from_url":"https://youtu.be/wG_nF1awSSY","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png","id":1,"original_url":"https://youtu.be/wG_nF1awSSY"}],"blocks":[{"type":"rich_text","block_id":"=waZ2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I found this nice short overview video on the differences between Forward Mode and Reverse Mode and the mechanics of it. I found it really understandable for me as a beginner and even went into what Lyndon was saying with advantages of Reverse Mode when the number of input variables (the ones you want to take a derivative with respect to) is large and the video mentioned how backprop is a special case of reverse mode\n\nWhat is Automatic Differentiation? by Ari Seff\n"},{"type":"link","url":"https://youtu.be/wG_nF1awSSY","text":"https://youtu.be/wG_nF1awSSY"}]}]}],"client_msg_id":"8b104e6c-9873-419e-a8ed-ee7938467c0b","edited":{"user":"U0138UTB7A4","ts":"1614019707.000000"}},{"client_msg_id":"133ef9d3-94f2-4b40-9bd2-adacc02a4d02","type":"message","text":"Guys, I use CodeTracking in my code, and I want to simplify:\nI have:\n```res = @code_expr myfn()\nres !== nothing ? res : Meta.parse(@code_string myfn())```\nI want to have it in one line:\n`@code_expr_easy myfn()`\nSo I defined this:\n```macro code_expr_easy(ex)\n  esc(quote\n    res = @code_expr $ex\n    res !== nothing ? res : Meta.parse(@code_string $ex)\n  end)\nend```\n```What works in files where using CodeTracking is used, but in other cases I get the error @code_expr not defined```\nUndefVarError: @code_expr not defined\n\nSo I changed @code_expr to $@code_expr but it is not working.\nSo the question is, how to interpolate macro into a macro?","user":"U016RL8KEHX","ts":"1614030355.053500","team":"T68168MUP","edited":{"user":"U016RL8KEHX","ts":"1614030456.000000"},"blocks":[{"type":"rich_text","block_id":"8Gb=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Guys, I use CodeTracking in my code, and I want to simplify:\nI have:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"res = @code_expr myfn()\nres !== nothing ? res : Meta.parse(@code_string myfn())"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I want to have it in one line:\n"},{"type":"text","text":"@code_expr_easy myfn()","style":{"code":true}},{"type":"text","text":"\nSo I defined this:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"macro code_expr_easy(ex)\n  esc(quote\n    res = @code_expr $ex\n    res !== nothing ? res : Meta.parse(@code_string $ex)\n  end)\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"What works in files where using CodeTracking is used, but in other cases I get the error @code_expr not defined"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"UndefVarError: @code_expr not defined\n\nSo I changed @code_expr to $@code_expr but it is not working.\nSo the question is, how to interpolate macro into a macro?"}]}]}],"thread_ts":"1614030355.053500","reply_count":3,"reply_users_count":2,"latest_reply":"1614031360.054500","reply_users":["U6A936746","U016RL8KEHX"],"subscribed":false},{"client_msg_id":"996cd9e0-bfc2-443a-83da-bf02b0d9c0c2","type":"message","text":"`getproperty` in `Zygote@0.6`: how much work has been put into optimising it? IIRC there was a bug fix between 0.5 and 0.6, which is great, but I’m now getting type-stability issues whenever I write `my_struct.a_field` . Are we confident that this is the price of correctness until we have some compiler upgrades, or is it worth me trying to figure out if there is the opportunity to improve our current implementation so that we can have type stability?","user":"U6PQP41C3","ts":"1614077815.058900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VdcBO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"getproperty","style":{"code":true}},{"type":"text","text":" in "},{"type":"text","text":"Zygote@0.6","style":{"code":true}},{"type":"text","text":": how much work has been put into optimising it? IIRC there was a bug fix between 0.5 and 0.6, which is great, but I’m now getting type-stability issues whenever I write "},{"type":"text","text":"my_struct.a_field","style":{"code":true}},{"type":"text","text":" . Are we confident that this is the price of correctness until we have some compiler upgrades, or is it worth me trying to figure out if there is the opportunity to improve our current implementation so that we can have type stability?"}]}]}],"thread_ts":"1614077815.058900","reply_count":3,"reply_users_count":2,"latest_reply":"1614078315.059400","reply_users":["U6A936746","UM30MT6RF"],"subscribed":false},{"client_msg_id":"fed4b0a9-8d2b-4374-8aa5-e32bd8d4935a","type":"message","text":"Btw in this blog: <https://www.juliabloggers.com/automatic-differentiation-does-incur-truncation-errors-kinda/>\nI think the 6 different API for the autograd libs is to not get confused which one someone uses in their codes.","user":"U016RL8KEHX","ts":"1614079707.060700","team":"T68168MUP","edited":{"user":"U016RL8KEHX","ts":"1614079732.000000"},"blocks":[{"type":"rich_text","block_id":"x=UJI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Btw in this blog: "},{"type":"link","url":"https://www.juliabloggers.com/automatic-differentiation-does-incur-truncation-errors-kinda/"},{"type":"text","text":"\nI think the 6 different API for the autograd libs is to not get confused which one someone uses in their codes."}]}]}]},{"client_msg_id":"385a1618-5855-410e-a723-8e06c1c60dc9","type":"message","text":"Any workaround for the following issue?\n```julia&gt; using Zygote, Flux\njulia&gt; X = randn(5); Y = randn(5);\njulia&gt; ps = Flux.params(X,Y);\njulia&gt; gs = gradient(ps) do\n       sum([sin(x*y) for x in X, y in Y])\n       end```\n&gt; ERROR: Need an adjoint for constructor Base.Iterators.ProductIterator{Tuple{Array{Float64,1},Array{Float64,1}}}. Gradient is of type Array{Tuple{Float64,Float64},2}","user":"U7YD3DKL2","ts":"1614091216.062700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BBSFh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any workaround for the following issue?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> using Zygote, Flux\njulia> X = randn(5); Y = randn(5);\njulia> ps = Flux.params(X,Y);\njulia> gs = gradient(ps) do\n       sum([sin(x*y) for x in X, y in Y])\n       end"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"ERROR: Need an adjoint for constructor Base.Iterators.ProductIterator{Tuple{Array{Float64,1},Array{Float64,1}}}. Gradient is of type Array{Tuple{Float64,Float64},2}"}]}]}]},{"client_msg_id":"5f31ec7e-dfba-4274-835e-9bceb45f9405","type":"message","text":"Why does this work\n```julia&gt; f2(x) = sum(SMatrix{2,2,Float64,4}(x,x^2,√x,sin(x)))\njulia&gt; Zygote.gradient(f2,3.3)  # (6.887761171372725,)```\nwhen this fails?\n```julia&gt; function f3(x)::SMatrix{2,2,Float64,4}\n           [ x x^2; √x sin(x) ]\n       end\njulia&gt; Zygote.gradient(x-&gt;sum(f3(x)),3.3)  #  ERROR: Need an adjoint for constructor SMatrix{2, 2, Float64, 4}. Gradient is of type FillArrays.Fill{...```\nIt seems like function defs with return-type specifications cause Zygote missing-constructor-adjoint errors even when the constructor `rrule` is defined, but I could be misunderstanding something more basic. In my case, before the code above I have defined `rrule`s for `SMatrix` construction like this\n```julia&gt; ChainRulesCore.rrule(T::Type{&lt;:SMatrix}, x::AbstractMatrix) = ( T(x), dv -&gt; (nothing, dv) )\njulia&gt; ChainRulesCore.rrule(T::Type{&lt;:SMatrix}, xs::Number...) = ( T(xs...), dv -&gt; (nothing, dv...) )\njulia&gt; ChainRules.refresh_rules()\njulia&gt; Zygote.refresh()```\nSorry, probably a dumb question. Any advice or workaround would be much appreciated! Some of the functions causing this error for me are in imported packages, so I'm hoping to avoid this without redefining them.","user":"U01HK5WRVJT","ts":"1614104611.078100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DgBpT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Why does this work\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> f2(x) = sum(SMatrix{2,2,Float64,4}(x,x^2,√x,sin(x)))\njulia> Zygote.gradient(f2,3.3)  # (6.887761171372725,)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"when this fails?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> function f3(x)::SMatrix{2,2,Float64,4}\n           [ x x^2; √x sin(x) ]\n       end\njulia> Zygote.gradient(x->sum(f3(x)),3.3)  #  ERROR: Need an adjoint for constructor SMatrix{2, 2, Float64, 4}. Gradient is of type FillArrays.Fill{..."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"It seems like function defs with return-type specifications cause Zygote missing-constructor-adjoint errors even when the constructor "},{"type":"text","text":"rrule","style":{"code":true}},{"type":"text","text":" is defined, but I could be misunderstanding something more basic. In my case, before the code above I have defined "},{"type":"text","text":"rrule","style":{"code":true}},{"type":"text","text":"s for "},{"type":"text","text":"SMatrix","style":{"code":true}},{"type":"text","text":" construction like this\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> ChainRulesCore.rrule(T::Type{<:SMatrix}, x::AbstractMatrix) = ( T(x), dv -> (nothing, dv) )\njulia> ChainRulesCore.rrule(T::Type{<:SMatrix}, xs::Number...) = ( T(xs...), dv -> (nothing, dv...) )\njulia> ChainRules.refresh_rules()\njulia> Zygote.refresh()"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Sorry, probably a dumb question. Any advice or workaround would be much appreciated! Some of the functions causing this error for me are in imported packages, so I'm hoping to avoid this without redefining them."}]}]}],"thread_ts":"1614104611.078100","reply_count":9,"reply_users_count":2,"latest_reply":"1614107503.080200","reply_users":["U6A936746","U01HK5WRVJT"],"subscribed":false},{"client_msg_id":"1929b266-aa1e-41db-ac44-3fc4fbaec7f6","type":"message","text":"Is this (below) an accurate view of one of the the differences with Julia's autodiff ecosystem and Python's autodiff frameworks?\n\nIt seems to me likes long as your code is written in normal Julia code, the Julia autodiff packages will probably work(?) at doing the autodiff in ways you want! Which leads to things like being able to backprop through other Julia packages like powerful differential equation solvers. \n\nWhereas in Python, with Tensorflow and Pytorch, you have to build the computational graph using the objects made for that purpose with knowing in mind in advance that you want to autodiff.\n\nIf anyone has some some other significant differences, feel free to suggest! I would love to look into them","user":"U0138UTB7A4","ts":"1614178341.085700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"v3=Rt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is this (below) an accurate view of one of the the differences with Julia's autodiff ecosystem and Python's autodiff frameworks?\n\nIt seems to me likes long as your code is written in normal Julia code, the Julia autodiff packages will probably work(?) at doing the autodiff in ways you want! Which leads to things like being able to backprop through other Julia packages like powerful differential equation solvers. \n\nWhereas in Python, with Tensorflow and Pytorch, you have to build the computational graph using the objects made for that purpose with knowing in mind in advance that you want to autodiff.\n\nIf anyone has some some other significant differences, feel free to suggest! I would love to look into them"}]}]}],"thread_ts":"1614178341.085700","reply_count":2,"reply_users_count":1,"latest_reply":"1614178816.086100","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"75c29e1a-21f6-49d6-9ec4-e21005dde50f","type":"message","text":"Hey folks. I was just trying to understand what it means to make a library \"differentiable.\" Like is there a template for what a differentiable library looks like or how one is implemented. I need to write a differentiable solver for a linear program. Linear programs are not usually differentiable, but I can apply some smoothing to make it differentiable. But I am not sure how to implement this in a library so that I can connect it back to Flux or something. Any guidance would be appreciated.","user":"UDDSTBX19","ts":"1614188557.089700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VlAK5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey folks. I was just trying to understand what it means to make a library \"differentiable.\" Like is there a template for what a differentiable library looks like or how one is implemented. I need to write a differentiable solver for a linear program. Linear programs are not usually differentiable, but I can apply some smoothing to make it differentiable. But I am not sure how to implement this in a library so that I can connect it back to Flux or something. Any guidance would be appreciated."}]}]}],"thread_ts":"1614188557.089700","reply_count":15,"reply_users_count":6,"latest_reply":"1614189597.094000","reply_users":["ULG5V164A","UDDSTBX19","U67G3QRJM","U6A936746","U82RE6STE","UCZ7VBGUD"],"subscribed":false},{"client_msg_id":"28b63518-d467-4cf7-8c0f-8f59e1a5e6e2","type":"message","text":"Hello everyone, I am cross-posting here from my <https://discourse.julialang.org/t/how-to-achieve-good-performance-with-zygote-pushforward-on-a-neural-network/55971|thread on discourse>.\nI am trying to use the function Zygote.pushforward on a neural network:\n```using Flux\nusing Statistics\n\nconst X = reshape(0:1f-1:10, 1, :)\nconst Y = sin.(X)\n\nm = Chain(\n    Dense(1, 10, tanh),\n    Dense(10, 10, tanh),\n    Dense(10, 10, tanh),\n    Dense(10, 1),\n)\n\nscalar_m(x) = first(m([x]))\nscalar_m′(x) = Flux.pushforward(scalar_m, x)(1)\nm′(X) = scalar_m′.(X)\n\nloss(X, Y) = Flux.mse(m(X), Y) + mean(abs2.(cos.(X) - m′(X)))\n\nopt = ADAM()\ncb() = @show loss(X, Y)\n@time Flux.@epochs 1000 Flux.train!(loss, params(m), [(X, Y)], opt; cb)```\nFor some reason, computing the derivative of the neural network using the finite difference method is many times faster. Anybody knows why?","user":"U01KF7VFJB1","ts":"1614237744.108900","team":"T68168MUP","edited":{"user":"U01KF7VFJB1","ts":"1614237832.000000"},"blocks":[{"type":"rich_text","block_id":"iat1n","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello everyone, I am cross-posting here from my "},{"type":"link","url":"https://discourse.julialang.org/t/how-to-achieve-good-performance-with-zygote-pushforward-on-a-neural-network/55971","text":"thread on discourse"},{"type":"text","text":".\nI am trying to use the function Zygote.pushforward on a neural network:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Flux\nusing Statistics\n\nconst X = reshape(0:1f-1:10, 1, :)\nconst Y = sin.(X)\n\nm = Chain(\n    Dense(1, 10, tanh),\n    Dense(10, 10, tanh),\n    Dense(10, 10, tanh),\n    Dense(10, 1),\n)\n\nscalar_m(x) = first(m([x]))\nscalar_m′(x) = Flux.pushforward(scalar_m, x)(1)\nm′(X) = scalar_m′.(X)\n\nloss(X, Y) = Flux.mse(m(X), Y) + mean(abs2.(cos.(X) - m′(X)))\n\nopt = ADAM()\ncb() = @show loss(X, Y)\n@time Flux.@epochs 1000 Flux.train!(loss, params(m), [(X, Y)], opt; cb)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"For some reason, computing the derivative of the neural network using the finite difference method is many times faster. Anybody knows why?"}]}]}]},{"type":"message","text":"What's the meeting code for the ML and AD Development/Usage call?","user":"U9MD78Z9N","ts":"1614270861.110100","team":"T68168MUP"},{"client_msg_id":"0027df1e-1e24-4f88-8044-a7e499af694d","type":"message","text":"is there a meeting code?","user":"U69BL50BF","ts":"1614270906.110300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"S6PI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is there a meeting code?"}]}]}]},{"client_msg_id":"12f8f1b7-7cf6-488b-8dc0-770d5b90926e","type":"message","text":"oh","user":"U69BL50BF","ts":"1614270917.110500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"h=oC+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oh"}]}]}]},{"client_msg_id":"f0155c6b-ec89-4c4a-85b3-5e7fe4d0a70b","type":"message","text":"password is `julia` I think?","user":"U69BL50BF","ts":"1614270924.110800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oJ3C","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"password is "},{"type":"text","text":"julia","style":{"code":true}},{"type":"text","text":" I think?"}]}]}]},{"type":"message","text":"Thanks, it wasn't in the canedar","user":"U9MD78Z9N","ts":"1614270961.110900","team":"T68168MUP"},{"client_msg_id":"6ca4548b-6c65-4477-bc3f-4302ecebcdbd","type":"message","text":"Hi, I'd like to obtain the second order gradient of an NN. And I wrote","user":"U0197S1773K","ts":"1614323301.112900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2pQsQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I'd like to obtain the second order gradient of an NN. And I wrote"}]}]}]},{"client_msg_id":"129d5da5-e016-477e-add5-efa6855fdebe","type":"message","text":"```gs = gradient(inp) do hidden_out\n    tmp_gs = (gradient(ps) do\n        Flux.Losses.logitcrossentropy(tail_layers(inp), targ_c)\n    end)\n    tmp_gs[tmp_gs.params[3]][3, 6]\nend```\nBut the `getindex` of `tmp_gs` seemed unable to be differentiated.","user":"U0197S1773K","ts":"1614323389.114300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ze5mL","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"gs = gradient(inp) do hidden_out\n    tmp_gs = (gradient(ps) do\n        Flux.Losses.logitcrossentropy(tail_layers(inp), targ_c)\n    end)\n    tmp_gs[tmp_gs.params[3]][3, 6]\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"But the "},{"type":"text","text":"getindex","style":{"code":true}},{"type":"text","text":" of "},{"type":"text","text":"tmp_gs","style":{"code":true}},{"type":"text","text":" seemed unable to be differentiated."}]}]}]},{"client_msg_id":"87313512-44a7-4da2-b8a0-c98a06e74268","type":"message","text":"This is probably the most useless use of ForwardDiff you can have, but I implemented `a+b` using it.\n```julia&gt; using ForwardDiff\n\njulia&gt; f((a, b)) = (a^2)/2 + a*b\nf (generic function with 1 method)\n\njulia&gt; plus(a, b) = ForwardDiff.gradient(f, [a, b])[1]\nplus (generic function with 1 method)\n\njulia&gt; plus(5, 10)\n15.0```","user":"U01CQTKB86N","ts":"1614364808.118000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Wbf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This is probably the most useless use of ForwardDiff you can have, but I implemented "},{"type":"text","text":"a+b","style":{"code":true}},{"type":"text","text":" using it.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> using ForwardDiff\n\njulia> f((a, b)) = (a^2)/2 + a*b\nf (generic function with 1 method)\n\njulia> plus(a, b) = ForwardDiff.gradient(f, [a, b])[1]\nplus (generic function with 1 method)\n\njulia> plus(5, 10)\n15.0"}]}]}],"thread_ts":"1614364808.118000","reply_count":1,"reply_users_count":1,"latest_reply":"1614364993.118100","reply_users":["U01CQTKB86N"],"subscribed":false,"reactions":[{"name":"joy","users":["U674T0Y9Z"],"count":1}]},{"client_msg_id":"22c635ad-0376-4f5a-84c0-379b24694e9b","type":"message","text":"Hi all. I’m working on a differentiable physics simulation code and am getting started with Zygote.\nIs this code below a good way to calculate the Jacobian using Zygote? I’m trying to develop a simple example based off of the zygote docs\n```# Evaluate the Jacobian matrix using Zygote and compare to finite differences\nbegin\n\t# define a function f(x): R³ → R³\n\n\tf(x) = [x[1]^2 + 2*x[2]^2 + 3*x[3]^2\n\t\t\t10*x[1]^2 + 20*x[2]^2 + 30*x[3]^2\n\t\t\t100*x[1]^2 + 200*x[2]^2 + 300*x[3]^2]\n\t\n\t# Calculate the Jacobian of f using finite differences\n\t# fᵢ'(x0) ≈ (fᵢ(x0 + ϵd) - f(x0)) / ϵd\n\tx0 = 11.0\n\tϵd = 1e-6\n\n\tr1 = (f([x0+ϵd 0 0]) - f([x0 0 0])) / ϵd\n\tr2 = (f([0 x0+ϵd 0]) - f([0 x0 0])) / ϵd\n\tr3 = (f([0 0 x0+ϵd 0]) - f([0 0 x0])) / ϵd\n\tJ_fd = [r1 r2 r3]\n\t\n\t# Now calculate the Jacobian using Zygote.pullback\n\t# First calculate the pullback: \n\tfx0, back = Zygote.pullback(f, [x0 x0 x0])\n\t# Evaluate the Jacobian matrix row-wise by\n\t# evaluating back at the unit vectors\n\tr1 = back([1 0 0])[1]\n\tr2 = back([0 1 0])[1]\n\tr3 = back([0 0 1])[1]\n\tJ_zg = [r1; r2; r3]\nend```","user":"U018F5W2H24","ts":"1614372412.120200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4FrNS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all. I’m working on a differentiable physics simulation code and am getting started with Zygote.\nIs this code below a good way to calculate the Jacobian using Zygote? I’m trying to develop a simple example based off of the zygote docs\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"# Evaluate the Jacobian matrix using Zygote and compare to finite differences\nbegin\n\t# define a function f(x): R³ → R³\n\n\tf(x) = [x[1]^2 + 2*x[2]^2 + 3*x[3]^2\n\t\t\t10*x[1]^2 + 20*x[2]^2 + 30*x[3]^2\n\t\t\t100*x[1]^2 + 200*x[2]^2 + 300*x[3]^2]\n\t\n\t# Calculate the Jacobian of f using finite differences\n\t# fᵢ'(x0) ≈ (fᵢ(x0 + ϵd) - f(x0)) / ϵd\n\tx0 = 11.0\n\tϵd = 1e-6\n\n\tr1 = (f([x0+ϵd 0 0]) - f([x0 0 0])) / ϵd\n\tr2 = (f([0 x0+ϵd 0]) - f([0 x0 0])) / ϵd\n\tr3 = (f([0 0 x0+ϵd 0]) - f([0 0 x0])) / ϵd\n\tJ_fd = [r1 r2 r3]\n\t\n\t# Now calculate the Jacobian using Zygote.pullback\n\t# First calculate the pullback: \n\tfx0, back = Zygote.pullback(f, [x0 x0 x0])\n\t# Evaluate the Jacobian matrix row-wise by\n\t# evaluating back at the unit vectors\n\tr1 = back([1 0 0])[1]\n\tr2 = back([0 1 0])[1]\n\tr3 = back([0 0 1])[1]\n\tJ_zg = [r1; r2; r3]\nend"}]}]}],"thread_ts":"1614372412.120200","reply_count":29,"reply_users_count":3,"latest_reply":"1614373864.127300","reply_users":["U6A936746","U018F5W2H24","UCD4Z3NJZ"],"subscribed":false},{"client_msg_id":"cb1150e3-9ad1-4145-a33c-2f7376a4f19f","type":"message","text":"It seems that Zygote converts `BitArray`  to `Array{Bool}`? This is causing me some issues.","user":"U7YD3DKL2","ts":"1614424641.130000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7e/5J","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It seems that Zygote converts "},{"type":"text","text":"BitArray","style":{"code":true}},{"type":"text","text":"  to "},{"type":"text","text":"Array{Bool}","style":{"code":true}},{"type":"text","text":"? This is causing me some issues."}]}]}],"thread_ts":"1614424641.130000","reply_count":1,"reply_users_count":1,"latest_reply":"1614425048.130100","reply_users":["U7YD3DKL2"],"subscribed":false},{"client_msg_id":"b4dd4e54-6b89-496c-b330-985c0655a2cb","type":"message","text":"Hi. I'm trying understand AD starting from the basics. Right now I am going through <https://github.com/MikeInnes/diff-zoo/blob/notebooks/intro.ipynb> , which is super helpful btw! :)\nThere is an example comparing interpolated expressions and non-interpolated expressions in their behaviour in the following code. My question is this: Given `y2` and `y3` as below, how do I actually distinguish them from each other in general?\n```julia&gt; printstructure(x, _, _) = x\nprintstructure (generic function with 1 method)\n\njulia&gt; function printstructure(ex::Expr, cache = IdDict(), n = Ref(0))\n         haskey(cache, ex) &amp;&amp; return cache[ex]\n         args = map(x -&gt; printstructure(x, cache, n), ex.args)\n         cache[ex] = sym = Symbol(:y, n[] += 1)\n         println(:($sym = $(Expr(ex.head, args...))))\n         return sym\n       end\nprintstructure (generic function with 4 methods)\n\njulia&gt; y1 = :(1 * 2)\n:(1 * 2)\n\njulia&gt; y2 = :($y1 + $y1 + $y1 + $y1)\n:(1 * 2 + 1 * 2 + 1 * 2 + 1 * 2)\n\njulia&gt; printstructure(y2);\ny1 = 1 * 2\ny2 = y1 + y1 + y1 + y1\n\njulia&gt; y3 = :($(:(1 * 2)) + $(:(1 * 2)) + $(:(1 * 2)) + $(:(1 * 2)))\n:(1 * 2 + 1 * 2 + 1 * 2 + 1 * 2)\n\njulia&gt; y2 == y3\ntrue\n\njulia&gt; y2 === y3\nfalse\n\njulia&gt; printstructure(y3);\ny1 = 1 * 2\ny2 = 1 * 2\ny3 = 1 * 2\ny4 = 1 * 2\ny5 = y1 + y2 + y3 + y4\n\njulia&gt;```\nAlso, can someone explain the following strange behaviour? Why is `y1.args` bigger than `y1` itself?\n```julia&gt; sizeof(y1)\n16\n\njulia&gt; sizeof(y1.args)\n24```","user":"U0190AJCYK0","ts":"1614434572.134500","team":"T68168MUP","edited":{"user":"U0190AJCYK0","ts":"1614434989.000000"},"blocks":[{"type":"rich_text","block_id":"IR5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi. I'm trying understand AD starting from the basics. Right now I am going through "},{"type":"link","url":"https://github.com/MikeInnes/diff-zoo/blob/notebooks/intro.ipynb"},{"type":"text","text":" , which is super helpful btw! :)\nThere is an example comparing interpolated expressions and non-interpolated expressions in their behaviour in the following code. My question is this: Given "},{"type":"text","text":"y2","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"y3","style":{"code":true}},{"type":"text","text":" as below, how do I actually distinguish them from each other in general?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> printstructure(x, _, _) = x\nprintstructure (generic function with 1 method)\n\njulia> function printstructure(ex::Expr, cache = IdDict(), n = Ref(0))\n         haskey(cache, ex) && return cache[ex]\n         args = map(x -> printstructure(x, cache, n), ex.args)\n         cache[ex] = sym = Symbol(:y, n[] += 1)\n         println(:($sym = $(Expr(ex.head, args...))))\n         return sym\n       end\nprintstructure (generic function with 4 methods)\n\njulia> y1 = :(1 * 2)\n:(1 * 2)\n\njulia> y2 = :($y1 + $y1 + $y1 + $y1)\n:(1 * 2 + 1 * 2 + 1 * 2 + 1 * 2)\n\njulia> printstructure(y2);\ny1 = 1 * 2\ny2 = y1 + y1 + y1 + y1\n\njulia> y3 = :($(:(1 * 2)) + $(:(1 * 2)) + $(:(1 * 2)) + $(:(1 * 2)))\n:(1 * 2 + 1 * 2 + 1 * 2 + 1 * 2)\n\njulia> y2 == y3\ntrue\n\njulia> y2 === y3\nfalse\n\njulia> printstructure(y3);\ny1 = 1 * 2\ny2 = 1 * 2\ny3 = 1 * 2\ny4 = 1 * 2\ny5 = y1 + y2 + y3 + y4\n\njulia>"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Also, can someone explain the following strange behaviour? Why is "},{"type":"text","text":"y1.args","style":{"code":true}},{"type":"text","text":" bigger than "},{"type":"text","text":"y1","style":{"code":true}},{"type":"text","text":" itself?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> sizeof(y1)\n16\n\njulia> sizeof(y1.args)\n24"}]}]}],"thread_ts":"1614434572.134500","reply_count":1,"reply_users_count":1,"latest_reply":"1614435223.134700","reply_users":["U6A936746"],"subscribed":false},{"client_msg_id":"2ea397d5-193b-47c7-b698-9de90559b94d","type":"message","text":"Is there any reversediff style package that supports array mutation? My problem has 300 input variables and 1 output. A function evaluation takes 2.5s on my machine. ForwardDiff takes quite some time.","user":"UMC2RHKLZ","ts":"1614472691.140600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NfZFy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there any reversediff style package that supports array mutation? My problem has 300 input variables and 1 output. A function evaluation takes 2.5s on my machine. ForwardDiff takes quite some time."}]}]}],"thread_ts":"1614472691.140600","reply_count":9,"reply_users_count":2,"latest_reply":"1614474259.143200","reply_users":["UCD4Z3NJZ","UMC2RHKLZ"],"subscribed":false},{"client_msg_id":"b76f3d37-83e7-458e-84bb-d588f8c11790","type":"message","text":"Can zygote calculate gradients of functions that internally use `Dual` types from `ForwardDiff` ? The two AD systems are not calculating derivatives toward the same parameters. Any suggestions for other (combinations of) AD systems, this would work with?","user":"UQEDP1Q5V","ts":"1614569742.147700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vK5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can zygote calculate gradients of functions that internally use "},{"type":"text","text":"Dual","style":{"code":true}},{"type":"text","text":" types from "},{"type":"text","text":"ForwardDiff","style":{"code":true}},{"type":"text","text":" ? The two AD systems are not calculating derivatives toward the same parameters. Any suggestions for other (combinations of) AD systems, this would work with?"}]}]}],"thread_ts":"1614569742.147700","reply_count":1,"reply_users_count":1,"latest_reply":"1614572086.148100","reply_users":["U69BL50BF"],"subscribed":false},{"client_msg_id":"c04e5099-4520-4bf8-b59b-0039d576a34f","type":"message","text":"Hi. I’m trying reverse-mode AD on my physics simulation and am getting an error which I don’t know how to fix:\n```\nERROR: ArgumentError: unable to check bounds for indices of type Interpolations.WeightedAdjIndex{2,Float64}\nStacktrace:\n [1] checkindex(::Type{Bool}, ::Base.OneTo{Int64}, ::Interpolations.WeightedAdjIndex{2,Float64}) at ./abstractarray.jl:561\n [2] checkbounds at ./abstractarray.jl:491 [inlined]\n [3] checkbounds at ./abstractarray.jl:506 [inlined]\n [4] view at ./subarray.jl:158 [inlined]\n [5] (::Zygote.var\"#364#366\"{Array{Float64,1},Tuple{Interpolations.WeightedAdjIndex{2,Float64}}})(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/lib/array.jl:41\n [6] (::Zygote.var\"#2225#back#360\"{Zygote.var\"#364#366\"{Array{Float64,1},Tuple{Interpolations.WeightedAdjIndex{2,Float64}}}})(::Float64) at /Users/ralph/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59\n [7] (::Zygote.var\"#151#152\"{Zygote.var\"#2225#back#360\"{Zygote.var\"#364#366\"{Array{Float64,1},Tuple{Interpolations.WeightedAdjIndex{2,Float64}}}},Tuple{Tuple{Nothing},Tuple{Nothing}}})(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/lib/lib.jl:191\n [8] (::Zygote.var\"#1694#back#153\"{Zygote.var\"#151#152\"{Zygote.var\"#2225#back#360\"{Zygote.var\"#364#366\"{Array{Float64,1},Tuple{Interpolations.WeightedAdjIndex{2,Float64}}}},Tuple{Tuple{Nothing},Tuple{Nothing}}}})(::Float64) at /Users/ralph/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59\n [9] BSplineInterpolation at /Users/ralph/.julia/packages/Interpolations/qHlUr/src/b-splines/indexing.jl:8 [inlined]\n [10] (::Zygote.var\"#151#152\"{typeof(∂(λ)),Tuple{Tuple{Nothing}}})(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/lib/lib.jl:191\n [11] (::Zygote.var\"#1694#back#153\"{Zygote.var\"#151#152\"{typeof(∂(λ)),Tuple{Tuple{Nothing}}}})(::Float64) at /Users/ralph/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59\n [12] ScaledInterpolation at /Users/ralph/.julia/packages/Interpolations/qHlUr/src/scaling/scaling.jl:73 [inlined]\n [13] (::Zygote.var\"#151#152\"{typeof(∂(λ)),Tuple{Tuple{Nothing}}})(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/lib/lib.jl:191\n [14] (::Zygote.var\"#1694#back#153\"{Zygote.var\"#151#152\"{typeof(∂(λ)),Tuple{Tuple{Nothing}}}})(::Float64) at /Users/ralph/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59\n [15] Extrapolation at /Users/ralph/.julia/packages/Interpolations/qHlUr/src/extrapolation/extrapolation.jl:49 [inlined]\n [16] (::typeof(∂(λ)))(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface2.jl:0\n [17] push_here! at /Users/ralph/source/repos/picfun/test_push_autodiff.jl:93 [inlined]\n [18] (::typeof(∂(push_here!)))(::Nothing) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface2.jl:0\n [19] diff_me at /Users/ralph/source/repos/picfun/test_push_autodiff.jl:220 [inlined]\n [20] (::typeof(∂(diff_me)))(::Array{Float64,1}) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface2.jl:0\n [21] diff_capture at /Users/ralph/source/repos/picfun/test_push_autodiff.jl:233 [inlined]\n [22] (::typeof(∂(diff_capture)))(::Array{Float64,1}) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface2.jl:0\n [23] (::Zygote.var\"#41#42\"{typeof(∂(diff_capture))})(::Array{Float64,1}) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface.jl:40\n [24] top-level scope at ./REPL[9]:5```\nFrom [17] on the Stacktrace is within the function `push_here!` which uses interpolations in combination with an iterative solver for a set of equations.\nThe signature of the function is like this:\n```function push_here(aux_0, aux_12, aux_new, interpolated_field, parameters, convergence_tolerances)```\nand updates `aux_12` and `aux_new` .\n\nI’ve came across this issue here <https://github.com/FluxML/Zygote.jl/issues/643>\nbut I’m unsure how to define a custom adjoint when the function mutates its arguments `aux_12` and `aux_new`. Does anyone have a suggestion on how to get such a function working with Zygote or reverse-mode AD?","user":"U018F5W2H24","ts":"1614682603.154400","team":"T68168MUP","edited":{"user":"U018F5W2H24","ts":"1614683005.000000"},"blocks":[{"type":"rich_text","block_id":"E7U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi. I’m trying reverse-mode AD on my physics simulation and am getting an error which I don’t know how to fix:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"\nERROR: ArgumentError: unable to check bounds for indices of type Interpolations.WeightedAdjIndex{2,Float64}\nStacktrace:\n [1] checkindex(::Type{Bool}, ::Base.OneTo{Int64}, ::Interpolations.WeightedAdjIndex{2,Float64}) at ./abstractarray.jl:561\n [2] checkbounds at ./abstractarray.jl:491 [inlined]\n [3] checkbounds at ./abstractarray.jl:506 [inlined]\n [4] view at ./subarray.jl:158 [inlined]\n [5] (::Zygote.var\"#364#366\"{Array{Float64,1},Tuple{Interpolations.WeightedAdjIndex{2,Float64}}})(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/lib/array.jl:41\n [6] (::Zygote.var\"#2225#back#360\"{Zygote.var\"#364#366\"{Array{Float64,1},Tuple{Interpolations.WeightedAdjIndex{2,Float64}}}})(::Float64) at /Users/ralph/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59\n [7] (::Zygote.var\"#151#152\"{Zygote.var\"#2225#back#360\"{Zygote.var\"#364#366\"{Array{Float64,1},Tuple{Interpolations.WeightedAdjIndex{2,Float64}}}},Tuple{Tuple{Nothing},Tuple{Nothing}}})(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/lib/lib.jl:191\n [8] (::Zygote.var\"#1694#back#153\"{Zygote.var\"#151#152\"{Zygote.var\"#2225#back#360\"{Zygote.var\"#364#366\"{Array{Float64,1},Tuple{Interpolations.WeightedAdjIndex{2,Float64}}}},Tuple{Tuple{Nothing},Tuple{Nothing}}}})(::Float64) at /Users/ralph/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59\n [9] BSplineInterpolation at /Users/ralph/.julia/packages/Interpolations/qHlUr/src/b-splines/indexing.jl:8 [inlined]\n [10] (::Zygote.var\"#151#152\"{typeof(∂(λ)),Tuple{Tuple{Nothing}}})(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/lib/lib.jl:191\n [11] (::Zygote.var\"#1694#back#153\"{Zygote.var\"#151#152\"{typeof(∂(λ)),Tuple{Tuple{Nothing}}}})(::Float64) at /Users/ralph/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59\n [12] ScaledInterpolation at /Users/ralph/.julia/packages/Interpolations/qHlUr/src/scaling/scaling.jl:73 [inlined]\n [13] (::Zygote.var\"#151#152\"{typeof(∂(λ)),Tuple{Tuple{Nothing}}})(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/lib/lib.jl:191\n [14] (::Zygote.var\"#1694#back#153\"{Zygote.var\"#151#152\"{typeof(∂(λ)),Tuple{Tuple{Nothing}}}})(::Float64) at /Users/ralph/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59\n [15] Extrapolation at /Users/ralph/.julia/packages/Interpolations/qHlUr/src/extrapolation/extrapolation.jl:49 [inlined]\n [16] (::typeof(∂(λ)))(::Float64) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface2.jl:0\n [17] push_here! at /Users/ralph/source/repos/picfun/test_push_autodiff.jl:93 [inlined]\n [18] (::typeof(∂(push_here!)))(::Nothing) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface2.jl:0\n [19] diff_me at /Users/ralph/source/repos/picfun/test_push_autodiff.jl:220 [inlined]\n [20] (::typeof(∂(diff_me)))(::Array{Float64,1}) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface2.jl:0\n [21] diff_capture at /Users/ralph/source/repos/picfun/test_push_autodiff.jl:233 [inlined]\n [22] (::typeof(∂(diff_capture)))(::Array{Float64,1}) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface2.jl:0\n [23] (::Zygote.var\"#41#42\"{typeof(∂(diff_capture))})(::Array{Float64,1}) at /Users/ralph/.julia/packages/Zygote/KpME9/src/compiler/interface.jl:40\n [24] top-level scope at ./REPL[9]:5"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"From [17] on the Stacktrace is within the function "},{"type":"text","text":"push_here!","style":{"code":true}},{"type":"text","text":" which uses interpolations in combination with an iterative solver for a set of equations.\nThe signature of the function is like this:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function push_here(aux_0, aux_12, aux_new, interpolated_field, parameters, convergence_tolerances)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"and updates "},{"type":"text","text":"aux_12","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"aux_new","style":{"code":true}},{"type":"text","text":" .\n\nI’ve came across this issue here "},{"type":"link","url":"https://github.com/FluxML/Zygote.jl/issues/643"},{"type":"text","text":"\nbut I’m unsure how to define a custom adjoint when the function mutates its arguments "},{"type":"text","text":"aux_12","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"aux_new","style":{"code":true}},{"type":"text","text":". Does anyone have a suggestion on how to get such a function working with Zygote or reverse-mode AD?"}]}]}]},{"client_msg_id":"ee8798e2-a539-4e16-8e81-546d67075327","type":"message","text":"Can you use the convenient `ps = Flux.params(model)`  and `gs = gradient(ps) do loss(model) end` interface, but with ReverseDiff instead of Zygote?","user":"U7YD3DKL2","ts":"1614710568.159300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yUc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can you use the convenient "},{"type":"text","text":"ps = Flux.params(model)","style":{"code":true}},{"type":"text","text":"  and "},{"type":"text","text":"gs = gradient(ps) do loss(model) end","style":{"code":true}},{"type":"text","text":" interface, but with ReverseDiff instead of Zygote?"}]}]}]},{"client_msg_id":"c9f1418b-811f-4737-81f4-03e8c08da760","type":"message","text":"Similarly, it would be nice to have a \"Hessian\" that understands `params` . So that you can do `hs[ps1, ps2]`  and it would return the correct block of the Hessian","user":"U7YD3DKL2","ts":"1614780460.163400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"s8+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Similarly, it would be nice to have a \"Hessian\" that understands "},{"type":"text","text":"params","style":{"code":true}},{"type":"text","text":" . So that you can do "},{"type":"text","text":"hs[ps1, ps2]","style":{"code":true}},{"type":"text","text":"  and it would return the correct block of the Hessian"}]}]}]},{"client_msg_id":"bbcaee99-915d-4a3b-a9e9-2090812ec50a","type":"message","text":"How to get a ForwardSensitivity method to work, through the highest level interface?\n```using DiffEqSensitivity\nusing OrdinaryDiffEq\nusing ForwardDiff\nfunction fiip(du,u,p,t)\n    if t &lt; 0.01 ; println(u) end\n    du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n    du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]\nend\nfunction cost2(p)\n    prob = ODEProblem(fiip,[1.0,1.0],(0.0,10.0),p,abstol= 1e-6,reltol = 1e-6)  \n    sol = solve(prob,Tsit5();saveat=0:10,sensealg=ForwardSensitivity())\n    sum(sol)\nend\nForwardDiff.gradient(cost2,[1.5,1.0,3.0,1.0])```\n```ForwardDiff.Dual{ForwardDiff.Tag{typeof(cost2),Float64},Float64,4}[Dual{ForwardDiff.Tag{typeof(cost2),Float64}}(1.0,0.0,0.0,0.0,0.0), Dual{ForwardDiff.Tag{typeof(cost2),Float64}}(1.0,0.0,0.0,0.0,0.0)]\nForwardDiff.Dual{ForwardDiff.Tag{typeof(cost2),Float64},Float64,4}[Dual{ForwardDiff.Tag{typeof(cost2),Float64}}(1.0,0.0,0.0,0.0,0.0), Dual{ForwardDiff.Tag{typeof(cost2),Float64}}(1.0,0.0,0.0,0.0,0.0)]\n...```","user":"UQEDP1Q5V","ts":"1614783537.165300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SAtzZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How to get a ForwardSensitivity method to work, through the highest level interface?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using DiffEqSensitivity\nusing OrdinaryDiffEq\nusing ForwardDiff\nfunction fiip(du,u,p,t)\n    if t < 0.01 ; println(u) end\n    du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n    du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]\nend\nfunction cost2(p)\n    prob = ODEProblem(fiip,[1.0,1.0],(0.0,10.0),p,abstol= 1e-6,reltol = 1e-6)  \n    sol = solve(prob,Tsit5();saveat=0:10,sensealg=ForwardSensitivity())\n    sum(sol)\nend\nForwardDiff.gradient(cost2,[1.5,1.0,3.0,1.0])"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ForwardDiff.Dual{ForwardDiff.Tag{typeof(cost2),Float64},Float64,4}[Dual{ForwardDiff.Tag{typeof(cost2),Float64}}(1.0,0.0,0.0,0.0,0.0), Dual{ForwardDiff.Tag{typeof(cost2),Float64}}(1.0,0.0,0.0,0.0,0.0)]\nForwardDiff.Dual{ForwardDiff.Tag{typeof(cost2),Float64},Float64,4}[Dual{ForwardDiff.Tag{typeof(cost2),Float64}}(1.0,0.0,0.0,0.0,0.0), Dual{ForwardDiff.Tag{typeof(cost2),Float64}}(1.0,0.0,0.0,0.0,0.0)]\n..."}]}]}]},{"client_msg_id":"7524979c-368c-4ab5-bb87-3110d8e63584","type":"message","text":"ForwardSensitivity is an overload for reverse mode","user":"U69BL50BF","ts":"1614783782.165600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qttff","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ForwardSensitivity is an overload for reverse mode"}]}]}]},{"client_msg_id":"3e51d493-16f3-4330-81d5-3d446715a4a7","type":"message","text":"It basically is, if you do Zygote on this (or whatever else uses ChainRules), then replace the derivative calculation of `solve` with `ForwardSensitivity`.","user":"U69BL50BF","ts":"1614783807.166200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3=cZQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It basically is, if you do Zygote on this (or whatever else uses ChainRules), then replace the derivative calculation of "},{"type":"text","text":"solve","style":{"code":true}},{"type":"text","text":" with "},{"type":"text","text":"ForwardSensitivity","style":{"code":true}},{"type":"text","text":"."}]}]}]},{"client_msg_id":"8ad39c97-c80e-4f4c-835e-ae3c345d20b4","type":"message","text":"What does that mean in practice: cross-country AD for Zygote and forward mode for (eventually) ForwardDiff2 ?\nAnyway, how the different sensalg interact with wider forward/reverse AD systems, is maybe something that should be added to the docs?\nFor ForwardSensitivity the docs just say:  An implementation of continuous forward sensitivity analysis.\nI interpreted this as that in combination with ForwardDiff it would make a DiffRule, similar to ChainRules.","user":"UQEDP1Q5V","ts":"1614785964.173000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9ej","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What does that mean in practice: cross-country AD for Zygote and forward mode for (eventually) ForwardDiff2 ?\nAnyway, how the different sensalg interact with wider forward/reverse AD systems, is maybe something that should be added to the docs?\nFor ForwardSensitivity the docs just say:  An implementation of continuous forward sensitivity analysis.\nI interpreted this as that in combination with ForwardDiff it would make a DiffRule, similar to ChainRules."}]}]}],"thread_ts":"1614785964.173000","reply_count":1,"reply_users_count":1,"latest_reply":"1614787996.173300","reply_users":["UQEDP1Q5V"],"subscribed":false},{"client_msg_id":"ca170dd4-05ce-4758-a193-97f91b44bc62","type":"message","text":"AFAIK OpenAD is the only AD system that does cross-country AD. no?\n\nIt is Chapter 9 of Griewank and Walther.\nI feel like along with chapter 13 it is a chapter of forbidden lore.\n(<@U90JR0C80>)","user":"U6A936746","ts":"1614793917.174900","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1614795594.000000"},"blocks":[{"type":"rich_text","block_id":"5vMd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"AFAIK OpenAD is the only AD system that does cross-country AD. no?\n\nIt is Chapter 9 of Griewank and Walther.\nI feel like along with chapter 13 it is a chapter of forbidden lore.\n("},{"type":"user","user_id":"U90JR0C80"},{"type":"text","text":")"}]}]}],"thread_ts":"1614793917.174900","reply_count":5,"reply_users_count":3,"latest_reply":"1614795701.176500","reply_users":["U9MD78Z9N","U82RE6STE","U6A936746"],"subscribed":false}]}