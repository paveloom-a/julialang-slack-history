[{"type":"message","subtype":"thread_broadcast","text":"I've had some weirdness come up in Soss once in a while that traces back to named tuples being ordered.\n\n<https://github.com/simonbyrne/KeywordDispatch.jl> has a nice trick here, basically sort the named tuple before passing to the call. For small named tuples that works great, but with a few levels of nesting there's a fair amount of overhead.\n\nSo the idea here is to instead just sort once, recursively, and then use that in all calls. I expect this will also allow a recursive merge to be faster, since we can walk linearly through both arguments.","user":"U81PB6N77","ts":"1608435203.438300","thread_ts":"1608313780.433000","root":{"client_msg_id":"f21fdbee-4008-4dd2-90e0-57c3e3856b38","type":"message","text":"Got this recursive keysort for nested named tuples working pretty well:\n```julia&gt; nt\n(p = (m = (d = :d, u = :u, h = :h), j = (p = :p, j = :j, b = :b), k = (y = :y, s = :s, c = :c)), j = (l = (a = :a, f = :f, e = :e), f = (o = :o, y = :y, q = :q), p = (g = :g, k = :k, p = :p)), a = (s = (n = :n, h = :h, i = :i), m = (i = :i, w = :w, e = :e), o = (x = :x, t = :t, r = :r)))\n\njulia&gt; @btime keysort($nt)\n  5.520 ns (0 allocations: 0 bytes)\n(a = (m = (e = :e, i = :i, w = :w), o = (r = :r, t = :t, x = :x), s = (h = :h, i = :i, n = :n)), j = (f = (o = :o, q = :q, y = :y), l = (a = :a, e = :e, f = :f), p = (g = :g, k = :k, p = :p)), p = (j = (b = :b, j = :j, p = :p), k = (c = :c, s = :s, y = :y), m = (d = :d, h = :h, u = :u)))```","user":"U81PB6N77","ts":"1608313780.433000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YBO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Got this recursive keysort for nested named tuples working pretty well:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> nt\n(p = (m = (d = :d, u = :u, h = :h), j = (p = :p, j = :j, b = :b), k = (y = :y, s = :s, c = :c)), j = (l = (a = :a, f = :f, e = :e), f = (o = :o, y = :y, q = :q), p = (g = :g, k = :k, p = :p)), a = (s = (n = :n, h = :h, i = :i), m = (i = :i, w = :w, e = :e), o = (x = :x, t = :t, r = :r)))\n\njulia> @btime keysort($nt)\n  5.520 ns (0 allocations: 0 bytes)\n(a = (m = (e = :e, i = :i, w = :w), o = (r = :r, t = :t, x = :x), s = (h = :h, i = :i, n = :n)), j = (f = (o = :o, q = :q, y = :y), l = (a = :a, e = :e, f = :f), p = (g = :g, k = :k, p = :p)), p = (j = (b = :b, j = :j, p = :p), k = (c = :c, s = :s, y = :y), m = (d = :d, h = :h, u = :u)))"}]}]}],"thread_ts":"1608313780.433000","reply_count":8,"reply_users_count":2,"latest_reply":"1608435203.438300","reply_users":["U81PB6N77","U9JNHB83X"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"o=4a0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've had some weirdness come up in Soss once in a while that traces back to named tuples being ordered.\n\n"},{"type":"link","url":"https://github.com/simonbyrne/KeywordDispatch.jl"},{"type":"text","text":" has a nice trick here, basically sort the named tuple before passing to the call. For small named tuples that works great, but with a few levels of nesting there's a fair amount of overhead.\n\nSo the idea here is to instead just sort once, recursively, and then use that in all calls. I expect this will also allow a recursive merge to be faster, since we can walk linearly through both arguments."}]}]}],"client_msg_id":"5a9bb67a-f820-4d5d-a2ae-92108b87dee5"},{"client_msg_id":"a34fdc15-dccf-4b3b-8617-bc108ae4f545","type":"message","text":"I vaguely recall an announcement on discourse a couple of months ago, of a package that attempted to provide a posterior distribution over the optimal solution to an optimization problem after it had been solved, using only the loss function and the optimal solution. I can't seem to find the post announcing it, and wonder if anyone here might know what I'm talking about?","user":"UJ7DVTVQ8","ts":"1608374014.436300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ynsp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I vaguely recall an announcement on discourse a couple of months ago, of a package that attempted to provide a posterior distribution over the optimal solution to an optimization problem after it had been solved, using only the loss function and the optimal solution. I can't seem to find the post announcing it, and wonder if anyone here might know what I'm talking about?"}]}]}],"thread_ts":"1608374014.436300","reply_count":2,"reply_users_count":2,"latest_reply":"1608399128.437200","reply_users":["UJ7DVTVQ8","U81PB6N77"],"subscribed":false},{"client_msg_id":"f21fdbee-4008-4dd2-90e0-57c3e3856b38","type":"message","text":"Got this recursive keysort for nested named tuples working pretty well:\n```julia&gt; nt\n(p = (m = (d = :d, u = :u, h = :h), j = (p = :p, j = :j, b = :b), k = (y = :y, s = :s, c = :c)), j = (l = (a = :a, f = :f, e = :e), f = (o = :o, y = :y, q = :q), p = (g = :g, k = :k, p = :p)), a = (s = (n = :n, h = :h, i = :i), m = (i = :i, w = :w, e = :e), o = (x = :x, t = :t, r = :r)))\n\njulia&gt; @btime keysort($nt)\n  5.520 ns (0 allocations: 0 bytes)\n(a = (m = (e = :e, i = :i, w = :w), o = (r = :r, t = :t, x = :x), s = (h = :h, i = :i, n = :n)), j = (f = (o = :o, q = :q, y = :y), l = (a = :a, e = :e, f = :f), p = (g = :g, k = :k, p = :p)), p = (j = (b = :b, j = :j, p = :p), k = (c = :c, s = :s, y = :y), m = (d = :d, h = :h, u = :u)))```","user":"U81PB6N77","ts":"1608313780.433000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YBO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Got this recursive keysort for nested named tuples working pretty well:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> nt\n(p = (m = (d = :d, u = :u, h = :h), j = (p = :p, j = :j, b = :b), k = (y = :y, s = :s, c = :c)), j = (l = (a = :a, f = :f, e = :e), f = (o = :o, y = :y, q = :q), p = (g = :g, k = :k, p = :p)), a = (s = (n = :n, h = :h, i = :i), m = (i = :i, w = :w, e = :e), o = (x = :x, t = :t, r = :r)))\n\njulia> @btime keysort($nt)\n  5.520 ns (0 allocations: 0 bytes)\n(a = (m = (e = :e, i = :i, w = :w), o = (r = :r, t = :t, x = :x), s = (h = :h, i = :i, n = :n)), j = (f = (o = :o, q = :q, y = :y), l = (a = :a, e = :e, f = :f), p = (g = :g, k = :k, p = :p)), p = (j = (b = :b, j = :j, p = :p), k = (c = :c, s = :s, y = :y), m = (d = :d, h = :h, u = :u)))"}]}]}],"thread_ts":"1608313780.433000","reply_count":8,"reply_users_count":2,"latest_reply":"1608435203.438300","reply_users":["U81PB6N77","U9JNHB83X"],"subscribed":false},{"client_msg_id":"5EBE4665-F77C-46F5-BE04-09E606B5577D","type":"message","text":"We have to be careful now, I have a formal set theory book where the author bootstraps the theory setting {} = :waxing_crescent_moon: but I canâ€™t remember why ","user":"U6C937ENB","ts":"1608140273.428800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GOiC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We have to be careful now, I have a formal set theory book where the author bootstraps the theory setting {} = "},{"type":"emoji","name":"waxing_crescent_moon"},{"type":"text","text":" but I canâ€™t remember why "}]}]}]},{"client_msg_id":"4e203595-0651-43a2-9629-5c3f60e87cac","type":"message","text":"{:waxing_crescent_moon:}  is unique, but only up to unique isomorphism :P","user":"UN45LV5K6","ts":"1608139325.424400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lmiPz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"{"},{"type":"emoji","name":"waxing_crescent_moon"},{"type":"text","text":"}  is unique, but only up to unique isomorphism :P"}]}]}]},{"client_msg_id":"8dfe1ae2-cad2-4bd4-be8c-f89a4bdb3222","type":"message","text":"Normally my latents donâ€™t depend on the phases of the moon.","user":"UKA81L34J","ts":"1608136922.421000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9TM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Normally my latents donâ€™t depend on the phases of the moon."}]}]}],"thread_ts":"1608136922.421000","reply_count":1,"reply_users_count":1,"latest_reply":"1608141794.429900","reply_users":["U81PB6N77"],"subscribed":false,"reactions":[{"name":"joy","users":["UN97XTLCV","UPUBAM63X"],"count":2}]},{"client_msg_id":"b659c660-8ad4-456b-8584-c2338c908564","type":"message","text":"Just like we usually consider `f()` a function","user":"U6C937ENB","ts":"1608133863.420600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wpVT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just like we usually consider "},{"type":"text","text":"f()","style":{"code":true}},{"type":"text","text":" a function"}]}]}]},{"client_msg_id":"9ca3f5da-585c-44a9-83fb-97813b3d6560","type":"message","text":"Yes, and if you want you can write `P(x | ðŸŒ’)` instead of `P(x)` for some formal element :waxing_crescent_moon: of a 1-element set {:waxing_crescent_moon:}","user":"U6C937ENB","ts":"1608133728.420300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rbg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, and if you want you can write "},{"type":"text","text":"P(x | ðŸŒ’)","style":{"code":true}},{"type":"text","text":" instead of "},{"type":"text","text":"P(x)","style":{"code":true}},{"type":"text","text":" for some formal element "},{"type":"emoji","name":"waxing_crescent_moon"},{"type":"text","text":" of a 1-element set {"},{"type":"emoji","name":"waxing_crescent_moon"},{"type":"text","text":"}"}]}]}],"reactions":[{"name":"+1","users":["UCNCMAZ6E"],"count":1}]},{"client_msg_id":"4b18f51d-81e6-4304-a1c0-ae11618cf04f","type":"message","text":"My understanding of it (<@U6C937ENB> correct me if your take is different):\nProbability distributions form a monad, so for any type `a` we can form `Prob a` (haskell notation), \"probability distributions over `a`).\n\nMonads can be described in terms of *Kleisli arrows*, which are just functions `a -&gt; Prob b`.\n\nAs I understand it, a Markov kernel is just this, a function that takes a value and returns a distribution over values of some (generally different) type.","user":"U81PB6N77","ts":"1608132224.419100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MoeBD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My understanding of it ("},{"type":"user","user_id":"U6C937ENB"},{"type":"text","text":" correct me if your take is different):\nProbability distributions form a monad, so for any type "},{"type":"text","text":"a","style":{"code":true}},{"type":"text","text":" we can form "},{"type":"text","text":"Prob a","style":{"code":true}},{"type":"text","text":" (haskell notation), \"probability distributions over "},{"type":"text","text":"a","style":{"code":true}},{"type":"text","text":").\n\nMonads can be described in terms of "},{"type":"text","text":"Kleisli arrows","style":{"bold":true}},{"type":"text","text":", which are just functions "},{"type":"text","text":"a -> Prob b","style":{"code":true}},{"type":"text","text":".\n\nAs I understand it, a Markov kernel is just this, a function that takes a value and returns a distribution over values of some (generally different) type."}]}]}],"thread_ts":"1608132224.419100","reply_count":5,"reply_users_count":3,"latest_reply":"1608298989.431300","reply_users":["UN45LV5K6","U81PB6N77","U6C937ENB"],"subscribed":false,"reactions":[{"name":"point_up","users":["UCNCMAZ6E"],"count":1}]},{"client_msg_id":"e380c247-6f4a-40cb-b675-19f7fd86580a","type":"message","text":"Unless youâ€™re describing a Markov kernel as any pure transformation from distribution to distribution. In which case I basically agree, but itâ€™s sort of a tautology no ? If you have a transformation which is pure and measure preserving - that almost by definition describes functional PP.","user":"UKA81L34J","ts":"1608131317.415500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pB7Y4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Unless youâ€™re describing a Markov kernel as any pure transformation from distribution to distribution. In which case I basically agree, but itâ€™s sort of a tautology no ? If you have a transformation which is pure and measure preserving - that almost by definition describes functional PP."}]}]}]},{"client_msg_id":"c7b6ace4-02a7-4159-93ef-fe43c66a9f71","type":"message","text":"<@U6C937ENB> how does a markov kernel handle a transition like `P(x) -&gt; P(z, y | x)` ?","user":"UKA81L34J","ts":"1608131212.413800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WMQ","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U6C937ENB"},{"type":"text","text":" how does a markov kernel handle a transition like "},{"type":"text","text":"P(x) -> P(z, y | x)","style":{"code":true}},{"type":"text","text":" ?"}]}]}]},{"client_msg_id":"1f35521d-5819-4328-a28b-31771f30ed51","type":"message","text":"Oops I mean uniqueness typing, not quite the same as linear logic:\n<https://en.wikipedia.org/wiki/Uniqueness_type>","user":"U81PB6N77","ts":"1608129696.413100","team":"T68168MUP","attachments":[{"title":"Uniqueness type","title_link":"https://en.wikipedia.org/wiki/Uniqueness_type","from_url":"https://en.wikipedia.org/wiki/Uniqueness_type","author_name":"Wikipedia","author_link":"https://en.wikipedia.org/","text":"In computing, a unique type guarantees that an object is used in a single-threaded way, with at most a single reference to it. If a value has a unique type, a function applied to it can be optimized to update the value in-place in the object code. Such in-place updates improve the efficiency of functional languages while maintaining referential transparency. Unique types can also be used to integrate functional and imperative programming.","fallback":"wikipedia: Uniqueness type","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/wikipedia.png","id":1,"original_url":"https://en.wikipedia.org/wiki/Uniqueness_type"}],"blocks":[{"type":"rich_text","block_id":"wdoJg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oops I mean uniqueness typing, not quite the same as linear logic:\n"},{"type":"link","url":"https://en.wikipedia.org/wiki/Uniqueness_type"}]}]}]},{"client_msg_id":"32637c8c-3ee8-461d-af17-baba43c149dc","type":"message","text":"So I guess my answer is, with the right abstraction it's probably still a Markov kernel","user":"U81PB6N77","ts":"1608129556.412600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1YM2G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So I guess my answer is, with the right abstraction it's probably still a Markov kernel"}]}]}]},{"client_msg_id":"85cedea3-c527-4218-8561-21aed007df8b","type":"message","text":"Some imperative code is very easy to reason about. For example, check out the reversible computing paradigm in  NiLang. Even SSA can be really nice :slightly_smiling_face:","user":"U81PB6N77","ts":"1608129507.412000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sdf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Some imperative code is very easy to reason about. For example, check out the reversible computing paradigm in  NiLang. Even SSA can be really nice "},{"type":"emoji","name":"slightly_smiling_face"}]}]}]},{"client_msg_id":"bdfb95a4-0475-4a04-a45e-557f5a179263","type":"message","text":"I think form this perspective functional and imperative are not so different. FP is a way of programming that makes code very easy to reason about, but it's not the only way. Imperative code that takes `f(x)` and returns `y` is like functional code that takes `f*(x, world1)` and returns `(y, world2)`. The biggest difference is a given \"world\" can only be referenced once, but this can be put in terms of linear logic. The Clean programming language, for example, is functional but handled IO in this way.","user":"U81PB6N77","ts":"1608129436.410800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"avQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think form this perspective functional and imperative are not so different. FP is a way of programming that makes code very easy to reason about, but it's not the only way. Imperative code that takes "},{"type":"text","text":"f(x)","style":{"code":true}},{"type":"text","text":" and returns "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":" is like functional code that takes "},{"type":"text","text":"f*(x, world1)","style":{"code":true}},{"type":"text","text":" and returns "},{"type":"text","text":"(y, world2)","style":{"code":true}},{"type":"text","text":". The biggest difference is a given \"world\" can only be referenced once, but this can be put in terms of linear logic. The Clean programming language, for example, is functional but handled IO in this way."}]}]}]},{"client_msg_id":"7e3ac5c3-de82-4035-8502-2899a61c2dfa","type":"message","text":"I am now convinced that the Markov kernel is the fundamental conceptional unit of functional probabilistic programming. So what is itâ€™s equivalent in imperative code? A randomized instruction?","user":"U6C937ENB","ts":"1608125575.406900","team":"T68168MUP","edited":{"user":"U6C937ENB","ts":"1608125590.000000"},"blocks":[{"type":"rich_text","block_id":"ybkW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am now convinced that the Markov kernel is the fundamental conceptional unit of functional probabilistic programming. So what is itâ€™s equivalent in imperative code? A randomized instruction?"}]}]}]},{"client_msg_id":"65878fb9-c825-496d-9f28-5ebb2c5e200b","type":"message","text":"<https://ai.facebook.com/blog/ppl-bench-creating-a-standard-for-benchmarking-probabilistic-programming-languages/|https://ai.facebook.com/blog/ppl-bench-creating-a-standard-for-benchmarking-probabilistic-programming-languages/>","user":"UDGT4PM41","ts":"1608004645.405100","team":"T68168MUP","attachments":[{"title":"PPL Bench: Creating a standard for benchmarking probabilistic programming languages","title_link":"https://ai.facebook.com/blog/ppl-bench-creating-a-standard-for-benchmarking-probabilistic-programming-languages/","text":"PPL Bench is an open-source, standardized benchmarking framework for measuring inference performance in probabilistic programming languages.","fallback":"PPL Bench: Creating a standard for benchmarking probabilistic programming languages","thumb_url":"https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/122174564_823527068401904_6421496198039070291_n.png?_nc_cat=101&ccb=2&_nc_sid=ad8a9d&_nc_ohc=LLIQ4Qo4DU4AX8GoIF6&_nc_ht=scontent-iad3-1.xx&oh=3df55048ed07e801738638cef4e0721d&oe=5FFD90E3","from_url":"https://ai.facebook.com/blog/ppl-bench-creating-a-standard-for-benchmarking-probabilistic-programming-languages/","thumb_width":4756,"thumb_height":1427,"service_icon":"https://static.xx.fbcdn.net/rsrc.php/v3/yh/r/5ZP3mZo0oAE.png","service_name":"ai.facebook.com","id":1,"original_url":"https://ai.facebook.com/blog/ppl-bench-creating-a-standard-for-benchmarking-probabilistic-programming-languages/"}],"blocks":[{"type":"rich_text","block_id":"Xe/2w","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://ai.facebook.com/blog/ppl-bench-creating-a-standard-for-benchmarking-probabilistic-programming-languages/","text":"https://ai.facebook.com/blog/ppl-bench-creating-a-standard-for-benchmarking-probabilistic-programming-languages/"}]}]}]}]