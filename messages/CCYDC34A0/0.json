{"cursor": 0, "messages": [{"client_msg_id":"756f0666-93a0-43d0-9d68-f8f86a345e3f","type":"message","text":"To everyone,\nWe will have an open meeting on *18.12.2020 at 3pm CET*. If you have anything in mind that you like to discuss/ask (things that bother you, feature requests, …) or just want to hang out then fell free to join the video call. I’ll post the invite link in time in this channel.","user":"UC0SY9JFP","ts":"1607931638.077900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qEeDO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"To everyone,\nWe will have an open meeting on "},{"type":"text","text":"18.12.2020 at 3pm CET","style":{"bold":true}},{"type":"text","text":". If you have anything in mind that you like to discuss/ask (things that bother you, feature requests, …) or just want to hang out then fell free to join the video call. I’ll post the invite link in time in this channel."}]}]}],"thread_ts":"1607931638.077900","reply_count":2,"reply_users_count":2,"latest_reply":"1608023698.082900","reply_users":["U011PPW7K53","UC0SY9JFP"],"subscribed":false,"reactions":[{"name":"+1","users":["UGB3MK8MC","UHDQQ4GN6","UH08DT0JU","UTVH86LJ0","U01C2AJ9F63","U01A08JMUKT","U9JNHB83X","UAZHEDVBR","UCRDHV7PB","U011PPW7K53"],"count":10},{"name":"turing","users":["U011PPW7K53"],"count":1}]},{"type":"message","subtype":"thread_broadcast","text":"Some ongoing progress:\n\n1. Refactor and improve particle MCMC and particle filtering samplers into a light-weight package `AdvancedPS` \n2. Unify and modularise some core tracing data structure in `DynamicPPL` and separate them into `AbstractPPL` <@UN45LV5K6> <@UCRDHV7PB> \n3. Implement an experimental sub-DSL that’s compatible with the BUGS modelling language, and add support for efficient generalised Gibbs sampling.  \n4. Improve documentation and tutorials. \n5. Initial GPU accelerated HMC and RWMH support. \n6. Initial Annealed Important Sampling support and other model assessment methods. \n7. Initial Nested Sampling support. \n8. Revisit all Github existing issues, improve stability of public APIs and plan for Turing 1.0 release. \n9. any other issues raised by the Turing.jl and probabilistic programming community during the Turing.jl general public meeting and later feedbacks. \nWe aim to keep this progress as transparent as possible. We’ll also try to minimise disruption to existing Turing.jl users by maximising backward compatibility.\nWe anticipate it might still be a long way ahead before we can release Turing 1.0. Any help, comments feedbacks on improving the development and release of Turing are welcome! We also welcome community developers to join the Turing.jl team. Together, we aim to make Julia the go-to language for Bayesian inference and computation.","user":"UCRDHV7PB","ts":"1607986152.079200","thread_ts":"1607864180.072700","root":{"client_msg_id":"087cca24-8b16-476f-afc5-91096c1fe149","type":"message","text":"Out of curiosity, what is the development plan for Turing over the next 6-12 months?","user":"UH08DT0JU","ts":"1607864180.072700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Q6W","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Out of curiosity, what is the development plan for Turing over the next 6-12 months?"}]}]}],"thread_ts":"1607864180.072700","reply_count":10,"reply_users_count":5,"latest_reply":"1608002405.080600","reply_users":["U9JNHB83X","UH08DT0JU","U011PPW7K53","U85JBUGGP","UCRDHV7PB"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"oiGby","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Some ongoing progress:\n\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Refactor and improve particle MCMC and particle filtering samplers into a light-weight package "},{"type":"text","text":"AdvancedPS","style":{"code":true}},{"type":"text","text":" "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Unify and modularise some core tracing data structure in "},{"type":"text","text":"DynamicPPL","style":{"code":true}},{"type":"text","text":" and separate them into "},{"type":"text","text":"AbstractPPL","style":{"code":true}},{"type":"text","text":" "},{"type":"user","user_id":"UN45LV5K6"},{"type":"text","text":" "},{"type":"user","user_id":"UCRDHV7PB"},{"type":"text","text":" "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Implement an experimental sub-DSL that’s compatible with the BUGS modelling language, and add support for efficient generalised Gibbs sampling.  "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Improve documentation and tutorials. "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Initial GPU accelerated HMC and RWMH support. "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Initial Annealed Important Sampling support and other model assessment methods. "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Initial Nested Sampling support. "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Revisit all Github existing issues, improve stability of public APIs and plan for Turing 1.0 release. "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"any other issues raised by the Turing.jl and probabilistic programming community during the Turing.jl general public meeting and later feedbacks. "}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"\nWe aim to keep this progress as transparent as possible. We’ll also try to minimise disruption to existing Turing.jl users by maximising backward compatibility.\nWe anticipate it might still be a long way ahead before we can release Turing 1.0. Any help, comments feedbacks on improving the development and release of Turing are welcome! We also welcome community developers to join the Turing.jl team. Together, we aim to make Julia the go-to language for Bayesian inference and computation."}]}]}],"client_msg_id":"936126fd-fb92-4b66-a35b-b9e8ee041c28","edited":{"user":"UCRDHV7PB","ts":"1607986264.000000"},"reactions":[{"name":"heart","users":["UGD4K0Z25","U011PPW7K53","UTVH86LJ0","U7QLM6E2E","UF6T1632L","UC0SY9JFP","UH08DT0JU","U01A08JMUKT","U01BTNDCUBX","U011SGGQJCA","U018NKR9X70","UE98VNG4U","U680T6770","U6H9SJKCH"],"count":14},{"name":"juliaspinner","users":["U011PPW7K53","UGU761DU2","U018NKR9X70","U01A4SJJQDA","U680T6770","U6H9SJKCH"],"count":6},{"name":"turing","users":["U019X0KMT6Y","U01BTNDCUBX","U011PPW7K53","U018NKR9X70","U680T6770","U6H9SJKCH"],"count":6}]},{"client_msg_id":"332233e2-11f5-43ac-911c-0659cfd1b3fb","type":"message","text":"Hi, is there a way to stop sampling based on some criterion, like the callbacks in Tensorflow?","user":"U018NKR9X70","ts":"1608102775.084800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wpw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, is there a way to stop sampling based on some criterion, like the callbacks in Tensorflow?"}]}]}],"thread_ts":"1608102775.084800","reply_count":8,"reply_users_count":4,"latest_reply":"1608218495.111000","reply_users":["UH08DT0JU","UHDNY2YMA","U8T9JUA5R","U018NKR9X70"],"subscribed":false},{"client_msg_id":"78c2f7ac-491f-4979-b149-63c6c121531d","type":"message","text":"How come <https://turing.ml/dev/tutorials/10-bayesiandiffeq/> never got updated?","user":"U69BL50BF","ts":"1608118498.085900","team":"T68168MUP","attachments":[{"title":"Bayesian Estimation of Differential Equations","title_link":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/","text":"Bayesian Estimation of Differential Equations","fallback":"Bayesian Estimation of Differential Equations","from_url":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/","service_icon":"https://turing.ml/dev/assets/img/favicon.ico","service_name":"turing.ml","id":1,"original_url":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/"}],"blocks":[{"type":"rich_text","block_id":"mNDx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How come "},{"type":"link","url":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/"},{"type":"text","text":" never got updated?"}]}]}]},{"client_msg_id":"1847f756-f6ff-48c1-b271-2e6435c2e906","type":"message","text":"<@U9JNHB83X>","user":"U69BL50BF","ts":"1608118502.086200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Eyv","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U9JNHB83X"}]}]}],"thread_ts":"1608118502.086200","reply_count":1,"reply_users_count":1,"latest_reply":"1608126797.088400","reply_users":["U6QF223TN"],"subscribed":false},{"type":"message","text":"I was doing some (unrelated) dark-mode things today and thought you might enjoy this take of your graphic:","files":[{"id":"F01H1DGV70S","created":1608123938,"timestamp":1608123938,"name":"Screenshot 2020-12-16 at 13.04.19.png","title":"Screenshot 2020-12-16 at 13.04.19.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U69EQD0CD","editable":false,"size":252867,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01H1DGV70S/screenshot_2020-12-16_at_13.04.19.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01H1DGV70S/download/screenshot_2020-12-16_at_13.04.19.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01H1DGV70S-bb9c5e5386/screenshot_2020-12-16_at_13.04.19_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01H1DGV70S-bb9c5e5386/screenshot_2020-12-16_at_13.04.19_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01H1DGV70S-bb9c5e5386/screenshot_2020-12-16_at_13.04.19_360.png","thumb_360_w":331,"thumb_360_h":360,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01H1DGV70S-bb9c5e5386/screenshot_2020-12-16_at_13.04.19_480.png","thumb_480_w":441,"thumb_480_h":480,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01H1DGV70S-bb9c5e5386/screenshot_2020-12-16_at_13.04.19_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01H1DGV70S-bb9c5e5386/screenshot_2020-12-16_at_13.04.19_720.png","thumb_720_w":662,"thumb_720_h":720,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01H1DGV70S-bb9c5e5386/screenshot_2020-12-16_at_13.04.19_800.png","thumb_800_w":800,"thumb_800_h":871,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01H1DGV70S-bb9c5e5386/screenshot_2020-12-16_at_13.04.19_960.png","thumb_960_w":882,"thumb_960_h":960,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01H1DGV70S-bb9c5e5386/screenshot_2020-12-16_at_13.04.19_1024.png","thumb_1024_w":941,"thumb_1024_h":1024,"original_w":1042,"original_h":1134,"thumb_tiny":"AwAwACynkAY/pQo3HAyT7CkVQSSThR1NI0hI2r8q+g/r60ASeUc88fUimuhQ8gge9MSMvnGAB3JxQGeJiOnqD0oAWinEBl3qMY6r6f8A1qZQA6U4VV9tx/H/AOtUYBPQE1LIBlWboVGAO9CEn52+4vbsT6UMBJflCx+nJ+tD/PGr9x8p/pTd+77/AD79xT4xtzuI2NxntSsFhkTYkGeh4P0NKRgkHqDilwTJ5b8NniiQ5kYjuTVAOU7kxtDMvIz3FMaXdjKjA6CjkHIpxKPy4Kt/eXv+FIBm4f3BSb2znNP8sf8APVfyP+FAWNepLn06CmFx6SME3Ng44TjnP/1qipzMWOT/APqptID/2Q==","permalink":"https://julialang.slack.com/files/U69EQD0CD/F01H1DGV70S/screenshot_2020-12-16_at_13.04.19.png","permalink_public":"https://slack-files.com/T68168MUP-F01H1DGV70S-bd95de3bfc","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"5+3y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was doing some (unrelated) dark-mode things today and thought you might enjoy this take of your graphic:"}]}]}],"user":"U69EQD0CD","display_as_bot":false,"ts":"1608124133.087900","thread_ts":"1608124133.087900","reply_count":1,"reply_users_count":1,"latest_reply":"1608138856.088900","reply_users":["UN45LV5K6"],"subscribed":false,"reactions":[{"name":"juliaheartpulse-dark","users":["U85JBUGGP","U7QLM6E2E","UGU761DU2"],"count":3},{"name":"+1","users":["UC0SY9JFP","UH08DT0JU"],"count":2}]},{"type":"message","subtype":"thread_broadcast","text":"So very recently we actually introduced an iterator interface to Turing.jl. This means that you can now do stuff like: <https://gist.github.com/torfjelde/cc5c41e97eb4c97e22a19b8440f6d506>\n\nThis gives you waaay more control over the sampling process, if you want it:) This is a very recent change though, hence it's not yet in the documentation (soon!).","user":"UHDNY2YMA","ts":"1608164498.089400","thread_ts":"1608102775.084800","root":{"client_msg_id":"332233e2-11f5-43ac-911c-0659cfd1b3fb","type":"message","text":"Hi, is there a way to stop sampling based on some criterion, like the callbacks in Tensorflow?","user":"U018NKR9X70","ts":"1608102775.084800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wpw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, is there a way to stop sampling based on some criterion, like the callbacks in Tensorflow?"}]}]}],"thread_ts":"1608102775.084800","reply_count":8,"reply_users_count":4,"latest_reply":"1608218495.111000","reply_users":["UH08DT0JU","UHDNY2YMA","U8T9JUA5R","U018NKR9X70"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"mQ4I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So very recently we actually introduced an iterator interface to Turing.jl. This means that you can now do stuff like: "},{"type":"link","url":"https://gist.github.com/torfjelde/cc5c41e97eb4c97e22a19b8440f6d506"},{"type":"text","text":"\n\nThis gives you waaay more control over the sampling process, if you want it:) This is a very recent change though, hence it's not yet in the documentation (soon!)."}]}]}],"client_msg_id":"abf89027-90e2-4945-81c3-586c7c18f1c8","edited":{"user":"UHDNY2YMA","ts":"1608164533.000000"},"reactions":[{"name":"+1","users":["U018NKR9X70","U017YGFQTE3","UH08DT0JU","U7QLM6E2E"],"count":4},{"name":"100","users":["U018NKR9X70"],"count":1}]},{"client_msg_id":"7df3ff22-5b9b-4adb-89cd-a6754239e5d5","type":"message","text":"<@UCRDHV7PB> <@UHDNY2YMA> what does it take to get the Bayesian differential equations tutorial updated?","user":"U69BL50BF","ts":"1608199288.092000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=xG","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UCRDHV7PB"},{"type":"text","text":" "},{"type":"user","user_id":"UHDNY2YMA"},{"type":"text","text":" what does it take to get the Bayesian differential equations tutorial updated?"}]}]}]},{"client_msg_id":"05696569-026d-4432-bd5b-a48524179683","type":"message","text":"we've had <https://github.com/TuringLang/TuringTutorials/blob/master/10_diffeq.ipynb> sitting in the tutorials repo since September, and want to know what the process is to update the tutorial on the website","user":"U69BL50BF","ts":"1608199323.092600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hM3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"we've had "},{"type":"link","url":"https://github.com/TuringLang/TuringTutorials/blob/master/10_diffeq.ipynb"},{"type":"text","text":" sitting in the tutorials repo since September, and want to know what the process is to update the tutorial on the website"}]}]}],"thread_ts":"1608199323.092600","reply_count":1,"reply_users_count":1,"latest_reply":"1608200120.093400","reply_users":["U017YGFQTE3"],"subscribed":false},{"client_msg_id":"b95dceca-24eb-421d-b005-9d78c4579e7a","type":"message","text":"We'll be tweeting out everything around the Bayesian neural ODE paper today but hopefully this can get fixed up","user":"U69BL50BF","ts":"1608199785.093200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qGnSJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We'll be tweeting out everything around the Bayesian neural ODE paper today but hopefully this can get fixed up"}]}]}],"reactions":[{"name":"+1","users":["UC0SY9JFP"],"count":1}]},{"client_msg_id":"544f38e2-4fc0-4dd1-a7eb-b625f6e73d82","type":"message","text":"It is online: <https://turing.ml/dev/tutorials/10-diffeq/>","user":"U8T9JUA5R","ts":"1608200695.093800","team":"T68168MUP","attachments":[{"title":"Bayesian Estimation of Differential Equations","title_link":"https://turing.ml/dev/tutorials/10-diffeq/","text":"Bayesian Estimation of Differential Equations","fallback":"Bayesian Estimation of Differential Equations","from_url":"https://turing.ml/dev/tutorials/10-diffeq/","service_icon":"https://turing.ml/dev/assets/img/favicon.ico","service_name":"turing.ml","id":1,"original_url":"https://turing.ml/dev/tutorials/10-diffeq/"}],"blocks":[{"type":"rich_text","block_id":"lGks","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It is online: "},{"type":"link","url":"https://turing.ml/dev/tutorials/10-diffeq/"}]}]}]},{"client_msg_id":"94e1d86e-80f6-499f-95a9-ebafb1a9c219","type":"message","text":"As soon as Turing's documentation is updated (e.g., for a new release) the changes in TuringTutorials end up on the webpage automatically","user":"U8T9JUA5R","ts":"1608200732.094700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ufH60","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"As soon as Turing's documentation is updated (e.g., for a new release) the changes in TuringTutorials end up on the webpage automatically"}]}]}]},{"client_msg_id":"1378d287-9cd8-4fb6-a11e-3844f5dc45a4","type":"message","text":"It just seems the new tutorial was added but did not replace the old one","user":"U8T9JUA5R","ts":"1608200766.095200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VV9yT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It just seems the new tutorial was added but did not replace the old one"}]}]}]},{"client_msg_id":"ebd32ec3-37c6-4a9e-8ebc-e71b517d5c4e","type":"message","text":"In TuringTutorials","user":"U8T9JUA5R","ts":"1608200776.095400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Eq+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In TuringTutorials"}]}]}]},{"client_msg_id":"16ac8c4c-e0f3-4c4e-8551-f9df2a6e50cc","type":"message","text":"Hmm although seems correct in the repo. Maybe it's problematic that it was renamed","user":"U8T9JUA5R","ts":"1608200825.096500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sOLeS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hmm although seems correct in the repo. Maybe it's problematic that it was renamed"}]}]}],"thread_ts":"1608200825.096500","reply_count":16,"reply_users_count":2,"latest_reply":"1608243771.111800","reply_users":["U6QF223TN","U8T9JUA5R"],"subscribed":false},{"client_msg_id":"1d68c237-ef3a-4efe-b756-aa3853914cb6","type":"message","text":"It seems the current setup in Turing does not actually delete stuff that was removed: <https://github.com/TuringLang/Turing.jl/tree/gh-pages/dev/tutorials> Both versions are there","user":"U8T9JUA5R","ts":"1608200995.099300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZR/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It seems the current setup in Turing does not actually delete stuff that was removed: "},{"type":"link","url":"https://github.com/TuringLang/Turing.jl/tree/gh-pages/dev/tutorials"},{"type":"text","text":" Both versions are there"}]}]}],"reactions":[{"name":"man-facepalming","users":["UC0SY9JFP"],"count":1}]},{"client_msg_id":"599b1b23-e110-4ca8-84cb-b00137956c9d","type":"message","text":"So you can link to the tutorial but to fix the webpage one would have to remove all duplicates in the gh-pages branch manually (and I don't know if this would break any internal links) and remove the markdown files in TuringTutorials (to avoid the problem when the docs are rebuilt)","user":"U8T9JUA5R","ts":"1608201258.102900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gCrF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So you can link to the tutorial but to fix the webpage one would have to remove all duplicates in the gh-pages branch manually (and I don't know if this would break any internal links) and remove the markdown files in TuringTutorials (to avoid the problem when the docs are rebuilt)"}]}]}]},{"client_msg_id":"5965271b-c764-4805-bdb1-23ece2ab7d25","type":"message","text":"Maybe the new markdown-based setup of the tutorials that <@UHDNY2YMA> is working on would fix the problem for future iterations of the webpage automatically (<https://github.com/TuringLang/TuringTutorials/issues/86>)","user":"U8T9JUA5R","ts":"1608201487.106200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9Cs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe the new markdown-based setup of the tutorials that "},{"type":"user","user_id":"UHDNY2YMA"},{"type":"text","text":" is working on would fix the problem for future iterations of the webpage automatically ("},{"type":"link","url":"https://github.com/TuringLang/TuringTutorials/issues/86"},{"type":"text","text":")"}]}]}]},{"client_msg_id":"5d790a7d-f398-4560-abc4-74fb5df5624a","type":"message","text":"But maybe the better approach would be to rename everything to the old name 10-bayesiandiffeq such that links that might float around somewhere would still be valid?","user":"U8T9JUA5R","ts":"1608201836.108300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T54Vs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But maybe the better approach would be to rename everything to the old name 10-bayesiandiffeq such that links that might float around somewhere would still be valid?"}]}]}],"thread_ts":"1608201836.108300","reply_count":3,"reply_users_count":2,"latest_reply":"1608218691.111400","reply_users":["UHDNY2YMA","U8T9JUA5R"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"For reference: <https://github.com/TuringLang/TuringTutorials/pull/83#issuecomment-747361811|https://github.com/TuringLang/TuringTutorials/pull/83#issuecomment-747361811>","user":"U8T9JUA5R","ts":"1608202618.109600","thread_ts":"1608200825.096500","root":{"client_msg_id":"16ac8c4c-e0f3-4c4e-8551-f9df2a6e50cc","type":"message","text":"Hmm although seems correct in the repo. Maybe it's problematic that it was renamed","user":"U8T9JUA5R","ts":"1608200825.096500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sOLeS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hmm although seems correct in the repo. Maybe it's problematic that it was renamed"}]}]}],"thread_ts":"1608200825.096500","reply_count":16,"reply_users_count":2,"latest_reply":"1608243771.111800","reply_users":["U6QF223TN","U8T9JUA5R"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"cY42","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For reference: "},{"type":"link","url":"https://github.com/TuringLang/TuringTutorials/pull/83#issuecomment-747361811","text":"https://github.com/TuringLang/TuringTutorials/pull/83#issuecomment-747361811"}]}]}],"client_msg_id":"1b9b17c0-d838-45de-af11-302a1fa4e726","reactions":[{"name":"+1","users":["U6QF223TN"],"count":1}]},{"type":"message","subtype":"thread_broadcast","text":"The updated version is renamed now and available at <https://turing.ml/dev/tutorials/10-bayesiandiffeq/|https://turing.ml/dev/tutorials/10-bayesiandiffeq/> (same address as the old DE tutorial).","user":"U8T9JUA5R","ts":"1608243771.111800","thread_ts":"1608200825.096500","root":{"client_msg_id":"16ac8c4c-e0f3-4c4e-8551-f9df2a6e50cc","type":"message","text":"Hmm although seems correct in the repo. Maybe it's problematic that it was renamed","user":"U8T9JUA5R","ts":"1608200825.096500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sOLeS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hmm although seems correct in the repo. Maybe it's problematic that it was renamed"}]}]}],"thread_ts":"1608200825.096500","reply_count":16,"reply_users_count":2,"latest_reply":"1608243771.111800","reply_users":["U6QF223TN","U8T9JUA5R"],"subscribed":false},"attachments":[{"title":"Bayesian Estimation of Differential Equations","title_link":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/","text":"Bayesian Estimation of Differential Equations","fallback":"Bayesian Estimation of Differential Equations","from_url":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/","service_icon":"https://turing.ml/dev/assets/img/favicon.ico","service_name":"turing.ml","id":1,"original_url":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/"}],"blocks":[{"type":"rich_text","block_id":"tc8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The updated version is renamed now and available at "},{"type":"link","url":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/","text":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/"},{"type":"text","text":" (same address as the old DE tutorial)."}]}]}],"client_msg_id":"1a9c9ded-4664-402e-83d1-81d6d814fe81","reactions":[{"name":"+1","users":["UC0SY9JFP"],"count":1}]},{"client_msg_id":"4d03ad6c-811c-4efe-9c54-595447faf389","type":"message","text":"<@U8T9JUA5R> the image links are broken","user":"U69BL50BF","ts":"1608245348.112500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Xld5k","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U8T9JUA5R"},{"type":"text","text":" the image links are broken"}]}]}],"thread_ts":"1608245348.112500","reply_count":12,"reply_users_count":3,"latest_reply":"1608260318.115400","reply_users":["U8T9JUA5R","U69BL50BF","UHDNY2YMA"],"subscribed":false},{"client_msg_id":"4ae4dcc5-f024-48f4-bfdd-9342b468d73c","type":"message","text":"<@U8T9JUA5R> could you un-404 this while the paper is still going around? <https://github.com/TuringLang/TuringTutorials/blob/master/10_diffeq.ipynb>","user":"U69BL50BF","ts":"1608281279.116200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=QV","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U8T9JUA5R"},{"type":"text","text":" could you un-404 this while the paper is still going around? "},{"type":"link","url":"https://github.com/TuringLang/TuringTutorials/blob/master/10_diffeq.ipynb"}]}]}]},{"client_msg_id":"7b7b30c7-efbd-45a5-9365-26685ec399ba","type":"message","text":"I just got about 100 messages about that, so...","user":"U69BL50BF","ts":"1608281304.116600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"E7jht","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I just got about 100 messages about that, so..."}]}]}],"thread_ts":"1608281304.116600","reply_count":2,"reply_users_count":2,"latest_reply":"1608292726.119100","reply_users":["UCRDHV7PB","U69BL50BF"],"subscribed":false},{"client_msg_id":"f1508143-e474-4b54-81c5-9186f615ae20","type":"message","text":"To everyone, join us *today* at *3 pm* CET on gather town!\n\nLink: <https://gather.town/app/gzvyzGbOmGlfScYJ/turing>\nPasswd: turingisawesome","user":"UC0SY9JFP","ts":"1608290652.118600","team":"T68168MUP","attachments":[{"title":"Gather","title_link":"https://gather.town/app/gzvyzGbOmGlfScYJ/turing","text":"Gather is a video-calling space that lets multiple people hold separate conversations in parallel, walking in and out of those conversations just as easily as they would in real life.","fallback":"Gather","image_url":"https://gather.town/images/site/site_preview.png","from_url":"https://gather.town/app/gzvyzGbOmGlfScYJ/turing","image_width":418,"image_height":250,"image_bytes":168628,"service_icon":"https://gather.town/favicon.ico","service_name":"gather.town","id":1,"original_url":"https://gather.town/app/gzvyzGbOmGlfScYJ/turing"}],"blocks":[{"type":"rich_text","block_id":"/Hm7Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"To everyone, join us "},{"type":"text","text":"today","style":{"bold":true}},{"type":"text","text":" at "},{"type":"text","text":"3 pm","style":{"bold":true}},{"type":"text","text":" CET on gather town!\n\nLink: "},{"type":"link","url":"https://gather.town/app/gzvyzGbOmGlfScYJ/turing"},{"type":"text","text":"\nPasswd: turingisawesome"}]}]}]},{"client_msg_id":"7e2cbc64-cbc8-4819-b71d-9cc7a31a9883","type":"message","text":"If my Turing model has a positive variable `τ`, then `log(τ)` is what's actually being sampled. Is there a way given a `Chains` object and a `Model` to get all of the transformed samples (i.e. `log(τ)`)?","user":"UHDQQ4GN6","ts":"1608317946.121400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Zt6em","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If my Turing model has a positive variable "},{"type":"text","text":"τ","style":{"code":true}},{"type":"text","text":", then "},{"type":"text","text":"log(τ)","style":{"code":true}},{"type":"text","text":" is what's actually being sampled. Is there a way given a "},{"type":"text","text":"Chains","style":{"code":true}},{"type":"text","text":" object and a "},{"type":"text","text":"Model","style":{"code":true}},{"type":"text","text":" to get all of the transformed samples (i.e. "},{"type":"text","text":"log(τ)","style":{"code":true}},{"type":"text","text":")?"}]}]}],"thread_ts":"1608317946.121400","reply_count":7,"reply_users_count":2,"latest_reply":"1608326456.122800","reply_users":["U9JNHB83X","UHDQQ4GN6"],"subscribed":false},{"client_msg_id":"dee24eb2-4cde-40cf-a807-e4e3a74f68e3","type":"message","text":"Somehow when I run the Turing sampler with `progress = true`  in VSCode, there's no progress bar any more. Does anyone encounter the same issue?","user":"UMRTL1HKP","ts":"1608332106.123900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"akIq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Somehow when I run the Turing sampler with "},{"type":"text","text":"progress = true","style":{"code":true}},{"type":"text","text":"  in VSCode, there's no progress bar any more. Does anyone encounter the same issue?"}]}]}],"thread_ts":"1608332106.123900","reply_count":21,"reply_users_count":4,"latest_reply":"1608541096.159100","reply_users":["UN97XTLCV","UMRTL1HKP","U8T9JUA5R","U01C2AJ9F63"],"subscribed":false},{"type":"message","text":"Hi folks, possibly non-Turing question here. I'm a newbie to Bayesian modeling and am working on learning the rudiments using a dataset of dogs in New York City.\n\nI want to model the joint distribution of name and breed, and my raw data is (name, breed, count).\n\nSo far I've gotten as far as \"learning\" a Dirichlet posterior over dog breeds using a uniform Dirichlet prior and a multinomial likelihood (the observed counts).\n\nI've been using a funny strategy of learning from e.g. all of the dogs NOT named Pugsley, then additionally learning from the Pugsleys and ranking breeds by the relative entropy between the prior and posterior, which surfaces those breeds for which learning that a name is Pugsley is most informative.\n\nThis feels like a bit of a hack, and what I'd really like is a model where I can ask about `p(name|pug)` and `p(breed|pugsley)`, which sounds like it would involve learning something about the joint distribution rather than going one variable at a time.\n\nNot sure this is the best place to ask, but any suggestions or pointers to resources would be appreciated!\n\nFor fun, here are the breeds that are most likely when the dog name includes \"snow\":","files":[{"id":"F01HNLL81L1","created":1608352084,"timestamp":1608352084,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U68M6ERG8","editable":false,"size":203186,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HNLL81L1/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HNLL81L1/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HNLL81L1-f22cbda5d0/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HNLL81L1-f22cbda5d0/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HNLL81L1-f22cbda5d0/image_360.png","thumb_360_w":360,"thumb_360_h":221,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HNLL81L1-f22cbda5d0/image_480.png","thumb_480_w":480,"thumb_480_h":295,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HNLL81L1-f22cbda5d0/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01HNLL81L1-f22cbda5d0/image_720.png","thumb_720_w":720,"thumb_720_h":443,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01HNLL81L1-f22cbda5d0/image_800.png","thumb_800_w":800,"thumb_800_h":492,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01HNLL81L1-f22cbda5d0/image_960.png","thumb_960_w":960,"thumb_960_h":590,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01HNLL81L1-f22cbda5d0/image_1024.png","thumb_1024_w":1024,"thumb_1024_h":630,"original_w":2234,"original_h":1374,"thumb_tiny":"AwAdADDSIzRt96WigBuPel/GkJ9cYpW6dPzoAX8aKB0ooAKD0ooPSgBvelbpRjmg5NACjpRQOlFAH//Z","permalink":"https://julialang.slack.com/files/U68M6ERG8/F01HNLL81L1/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HNLL81L1-1307c53b4b","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"4AH8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi folks, possibly non-Turing question here. I'm a newbie to Bayesian modeling and am working on learning the rudiments using a dataset of dogs in New York City.\n\nI want to model the joint distribution of name and breed, and my raw data is (name, breed, count).\n\nSo far I've gotten as far as \"learning\" a Dirichlet posterior over dog breeds using a uniform Dirichlet prior and a multinomial likelihood (the observed counts).\n\nI've been using a funny strategy of learning from e.g. all of the dogs NOT named Pugsley, then additionally learning from the Pugsleys and ranking breeds by the relative entropy between the prior and posterior, which surfaces those breeds for which learning that a name is Pugsley is most informative.\n\nThis feels like a bit of a hack, and what I'd really like is a model where I can ask about "},{"type":"text","text":"p(name|pug)","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"p(breed|pugsley)","style":{"code":true}},{"type":"text","text":", which sounds like it would involve learning something about the joint distribution rather than going one variable at a time.\n\nNot sure this is the best place to ask, but any suggestions or pointers to resources would be appreciated!\n\nFor fun, here are the breeds that are most likely when the dog name includes \"snow\":"}]}]}],"user":"U68M6ERG8","display_as_bot":false,"ts":"1608352096.137600","thread_ts":"1608352096.137600","reply_count":4,"reply_users_count":2,"latest_reply":"1608389923.147900","reply_users":["U01C2AJ9F63","U68M6ERG8"],"subscribed":false},{"client_msg_id":"3ee970dd-e17f-4985-afe0-ba0c72aa15eb","type":"message","text":"So we talked yesterday during the meeting about how my relatively simple model takes quite some time to run already (40+ minutes), and that I should post a snippet here to see if maybe there is a problem in the code, because I thought it might be normal given the 1800 samples and the model. There is quite a lot of missing data as well, but even when I just reran it with complete cases only, I still got above 40 minutes somehow anyway. I'll post a code snippet in the thread/comments.","user":"U01C2AJ9F63","ts":"1608379428.141500","team":"T68168MUP","edited":{"user":"U01C2AJ9F63","ts":"1608379706.000000"},"blocks":[{"type":"rich_text","block_id":"yLl0f","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So we talked yesterday during the meeting about how my relatively simple model takes quite some time to run already (40+ minutes), and that I should post a snippet here to see if maybe there is a problem in the code, because I thought it might be normal given the 1800 samples and the model. There is quite a lot of missing data as well, but even when I just reran it with complete cases only, I still got above 40 minutes somehow anyway. I'll post a code snippet in the thread/comments."}]}]}],"thread_ts":"1608379428.141500","reply_count":29,"reply_users_count":5,"latest_reply":"1608649623.167500","reply_users":["U01C2AJ9F63","U017YGFQTE3","UH08DT0JU","UC0SY9JFP","U85JBUGGP"],"subscribed":false},{"client_msg_id":"f4131c24-621c-4d43-bd00-e2f75be9b20a","type":"message","text":"Hi, if I have a model like (from tutorial)\n\n@model function coinFlip(Y)\n\tp ~ Beta(1, 1)\n\tfor n in 1:length(Y)\n\t\tY[n] ~ Bernoulli(p)\n\tend\nend\n\nand want to compute the posterior likelihood given p=0.5 with coinFlip([true, true, true, false]). Is there a way to do this within Turing?\n\nThank you!","user":"UCM61ND7F","ts":"1608466243.153300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MZOyY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, if I have a model like (from tutorial)\n\n@model function coinFlip(Y)\n\tp ~ Beta(1, 1)\n\tfor n in 1:length(Y)\n\t\tY[n] ~ Bernoulli(p)\n\tend\nend\n\nand want to compute the posterior likelihood given p=0.5 with coinFlip([true, true, true, false]). Is there a way to do this within Turing?\n\nThank you!"}]}]}],"thread_ts":"1608466243.153300","reply_count":6,"reply_users_count":3,"latest_reply":"1608475134.158300","reply_users":["UH08DT0JU","UC0SY9JFP","UCM61ND7F"],"subscribed":false},{"client_msg_id":"0f45f689-10e3-4971-bee5-cadd0593d85e","type":"message","text":"Hello Turing friends! The <https://turing.ml/dev/tutorials/10-bayesiandiffeq/#inference-of-a-stochastic-differential-equation|Bayesian DiffEq tutorial> mentions SGHMC as a possibly better alternative to NUTS for SDE inference. Is this currently implemented? I don't see it in the docs. I implemented SGHMC in python/Tensorflow Probability a few months ago, so I would happy to help contribute to an implementation.","user":"U01H36BUDJB","ts":"1608733275.169800","team":"T68168MUP","attachments":[{"title":"Bayesian Estimation of Differential Equations","title_link":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/#inference-of-a-stochastic-differential-equation","text":"Bayesian Estimation of Differential Equations","fallback":"Bayesian Estimation of Differential Equations","from_url":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/#inference-of-a-stochastic-differential-equation","service_icon":"https://turing.ml/dev/assets/img/favicon.ico","service_name":"turing.ml","id":1,"original_url":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/#inference-of-a-stochastic-differential-equation"}],"blocks":[{"type":"rich_text","block_id":"xeVKj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello Turing friends! The "},{"type":"link","url":"https://turing.ml/dev/tutorials/10-bayesiandiffeq/#inference-of-a-stochastic-differential-equation","text":"Bayesian DiffEq tutorial"},{"type":"text","text":" mentions SGHMC as a possibly better alternative to NUTS for SDE inference. Is this currently implemented? I don't see it in the docs. I implemented SGHMC in python/Tensorflow Probability a few months ago, so I would happy to help contribute to an implementation."}]}]}],"thread_ts":"1608733275.169800","reply_count":10,"reply_users_count":3,"latest_reply":"1608734644.172800","reply_users":["U8T9JUA5R","U01H36BUDJB","U6C937ENB"],"subscribed":false},{"client_msg_id":"d9cc74f8-f1d7-4cdb-9ce2-55fbaabede23","type":"message","text":"Hello everyone\nI was trying to write a custom gradient in `reversediff` for lambertw function from <https://github.com/jlapeyre/LambertW.jl|this package>. Here is my code\n```using ReverseDiff, LambertW\n\nlambert_ext(x::Float64) = lambertw(x)\nlambert_ext(x::Array{Float64, 1}) = lambertw.(x)\n\nlambert_ext(x::ReverseDiff.TrackedVector) = ReverseDiff.track(lambert_ext, x)\n\nReverseDiff.@grad function lambert_ext(x)\n    xv = ReverseDiff.value(x)\n    return lambert_ext(xv), function (Δ)\n        w = lambert_ext(xv)\n        return (Δ.*((xv.*w)./(w.+1)), )\n    end\nend\n\ninputs = [1.0]\nw = lambert_ext(inputs)\nprintln(\"actual derivative: $((inputs.*w)./(w.+1))\")\nprintln(\"derivative reversediff: $(ReverseDiff.gradient(lambert_ext, inputs))\")\n\ninputs = [1.0, 2.0]\nw = lambert_ext(inputs)\nprintln(\"actual derivative: $((inputs.*w)./(w.+1))\")\nprintln(\"derivative reversediff: $(ReverseDiff.gradient(lambert_ext, inputs))\")```\nThe method works fine with array of shape (1,). But it","user":"UR43MA5DY","ts":"1608748159.177000","team":"T68168MUP","edited":{"user":"UR43MA5DY","ts":"1608748217.000000"},"blocks":[{"type":"rich_text","block_id":"EvKZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello everyone\nI was trying to write a custom gradient in `reversediff` for lambertw function from "},{"type":"link","url":"https://github.com/jlapeyre/LambertW.jl","text":"this package"},{"type":"text","text":". Here is my code\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using ReverseDiff, LambertW\n\nlambert_ext(x::Float64) = lambertw(x)\nlambert_ext(x::Array{Float64, 1}) = lambertw.(x)\n\nlambert_ext(x::ReverseDiff.TrackedVector) = ReverseDiff.track(lambert_ext, x)\n\nReverseDiff.@grad function lambert_ext(x)\n    xv = ReverseDiff.value(x)\n    return lambert_ext(xv), function (Δ)\n        w = lambert_ext(xv)\n        return (Δ.*((xv.*w)./(w.+1)), )\n    end\nend\n\ninputs = [1.0]\nw = lambert_ext(inputs)\nprintln(\"actual derivative: $((inputs.*w)./(w.+1))\")\nprintln(\"derivative reversediff: $(ReverseDiff.gradient(lambert_ext, inputs))\")\n\ninputs = [1.0, 2.0]\nw = lambert_ext(inputs)\nprintln(\"actual derivative: $((inputs.*w)./(w.+1))\")\nprintln(\"derivative reversediff: $(ReverseDiff.gradient(lambert_ext, inputs))\")"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"The method works fine with array of shape (1,). But it"}]}]}]},{"client_msg_id":"a7d168fc-37c6-4cfc-9154-9ab1ebe64a60","type":"message","text":"Puzzling question here <https://discourse.julialang.org/t/why-does-shuffling-rows-change-the-estimates/52305/1>","user":"U01ARRMLM7E","ts":"1608780880.178700","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Why does shuffling rows change the estimates?","title_link":"https://discourse.julialang.org/t/why-does-shuffling-rows-change-the-estimates/52305/1","text":"using DataFrames using Pipe: @pipe using StatsBase: StatsBase, mad, median, percentile, sample, shuffle using Distributions using CategoricalArrays using Turing ## df, parameters = let β = ( β_0 = 7, β_1 = 0.001, β_2 = 0.05, β_3 = 0.05, β_4 = 0.01, ) σ = 2 parameters = (β..., σ=σ) parameters_df = DataFrame( parameter=collect(keys(parameters)), value=collect(values(parameters)), ) N = 100_000 X = DataF...","fallback":"JuliaLang: Why does shuffling rows change the estimates?","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1608765251,"from_url":"https://discourse.julialang.org/t/why-does-shuffling-rows-change-the-estimates/52305/1","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/why-does-shuffling-rows-change-the-estimates/52305/1"}],"blocks":[{"type":"rich_text","block_id":"a/8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Puzzling question here "},{"type":"link","url":"https://discourse.julialang.org/t/why-does-shuffling-rows-change-the-estimates/52305/1"}]}]}]},{"client_msg_id":"24d42679-410c-4fdb-a559-25dfdff94129","type":"message","text":"Hi all-\n\nI have noticed that Turing takes about twice as long to load and precompile than Plots.jl. I was wondering whether there are any optimizations that could be used to speed this up?","user":"UH08DT0JU","ts":"1608816492.181200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aOHe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all-\n\nI have noticed that Turing takes about twice as long to load and precompile than Plots.jl. I was wondering whether there are any optimizations that could be used to speed this up?"}]}]}]},{"type":"message","text":"Hi, I'm playing with Turing and I want to create a model for ridge regression solution via HMC. My resource is in the picture. I can't find a way to do this and compose `@model`. I posted my question here: <https://discourse.julialang.org/t/ridge-regression-using-turing-jl/52378>\n\nIs there anyone who could help me? Is it even possible to use HMC for this kind of problem? Thanks in advance for any suggestions :slightly_smiling_face:","files":[{"id":"F01HMDS6JHH","created":1608917268,"timestamp":1608917268,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UR51BK15E","editable":false,"size":41601,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01HMDS6JHH/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01HMDS6JHH/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01HMDS6JHH-45ce8df9b2/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01HMDS6JHH-45ce8df9b2/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01HMDS6JHH-45ce8df9b2/image_360.png","thumb_360_w":360,"thumb_360_h":236,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01HMDS6JHH-45ce8df9b2/image_480.png","thumb_480_w":480,"thumb_480_h":314,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01HMDS6JHH-45ce8df9b2/image_160.png","original_w":561,"original_h":367,"thumb_tiny":"AwAfADDSIPqfwpM4HOaUn3x+FA57/pQAm7/OaUMD7UY96MH1/SgBaKTBz1pRQAhJzwP1o69ePxpTntSHJ7CgAx7n86Me5/OgD1UUuB6UAAooAx0ooA//2Q==","permalink":"https://julialang.slack.com/files/UR51BK15E/F01HMDS6JHH/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01HMDS6JHH-eccf6b9442","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"R7Bb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I'm playing with Turing and I want to create a model for ridge regression solution via HMC. My resource is in the picture. I can't find a way to do this and compose "},{"type":"text","text":"@model","style":{"code":true}},{"type":"text","text":". I posted my question here: "},{"type":"link","url":"https://discourse.julialang.org/t/ridge-regression-using-turing-jl/52378"},{"type":"text","text":"\n\nIs there anyone who could help me? Is it even possible to use HMC for this kind of problem? Thanks in advance for any suggestions "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"user":"UR51BK15E","display_as_bot":false,"ts":"1608917433.198700"},{"client_msg_id":"c0b375d6-be00-4d6e-bb77-c07d94393e4b","type":"message","text":"Is it possible to get a list of the parameters of a model object?","user":"U01ARRMLM7E","ts":"1609099471.206500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Va9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it possible to get a list of the parameters of a model object?"}]}]}],"thread_ts":"1609099471.206500","reply_count":1,"reply_users_count":1,"latest_reply":"1609099921.206600","reply_users":["U01ARRMLM7E"],"subscribed":false},{"client_msg_id":"963f39b5-342e-4945-b1bb-68f86093aa8e","type":"message","text":"Hi all. Quick question. How can I quickly test out whether I've made a mistake in my model definition? Currently, I'm using the NUTS sampler with as few as 4 samples, but it takes ages (infinite maybe) since it keeps rejecting proposals.","user":"U01BTNDCUBX","ts":"1609242820.210900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MRP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all. Quick question. How can I quickly test out whether I've made a mistake in my model definition? Currently, I'm using the NUTS sampler with as few as 4 samples, but it takes ages (infinite maybe) since it keeps rejecting proposals."}]}]}],"thread_ts":"1609242820.210900","reply_count":3,"reply_users_count":2,"latest_reply":"1609243877.211600","reply_users":["U01BTNDCUBX","U8T9JUA5R"],"subscribed":false},{"client_msg_id":"37973ed3-3138-4331-9b1e-b343ea154287","type":"message","text":"Hey folks. I was hoping someone could point me in the right direction with this error message. I am setting up a very simple vanilla discrete dynamical simulation (to proof of concept). So I define a simple growth model, generate some data, and then wrote a Turing model to see if I can recover the parameters used to generate the simulated data. The code is below. But I am getting an error when I run the `chain` function to execute the sample. The error is `TypeError: in typeassert, expected Float64, got a value of type ForwardDiff.Dual{Nothing,Float64,2}`. I am not really sure how to debug these types of issues in Turing, so if anyone could tell me where to look, I would appreciate it. Here is the simple code that I wrote. I use the Turing Diffeq tutorial as a model, but removed the Diffeq solver with my own solver. I can add more to the stacktrace if it is helpful.\n```\n# Create a simple discrete simulation\nfunction simple_growth!(du, u0, p)\n    r = p[1]\n    du[1] = r*u0[1]\n    du\nend\n\n# solve the dynamical system\nfunction solve_system(f,u0,p,n)\n    u = Vector{typeof(u0)}(undef,n)\n    du = similar(u0)\n    u[1] = u0\n    for i in 1:n-1\n        f(du,u[i],p)\n        u[i+1] = copy(du)\n    end\n    u\nend\n\n# simulate some data\ndata = solve_system(simple_growth!, [0.9], [2.0], 10)\ndata = [data[i][1] for i in 1:length(data)]\n\n# define the Turing model\nTuring.setadbackend(:forwarddiff)\n\n@model function fitlv(data, f, u0, n)\n    σ ~ InverseGamma(2, 3) # ~ is the tilde character\n    α ~ truncated(Normal(0.7,0.5),0.5,2.5)\n\n    p = [α]\n    #prob = remake(prob1, p=p)\n    predicted = solve_system(f, u0, p, n)\n\tpredicted = [predicted[i][1] for i in 1:length(predicted)]\n    for i = 1:length(predicted)\n        data[i] ~ Normal(predicted[i], σ)\n    end\nend\n\n# setup the Turing sampler\nu0 = [0.9]\nn = 10\nmodel = fitlv(data, simple_growth!, u0, n)\nchain = mapreduce(c -&gt; sample(model, NUTS(.65),1000), chainscat, 1:3)```\nHere is just the first part of the stacktrace for the error.\n\n```chain\n\nTypeError: in typeassert, expected Float64, got a value of type ForwardDiff.Dual{Nothing,Float64,2}\n\n    setindex!(::Array{Float64,1}, ::ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2}, ::Int64)@array.jl:847\n    simple_growth!(::Array{Float64,1}, ::Array{Float64,1}, ::Array{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2},1})@Other: 3\n    solve_system(::typeof(Main.workspace115.simple_growth!), ::Array{Float64,1}, ::Array{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2},1}, ::Int64)@Other: 6\n    #1@Other: 10[inlined]\n    (::Main.workspace150.var\"#1#3\")(::Random._GLOBAL_RNG, ::DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}}, ::DynamicPPL.ThreadSafeVarInfo{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2},1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2},1},Array{Set{DynamicPPL.Selector},1}}}},ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2}},Array{Base.RefValue{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2}},1}}, ::DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}}, ::DynamicPPL.DefaultContext, ::Array{Float64,1}, ::Function, ::Array{Float64,1}, ::Int64)@none:0```","user":"UDDSTBX19","ts":"1609447055.218000","team":"T68168MUP","edited":{"user":"UDDSTBX19","ts":"1609447459.000000"},"blocks":[{"type":"rich_text","block_id":"ZZ9K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey folks. I was hoping someone could point me in the right direction with this error message. I am setting up a very simple vanilla discrete dynamical simulation (to proof of concept). So I define a simple growth model, generate some data, and then wrote a Turing model to see if I can recover the parameters used to generate the simulated data. The code is below. But I am getting an error when I run the `chain` function to execute the sample. The error is "},{"type":"text","text":"TypeError: in typeassert, expected Float64, got a value of type ForwardDiff.Dual{Nothing,Float64,2}","style":{"code":true}},{"type":"text","text":". I am not really sure how to debug these types of issues in Turing, so if anyone could tell me where to look, I would appreciate it. Here is the simple code that I wrote. I use the Turing Diffeq tutorial as a model, but removed the Diffeq solver with my own solver. I can add more to the stacktrace if it is helpful.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"\n# Create a simple discrete simulation\nfunction simple_growth!(du, u0, p)\n    r = p[1]\n    du[1] = r*u0[1]\n    du\nend\n\n# solve the dynamical system\nfunction solve_system(f,u0,p,n)\n    u = Vector{typeof(u0)}(undef,n)\n    du = similar(u0)\n    u[1] = u0\n    for i in 1:n-1\n        f(du,u[i],p)\n        u[i+1] = copy(du)\n    end\n    u\nend\n\n# simulate some data\ndata = solve_system(simple_growth!, [0.9], [2.0], 10)\ndata = [data[i][1] for i in 1:length(data)]\n\n# define the Turing model\nTuring.setadbackend(:forwarddiff)\n\n@model function fitlv(data, f, u0, n)\n    σ ~ InverseGamma(2, 3) # ~ is the tilde character\n    α ~ truncated(Normal(0.7,0.5),0.5,2.5)\n\n    p = [α]\n    #prob = remake(prob1, p=p)\n    predicted = solve_system(f, u0, p, n)\n\tpredicted = [predicted[i][1] for i in 1:length(predicted)]\n    for i = 1:length(predicted)\n        data[i] ~ Normal(predicted[i], σ)\n    end\nend\n\n# setup the Turing sampler\nu0 = [0.9]\nn = 10\nmodel = fitlv(data, simple_growth!, u0, n)\nchain = mapreduce(c -> sample(model, NUTS(.65),1000), chainscat, 1:3)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Here is just the first part of the stacktrace for the error.\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"chain\n\nTypeError: in typeassert, expected Float64, got a value of type ForwardDiff.Dual{Nothing,Float64,2}\n\n    setindex!(::Array{Float64,1}, ::ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2}, ::Int64)@array.jl:847\n    simple_growth!(::Array{Float64,1}, ::Array{Float64,1}, ::Array{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2},1})@Other: 3\n    solve_system(::typeof(Main.workspace115.simple_growth!), ::Array{Float64,1}, ::Array{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2},1}, ::Int64)@Other: 6\n    #1@Other: 10[inlined]\n    (::Main.workspace150.var\"#1#3\")(::Random._GLOBAL_RNG, ::DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}}, ::DynamicPPL.ThreadSafeVarInfo{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2},1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2},1},Array{Set{DynamicPPL.Selector},1}}}},ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2}},Array{Base.RefValue{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.VarInfo{NamedTuple{(:σ, :α),Tuple{DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:σ,Tuple{}},Int64},Array{Distributions.InverseGamma{Float64},1},Array{DynamicPPL.VarName{:σ,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}},DynamicPPL.Metadata{Dict{DynamicPPL.VarName{:α,Tuple{}},Int64},Array{Distributions.Truncated{Distributions.Normal{Float64},Distributions.Continuous,Float64},1},Array{DynamicPPL.VarName{:α,Tuple{}},1},Array{Float64,1},Array{Set{DynamicPPL.Selector},1}}}},Float64},DynamicPPL.Model{Main.workspace150.var\"#1#3\",(:data, :f, :u0, :n),(),(),Tuple{Array{Float64,1},typeof(Main.workspace115.simple_growth!),Array{Float64,1},Int64},Tuple{}},DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}},DynamicPPL.DefaultContext},Float64},Float64,2}},1}}, ::DynamicPPL.Sampler{Turing.Inference.NUTS{Turing.Core.ForwardDiffAD{40},(),AdvancedHMC.DiagEuclideanMetric}}, ::DynamicPPL.DefaultContext, ::Array{Float64,1}, ::Function, ::Array{Float64,1}, ::Int64)@none:0"}]}]}],"thread_ts":"1609447055.218000","reply_count":10,"reply_users_count":2,"latest_reply":"1609448470.220100","reply_users":["U69BL50BF","UDDSTBX19"],"subscribed":false},{"client_msg_id":"50d55569-e8ca-428a-bc5d-65d21d4fc23c","type":"message","text":"I can correctly estimate the parameters with NUTS, but ADVI gives very wrong answers. How can I fix it?\n```\nimport Random\nusing DataFrames\n\nusing StatsBase: StatsBase, mad, median, percentile, sample, shuffle\nusing Distributions\nusing Turing\nusing Chain\n\nRandom.seed!(1)\n##\n\n\n\ndf, parameters = let\n    β = (\n        β_0 = 7,\n        β_1 = 0.05,\n        β_2 = 0.10,\n        β_3 = 0.15,\n        β_4 = 0.20,\n    )\n    σ = 2\n    parameters = (β..., σ=σ)\n    parameters_df = DataFrame(\n        parameter=collect(keys(parameters)),\n        value=collect(values(parameters)),\n    )\n\n    N = 100_000\n    X = DataFrame(\n        x_0=fill(1, N),\n        x_1=rand([1,2], N),\n        x_2=rand(1:1:10, N),\n        x_3=rand([0,1], N),\n        x_4=rand(0:1:10, N),\n    )\n    df = transform(X)\n    μ = Matrix(df) * collect(β)\n    ϵ = rand(Normal(0, σ), N)\n    y = μ .+ ϵ\n\n    (df = transform(\n        X,\n        [] =&gt; (() -&gt; μ) =&gt; :μ,\n        [] =&gt; (() -&gt; ϵ) =&gt; :ϵ,\n        [] =&gt; (() -&gt; y) =&gt; :y,\n        ),\n     parameters = parameters_df,    )\nend\n\n##\n@model function linear_outcome_model(X, y)\n    β_0 ~ Normal(mean(y), 2std(y))\n    β_1 ~ Normal(0, .5)\n    β_2 ~ Normal(0, .5)\n    β_3 ~ Normal(0, .5)\n    β_4 ~ Normal(0, .5)\n\n    μ = (\n            β_0 .* X.x_0\n            .+ β_1 .* X.x_1\n            .+ β_2 .* X.x_2\n            .+ β_3 .* X.x_3\n            .+ β_4 .* X.x_4\n\n    )\n    σ ~ truncated(Normal(0, 2std(y)), 0, Inf)\n    y ~ MvNormal(μ, σ)\nend\n\n\nfields = [    :x_0,    :x_1,    :x_2,    :x_3,    :x_4,]\n\n\nmodel = @chain df begin\n    linear_outcome_model(_[:, fields], _.y) \nend\n\n\nsamples_nuts =  sample(model, NUTS(0.65), 3000)\n\nsamples_vi = let\n    estimate_vi = vi(model, ADVI())\n    samplesarray_vi = rand(estimate_vi, 1000)\n    _, sym2range = bijector(model, Val(true))\n    parameters = keys(sym2range)\n\n    rearranged = DataFrame(Dict(\n        param =&gt; vec(samplesarray_vi[sym2range[param]..., :])\n        for param in parameters\n    ))\n    insertcols!(rearranged, 1, :index =&gt; 1:1:nrow(rearranged))\n    DataFrames.stack(rearranged, Not(:index), variable_name=:parameter)\nend\n\n\nsummary_nuts = @chain samples_nuts begin\n    DataFrame(summarize(_, mean, std)) \n    rename(_, :parameters =&gt; :parameter) \n    transform(:parameter =&gt; ByRow(Symbol) =&gt; :parameter)\n    innerjoin(_, parameters, on=:parameter)\nend\n\n\nsummary_vi = @chain samples_vi begin\n    groupby(:parameter)\n    combine(:value =&gt; mean =&gt; :mean, :value =&gt; std =&gt; :std)\n    transform(:parameter =&gt; ByRow(Symbol) =&gt; :parameter)\n    innerjoin(parameters, on=:parameter)\nend```","user":"U01ARRMLM7E","ts":"1609457022.221800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WEsN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can correctly estimate the parameters with NUTS, but ADVI gives very wrong answers. How can I fix it?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"\nimport Random\nusing DataFrames\n\nusing StatsBase: StatsBase, mad, median, percentile, sample, shuffle\nusing Distributions\nusing Turing\nusing Chain\n\nRandom.seed!(1)\n##\n\n\n\ndf, parameters = let\n    β = (\n        β_0 = 7,\n        β_1 = 0.05,\n        β_2 = 0.10,\n        β_3 = 0.15,\n        β_4 = 0.20,\n    )\n    σ = 2\n    parameters = (β..., σ=σ)\n    parameters_df = DataFrame(\n        parameter=collect(keys(parameters)),\n        value=collect(values(parameters)),\n    )\n\n    N = 100_000\n    X = DataFrame(\n        x_0=fill(1, N),\n        x_1=rand([1,2], N),\n        x_2=rand(1:1:10, N),\n        x_3=rand([0,1], N),\n        x_4=rand(0:1:10, N),\n    )\n    df = transform(X)\n    μ = Matrix(df) * collect(β)\n    ϵ = rand(Normal(0, σ), N)\n    y = μ .+ ϵ\n\n    (df = transform(\n        X,\n        [] => (() -> μ) => :μ,\n        [] => (() -> ϵ) => :ϵ,\n        [] => (() -> y) => :y,\n        ),\n     parameters = parameters_df,    )\nend\n\n##\n@model function linear_outcome_model(X, y)\n    β_0 ~ Normal(mean(y), 2std(y))\n    β_1 ~ Normal(0, .5)\n    β_2 ~ Normal(0, .5)\n    β_3 ~ Normal(0, .5)\n    β_4 ~ Normal(0, .5)\n\n    μ = (\n            β_0 .* X.x_0\n            .+ β_1 .* X.x_1\n            .+ β_2 .* X.x_2\n            .+ β_3 .* X.x_3\n            .+ β_4 .* X.x_4\n\n    )\n    σ ~ truncated(Normal(0, 2std(y)), 0, Inf)\n    y ~ MvNormal(μ, σ)\nend\n\n\nfields = [    :x_0,    :x_1,    :x_2,    :x_3,    :x_4,]\n\n\nmodel = @chain df begin\n    linear_outcome_model(_[:, fields], _.y) \nend\n\n\nsamples_nuts =  sample(model, NUTS(0.65), 3000)\n\nsamples_vi = let\n    estimate_vi = vi(model, ADVI())\n    samplesarray_vi = rand(estimate_vi, 1000)\n    _, sym2range = bijector(model, Val(true))\n    parameters = keys(sym2range)\n\n    rearranged = DataFrame(Dict(\n        param => vec(samplesarray_vi[sym2range[param]..., :])\n        for param in parameters\n    ))\n    insertcols!(rearranged, 1, :index => 1:1:nrow(rearranged))\n    DataFrames.stack(rearranged, Not(:index), variable_name=:parameter)\nend\n\n\nsummary_nuts = @chain samples_nuts begin\n    DataFrame(summarize(_, mean, std)) \n    rename(_, :parameters => :parameter) \n    transform(:parameter => ByRow(Symbol) => :parameter)\n    innerjoin(_, parameters, on=:parameter)\nend\n\n\nsummary_vi = @chain samples_vi begin\n    groupby(:parameter)\n    combine(:value => mean => :mean, :value => std => :std)\n    transform(:parameter => ByRow(Symbol) => :parameter)\n    innerjoin(parameters, on=:parameter)\nend"}]}]}],"thread_ts":"1609457022.221800","reply_count":1,"reply_users_count":1,"latest_reply":"1609457035.221900","reply_users":["U01ARRMLM7E"],"subscribed":false},{"client_msg_id":"d94de493-fe5c-4ede-8bb0-415f80ec8012","type":"message","text":"Hi! I was messing around with Bijectors.jl and was really interested in the normalizing flows section and was wondering how to fit these flows. Below is some code that I am trying to use as an example. I keep running into a mutating arrays issue like `ERROR: LoadError: Mutating arrays is not supported`\n\nAny help would be appreciated!\n```@model function gen()\n    x ~ Exponential(0.5)\n    y ~ Normal(0, x)\nend\n\ns = sample(gen(), NUTS(), 500)\ntrain_data = hcat(s[:x].data, s[:y].data)' |&gt; Array\n\nb = PlanarLayer(2) ∘ LeakyReLU{Float64, 1}(0.05) ∘ RadialLayer(2) ∘ LeakyReLU{Float64, 1}(0.05) ∘ PlanarLayer(2)\nd = MvNormal(zeros(2), ones(2))\ntb = transformed(d, b);\nloss(tb :: Bijectors.TransformedDistribution, x :: Matrix{Float64}) = begin\n    loss = 0\n    for i ∈ 1:size(x, 2)\n        loss += -logpdf(tb, x[:, i])\n    end\n    return loss\nend\n\nfunction bnf_train!(tb, x, opt, ps, epochs)\n    @showprogress for i ∈ 1:epochs\n        train_loss, back = Zygote.pullback(() -&gt; loss(tb, x), ps)\n        gs = back(one(train_loss))\n        Flux.update!(opt, ps, gs)\n    end\nend\n\nbnf_train!(tb, train_data, ADAM(), Zygote.Params(Flux.params(b)), 10)```\n","user":"U01HWKB076G","ts":"1609460100.224400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AwB8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi! I was messing around with Bijectors.jl and was really interested in the normalizing flows section and was wondering how to fit these flows. Below is some code that I am trying to use as an example. I keep running into a mutating arrays issue like "},{"type":"text","text":"ERROR: LoadError: Mutating arrays is not supported","style":{"code":true}},{"type":"text","text":"\n\nAny help would be appreciated!\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"@model function gen()\n    x ~ Exponential(0.5)\n    y ~ Normal(0, x)\nend\n\ns = sample(gen(), NUTS(), 500)\ntrain_data = hcat(s[:x].data, s[:y].data)' |> Array\n\nb = PlanarLayer(2) ∘ LeakyReLU{Float64, 1}(0.05) ∘ RadialLayer(2) ∘ LeakyReLU{Float64, 1}(0.05) ∘ PlanarLayer(2)\nd = MvNormal(zeros(2), ones(2))\ntb = transformed(d, b);\nloss(tb :: Bijectors.TransformedDistribution, x :: Matrix{Float64}) = begin\n    loss = 0\n    for i ∈ 1:size(x, 2)\n        loss += -logpdf(tb, x[:, i])\n    end\n    return loss\nend\n\nfunction bnf_train!(tb, x, opt, ps, epochs)\n    @showprogress for i ∈ 1:epochs\n        train_loss, back = Zygote.pullback(() -> loss(tb, x), ps)\n        gs = back(one(train_loss))\n        Flux.update!(opt, ps, gs)\n    end\nend\n\nbnf_train!(tb, train_data, ADAM(), Zygote.Params(Flux.params(b)), 10)"}]},{"type":"rich_text_section","elements":[]}]}]},{"client_msg_id":"2E6D4F3F-7864-4831-9FC0-AF63DC882FC9","type":"message","text":"Happy new year everyone!","user":"UC0SY9JFP","ts":"1609460266.224900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3fs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Happy new year everyone!"}]}]}]},{"client_msg_id":"e7d1e22e-5be3-4e6d-8a30-e9dd38641d84","type":"message","text":"Happy New Year.","user":"UDDSTBX19","ts":"1609471604.225400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DmP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Happy New Year."}]}]}]},{"client_msg_id":"905C64D7-F88F-4885-A11D-A7D88F3F274E","type":"message","text":"Hi Turing developers. I think an compliment is in order. I’m now halfway moving the StatisticalRethinkingJulia models over to a static site and most models run in about 10 seconds (!!). Yes, “using Turing” takes ages, but I’m still impressed with the speed! Thanks for all the work","user":"U01BTNDCUBX","ts":"1609626254.230300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3v3+h","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi Turing developers. I think an compliment is in order. I’m now halfway moving the StatisticalRethinkingJulia models over to a static site and most models run in about 10 seconds (!!). Yes, “using Turing” takes ages, but I’m still impressed with the speed! Thanks for all the work"}]}]}]},{"client_msg_id":"6617e50b-f8ba-44dc-8470-c759b0bc3934","type":"message","text":"I'm doing linear regression with 5 data columns and 100k rows, and it takes about 15 minutes with ADVI(10, 10_000). Is that normal?","user":"U01ARRMLM7E","ts":"1609634954.233000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CtCIh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm doing linear regression with 5 data columns and 100k rows, and it takes about 15 minutes with ADVI(10, 10_000). Is that normal?"}]}]}],"thread_ts":"1609634954.233000","reply_count":2,"reply_users_count":2,"latest_reply":"1609635314.233700","reply_users":["U9JNHB83X","U01ARRMLM7E"],"subscribed":false}]}