[{"client_msg_id":"c0157edb-0c16-4f14-ba38-76d636a57e53","type":"message","text":"I have a question so simple it's almost embarrassing to ask. When I run `fit!` on a machine, particularly when tuning hyperparameters, it uses cross-validation by default. My intuition here is that it would evaluate the model over x folds and average the results. And then it will train the _final_ model on the whole dataset, in the case of hyperparameter optimisation using the best hyperparameters (which would probably need to be evaluated on a holdout data set). Have I got that right?","user":"U0198R8T7LY","ts":"1614393550.015300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"01x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a question so simple it's almost embarrassing to ask. When I run "},{"type":"text","text":"fit!","style":{"code":true}},{"type":"text","text":" on a machine, particularly when tuning hyperparameters, it uses cross-validation by default. My intuition here is that it would evaluate the model over x folds and average the results. And then it will train the "},{"type":"text","text":"final","style":{"italic":true}},{"type":"text","text":" model on the whole dataset, in the case of hyperparameter optimisation using the best hyperparameters (which would probably need to be evaluated on a holdout data set). Have I got that right?"}]}]}],"thread_ts":"1614393550.015300","reply_count":10,"reply_users_count":3,"latest_reply":"1614472495.025600","reply_users":["U0198R8T7LY","UAZP7LJLU","UD0SQV5LL"],"subscribed":false},{"client_msg_id":"91383307-cb94-497b-97f0-2c65d9db79f8","type":"message","text":"I think, in other frameworks all of these are separate steps with separate code. MLJ does everything all at once, which I like but need to get used to.","user":"U0198R8T7LY","ts":"1614393591.015400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iJg/r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think, in other frameworks all of these are separate steps with separate code. MLJ does everything all at once, which I like but need to get used to."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"c16cfea6-89e0-4832-b014-3071903a574b","type":"message","text":"Yeah thats a rough idea of what MLJ does. It implemented as an heuristic called `NaiveSelection` . Other heuristics can be added.\n\nAlthough the final training of the best model (which may be supressed by the `train_best=false` in the `TunedModel` constructor) is done using the whole training data passed during machine construction.","user":"UAZP7LJLU","ts":"1614415092.015600","team":"T68168MUP","edited":{"user":"UAZP7LJLU","ts":"1614415528.000000"},"blocks":[{"type":"rich_text","block_id":"HuBQh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah thats a rough idea of what MLJ does. It implemented as an heuristic called "},{"type":"text","text":"NaiveSelection","style":{"code":true}},{"type":"text","text":" . Other heuristics can be added.\n\nAlthough the final training of the best model (which may be supressed by the "},{"type":"text","text":"train_best=false","style":{"code":true}},{"type":"text","text":" in the "},{"type":"text","text":"TunedModel","style":{"code":true}},{"type":"text","text":" constructor) is done using the whole training data passed during machine construction."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"4a9f6be9-ca7f-4fe7-9e04-d917f0d8f701","type":"message","text":"Ahh right! That gives me a good idea of where to look in the source code, thank you. So if the idea is to:\n1. Separate out 20% of the training data as validation data\n2. Tune the model using cross-validation to optimise hyperparameters on that 80%\n3. Train the best model on the 80%\nthen I can do all of this with a single run of `fit!` with the `rows = ...` argument.","user":"U0198R8T7LY","ts":"1614422942.016200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eRR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ahh right! That gives me a good idea of where to look in the source code, thank you. So if the idea is to:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Separate out 20% of the training data as validation data"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Tune the model using cross-validation to optimise hyperparameters on that 80%"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Train the best model on the 80%"}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"then I can do all of this with a single run of "},{"type":"text","text":"fit!","style":{"code":true}},{"type":"text","text":" with the "},{"type":"text","text":"rows = ...","style":{"code":true}},{"type":"text","text":" argument."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY","reactions":[{"name":"heavy_check_mark","users":["UAZP7LJLU"],"count":1}]},{"client_msg_id":"589298bc-7228-48cf-8d7b-4f153e32421f","type":"message","text":"And is this similar for simple models and no tuning with the `evaluate!` function? As in, does `evaluate!` with the default CV strategy use cross-validation to evaluate the model, then train the final model on all data available to the machine?","user":"U0198R8T7LY","ts":"1614423354.016400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JtZD/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And is this similar for simple models and no tuning with the "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" function? As in, does "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" with the default CV strategy use cross-validation to evaluate the model, then train the final model on all data available to the machine?"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"997d5806-bb3a-42f5-a7c8-01e439992366","type":"message","text":"the default `ResamplingStrategy` for `evaluate!` function is 6-fold cross-validation. `evaluate!` or `evaluate` function doesn't return the best model instead it helps one determine how a fixed model is doing with respect to one or more performance metrics (called `Measures` in MLJ)","user":"UAZP7LJLU","ts":"1614463227.016800","team":"T68168MUP","edited":{"user":"UAZP7LJLU","ts":"1614463272.000000"},"blocks":[{"type":"rich_text","block_id":"bzv5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the default "},{"type":"text","text":"ResamplingStrategy","style":{"code":true}},{"type":"text","text":" for "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" function is 6-fold cross-validation. "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"evaluate","style":{"code":true}},{"type":"text","text":" function doesn't return the best model instead it helps one determine how a fixed model is doing with respect to one or more performance metrics (called "},{"type":"text","text":"Measures","style":{"code":true}},{"type":"text","text":" in MLJ)"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"7832596A-BF04-4F6F-8695-CA1C8DCFFB32","type":"message","text":"Oh! Okay I’ve got this very wrong then. I thought evaluate! fitted a model too because of the exclamation mark. But looking through the documentation, you’re right, it doesn't suggest that at all.","user":"U0198R8T7LY","ts":"1614465826.019400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gF5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh! Okay I’ve got this very wrong then. I thought evaluate! fitted a model too because of the exclamation mark. But looking through the documentation, you’re right, it doesn't suggest that at all."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"934CDA7D-5D2A-4F20-9FF7-B7F2D9189FDA","type":"message","text":"Thank you so much! I’m just putting together a little blog post on a simple MLJ workflow for those coming from R, and this was the last piece I needed","user":"U0198R8T7LY","ts":"1614465909.020400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"peY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you so much! I’m just putting together a little blog post on a simple MLJ workflow for those coming from R, and this was the last piece I needed"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY","reactions":[{"name":"heart","users":["UAZP7LJLU"],"count":1}]},{"client_msg_id":"ce53f766-978c-47a3-933d-3496a3d39ede","type":"message","text":"Yes `evaluate!`  just evaluates a model using some resampling strategy. The `TunedModel` wrapper uses `evaluate!` under the hood to turn the wrapped model into a “self-tuning” one:   optimize the specified hyper-parameters using resampling, then retrain on all the data.  I believe tuning as wrapper idea actually originated in MLR, if you already familiar with that.","user":"UD0SQV5LL","ts":"1614466682.020600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tmoYW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":"  just evaluates a model using some resampling strategy. The "},{"type":"text","text":"TunedModel","style":{"code":true}},{"type":"text","text":" wrapper uses "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" under the hood to turn the wrapped model into a “self-tuning” one:   optimize the specified hyper-parameters using resampling, then retrain on all the data.  I believe tuning as wrapper idea actually originated in MLR, if you already familiar with that."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"74B292D8-41E9-416A-87CD-DCB154A12FA8","type":"message","text":"Hmm I find that a bit confusing. My brain is trying to sort the `evaluate!` function into a separate bucket than the `fit!` function. If `evaluate!` also fits a final model (that can be used to score new data) then my mental model breaks down","user":"U0198R8T7LY","ts":"1614472301.024500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CXh0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hmm I find that a bit confusing. My brain is trying to sort the "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" function into a separate bucket than the "},{"type":"text","text":"fit!","style":{"code":true}},{"type":"text","text":" function. If "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" also fits a final model (that can be used to score new data) then my mental model breaks down"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"FB28E41F-F635-4793-A3BD-82835FC3ACBC","type":"message","text":"Oh no actually, my mental model conforms with what you've just said. I glossed over the “under the hood” part ","user":"U0198R8T7LY","ts":"1614472495.025600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yf4LG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh no actually, my mental model conforms with what you've just said. I glossed over the “under the hood” part "}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"}]