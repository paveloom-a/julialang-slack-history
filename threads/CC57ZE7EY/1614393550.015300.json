[{"client_msg_id":"c0157edb-0c16-4f14-ba38-76d636a57e53","type":"message","text":"I have a question so simple it's almost embarrassing to ask. When I run `fit!` on a machine, particularly when tuning hyperparameters, it uses cross-validation by default. My intuition here is that it would evaluate the model over x folds and average the results. And then it will train the _final_ model on the whole dataset, in the case of hyperparameter optimisation using the best hyperparameters (which would probably need to be evaluated on a holdout data set). Have I got that right?","user":"U0198R8T7LY","ts":"1614393550.015300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"01x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a question so simple it's almost embarrassing to ask. When I run "},{"type":"text","text":"fit!","style":{"code":true}},{"type":"text","text":" on a machine, particularly when tuning hyperparameters, it uses cross-validation by default. My intuition here is that it would evaluate the model over x folds and average the results. And then it will train the "},{"type":"text","text":"final","style":{"italic":true}},{"type":"text","text":" model on the whole dataset, in the case of hyperparameter optimisation using the best hyperparameters (which would probably need to be evaluated on a holdout data set). Have I got that right?"}]}]}],"thread_ts":"1614393550.015300","reply_count":2,"reply_users_count":2,"latest_reply":"1614415092.015600","reply_users":["U0198R8T7LY","UAZP7LJLU"],"subscribed":false},{"client_msg_id":"91383307-cb94-497b-97f0-2c65d9db79f8","type":"message","text":"I think, in other frameworks all of these are separate steps with separate code. MLJ does everything all at once, which I like but need to get used to.","user":"U0198R8T7LY","ts":"1614393591.015400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iJg/r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think, in other frameworks all of these are separate steps with separate code. MLJ does everything all at once, which I like but need to get used to."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"c16cfea6-89e0-4832-b014-3071903a574b","type":"message","text":"Yeah thats a rough idea of what MLJ does. It implemented as an heuristic called `NaiveSelection` . Other heuristics can be added.\n\nAlthough the final training of the best model (which may be supressed by the `train_best=false` in the `TunedModel` constructor) is done using the whole training data passed during machine construction.","user":"UAZP7LJLU","ts":"1614415092.015600","team":"T68168MUP","edited":{"user":"UAZP7LJLU","ts":"1614415528.000000"},"blocks":[{"type":"rich_text","block_id":"HuBQh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah thats a rough idea of what MLJ does. It implemented as an heuristic called "},{"type":"text","text":"NaiveSelection","style":{"code":true}},{"type":"text","text":" . Other heuristics can be added.\n\nAlthough the final training of the best model (which may be supressed by the "},{"type":"text","text":"train_best=false","style":{"code":true}},{"type":"text","text":" in the "},{"type":"text","text":"TunedModel","style":{"code":true}},{"type":"text","text":" constructor) is done using the whole training data passed during machine construction."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"}]