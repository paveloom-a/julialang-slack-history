[{"client_msg_id":"c0157edb-0c16-4f14-ba38-76d636a57e53","type":"message","text":"I have a question so simple it's almost embarrassing to ask. When I run `fit!` on a machine, particularly when tuning hyperparameters, it uses cross-validation by default. My intuition here is that it would evaluate the model over x folds and average the results. And then it will train the _final_ model on the whole dataset, in the case of hyperparameter optimisation using the best hyperparameters (which would probably need to be evaluated on a holdout data set). Have I got that right?","user":"U0198R8T7LY","ts":"1614393550.015300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"01x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a question so simple it's almost embarrassing to ask. When I run "},{"type":"text","text":"fit!","style":{"code":true}},{"type":"text","text":" on a machine, particularly when tuning hyperparameters, it uses cross-validation by default. My intuition here is that it would evaluate the model over x folds and average the results. And then it will train the "},{"type":"text","text":"final","style":{"italic":true}},{"type":"text","text":" model on the whole dataset, in the case of hyperparameter optimisation using the best hyperparameters (which would probably need to be evaluated on a holdout data set). Have I got that right?"}]}]}],"thread_ts":"1614393550.015300","reply_count":13,"reply_users_count":3,"latest_reply":"1614480340.028100","reply_users":["U0198R8T7LY","UAZP7LJLU","UD0SQV5LL"],"subscribed":false},{"client_msg_id":"91383307-cb94-497b-97f0-2c65d9db79f8","type":"message","text":"I think, in other frameworks all of these are separate steps with separate code. MLJ does everything all at once, which I like but need to get used to.","user":"U0198R8T7LY","ts":"1614393591.015400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iJg/r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think, in other frameworks all of these are separate steps with separate code. MLJ does everything all at once, which I like but need to get used to."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"c16cfea6-89e0-4832-b014-3071903a574b","type":"message","text":"Yeah thats a rough idea of what MLJ does. It implemented as an heuristic called `NaiveSelection` . Other heuristics can be added.\n\nAlthough the final training of the best model (which may be supressed by the `train_best=false` in the `TunedModel` constructor) is done using the whole training data passed during machine construction.","user":"UAZP7LJLU","ts":"1614415092.015600","team":"T68168MUP","edited":{"user":"UAZP7LJLU","ts":"1614415528.000000"},"blocks":[{"type":"rich_text","block_id":"HuBQh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah thats a rough idea of what MLJ does. It implemented as an heuristic called "},{"type":"text","text":"NaiveSelection","style":{"code":true}},{"type":"text","text":" . Other heuristics can be added.\n\nAlthough the final training of the best model (which may be supressed by the "},{"type":"text","text":"train_best=false","style":{"code":true}},{"type":"text","text":" in the "},{"type":"text","text":"TunedModel","style":{"code":true}},{"type":"text","text":" constructor) is done using the whole training data passed during machine construction."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"4a9f6be9-ca7f-4fe7-9e04-d917f0d8f701","type":"message","text":"Ahh right! That gives me a good idea of where to look in the source code, thank you. So if the idea is to:\n1. Separate out 20% of the training data as validation data\n2. Tune the model using cross-validation to optimise hyperparameters on that 80%\n3. Train the best model on the 80%\nthen I can do all of this with a single run of `fit!` with the `rows = ...` argument.","user":"U0198R8T7LY","ts":"1614422942.016200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eRR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ahh right! That gives me a good idea of where to look in the source code, thank you. So if the idea is to:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Separate out 20% of the training data as validation data"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Tune the model using cross-validation to optimise hyperparameters on that 80%"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Train the best model on the 80%"}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"then I can do all of this with a single run of "},{"type":"text","text":"fit!","style":{"code":true}},{"type":"text","text":" with the "},{"type":"text","text":"rows = ...","style":{"code":true}},{"type":"text","text":" argument."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY","reactions":[{"name":"heavy_check_mark","users":["UAZP7LJLU"],"count":1}]},{"client_msg_id":"589298bc-7228-48cf-8d7b-4f153e32421f","type":"message","text":"And is this similar for simple models and no tuning with the `evaluate!` function? As in, does `evaluate!` with the default CV strategy use cross-validation to evaluate the model, then train the final model on all data available to the machine?","user":"U0198R8T7LY","ts":"1614423354.016400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JtZD/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And is this similar for simple models and no tuning with the "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" function? As in, does "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" with the default CV strategy use cross-validation to evaluate the model, then train the final model on all data available to the machine?"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"997d5806-bb3a-42f5-a7c8-01e439992366","type":"message","text":"the default `ResamplingStrategy` for `evaluate!` function is 6-fold cross-validation. `evaluate!` or `evaluate` function doesn't return the best model instead it helps one determine how a fixed model is doing with respect to one or more performance metrics (called `Measures` in MLJ)","user":"UAZP7LJLU","ts":"1614463227.016800","team":"T68168MUP","edited":{"user":"UAZP7LJLU","ts":"1614463272.000000"},"blocks":[{"type":"rich_text","block_id":"bzv5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the default "},{"type":"text","text":"ResamplingStrategy","style":{"code":true}},{"type":"text","text":" for "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" function is 6-fold cross-validation. "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"evaluate","style":{"code":true}},{"type":"text","text":" function doesn't return the best model instead it helps one determine how a fixed model is doing with respect to one or more performance metrics (called "},{"type":"text","text":"Measures","style":{"code":true}},{"type":"text","text":" in MLJ)"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"7832596A-BF04-4F6F-8695-CA1C8DCFFB32","type":"message","text":"Oh! Okay I’ve got this very wrong then. I thought evaluate! fitted a model too because of the exclamation mark. But looking through the documentation, you’re right, it doesn't suggest that at all.","user":"U0198R8T7LY","ts":"1614465826.019400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gF5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh! Okay I’ve got this very wrong then. I thought evaluate! fitted a model too because of the exclamation mark. But looking through the documentation, you’re right, it doesn't suggest that at all."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"934CDA7D-5D2A-4F20-9FF7-B7F2D9189FDA","type":"message","text":"Thank you so much! I’m just putting together a little blog post on a simple MLJ workflow for those coming from R, and this was the last piece I needed","user":"U0198R8T7LY","ts":"1614465909.020400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"peY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you so much! I’m just putting together a little blog post on a simple MLJ workflow for those coming from R, and this was the last piece I needed"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY","reactions":[{"name":"heart","users":["UAZP7LJLU"],"count":1}]},{"client_msg_id":"ce53f766-978c-47a3-933d-3496a3d39ede","type":"message","text":"Yes `evaluate!`  just evaluates a model using some resampling strategy. The `TunedModel` wrapper uses `evaluate!` under the hood to turn the wrapped model into a “self-tuning” one:   optimize the specified hyper-parameters using resampling, then retrain on all the data.  I believe tuning as wrapper idea actually originated in MLR, if you already familiar with that.","user":"UD0SQV5LL","ts":"1614466682.020600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tmoYW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":"  just evaluates a model using some resampling strategy. The "},{"type":"text","text":"TunedModel","style":{"code":true}},{"type":"text","text":" wrapper uses "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" under the hood to turn the wrapped model into a “self-tuning” one:   optimize the specified hyper-parameters using resampling, then retrain on all the data.  I believe tuning as wrapper idea actually originated in MLR, if you already familiar with that."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"847a94da-9320-4a90-8b89-51bd6fa80b9e","type":"message","text":"Sorry to keep pestering you with these questions but I'm not sure this is right! If I run the following code (for any `X` and `y`, really) then it works ---  I can `predict` on new data. If `evaluate!` doesn't train a final model, then what is it using to predict?\n```rf_classifier = @load(RandomForestClassifier, pkg = \"DecisionTree\")\nrf = rf_classifier()\nrf_machine = machine(rf, X, categorical(y))\nevaluate!(rf_machine)\npredict(rf_machine, X)```","user":"U0198R8T7LY","ts":"1614477248.026900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nJhX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sorry to keep pestering you with these questions but I'm not sure this is right! If I run the following code (for any "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":", really) then it works ---  I can "},{"type":"text","text":"predict","style":{"code":true}},{"type":"text","text":" on new data. If "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" doesn't train a final model, then what is it using to predict?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"rf_classifier = @load(RandomForestClassifier, pkg = \"DecisionTree\")\nrf = rf_classifier()\nrf_machine = machine(rf, X, categorical(y))\nevaluate!(rf_machine)\npredict(rf_machine, X)"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"4c4d369b-0dc4-482d-a80f-a6c15a508cd3","type":"message","text":"No, this is a good question. It will predict using the the latest train set used in the resampling. So , if you used `resampling=Holdout()` (the default implied here) then the machine has been trained on the first 70% of observations. More generally, you have no idea what the last set used was (if using `CV()` with `acceleration=CPUThreads()` for example) and so predicting after `evaluate!` is not a good workflow. (BTW, you can also do `evaluate(rf_classifier, X, y; kwargs…)` in which case no machine gets exposed).","user":"UD0SQV5LL","ts":"1614479765.027500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"r6mKS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"No, this is a good question. It will predict using the the latest train set used in the resampling. So , if you used "},{"type":"text","text":"resampling=Holdout()","style":{"code":true}},{"type":"text","text":" (the default implied here) then the machine has been trained on the first 70% of observations. More generally, you have no idea what the last set used was (if using "},{"type":"text","text":"CV()","style":{"code":true}},{"type":"text","text":" with "},{"type":"text","text":"acceleration=CPUThreads()","style":{"code":true}},{"type":"text","text":" for example) and so predicting after "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" is not a good workflow. (BTW, you can also do "},{"type":"text","text":"evaluate(rf_classifier, X, y; kwargs…)","style":{"code":true}},{"type":"text","text":" in which case no machine gets exposed)."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"9d6d4dd6-bc12-4323-adf8-068272079a81","type":"message","text":"Ahh! Good, I'm kind of glad I've stumbled onto this. I'm trying to create a mental model that separates `evaluate` from `fit` and this helps.\n\nI created a little \"pre-processing\" function that logs the number of rows being manipulated, and it's helped me keep track of what the code is trying to process.\n\nThank you so much for your help!","user":"U0198R8T7LY","ts":"1614480023.027700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZJkw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ahh! Good, I'm kind of glad I've stumbled onto this. I'm trying to create a mental model that separates "},{"type":"text","text":"evaluate","style":{"code":true}},{"type":"text","text":" from "},{"type":"text","text":"fit","style":{"code":true}},{"type":"text","text":" and this helps.\n\nI created a little \"pre-processing\" function that logs the number of rows being manipulated, and it's helped me keep track of what the code is trying to process.\n\nThank you so much for your help!"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"8596fbb1-a825-45d6-9040-2c09d7b81609","type":"message","text":"It means I can also see that final model being trained when tuning:\n```...\n┌ Info: processing 448 rows\n└ @ Main REPL[107]:3\n┌ Info: processing 112 rows\n└ @ Main REPL[107]:3\n┌ Info: processing 448 rows\n└ @ Main REPL[107]:3\n┌ Info: processing 112 rows\n└ @ Main REPL[107]:3\n┌ Info: processing 560 rows\n└ @ Main REPL[107]:3```","user":"U0198R8T7LY","ts":"1614480120.027900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Jze","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It means I can also see that final model being trained when tuning:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"...\n┌ Info: processing 448 rows\n└ @ Main REPL[107]:3\n┌ Info: processing 112 rows\n└ @ Main REPL[107]:3\n┌ Info: processing 448 rows\n└ @ Main REPL[107]:3\n┌ Info: processing 112 rows\n└ @ Main REPL[107]:3\n┌ Info: processing 560 rows\n└ @ Main REPL[107]:3"}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY"},{"client_msg_id":"44839575-98c8-42d9-86b0-57f98e8b9d2e","type":"message","text":"You can give `evaluate!` and `fit!` the kwarg `verbosity=…` (any integer) and play with that too. Higher the number the more noisy.","user":"UD0SQV5LL","ts":"1614480340.028100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"a=SBl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can give "},{"type":"text","text":"evaluate!","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"fit!","style":{"code":true}},{"type":"text","text":" the kwarg "},{"type":"text","text":"verbosity=…","style":{"code":true}},{"type":"text","text":" (any integer) and play with that too. Higher the number the more noisy."}]}]}],"thread_ts":"1614393550.015300","parent_user_id":"U0198R8T7LY","reactions":[{"name":"+1","users":["U0198R8T7LY","UAZP7LJLU"],"count":2}]}]