[{"client_msg_id":"453a6ccf-3271-409c-b150-65d9be411df9","type":"message","text":"I was wondering, what is the reason for MLJ to store the training data in a `Machine` instead of passing it to the `fit!` method?","user":"UBEF50B7C","ts":"1614100691.009600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"di3K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was wondering, what is the reason for MLJ to store the training data in a "},{"type":"text","text":"Machine","style":{"code":true}},{"type":"text","text":" instead of passing it to the "},{"type":"text","text":"fit!","style":{"code":true}},{"type":"text","text":" method?"}]}]}],"thread_ts":"1614100691.009600","reply_count":9,"reply_users_count":3,"latest_reply":"1614107785.012400","reply_users":["UDP5WL2RX","UD0SQV5LL","UBEF50B7C"],"subscribed":false},{"client_msg_id":"d668c334-02e7-4595-93c5-afe725bc8dab","type":"message","text":"you might be interested in the section  6 of the paper:  <https://arxiv.org/pdf/2007.12285.pdf> :slightly_smiling_face:","user":"UDP5WL2RX","ts":"1614104968.010600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vqyc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you might be interested in the section  6 of the paper:  "},{"type":"link","url":"https://arxiv.org/pdf/2007.12285.pdf"},{"type":"text","text":" "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"thread_ts":"1614100691.009600","parent_user_id":"UBEF50B7C"},{"client_msg_id":"f9d04b01-ae5c-4978-8d03-f7ef27cf81ef","type":"message","text":"If you really want, you can use the purely functional model interface on which the machine interface is based. So, for example, there are methods\n```MLJModelInterface.fit(model, verbosity, X, y) -&gt; fitresult, cache, report```","user":"UD0SQV5LL","ts":"1614106868.010800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kbGS3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you really want, you can use the purely functional model interface on which the machine interface is based. So, for example, there are methods\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"MLJModelInterface.fit(model, verbosity, X, y) -> fitresult, cache, report"}]}]}],"thread_ts":"1614100691.009600","parent_user_id":"UBEF50B7C"},{"client_msg_id":"e033e7d0-27d8-4214-b7a9-edf1489f74e6","type":"message","text":"So if I read that correctly, it is because we want to  be able to build networks of  machines, so we need the ability to specify the data at the machine level anyway?\n\nSo technically it would still be possible to implement a `fit!(node, X, y)`  method  that replaces the sources, like `predict(node, Xnew) ` does?\n\nAnd if one wants to replace source data at some point in training (online training, or from some generator), one would just replace the data in the source or create some custom source node that generates data?","user":"UBEF50B7C","ts":"1614106869.011000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=C/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So if I read that correctly, it is because we want to  be able to build networks of  machines, so we need the ability to specify the data at the machine level anyway?\n\nSo technically it would still be possible to implement a "},{"type":"text","text":"fit!(node, X, y)","style":{"code":true}},{"type":"text","text":"  method  that replaces the sources, like `predict(node, Xnew) ` does?\n\nAnd if one wants to replace source data at some point in training (online training, or from some generator), one would just replace the data in the source or create some custom source node that generates data?"}]}]}],"thread_ts":"1614100691.009600","parent_user_id":"UBEF50B7C"},{"client_msg_id":"e3b7ffea-6794-4697-8b7b-8470764961a9","type":"message","text":"…continuing previous commment:\n```MLJModelInterface(model, fitresult, Xnew) -&gt; yhat```","user":"UD0SQV5LL","ts":"1614106942.011200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ht9TZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"…continuing previous commment:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"MLJModelInterface(model, fitresult, Xnew) -> yhat"}]}]}],"thread_ts":"1614100691.009600","parent_user_id":"UBEF50B7C"},{"client_msg_id":"1a74dc9f-c461-4cf1-8387-932b5983d363","type":"message","text":"Indeed, this is the API implemented by new models.","user":"UD0SQV5LL","ts":"1614106961.011400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NAcn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Indeed, this is the API implemented by new models."}]}]}],"thread_ts":"1614100691.009600","parent_user_id":"UBEF50B7C"},{"client_msg_id":"459bacad-b9f9-4bbe-b5e6-053d12e492bc","type":"message","text":"“So if I read that correctly, it is because we want to be able to build networks of machines, so we need the ability to specify the data at the machine level anyway?” Yes, basically, the idea was to have an API that looks the same for atomic models and learning networks. For even more detail see <https://arxiv.org/abs/2012.15505> .","user":"UD0SQV5LL","ts":"1614107109.011600","team":"T68168MUP","attachments":[{"service_name":"arXiv.org","title":"Flexible model composition in machine learning and its...","title_link":"https://arxiv.org/abs/2012.15505","text":"A graph-based protocol called `learning networks' which combine assorted machine learning models into meta-models is described. Learning networks are shown to overcome several limitations of model...","fallback":"arXiv.org: Flexible model composition in machine learning and its...","from_url":"https://arxiv.org/abs/2012.15505","service_icon":"https://static.arxiv.org/static/browse/0.3.2.6/images/icons/favicon.ico","id":1,"original_url":"https://arxiv.org/abs/2012.15505"}],"blocks":[{"type":"rich_text","block_id":"f1z9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"“So if I read that correctly, it is because we want to be able to build networks of machines, so we need the ability to specify the data at the machine level anyway?” Yes, basically, the idea was to have an API that looks the same for atomic models and learning networks. For even more detail see "},{"type":"link","url":"https://arxiv.org/abs/2012.15505"},{"type":"text","text":" ."}]}]}],"thread_ts":"1614100691.009600","parent_user_id":"UBEF50B7C"},{"client_msg_id":"81bcbcec-72e0-4d65-99b3-feb15ce90b17","type":"message","text":"“So technically it would still be possible to implement a `fit!(node, X, y)`  method  that replaces the sources, like `predict(node, Xnew) ` does?” You cannot inject data at a particular node, except at source nodes, although changing data wrapped at a source node is not advised. Online learning, even in the case  of atomic models, is not really supported yet. <https://github.com/alan-turing-institute/MLJ.jl/issues/60> .","user":"UD0SQV5LL","ts":"1614107141.011900","team":"T68168MUP","edited":{"user":"UD0SQV5LL","ts":"1614107293.000000"},"blocks":[{"type":"rich_text","block_id":"deojC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"“So technically it would still be possible to implement a "},{"type":"text","text":"fit!(node, X, y)","style":{"code":true}},{"type":"text","text":"  method  that replaces the sources, like `predict(node, Xnew) ` does?” You cannot inject data at a particular node, except at source nodes, although changing data wrapped at a source node is not advised. Online learning, even in the case  of atomic models, is not really supported yet. "},{"type":"link","url":"https://github.com/alan-turing-institute/MLJ.jl/issues/60"},{"type":"text","text":" ."}]}]}],"thread_ts":"1614100691.009600","parent_user_id":"UBEF50B7C"},{"client_msg_id":"1c41d992-d27c-4e1b-9f1e-0725cd28a581","type":"message","text":"Technically, you could however, replace the node arguments of a nodal machine with new data (wrapped in source nodes, as data always is), essentially disconnecting the machine from the network, and train that; but I don’t see why you would want to do that - you could must construct a new machine. But probably I’m missing your idea :smile:","user":"UD0SQV5LL","ts":"1614107422.012200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fwR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Technically, you could however, replace the node arguments of a nodal machine with new data (wrapped in source nodes, as data always is), essentially disconnecting the machine from the network, and train that; but I don’t see why you would want to do that - you could must construct a new machine. But probably I’m missing your idea "},{"type":"emoji","name":"smile"}]}]}],"thread_ts":"1614100691.009600","parent_user_id":"UBEF50B7C"},{"client_msg_id":"f4cbe4ea-db00-435e-b11b-4e65baf3a437","type":"message","text":"Hmm, I think I was comparing MLJ a bit with deep learning networks, where one trains in batches and with different learning rates. Now that I think about that, this might only make sense for some models - others really need to be retrained from the beginning when there is new data","user":"UBEF50B7C","ts":"1614107785.012400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kY2MZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hmm, I think I was comparing MLJ a bit with deep learning networks, where one trains in batches and with different learning rates. Now that I think about that, this might only make sense for some models - others really need to be retrained from the beginning when there is new data"}]}]}],"thread_ts":"1614100691.009600","parent_user_id":"UBEF50B7C"}]