[{"client_msg_id":"67191d21-e8de-4c41-ad7e-bbb0414f9678","type":"message","text":"Can anyone help me how I would convert a folder of CSVs files to a folder of arrow memory-mapped files using CSV.jl and/or Arrow.jl?\n\nI went through the docs and could not find anything about this.\n\nThat would be mostly for out-of-memory manipulation. Because each CSV would be 500MB (there is at least 60 of those) and I have 8GB RAM. I can do this in R using the `{arrow}` package, but I want to do this in Julia.","user":"U01QBF4PHKP","ts":"1615068696.247200","team":"T68168MUP","edited":{"user":"U01QBF4PHKP","ts":"1615068818.000000"},"blocks":[{"type":"rich_text","block_id":"STyl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can anyone help me how I would convert a folder of CSVs files to a folder of arrow memory-mapped files using CSV.jl and/or Arrow.jl?\n\nI went through the docs and could not find anything about this.\n\nThat would be mostly for out-of-memory manipulation. Because each CSV would be 500MB (there is at least 60 of those) and I have 8GB RAM. I can do this in R using the "},{"type":"text","text":"{arrow}","style":{"code":true}},{"type":"text","text":" package, but I want to do this in Julia."}]}]}],"thread_ts":"1615068696.247200","reply_count":19,"reply_users_count":2,"latest_reply":"1615074867.257100","reply_users":["U681ELA87","U01QBF4PHKP"],"subscribed":false},{"client_msg_id":"fb44d7ac-888a-4f56-ac66-88dc77b8ecad","type":"message","text":"We walk through kind of an example of this using `Tables.partitioner` in the <https://arrow.juliadata.org/dev/manual/#Arrow.write|docs>, there's also an issue where someone was doing exactly this: <https://github.com/JuliaData/Arrow.jl/issues/108>. Here's the docs for `Tables.partitioner` which should help as well (<https://tables.juliadata.org/stable/#Tables.partitioner>), at least if you're trying to write all the csv files out as a single arrow file with each file as a separate record batch in the arrow file. If you want to write each csv file as a separate arrow file entirely, then that's quite a bit more straightforward.","user":"U681ELA87","ts":"1615069736.247500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"E=qH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We walk through kind of an example of this using "},{"type":"text","text":"Tables.partitioner","style":{"code":true}},{"type":"text","text":" in the "},{"type":"link","url":"https://arrow.juliadata.org/dev/manual/#Arrow.write","text":"docs"},{"type":"text","text":", there's also an issue where someone was doing exactly this: "},{"type":"link","url":"https://github.com/JuliaData/Arrow.jl/issues/108"},{"type":"text","text":". Here's the docs for "},{"type":"text","text":"Tables.partitioner","style":{"code":true}},{"type":"text","text":" which should help as well ("},{"type":"link","url":"https://tables.juliadata.org/stable/#Tables.partitioner"},{"type":"text","text":"), at least if you're trying to write all the csv files out as a single arrow file with each file as a separate record batch in the arrow file. If you want to write each csv file as a separate arrow file entirely, then that's quite a bit more straightforward."}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP","reactions":[{"name":"heart","users":["U01QBF4PHKP"],"count":1}]},{"client_msg_id":"09847c51-7c22-418c-b2e7-38ba0c1bb6d1","type":"message","text":"Wow thanks for the fast reply.\nLet me see if I got this straight:\n\n1. Multiple CSVs -&gt; Multiple Arrow file\n```for file in files\n   Arrow.write(file * \".arrow\", CSV.File(file * \".csv\"))\nend```\n2. Multiple CSVs -&gt; One Arrow file\n```Arrow.write(\"BIGFILE.arrow\", Tables.partitioner(files) do file\n           CSV.File(file * \".csv\", datarow=5, header=[\"var1\", \"var2\", \"var3\", ...])\n       end)```\nEdit: I got confused with `enter` and `shift` + `enter` for new lines in Slack. New to this....","user":"U01QBF4PHKP","ts":"1615070438.247700","team":"T68168MUP","edited":{"user":"U01QBF4PHKP","ts":"1615070681.000000"},"blocks":[{"type":"rich_text","block_id":"UQS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Wow thanks for the fast reply.\nLet me see if I got this straight:\n\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Multiple CSVs -> Multiple Arrow file"}]}],"style":"ordered","indent":0},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"for file in files\n   Arrow.write(file * \".arrow\", CSV.File(file * \".csv\"))\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"2. Multiple CSVs -> One Arrow file\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Arrow.write(\"BIGFILE.arrow\", Tables.partitioner(files) do file\n           CSV.File(file * \".csv\", datarow=5, header=[\"var1\", \"var2\", \"var3\", ...])\n       end)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nEdit: I got confused with "},{"type":"text","text":"enter","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"shift","style":{"code":true}},{"type":"text","text":" + "},{"type":"text","text":"enter","style":{"code":true}},{"type":"text","text":" for new lines in Slack. New to this...."}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"e702d855-a86a-431b-ad73-9b0732538a8d","type":"message","text":"And then I can specify `Arrow.jl` to read all the `*.arrow` files in the example #1 as  `t = Arrow.Table(arrow_files_dir)`?","user":"U01QBF4PHKP","ts":"1615070834.248100","team":"T68168MUP","edited":{"user":"U01QBF4PHKP","ts":"1615070852.000000"},"blocks":[{"type":"rich_text","block_id":"4k=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And then I can specify "},{"type":"text","text":"Arrow.jl","style":{"code":true}},{"type":"text","text":" to read all the "},{"type":"text","text":"*.arrow","style":{"code":true}},{"type":"text","text":" files in the example #1 as  "},{"type":"text","text":"t = Arrow.Table(arrow_files_dir)","style":{"code":true}},{"type":"text","text":"?"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"1AE401DA-4493-48C6-9937-63E9E722936D","type":"message","text":"Yes That all sounds right to me","user":"U681ELA87","ts":"1615071138.248600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AL9/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes That all sounds right to me"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP","reactions":[{"name":"heart","users":["U01QBF4PHKP"],"count":1}]},{"client_msg_id":"f342081d-195f-4234-82bd-2fb592a4c252","type":"message","text":"Thank you so MUCH!","user":"U01QBF4PHKP","ts":"1615071184.249900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3t5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you so MUCH!"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"6D056B2A-C49F-471E-99A0-5869E53A6F62","type":"message","text":"Oh wait, no, in the first example you’d have to read each arrow file separately. Arrow.jl doesn’t have a way to read a whole directory of arrow files","user":"U681ELA87","ts":"1615071190.250300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pknu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh wait, no, in the first example you’d have to read each arrow file separately. Arrow.jl doesn’t have a way to read a whole directory of arrow files"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"C4BE7847-0020-4AB8-9499-155D16E97071","type":"message","text":"If you want a single table, you’d need to do example two","user":"U681ELA87","ts":"1615071216.250900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+jeD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you want a single table, you’d need to do example two"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"BD94BC85-F4AB-4A52-9A52-F08881F4801B","type":"message","text":"But we could probably support reason g a whole directory as a single table. It’s just not as common a workflow with arrow I think because it natively supports multiple record batches in a single arrow file ","user":"U681ELA87","ts":"1615071261.252600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9wn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But we could probably support reason g a whole directory as a single table. It’s just not as common a workflow with arrow I think because it natively supports multiple record batches in a single arrow file "}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"5d66ecbb-52db-4c8d-ae79-41644ae9b5d3","type":"message","text":"That would be indeed something quite useful because. I only have 8GB of RAM so if I have 50GB of data in several CSV files, I can convert every single CSV file to an arrow file and then I can store all of them in the same directory and use arrow to manipulate the data.","user":"U01QBF4PHKP","ts":"1615071774.252800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"v4BA5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That would be indeed something quite useful because. I only have 8GB of RAM so if I have 50GB of data in several CSV files, I can convert every single CSV file to an arrow file and then I can store all of them in the same directory and use arrow to manipulate the data."}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"2999626a-00c1-4662-9e53-71b1363748ea","type":"message","text":"Even if you have 8gb ram, it should still work to concat all the csv files into a single arrow file. Now, you might have to adjust the workflow of how you use the single arrow file/table, but the arrow file is ultimately mmapped, so the OS will swap the actual underlying data into memory as needed when you’re accessing different parts","user":"U681ELA87","ts":"1615072012.253000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RLZF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Even if you have 8gb ram, it should still work to concat all the csv files into a single arrow file. Now, you might have to adjust the workflow of how you use the single arrow file/table, but the arrow file is ultimately mmapped, so the OS will swap the actual underlying data into memory as needed when you’re accessing different parts"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP","reactions":[{"name":"heart","users":["U01QBF4PHKP"],"count":1}]},{"client_msg_id":"66513cb1-fb5c-4ecb-91c5-6fcec46674eb","type":"message","text":"So this:\n\n```Arrow.write(\"BIGFILE.arrow\", Tables.partitioner(files) do file\n           CSV.File(file)\n       end)```\nworks with limited RAM? (The only constraint would be how much RAM the largest CSV file would require?, because of the iterator?)","user":"U01QBF4PHKP","ts":"1615072475.253300","team":"T68168MUP","edited":{"user":"U01QBF4PHKP","ts":"1615072519.000000"},"blocks":[{"type":"rich_text","block_id":"QS5CT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So this:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Arrow.write(\"BIGFILE.arrow\", Tables.partitioner(files) do file\n           CSV.File(file)\n       end)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nworks with limited RAM? (The only constraint would be how much RAM the largest CSV file would require?, because of the iterator?)"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"1a1b3671-6a7c-4172-bf49-afc4cee6c4f5","type":"message","text":"yes, that should work. the other thing to think about is how many threads your julia session is running with, because `Arrow.write` will write `Threads.nthreads()` number of csv files out to the arrow file in parallel, so potentially more RAM than just your single largest csv file. I actually still have an open PR to be able to limit the number of tasks used to write in parallel, but it kind of stalled as I was waiting for someone to try it out. (<https://github.com/JuliaData/Arrow.jl/pull/106>)","user":"U681ELA87","ts":"1615073358.253800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kWwC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yes, that should work. the other thing to think about is how many threads your julia session is running with, because "},{"type":"text","text":"Arrow.write","style":{"code":true}},{"type":"text","text":" will write "},{"type":"text","text":"Threads.nthreads()","style":{"code":true}},{"type":"text","text":" number of csv files out to the arrow file in parallel, so potentially more RAM than just your single largest csv file. I actually still have an open PR to be able to limit the number of tasks used to write in parallel, but it kind of stalled as I was waiting for someone to try it out. ("},{"type":"link","url":"https://github.com/JuliaData/Arrow.jl/pull/106"},{"type":"text","text":")"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"7d0e4e7e-5cf6-47e4-8a6c-57b74282b062","type":"message","text":"I will subscribe to the PR and see how I can help","user":"U01QBF4PHKP","ts":"1615073720.254000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ksi6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I will subscribe to the PR and see how I can help"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"5d91840e-cf27-4400-ada2-b4fad03f5bc3","type":"message","text":"One more thing:\n```df = DataFrame(Arrow.Table(file))```\nDoes this loads a full DataFrame into RAM? Or is it still memory-mapped?","user":"U01QBF4PHKP","ts":"1615073952.254200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=H3NQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One more thing:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"df = DataFrame(Arrow.Table(file))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nDoes this loads a full DataFrame into RAM? Or is it still memory-mapped?"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"878956ec-9d69-455d-956e-b4531fbb5c4d","type":"message","text":"by default it's still memory-mapped, but note that DataFrame operations that mutate column values are not allowed","user":"U681ELA87","ts":"1615074059.254400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fBM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"by default it's still memory-mapped, but note that DataFrame operations that mutate column values are not allowed"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"0fc74c69-4ab2-4a2a-98f3-c02111a76ec4","type":"message","text":"And also....\n```julia&gt; df = DataFrame(tbl)\nERROR: LoadError: DimensionMismatch(\"column :VendorID has length 24648499 and column :store_and_fwd_flag has length 79378972\")\nStacktrace:\n [1] DataFrame(columns::Vector{AbstractVector{T} where T}, colindex::DataFrames.Index; copycols::Bool)\n   @ DataFrames ~/.julia/packages/DataFrames/oQ5c7/src/dataframe/dataframe.jl:181\n [2] fromcolumns(x::Tables.CopiedColumns{Arrow.Table}, names::Vector{Symbol}; copycols::Bool)\n   @ DataFrames ~/.julia/packages/DataFrames/oQ5c7/src/other/tables.jl:36\n [3] #DataFrame#648\n   @ ~/.julia/packages/DataFrames/oQ5c7/src/other/tables.jl:57 [inlined]\n [4] DataFrame(x::Arrow.Table)\n   @ DataFrames ~/.julia/packages/DataFrames/oQ5c7/src/other/tables.jl:46\n [5] top-level scope\n   @ ~/Documents/Julia_Scripts/Arrow/nyc_taxi.jl:26\nin expression starting at /Users/storopoli/Documents/Julia_Scripts/Arrow/nyc_taxi.jl:26```\nUsing the [NYC-Taxi data from 2020](<https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page>)","user":"U01QBF4PHKP","ts":"1615074134.254700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"v+r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And also....\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> df = DataFrame(tbl)\nERROR: LoadError: DimensionMismatch(\"column :VendorID has length 24648499 and column :store_and_fwd_flag has length 79378972\")\nStacktrace:\n [1] DataFrame(columns::Vector{AbstractVector{T} where T}, colindex::DataFrames.Index; copycols::Bool)\n   @ DataFrames ~/.julia/packages/DataFrames/oQ5c7/src/dataframe/dataframe.jl:181\n [2] fromcolumns(x::Tables.CopiedColumns{Arrow.Table}, names::Vector{Symbol}; copycols::Bool)\n   @ DataFrames ~/.julia/packages/DataFrames/oQ5c7/src/other/tables.jl:36\n [3] #DataFrame#648\n   @ ~/.julia/packages/DataFrames/oQ5c7/src/other/tables.jl:57 [inlined]\n [4] DataFrame(x::Arrow.Table)\n   @ DataFrames ~/.julia/packages/DataFrames/oQ5c7/src/other/tables.jl:46\n [5] top-level scope\n   @ ~/Documents/Julia_Scripts/Arrow/nyc_taxi.jl:26\nin expression starting at /Users/storopoli/Documents/Julia_Scripts/Arrow/nyc_taxi.jl:26"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nUsing the [NYC-Taxi data from 2020]("},{"type":"link","url":"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page"},{"type":"text","text":")"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"35f2805d-8ef9-4979-a3ce-7f2044a5c3be","type":"message","text":"hmmm....that seems pretty fishy. arrow table columns should definitely always have the same length","user":"U681ELA87","ts":"1615074181.255400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Zc7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hmmm....that seems pretty fishy. arrow table columns should definitely always have the same length"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"cb353d37-537b-4a3c-a7bd-c1e210af8489","type":"message","text":"This is the full code:\n\n```using Arrow, Tables, CSV, DataFrames, Query, Statistics\n\ncsvfiles = readdir(\"/Users/storopoli/Desktop/arrow_test\", join=true)\n\ncsv_parts_2019 = Tables.partitioner(CSV.File, csvfiles[1:12])\ncsv_parts_2020 = Tables.partitioner(CSV.File, csvfiles[13:end])\n\nArrow.write(\"/Users/storopoli/Desktop/2019.arrow\", csv_parts_2019)\nArrow.write(\"/Users/storopoli/Desktop/2020.arrow\", csv_parts_2020)\n\ntbl = Arrow.Table(\"/Users/storopoli/Desktop/2020.arrow\")```\nI get an error if I try to write both CSV from 2020 and 2019 so I had to break it up.\n\n```Arrow.write(\"/Users/storopoli/Desktop/2019.arrow\", csv_parts_2019)\nERROR: LoadError: TaskFailedException\n\n    nested task error: MethodError: no method matching SentinelArrays.ChainedVector(::Vector{Arrow.List{T, Int32, A} where {T, A}})\n    Closest candidates are:\n      SentinelArrays.ChainedVector(::Vector{A}) where {T, A&lt;:AbstractVector{T}} at /Users/storopoli/.julia/packages/SentinelArrays/Ubf17/src/chainedvector.jl:17\n      SentinelArrays.ChainedVector(::Vector{A}, ::Vector{Int64}) where {T, A&lt;:AbstractVector{T}} at /Users/storopoli/.julia/packages/SentinelArrays/Ubf17/src/chainedvector.jl:13\n    Stacktrace:\n      [1] macro expansion\n        @ ~/.julia/packages/Arrow/Re9EM/src/arraytypes/dictencoding.jl:180 [inlined]\n      [2] macro expansion\n        @ ~/.julia/packages/Arrow/Re9EM/src/utils.jl:155 [inlined]\n      [3] arrowvector(::Arrow.ArrowTypes.DictEncodedType, x::Arrow.DictEncode{Union{Missing, String}, PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; dictencode::Bool, dictencodenested::Bool, kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:compression, :largelists, :denseunions), Tuple{Nothing, Bool, Bool}}})\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/dictencoding.jl:157\n      [4] arrowvector(::Type{Arrow.DictEncodeType{Union{Missing, String}}}, x::Arrow.DictEncode{Union{Missing, String}, PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{5, Symbol}, NamedTuple{(:dictencode, :compression, :largelists, :denseunions, :dictencodenested), Tuple{Bool, Nothing, Bool, Bool, Bool}}})\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:90\n      [5] arrowvector(x::PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; dictencoding::Bool, dictencode::Bool, kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{4, Symbol}, NamedTuple{(:compression, :largelists, :denseunions, :dictencodenested), Tuple{Nothing, Bool, Bool, Bool}}})\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:58\n      [6] toarrowvector(x::PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}, i::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; compression::Nothing, kw::Base.Iterators.Pairs{Symbol, Bool, NTuple{4, Symbol}, NamedTuple{(:largelists, :denseunions, :dictencode, :dictencodenested), NTuple{4, Bool}}})\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:36\n      [7] (::Arrow.var\"#109#110\"{Dict{Int64, Any}, Bool, Nothing, Bool, Bool, Bool, Vector{Arrow.DictEncoding}, Vector{Type}, Vector{Any}})(col::PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}, i::Int64, nm::Symbol)\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/write.jl:202\n      [8] eachcolumn(f::Arrow.var\"#109#110\"{Dict{Int64, Any}, Bool, Nothing, Bool, Bool, Bool, Vector{Arrow.DictEncoding}, Vector{Type}, Vector{Any}}, sch::Tables.Schema{(:VendorID, :tpep_pickup_datetime, :tpep_dropoff_datetime, :passenger_count, :trip_distance, :RatecodeID, :store_and_fwd_flag, :PULocationID, :DOLocationID, :payment_type, :fare_amount, :extra, :mta_tax, :tip_amount, :tolls_amount, :improvement_surcharge, :total_amount, :congestion_surcharge), Tuple{Union{Missing, Int64}, String, String, Union{Missing, Int64}, Float64, Union{Missing, Int64}, Union{Missing, PooledString}, Int64, Int64, Union{Missing, Int64}, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64}}, row::CSV.File{true})\n        @ Tables ~/.julia/packages/Tables/8FVkV/src/utils.jl:70\n      [9] toarrowtable(x::Tables.LazyTable{UnionAll, String}, dictencodings::Dict{Int64, Any}, largelists::Bool, compress::Nothing, denseunions::Bool, dictencode::Bool, dictencodenested::Bool)\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/write.jl:201\n     [10] macro expansion\n        @ ~/.julia/packages/Arrow/Re9EM/src/write.jl:127 [inlined]\n     [11] (::Arrow.var\"#105#108\"{Bool, Bool, Bool, Bool, Int64, Dict{Int64, Any}, Base.RefValue{Tables.Schema}, Arrow.OrderedChannel{Arrow.Message}, Tables.LazyTable{UnionAll, String}, Int64})()\n        @ Arrow ./threadingconstructs.jl:169\n\n...and 5 more exceptions.\n\nStacktrace:\n [1] sync_end(c::Channel{Any})\n   @ Base ./task.jl:364\n [2] macro expansion\n   @ ./task.jl:383 [inlined]\n [3] write(io::IOStream, source::Tables.Partitioner{Base.Generator{Vector{String}, Tables.var\"#9#10\"{UnionAll}}}, writetofile::Bool, largelists::Bool, compress::Nothing, denseunions::Bool, dictencode::Bool, dictencodenested::Bool, alignment::Int64)\n   @ Arrow ~/.julia/packages/Arrow/Re9EM/src/write.jl:108\n [4] #100\n   @ ~/.julia/packages/Arrow/Re9EM/src/write.jl:77 [inlined]\n [5] open(::Arrow.var\"#100#101\"{Bool, Nothing, Bool, Bool, Bool, Int64, Tables.Partitioner{Base.Generator{Vector{String}, Tables.var\"#9#10\"{UnionAll}}}}, ::String, ::Vararg{String, N} where N; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})\n   @ Base ./io.jl:330\n [6] open\n   @ ./io.jl:328 [inlined]\n [7] #write#99\n   @ ~/.julia/packages/Arrow/Re9EM/src/write.jl:76 [inlined]\n [8] write(file::String, tbl::Tables.Partitioner{Base.Generator{Vector{String}, Tables.var\"#9#10\"{UnionAll}}})\n   @ Arrow ~/.julia/packages/Arrow/Re9EM/src/write.jl:76\n [9] top-level scope\n   @ ~/Documents/Julia_Scripts/Arrow/nyc_taxi.jl:8\nin expression starting at /Users/storopoli/Documents/Julia_Scripts/Arrow/nyc_taxi.jl:8```","user":"U01QBF4PHKP","ts":"1615074294.256400","team":"T68168MUP","edited":{"user":"U01QBF4PHKP","ts":"1615074317.000000"},"blocks":[{"type":"rich_text","block_id":"yic+t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This is the full code:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Arrow, Tables, CSV, DataFrames, Query, Statistics\n\ncsvfiles = readdir(\"/Users/storopoli/Desktop/arrow_test\", join=true)\n\ncsv_parts_2019 = Tables.partitioner(CSV.File, csvfiles[1:12])\ncsv_parts_2020 = Tables.partitioner(CSV.File, csvfiles[13:end])\n\nArrow.write(\"/Users/storopoli/Desktop/2019.arrow\", csv_parts_2019)\nArrow.write(\"/Users/storopoli/Desktop/2020.arrow\", csv_parts_2020)\n\ntbl = Arrow.Table(\"/Users/storopoli/Desktop/2020.arrow\")"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nI get an error if I try to write both CSV from 2020 and 2019 so I had to break it up.\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Arrow.write(\"/Users/storopoli/Desktop/2019.arrow\", csv_parts_2019)\nERROR: LoadError: TaskFailedException\n\n    nested task error: MethodError: no method matching SentinelArrays.ChainedVector(::Vector{Arrow.List{T, Int32, A} where {T, A}})\n    Closest candidates are:\n      SentinelArrays.ChainedVector(::Vector{A}) where {T, A<:AbstractVector{T}} at /Users/storopoli/.julia/packages/SentinelArrays/Ubf17/src/chainedvector.jl:17\n      SentinelArrays.ChainedVector(::Vector{A}, ::Vector{Int64}) where {T, A<:AbstractVector{T}} at /Users/storopoli/.julia/packages/SentinelArrays/Ubf17/src/chainedvector.jl:13\n    Stacktrace:\n      [1] macro expansion\n        @ ~/.julia/packages/Arrow/Re9EM/src/arraytypes/dictencoding.jl:180 [inlined]\n      [2] macro expansion\n        @ ~/.julia/packages/Arrow/Re9EM/src/utils.jl:155 [inlined]\n      [3] arrowvector(::Arrow.ArrowTypes.DictEncodedType, x::Arrow.DictEncode{Union{Missing, String}, PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; dictencode::Bool, dictencodenested::Bool, kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:compression, :largelists, :denseunions), Tuple{Nothing, Bool, Bool}}})\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/dictencoding.jl:157\n      [4] arrowvector(::Type{Arrow.DictEncodeType{Union{Missing, String}}}, x::Arrow.DictEncode{Union{Missing, String}, PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{5, Symbol}, NamedTuple{(:dictencode, :compression, :largelists, :denseunions, :dictencodenested), Tuple{Bool, Nothing, Bool, Bool, Bool}}})\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:90\n      [5] arrowvector(x::PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}, i::Int64, nl::Int64, fi::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; dictencoding::Bool, dictencode::Bool, kw::Base.Iterators.Pairs{Symbol, Union{Nothing, Bool}, NTuple{4, Symbol}, NamedTuple{(:compression, :largelists, :denseunions, :dictencodenested), Tuple{Nothing, Bool, Bool, Bool}}})\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:58\n      [6] toarrowvector(x::PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}, i::Int64, de::Dict{Int64, Any}, ded::Vector{Arrow.DictEncoding}, meta::Nothing; compression::Nothing, kw::Base.Iterators.Pairs{Symbol, Bool, NTuple{4, Symbol}, NamedTuple{(:largelists, :denseunions, :dictencode, :dictencodenested), NTuple{4, Bool}}})\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/arraytypes/arraytypes.jl:36\n      [7] (::Arrow.var\"#109#110\"{Dict{Int64, Any}, Bool, Nothing, Bool, Bool, Bool, Vector{Arrow.DictEncoding}, Vector{Type}, Vector{Any}})(col::PooledArrays.PooledVector{Union{Missing, String}, UInt32, SentinelArrays.ChainedVector{UInt32, Vector{UInt32}}}, i::Int64, nm::Symbol)\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/write.jl:202\n      [8] eachcolumn(f::Arrow.var\"#109#110\"{Dict{Int64, Any}, Bool, Nothing, Bool, Bool, Bool, Vector{Arrow.DictEncoding}, Vector{Type}, Vector{Any}}, sch::Tables.Schema{(:VendorID, :tpep_pickup_datetime, :tpep_dropoff_datetime, :passenger_count, :trip_distance, :RatecodeID, :store_and_fwd_flag, :PULocationID, :DOLocationID, :payment_type, :fare_amount, :extra, :mta_tax, :tip_amount, :tolls_amount, :improvement_surcharge, :total_amount, :congestion_surcharge), Tuple{Union{Missing, Int64}, String, String, Union{Missing, Int64}, Float64, Union{Missing, Int64}, Union{Missing, PooledString}, Int64, Int64, Union{Missing, Int64}, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64}}, row::CSV.File{true})\n        @ Tables ~/.julia/packages/Tables/8FVkV/src/utils.jl:70\n      [9] toarrowtable(x::Tables.LazyTable{UnionAll, String}, dictencodings::Dict{Int64, Any}, largelists::Bool, compress::Nothing, denseunions::Bool, dictencode::Bool, dictencodenested::Bool)\n        @ Arrow ~/.julia/packages/Arrow/Re9EM/src/write.jl:201\n     [10] macro expansion\n        @ ~/.julia/packages/Arrow/Re9EM/src/write.jl:127 [inlined]\n     [11] (::Arrow.var\"#105#108\"{Bool, Bool, Bool, Bool, Int64, Dict{Int64, Any}, Base.RefValue{Tables.Schema}, Arrow.OrderedChannel{Arrow.Message}, Tables.LazyTable{UnionAll, String}, Int64})()\n        @ Arrow ./threadingconstructs.jl:169\n\n...and 5 more exceptions.\n\nStacktrace:\n [1] sync_end(c::Channel{Any})\n   @ Base ./task.jl:364\n [2] macro expansion\n   @ ./task.jl:383 [inlined]\n [3] write(io::IOStream, source::Tables.Partitioner{Base.Generator{Vector{String}, Tables.var\"#9#10\"{UnionAll}}}, writetofile::Bool, largelists::Bool, compress::Nothing, denseunions::Bool, dictencode::Bool, dictencodenested::Bool, alignment::Int64)\n   @ Arrow ~/.julia/packages/Arrow/Re9EM/src/write.jl:108\n [4] #100\n   @ ~/.julia/packages/Arrow/Re9EM/src/write.jl:77 [inlined]\n [5] open(::Arrow.var\"#100#101\"{Bool, Nothing, Bool, Bool, Bool, Int64, Tables.Partitioner{Base.Generator{Vector{String}, Tables.var\"#9#10\"{UnionAll}}}}, ::String, ::Vararg{String, N} where N; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})\n   @ Base ./io.jl:330\n [6] open\n   @ ./io.jl:328 [inlined]\n [7] #write#99\n   @ ~/.julia/packages/Arrow/Re9EM/src/write.jl:76 [inlined]\n [8] write(file::String, tbl::Tables.Partitioner{Base.Generator{Vector{String}, Tables.var\"#9#10\"{UnionAll}}})\n   @ Arrow ~/.julia/packages/Arrow/Re9EM/src/write.jl:76\n [9] top-level scope\n   @ ~/Documents/Julia_Scripts/Arrow/nyc_taxi.jl:8\nin expression starting at /Users/storopoli/Documents/Julia_Scripts/Arrow/nyc_taxi.jl:8"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"},{"client_msg_id":"30ea0c9f-10f0-429d-bbf7-a6f01f801ada","type":"message","text":"Oh, interesting. Is this public data? Could you put all of that in an Arrow.jl issue and I'll take a look to see what's going on? that definitely looks like a bug","user":"U681ELA87","ts":"1615074867.257100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fhoT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh, interesting. Is this public data? Could you put all of that in an Arrow.jl issue and I'll take a look to see what's going on? that definitely looks like a bug"}]}]}],"thread_ts":"1615068696.247200","parent_user_id":"U01QBF4PHKP"}]