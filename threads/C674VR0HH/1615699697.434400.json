[{"client_msg_id":"aa72022e-cc0c-400b-a690-e9a6d5ca564a","type":"message","text":"<https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/>","user":"UDGT4PM41","ts":"1615699697.434400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FGe","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/"}]}]}],"thread_ts":"1615699697.434400","reply_count":36,"reply_users_count":5,"latest_reply":"1615759420.453500","reply_users":["UBF9YRB6H","U8JAMQGQY","UC7AF7NSU","U67431ELR","U681ELA87"],"subscribed":false},{"client_msg_id":"825ab950-f164-411d-a259-18d23d53ceed","type":"message","text":"Just a note, a lot of the slowdown in Julia's DataFrames will be fixed with a few things that are in the pipeline:\n\nFaster `groupby`:\n     <https://github.com/JuliaData/DataFrames.jl/pull/2610>\n     <https://github.com/JuliaData/DataFrames.jl/pull/2592> (maybe not as relevant)\n\nMultithreading\n    <https://github.com/JuliaData/DataFrames.jl/pull/2588>\n    <https://github.com/JuliaData/DataFrames.jl/pull/2491>\n    <https://github.com/JuliaData/DataFrames.jl/pull/2647>\n\nThe multi-threading ones will be the most relevant with those 50GB tests, when the cost of new threads is negligible compared to the rest of the operation.","user":"UBF9YRB6H","ts":"1615700380.434500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ieSsG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just a note, a lot of the slowdown in Julia's DataFrames will be fixed with a few things that are in the pipeline:\n\nFaster "},{"type":"text","text":"groupby","style":{"code":true}},{"type":"text","text":":\n     "},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/pull/2610"},{"type":"text","text":"\n     "},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/pull/2592"},{"type":"text","text":" (maybe not as relevant)\n\nMultithreading\n    "},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/pull/2588"},{"type":"text","text":"\n    "},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/pull/2491"},{"type":"text","text":"\n    "},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/pull/2647"},{"type":"text","text":"\n\nThe multi-threading ones will be the most relevant with those 50GB tests, when the cost of new threads is negligible compared to the rest of the operation."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"52f79360-34af-4ac5-a0c3-5ad38c9d91b3","type":"message","text":"The only major piece we are missing is multithreaded `AbstractDict`. We could use the approach of Polars, where items are distributed over multiple dicts based on remainder of hash. This would also allow for a deeper pool sharing in PooledArrays.jl. <@UC7AF7NSU> do you have experience/comments on such data structure?","user":"U8JAMQGQY","ts":"1615708452.434900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Kgg9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The only major piece we are missing is multithreaded "},{"type":"text","text":"AbstractDict","style":{"code":true}},{"type":"text","text":". We could use the approach of Polars, where items are distributed over multiple dicts based on remainder of hash. This would also allow for a deeper pool sharing in PooledArrays.jl. "},{"type":"user","user_id":"UC7AF7NSU"},{"type":"text","text":" do you have experience/comments on such data structure?"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"04428418-935b-49fd-b7d6-e890e69e21cd","type":"message","text":"Making a data structure data race-free (\"thread safe\"/multi-threaded in some sense) is almost always a bad decision for performance of *parallel* programs (it is, of course, required for the correctness of some *concurrent* programs like web servers). If you want to squeeze out the performance this way, I think you might need to go all the way down to lock-free programming.","user":"UC7AF7NSU","ts":"1615710167.435100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NBpP2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Making a data structure data race-free (\"thread safe\"/multi-threaded in some sense) is almost always a bad decision for performance of "},{"type":"text","text":"parallel","style":{"bold":true}},{"type":"text","text":" programs (it is, of course, required for the correctness of some "},{"type":"text","text":"concurrent","style":{"bold":true}},{"type":"text","text":" programs like web servers). If you want to squeeze out the performance this way, I think you might need to go all the way down to lock-free programming."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"41a9c6e4-960f-44da-ab18-194772b0f103","type":"message","text":"oh, \"5.2 Parallel hashing\" of the blog post discusses this, too. apparently, they have lock-free dict","user":"UC7AF7NSU","ts":"1615710326.435300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0Mm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oh, \"5.2 Parallel hashing\" of the blog post discusses this, too. apparently, they have lock-free dict"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"902862a6-8802-4564-a9dc-fcd054e1269b","type":"message","text":"But this is exactly what I am asking about - do you know if lock-free hashing dict is implemented for Julia somewhere and if not is it worth implementing it and how much overhead it would have?","user":"U8JAMQGQY","ts":"1615710641.435500","team":"T68168MUP","edited":{"user":"U8JAMQGQY","ts":"1615710709.000000"},"blocks":[{"type":"rich_text","block_id":"3uep","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But this is exactly what I am asking about - do you know if lock-free hashing dict is implemented for Julia somewhere and if not is it worth implementing it and how much overhead it would have?"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"0c291e0f-f310-4c60-891c-f6cbd6ee53f6","type":"message","text":"I don't know if there's any lock-free data containers in Julia","user":"UC7AF7NSU","ts":"1615710823.435800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3dbk3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't know if there's any lock-free data containers in Julia"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"be3411c5-2785-488f-8b47-60b7263516f0","type":"message","text":"I also don't understand how they resolve collision in a data race-free manner","user":"UC7AF7NSU","ts":"1615710828.436000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DeVA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I also don't understand how they resolve collision in a data race-free manner"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"92a80975-da1a-41c4-9d23-7670a3c95d32","type":"message","text":"Assume you have 4 threads. You create 4 `Dict`s each assigned to two lowest bits of hash value. Then you are sure that any operation of addition, deletion and lookup is done on the same thread. This works assuming that two lowest bits of hash are uniformly distributed but I guess this is an OK assumption.","user":"U8JAMQGQY","ts":"1615711165.436300","team":"T68168MUP","edited":{"user":"U8JAMQGQY","ts":"1615711190.000000"},"blocks":[{"type":"rich_text","block_id":"pK1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Assume you have 4 threads. You create 4 "},{"type":"text","text":"Dict","style":{"code":true}},{"type":"text","text":"s each assigned to two lowest bits of hash value. Then you are sure that any operation of addition, deletion and lookup is done on the same thread. This works assuming that two lowest bits of hash are uniformly distributed but I guess this is an OK assumption."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"cef8a0f0-049f-4c2c-83c2-a7984db8ed8e","type":"message","text":"There two things I don't understand about their approach: (1) even if you salt the hash with thread id, if your bucket is too small, isn't it possible to get collision? (2) even if you can \"partition\" the bucket by including the thread id, then I don't see the difference to the multiple dictionary approach","user":"UC7AF7NSU","ts":"1615711716.437100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"M/oaJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There two things I don't understand about their approach: (1) even if you salt the hash with thread id, if your bucket is too small, isn't it possible to get collision? (2) even if you can \"partition\" the bucket by including the thread id, then I don't see the difference to the multiple dictionary approach"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"6dbed17d-55d9-4e62-99e7-6eb4dcbf2b2c","type":"message","text":"but I saw another study about groupby on GPU using using lock-free approach. so I guess there's some way to make it work...?","user":"UC7AF7NSU","ts":"1615711821.437300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8+e","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but I saw another study about groupby on GPU using using lock-free approach. so I guess there's some way to make it work...?"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"23ab4188-9700-49b6-bb27-b7b5640af15e","type":"message","text":"anyway, I'm sorry, I'm a noob here","user":"UC7AF7NSU","ts":"1615711841.437500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1JO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"anyway, I'm sorry, I'm a noob here"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"3f7218a9-1cda-4e24-b358-dfa63a70332d","type":"message","text":"Very interesting. IIUC collisions between threads are not possible since each thread computes all hashes and checks whether they will end up in a bucket that has been attributed to it. Maybe we could implement it by creating several `Dict`s, calling `sizehint!` on them to ensure they have the same internal structure, and have each thread insert only some values after checking their hash. This would require copying and adapting the internal `Dict` implementation to avoid doing work twice. Finally, we would need a optimized `merge` implementation that takes advantage of the fact that dicts are completely compatible and independent. That said, this approach is quite wasteful as hashes are computed multiple times. I wonder whether computing hashes in parallel in a first pass wouldn't be better.","user":"U67431ELR","ts":"1615728975.437900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EVED+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Very interesting. IIUC collisions between threads are not possible since each thread computes all hashes and checks whether they will end up in a bucket that has been attributed to it. Maybe we could implement it by creating several "},{"type":"text","text":"Dict","style":{"code":true}},{"type":"text","text":"s, calling "},{"type":"text","text":"sizehint!","style":{"code":true}},{"type":"text","text":" on them to ensure they have the same internal structure, and have each thread insert only some values after checking their hash. This would require copying and adapting the internal "},{"type":"text","text":"Dict","style":{"code":true}},{"type":"text","text":" implementation to avoid doing work twice. Finally, we would need a optimized "},{"type":"text","text":"merge","style":{"code":true}},{"type":"text","text":" implementation that takes advantage of the fact that dicts are completely compatible and independent. That said, this approach is quite wasteful as hashes are computed multiple times. I wonder whether computing hashes in parallel in a first pass wouldn't be better."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"d2edd0c5-3b72-4b19-9ce0-ff7145a34576","type":"message","text":"Do you understand what's the \"filter trick\" he mentions? I don't really get it.","user":"U67431ELR","ts":"1615729016.438100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"j6fPQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Do you understand what's the \"filter trick\" he mentions? I don't really get it."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"49fbaca8-8656-4f46-b643-cd8adc9c4dca","type":"message","text":"We already ave an infrastructurw to precompute hashes in joins.","user":"U8JAMQGQY","ts":"1615732171.438300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XfS3l","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We already ave an infrastructurw to precompute hashes in joins."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"f9cc7a71-7d1d-4443-b1e0-06b60918d41e","type":"message","text":"Filter trick - you take densely encoded `Bool` vector and treat it as `UInt64` vector (actually this is the case in Julia already internally). Then you take number of leading `1`s in it and you can copy that part of the vector without branching. The same with leading `0`s which you can skip. This means that if your filter is very dense or very sparse you can process it faster. I think this optimization should be implemented in Julia Base and not in DataFrames.jl","user":"U8JAMQGQY","ts":"1615732671.438500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"D=RMu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Filter trick - you take densely encoded "},{"type":"text","text":"Bool","style":{"code":true}},{"type":"text","text":" vector and treat it as "},{"type":"text","text":"UInt64","style":{"code":true}},{"type":"text","text":" vector (actually this is the case in Julia already internally). Then you take number of leading "},{"type":"text","text":"1","style":{"code":true}},{"type":"text","text":"s in it and you can copy that part of the vector without branching. The same with leading "},{"type":"text","text":"0","style":{"code":true}},{"type":"text","text":"s which you can skip. This means that if your filter is very dense or very sparse you can process it faster. I think this optimization should be implemented in Julia Base and not in DataFrames.jl"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"30cd5f02-ca9b-4235-9b82-cff94347b224","type":"message","text":"By \"you take\" I mean you take 64-bit chunk of course - not the whole vector","user":"U8JAMQGQY","ts":"1615732718.438700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rCm7U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"By \"you take\" I mean you take 64-bit chunk of course - not the whole vector"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"baec9c2b-ee9a-4695-b14d-f5fe65d1ba8d","type":"message","text":"One minor thing about the source code of the benchmarks, is this line\n\n```x = DataFrame(CSV.File(\n  src_grp, pool=true,\n  types=[PooledString, PooledString, PooledString, Int, Int, Int, Int, Int, Float64]\n));```\nproducing `ChainedArray`s? If so, would doing `copycols = true` or similar improve the benchmarks?","user":"UBF9YRB6H","ts":"1615733103.438900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ynj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One minor thing about the source code of the benchmarks, is this line\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"x = DataFrame(CSV.File(\n  src_grp, pool=true,\n  types=[PooledString, PooledString, PooledString, Int, Int, Int, Int, Int, Float64]\n));"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nproducing `ChainedArray`s? If so, would doing "},{"type":"text","text":"copycols = true","style":{"code":true}},{"type":"text","text":" or similar improve the benchmarks?"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"cf524c7f-7fb7-408e-824f-03f1ee6d2505","type":"message","text":"Cc <@U681ELA87>","user":"U8JAMQGQY","ts":"1615733475.439100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"L71y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Cc "},{"type":"user","user_id":"U681ELA87"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"0a492c23-92a9-48d3-8e32-1bae031ad0a3","type":"message","text":"Or maybe using single thread to read data would avoid `ChainedArray`?","user":"U8JAMQGQY","ts":"1615733538.439300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"czY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Or maybe using single thread to read data would avoid "},{"type":"text","text":"ChainedArray","style":{"code":true}},{"type":"text","text":"?"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"dd93de98-feb7-4665-9862-3d3b4a324a5a","type":"message","text":"<@U67431ELR> in `groupby` we already use a custom fixed size hash table so maybe we could use it?","user":"U8JAMQGQY","ts":"1615733743.439500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IRyVV","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U67431ELR"},{"type":"text","text":" in "},{"type":"text","text":"groupby","style":{"code":true}},{"type":"text","text":" we already use a custom fixed size hash table so maybe we could use it?"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"75FA0A25-E989-4FF0-BEA0-8F0E73DC60D5","type":"message","text":"I’m currently doing a review of ChainedVector operations to ensure they are as fast or faster (using multi threading) than normal array. My goal is to make them even more “invisible”. And I’d like them to hopefully compose well with all the DataFrames operations.","user":"U681ELA87","ts":"1615736041.442000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TxWZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m currently doing a review of ChainedVector operations to ensure they are as fast or faster (using multi threading) than normal array. My goal is to make them even more “invisible”. And I’d like them to hopefully compose well with all the DataFrames operations."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"b8314e77-b608-480e-bb96-aa5dee46de35","type":"message","text":"fwiw i think that particular line isn't returning a `ChainedVector`, since there are no `missing`s and no partitions.\n\nThe use of `skipmissing` in the benchmarks is fair and probably not that big of a performance hit for us, but realistically if you are working with 50GB of data, you are checking whether your data has missing values and branching yourself.","user":"UBF9YRB6H","ts":"1615738779.442800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FPg5T","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"fwiw i think that particular line isn't returning a "},{"type":"text","text":"ChainedVector","style":{"code":true}},{"type":"text","text":", since there are no `missing`s and no partitions.\n\nThe use of "},{"type":"text","text":"skipmissing","style":{"code":true}},{"type":"text","text":" in the benchmarks is fair and probably not that big of a performance hit for us, but realistically if you are working with 50GB of data, you are checking whether your data has missing values and branching yourself."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"5f0ff6e1-1181-433b-bc83-72349efe424f","type":"message","text":"Regarding the filter trick, I'm surprised it's really faster in practice. If you have a series of `true` or `false` entries, branch prediction should be quite good already. Maybe the advantage of calling `memcpy` is SIMD instructions? Anyway, yes, that should be implemented in Base for `BitArray` if that's really faster.","user":"U67431ELR","ts":"1615743318.443100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LD/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Regarding the filter trick, I'm surprised it's really faster in practice. If you have a series of "},{"type":"text","text":"true","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"false","style":{"code":true}},{"type":"text","text":" entries, branch prediction should be quite good already. Maybe the advantage of calling "},{"type":"text","text":"memcpy","style":{"code":true}},{"type":"text","text":" is SIMD instructions? Anyway, yes, that should be implemented in Base for "},{"type":"text","text":"BitArray","style":{"code":true}},{"type":"text","text":" if that's really faster."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"c615c7e5-218b-4a9e-899d-525e2f0e619d","type":"message","text":"I think there might be something with the way they handle `null` values that is particularly fast. I've been trying to track down where that's handled and I ended up here: <https://github.com/ritchie46/polars/blob/8d3896bb67757bf61ff858f99699e49b0261f1e2/polars/polars-core/src/chunked_array/kernels/take.rs#L73>","user":"UBF9YRB6H","ts":"1615757121.450800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JvZQ6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think there might be something with the way they handle "},{"type":"text","text":"null","style":{"code":true}},{"type":"text","text":" values that is particularly fast. I've been trying to track down where that's handled and I ended up here: "},{"type":"link","url":"https://github.com/ritchie46/polars/blob/8d3896bb67757bf61ff858f99699e49b0261f1e2/polars/polars-core/src/chunked_array/kernels/take.rs#L73"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"ac226981-6e2d-4878-b448-216c56c90b22","type":"message","text":"<@U67431ELR> The blog post and your explanation doesn't mention any atomic operations. When I hear lock-free I imagine atomics. Is it all about clever data structure and merging construction? That's _technically_ \"lock-free\" but it's rather confusing way to discuss this (although you didn't mention it). Anyway, pairing clever data structure and merging is typically the best approach in data parallelism (i.e., avoid data race by construction) so at a high level it sounds good to me. (It solves my second question, too)","user":"UC7AF7NSU","ts":"1615757392.451000","team":"T68168MUP","edited":{"user":"UC7AF7NSU","ts":"1615759078.000000"},"blocks":[{"type":"rich_text","block_id":"eVFUl","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U67431ELR"},{"type":"text","text":" The blog post and your explanation doesn't mention any atomic operations. When I hear lock-free I imagine atomics. Is it all about clever data structure and merging construction? That's "},{"type":"text","text":"technically","style":{"italic":true}},{"type":"text","text":" \"lock-free\" but it's rather confusing way to discuss this (although you didn't mention it). Anyway, pairing clever data structure and merging is typically the best approach in data parallelism (i.e., avoid data race by construction) so at a high level it sounds good to me. (It solves my second question, too)"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"8ca58466-ce0d-4fb7-a9d5-0caa169bbbe7","type":"message","text":"Their approach doesn't use atomics. I'm not familiar with the terminology, but yes the trick is to build dicts with the same structure where each bucket can only be filled by one particular thread, so that they can be merged efficiently in the end.","user":"U67431ELR","ts":"1615759084.451400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PwE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Their approach doesn't use atomics. I'm not familiar with the terminology, but yes the trick is to build dicts with the same structure where each bucket can only be filled by one particular thread, so that they can be merged efficiently in the end."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"45d4f769-2b18-48d5-ab7c-505575f45b68","type":"message","text":"Thanks for the clarification!","user":"UC7AF7NSU","ts":"1615759156.451600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tNoHV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for the clarification!"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"38156f79-4a28-4fef-9c57-13c14e702356","type":"message","text":"<@UBF9YRB6H> Maybe their handling of missing values isn't faster than ours, but they are faster in other areas? In particular, we don't use multithreading in 0.22 (used for the benchmarks), and in some cases we have to use `dropmissing`, which is much slower than `skipmissing`.","user":"U67431ELR","ts":"1615759169.451800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8=i","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UBF9YRB6H"},{"type":"text","text":" Maybe their handling of missing values isn't faster than ours, but they are faster in other areas? In particular, we don't use multithreading in 0.22 (used for the benchmarks), and in some cases we have to use "},{"type":"text","text":"dropmissing","style":{"code":true}},{"type":"text","text":", which is much slower than "},{"type":"text","text":"skipmissing","style":{"code":true}},{"type":"text","text":"."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"76a83511-8544-4090-b653-fafdaea492ba","type":"message","text":"yeah, the `dropmissing` thing is something I will look more into.","user":"UBF9YRB6H","ts":"1615759208.452000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PKoz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, the "},{"type":"text","text":"dropmissing","style":{"code":true}},{"type":"text","text":" thing is something I will look more into."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"439cdbd6-99de-4157-a428-fefcefa1751b","type":"message","text":"(I think you do not even have to merge the `Dicts` at all - you can just leave several dicts and dispatch to an appropriate one based on the remainder of hash)","user":"U8JAMQGQY","ts":"1615759217.452200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jc=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(I think you do not even have to merge the "},{"type":"text","text":"Dicts","style":{"code":true}},{"type":"text","text":" at all - you can just leave several dicts and dispatch to an appropriate one based on the remainder of hash)"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41","reactions":[{"name":"+1","users":["U67431ELR"],"count":1}]},{"client_msg_id":"73eacc33-acb9-4c05-a0db-e5412d528563","type":"message","text":"IIRC we need to improve `cor` so that we can stop using `dropmissing`. :confused:","user":"U67431ELR","ts":"1615759301.452500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XbE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"IIRC we need to improve "},{"type":"text","text":"cor","style":{"code":true}},{"type":"text","text":" so that we can stop using "},{"type":"text","text":"dropmissing","style":{"code":true}},{"type":"text","text":". "},{"type":"emoji","name":"confused"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"16ec678a-d8fc-41c9-8b0b-0305b645bb44","type":"message","text":"we can tell them to use `pairwise`?","user":"UBF9YRB6H","ts":"1615759323.452700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"f3q7c","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"we can tell them to use "},{"type":"text","text":"pairwise","style":{"code":true}},{"type":"text","text":"?"}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"01dbdbe6-1b58-423f-a75a-4a5305c7138d","type":"message","text":"I think we can tell them to use `pairwise`","user":"U8JAMQGQY","ts":"1615759356.452900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SDAR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think we can tell them to use "},{"type":"text","text":"pairwise","style":{"code":true}}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"63763806-28b7-41f1-99fd-68a0d639787a","type":"message","text":"okay thats comforting.","user":"UBF9YRB6H","ts":"1615759369.453100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4lq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"okay thats comforting."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"308530ca-bbf3-4b17-9354-6859583a5188","type":"message","text":"`pairwise` takes a collection of columns and returns a matrix, so it's not super logical, even if it would probably be faster.","user":"U67431ELR","ts":"1615759374.453300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Luf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"pairwise","style":{"code":true}},{"type":"text","text":" takes a collection of columns and returns a matrix, so it's not super logical, even if it would probably be faster."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"},{"client_msg_id":"389de89a-f729-4b3a-8099-0105b132a30e","type":"message","text":"oh. I thought we also had a scalar output for `pairwise`.","user":"UBF9YRB6H","ts":"1615759420.453500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MpQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oh. I thought we also had a scalar output for "},{"type":"text","text":"pairwise","style":{"code":true}},{"type":"text","text":"."}]}]}],"thread_ts":"1615699697.434400","parent_user_id":"UDGT4PM41"}]