[{"client_msg_id":"cd02f951-1ddd-49fc-9d7f-7b909ce1c7cd","type":"message","text":"I'm trying to understand if/how the Arrow format and Parquet format can be used together.\nI see the Apache Arrow [FAQ](<https://arrow.apache.org/faq/>) says\n&gt;  Arrow and Parquet complement each other and are commonly used together in applications. Storing your data on disk using Parquet and reading it into memory in the Arrow format\nBut i'm not 100% sure what this means and i couldn't see how to do it with Parquet.jl and Arrow.jl\nIs e.g. reading Parquet files as an Arrow table possible?","user":"UDXST8ARK","ts":"1611766429.103500","team":"T68168MUP","edited":{"user":"UDXST8ARK","ts":"1611766804.000000"},"blocks":[{"type":"rich_text","block_id":"=ZUa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm trying to understand if/how the Arrow format and Parquet format can be used together.\nI see the Apache Arrow [FAQ]("},{"type":"link","url":"https://arrow.apache.org/faq/"},{"type":"text","text":") says\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":" Arrow and Parquet complement each other and are commonly used together in applications. Storing your data on disk using Parquet and reading it into memory in the Arrow format"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"But i'm not 100% sure what this means and i couldn't see how to do it with Parquet.jl and Arrow.jl\nIs e.g. reading Parquet files as an Arrow table possible?"}]}]}],"thread_ts":"1611766429.103500","reply_count":7,"reply_users_count":3,"latest_reply":"1611862117.111100","reply_users":["UDXST8ARK","U681ELA87","U01GXNFKY6R"],"subscribed":false},{"client_msg_id":"a29760ff-534c-4e98-95fb-9b752d3a7cf3","type":"message","text":"for context my data is:\n• ~12,000 files (one file per year, per state for ~25 years, ~50 states) \n• currently stored as gzipped CSV files (about 7.3 GB compressed, 100 GB uncompressed)\nAnd want to give users access to subsets of this data easily e.g. a DataFrame of all states for 2017, then later go investigat AZ in 2017 and 2018\nWithout ending up with \n• The whole uncompressed CSV data locally (100GB)\n• Running out of RAM (so not trying to load 100GB of data!)\n• Not being too slow to get into DataFrame\nSo i am thinking Parquet or Arrow would be a good fit for this\nand wondering if i need to choose between them e.g. store the data instead as `.arrow` (?)  and not use parquet (or gzipped csv)","user":"UDXST8ARK","ts":"1611766602.103600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Rs/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"for context my data is:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"~12,000 files (one file per year, per state for ~25 years, ~50 states) "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"currently stored as gzipped CSV files (about 7.3 GB compressed, 100 GB uncompressed)"}]}],"style":"bullet","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"\nAnd want to give users access to subsets of this data easily e.g. a DataFrame of all states for 2017, then later go investigat AZ in 2017 and 2018\nWithout ending up with \n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The whole uncompressed CSV data locally (100GB)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Running out of RAM (so not trying to load 100GB of data!)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Not being too slow to get into DataFrame"}]}],"style":"bullet","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"\nSo i am thinking Parquet or Arrow would be a good fit for this\nand wondering if i need to choose between them e.g. store the data instead as "},{"type":"text","text":".arrow","style":{"code":true}},{"type":"text","text":" (?)  and not use parquet (or gzipped csv)"}]}]}],"thread_ts":"1611766429.103500","parent_user_id":"UDXST8ARK"},{"client_msg_id":"8a72326f-644e-45f7-9e8e-61dbaeda1f0c","type":"message","text":"The only reason I'd recommend using parquet for file storage is if you're dealing with longer-term data that you're worried about needing/accessing in 5-10 years. The arrow format has tagged a 1.0 for the format version, and I'd say it's unlikely they do any major breaking changes for quite a while. I think it's likely they support new kinds of column types, but very strong liklihood everything remains backwards compatible otherwise.\n\nSo IMO, if you can keep it all in arrow, I think it simplifies a lot.\n\nOther consideration is the Parquet.jl julia package hasn't matured nearly as much as the parquet + arrow in the rust/c++ languages. I'd like to eventually get tighter integration because I think there are some efficiencies when converting between the two beyond what we can get with just the current Tables.jl-based integration.","user":"U681ELA87","ts":"1611767508.106300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fDCN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The only reason I'd recommend using parquet for file storage is if you're dealing with longer-term data that you're worried about needing/accessing in 5-10 years. The arrow format has tagged a 1.0 for the format version, and I'd say it's unlikely they do any major breaking changes for quite a while. I think it's likely they support new kinds of column types, but very strong liklihood everything remains backwards compatible otherwise.\n\nSo IMO, if you can keep it all in arrow, I think it simplifies a lot.\n\nOther consideration is the Parquet.jl julia package hasn't matured nearly as much as the parquet + arrow in the rust/c++ languages. I'd like to eventually get tighter integration because I think there are some efficiencies when converting between the two beyond what we can get with just the current Tables.jl-based integration."}]}]}],"thread_ts":"1611766429.103500","parent_user_id":"UDXST8ARK","reactions":[{"name":"thankyou","users":["UDXST8ARK"],"count":1}]},{"client_msg_id":"a6b9a36b-73d6-43e1-9edc-c8c605f2c523","type":"message","text":"thanks!","user":"UDXST8ARK","ts":"1611769002.108400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"URNE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thanks!"}]}]}],"thread_ts":"1611766429.103500","parent_user_id":"UDXST8ARK"},{"client_msg_id":"a6c1b581-50be-459a-ae79-600525611b5c","type":"message","text":"<@UDXST8ARK> <https://www.youtube.com/watch?v=dPb2ZXnt2_U> this video talks through creating a fast Parquet to Arrow reader","user":"U01GXNFKY6R","ts":"1611821367.109500","team":"T68168MUP","attachments":[{"service_name":"YouTube","service_url":"https://www.youtube.com/","title":"The columnar roadmap: Apache Parquet and Apache Arrow","title_link":"https://www.youtube.com/watch?v=dPb2ZXnt2_U","author_name":"DataWorks Summit","author_link":"https://www.youtube.com/user/HadoopSummit","thumb_url":"https://i.ytimg.com/vi/dPb2ZXnt2_U/hqdefault.jpg","thumb_width":480,"thumb_height":360,"fallback":"YouTube Video: The columnar roadmap: Apache Parquet and Apache Arrow","video_html":"<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/dPb2ZXnt2_U?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","video_html_width":400,"video_html_height":225,"from_url":"https://www.youtube.com/watch?v=dPb2ZXnt2_U","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png","id":1,"original_url":"https://www.youtube.com/watch?v=dPb2ZXnt2_U"}],"blocks":[{"type":"rich_text","block_id":"FguR","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UDXST8ARK"},{"type":"text","text":" "},{"type":"link","url":"https://www.youtube.com/watch?v=dPb2ZXnt2_U"},{"type":"text","text":" this video talks through creating a fast Parquet to Arrow reader"}]}]}],"thread_ts":"1611766429.103500","parent_user_id":"UDXST8ARK","reactions":[{"name":"+1","users":["UDXST8ARK"],"count":1}]},{"client_msg_id":"87d40ff9-b659-4d90-9811-9598dc25980a","type":"message","text":"Another option to explore is using the c++ arrow lib (or pyarrow) and access the arrow table using the <https://arrow.apache.org/docs/format/CDataInterface.html|C Data Interface>. This hasn’t been implemented either but it’s a more “resource efficient” path than writing your own parquet -&gt; arrow reader","user":"U01GXNFKY6R","ts":"1611821600.109800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"85n/p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Another option to explore is using the c++ arrow lib (or pyarrow) and access the arrow table using the "},{"type":"link","url":"https://arrow.apache.org/docs/format/CDataInterface.html","text":"C Data Interface"},{"type":"text","text":". This hasn’t been implemented either but it’s a more “resource efficient” path than writing your own parquet -> arrow reader"}]}]}],"thread_ts":"1611766429.103500","parent_user_id":"UDXST8ARK"},{"client_msg_id":"7b159ef9-63f9-413c-8c9b-826edb39f8fe","type":"message","text":"Of course this is if you are interested specifically reading parquet files as an arrow table. It is possible to store your data in the arrow format and not deal with any of this stuff","user":"U01GXNFKY6R","ts":"1611821772.110000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Gnb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Of course this is if you are interested specifically reading parquet files as an arrow table. It is possible to store your data in the arrow format and not deal with any of this stuff"}]}]}],"thread_ts":"1611766429.103500","parent_user_id":"UDXST8ARK"},{"client_msg_id":"f5762fa4-e940-4b79-9c3d-140df1b07178","type":"message","text":"Thanks!","user":"UDXST8ARK","ts":"1611862117.111100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iWY7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks!"}]}]}],"thread_ts":"1611766429.103500","parent_user_id":"UDXST8ARK"}]