[{"client_msg_id":"be76c705-f30e-4921-97fd-a5d24a36bd0f","type":"message","text":"But I need to admit that this is all still kind of fuzzy in my head; it might be most productive to hear some of the use-cases people have where they’re running into the issues mentioned above and have a solution grow out of the best way forward given the issues. In particular, it’s not clear to me whether people are trying to save a `Vector{CustomStruct}` in arrow format, or if they have DataFrames that happen to have `Tuple{Int, String}` columns that are running into issues. If anyone has thoughts/ideas, I’d love to hear them. I’ll try to post more thoughts as I have them.","user":"U681ELA87","ts":"1614228333.053300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IFuJK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But I need to admit that this is all still kind of fuzzy in my head; it might be most productive to hear some of the use-cases people have where they’re running into the issues mentioned above and have a solution grow out of the best way forward given the issues. In particular, it’s not clear to me whether people are trying to save a "},{"type":"text","text":"Vector{CustomStruct}","style":{"code":true}},{"type":"text","text":" in arrow format, or if they have DataFrames that happen to have "},{"type":"text","text":"Tuple{Int, String}","style":{"code":true}},{"type":"text","text":" columns that are running into issues. If anyone has thoughts/ideas, I’d love to hear them. I’ll try to post more thoughts as I have them."}]}]}],"thread_ts":"1614228333.053300","reply_count":11,"reply_users_count":9,"latest_reply":"1614429459.096400","reply_users":["UCZ7VBGUD","U674T0Y9Z","U9VG1AYSG","U681ELA87","U69J94HT9","U695B1S2X","UH8A351DJ","U679T6QF7","U6SHSF4R0"],"subscribed":false},{"client_msg_id":"f9a24930-a66b-4f60-a49d-6e987a8834e8","type":"message","text":"I’m sure <@U674T0Y9Z> can comment in more detail, but our Onda.jl package (as of last week) uses Arrow to store tables of annotations and information about signals. You can see the types of the columns in the format, specified here: <https://github.com/beacon-biosignals/OndaFormat#ondaannotationsarrow-files>. So I would say this is the “table” use-case, not the `Vector{CustomStruct}` use-case.\n\nI am also using Arrow for the latter use-case in <https://giordano.github.io/AnalyzeRegistry.jl/dev/serialization/>","user":"UCZ7VBGUD","ts":"1614259393.060800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ftFG=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m sure "},{"type":"user","user_id":"U674T0Y9Z"},{"type":"text","text":" can comment in more detail, but our Onda.jl package (as of last week) uses Arrow to store tables of annotations and information about signals. You can see the types of the columns in the format, specified here: "},{"type":"link","url":"https://github.com/beacon-biosignals/OndaFormat#ondaannotationsarrow-files"},{"type":"text","text":". So I would say this is the “table” use-case, not the "},{"type":"text","text":"Vector{CustomStruct}","style":{"code":true}},{"type":"text","text":" use-case.\n\nI am also using Arrow for the latter use-case in "},{"type":"link","url":"https://giordano.github.io/AnalyzeRegistry.jl/dev/serialization/"}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87"},{"client_msg_id":"1a39dd82-e5f7-4bb0-bee9-e1a9753e92d7","type":"message","text":"not sure how useful it is, but as a data point: after going back and forth on this kind of thing with MsgPack a while back, my conclusion ended up being that you should always have some mechanism to enable type specification at the callsite, even if there is a different way to set/register \"global defaults\" (which can also be useful)\n\nWe do potentially hit (or I guess the better word is \"allow\") the `Vector{CustomStruct}` use case for some columns, like the column we use to represent time spans and columns that might hold custom path types. So we have stuff like <https://github.com/beacon-biosignals/Onda.jl/blob/master/src/utilities.jl#L44> floating around\n\nmaybe a relevant part of our spec: <https://github.com/beacon-biosignals/OndaFormat#overview>\n\n&gt; [The sections that define how Onda uses Arrow refers] to the <https://github.com/apache/arrow/blob/master/format/Schema.fbs|logical types defined by the Arrow specification>. Onda reader/writer implementations may additionally employ Arrow extension types that directly alias a column's specified logical type in order to support application-level features (first-class UUID support, custom `file_path` type support, etc.).\n","user":"U674T0Y9Z","ts":"1614260074.061000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DD44","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"not sure how useful it is, but as a data point: after going back and forth on this kind of thing with MsgPack a while back, my conclusion ended up being that you should always have some mechanism to enable type specification at the callsite, even if there is a different way to set/register \"global defaults\" (which can also be useful)\n\nWe do potentially hit (or I guess the better word is \"allow\") the "},{"type":"text","text":"Vector{CustomStruct}","style":{"code":true}},{"type":"text","text":" use case for some columns, like the column we use to represent time spans and columns that might hold custom path types. So we have stuff like "},{"type":"link","url":"https://github.com/beacon-biosignals/Onda.jl/blob/master/src/utilities.jl#L44"},{"type":"text","text":" floating around\n\nmaybe a relevant part of our spec: "},{"type":"link","url":"https://github.com/beacon-biosignals/OndaFormat#overview"},{"type":"text","text":"\n\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"[The sections that define how Onda uses Arrow refers] to the "},{"type":"link","url":"https://github.com/apache/arrow/blob/master/format/Schema.fbs","text":"logical types defined by the Arrow specification"},{"type":"text","text":". Onda reader/writer implementations may additionally employ Arrow extension types that directly alias a column's specified logical type in order to support application-level features (first-class UUID support, custom "},{"type":"text","text":"file_path","style":{"code":true}},{"type":"text","text":" type support, etc.)."}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87"},{"client_msg_id":"e335d8ac-bf71-4557-9838-ccc8248e397e","type":"message","text":"<@U681ELA87>, in my opinion you should not feel obligated to support serialization for arbitrary Julia types.  After all, you would need custom metadata to deserialize them consistently.  Arrow in know way promises arbitrary object serialization, it just happens to be a really flexible tabular format.  I would say that as long as you handle standard `Base` types in a reasonable way and have appropriate handling of abstract types, that's the most anyone should really be asking out of arrow.  If there's been a lesson from JLD and JLD2 it's that supporting arbitrary serialization is really hard, and I don't think you should try fitting that particular round peg into arrow's square hole","user":"U9VG1AYSG","ts":"1614263675.067000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DqV","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U681ELA87"},{"type":"text","text":", in my opinion you should not feel obligated to support serialization for arbitrary Julia types.  After all, you would need custom metadata to deserialize them consistently.  Arrow in know way promises arbitrary object serialization, it just happens to be a really flexible tabular format.  I would say that as long as you handle standard "},{"type":"text","text":"Base","style":{"code":true}},{"type":"text","text":" types in a reasonable way and have appropriate handling of abstract types, that's the most anyone should really be asking out of arrow.  If there's been a lesson from JLD and JLD2 it's that supporting arbitrary serialization is really hard, and I don't think you should try fitting that particular round peg into arrow's square hole"}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87"},{"client_msg_id":"7b8afef4-8842-4d91-a6e7-7a61be9eb649","type":"message","text":"Yeah, I'm definitely not worried about any kind of automatic or exhaustive serialization.\n\nI'm leaning towards the future where if you do `Arrow.Table(source)`, then you'll only get the Julia equivalent of standard arrow types back, and any types you do `registertype!` for. For custom types (like StaticArrays, custom structs, hetero-typed tuples, etc.), we'll have a `Arrow.Table(source, schema)` method (or something along those lines), that will allow a user to \"pull\" their own types out from the arrow-formatted data, and all they need is to define the `ArrowType` of their custom struct (though the defaults already cover most cases I think). I think moving people away from `registertype!` for custom structs towards doing this \"callsite type requesting\" will lead to a more robust deserialization story.","user":"U681ELA87","ts":"1614267713.068400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"t9I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, I'm definitely not worried about any kind of automatic or exhaustive serialization.\n\nI'm leaning towards the future where if you do "},{"type":"text","text":"Arrow.Table(source)","style":{"code":true}},{"type":"text","text":", then you'll only get the Julia equivalent of standard arrow types back, and any types you do "},{"type":"text","text":"registertype!","style":{"code":true}},{"type":"text","text":" for. For custom types (like StaticArrays, custom structs, hetero-typed tuples, etc.), we'll have a "},{"type":"text","text":"Arrow.Table(source, schema)","style":{"code":true}},{"type":"text","text":" method (or something along those lines), that will allow a user to \"pull\" their own types out from the arrow-formatted data, and all they need is to define the "},{"type":"text","text":"ArrowType","style":{"code":true}},{"type":"text","text":" of their custom struct (though the defaults already cover most cases I think). I think moving people away from "},{"type":"text","text":"registertype!","style":{"code":true}},{"type":"text","text":" for custom structs towards doing this \"callsite type requesting\" will lead to a more robust deserialization story."}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87","reactions":[{"name":"+1","users":["U9VG1AYSG","U674T0Y9Z","ULG5V164A"],"count":3}]},{"client_msg_id":"a828dd07-9eb0-4aec-9f33-aaf0b0b26d84","type":"message","text":"<@U679T6QF7> maybe you have some comments around Intervals?","user":"U69J94HT9","ts":"1614273888.073800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"O3c","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U679T6QF7"},{"type":"text","text":" maybe you have some comments around Intervals?"}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87"},{"client_msg_id":"7948793c-9b2c-4d56-80af-ebe186cd3313","type":"message","text":"I'm not sure I'm seeing the issue with the `registertype!` API :confused: I feel like having package authors register their types is nice for the end users who just need to have the package loaded and don't want to worry about explicit conversions/schemas. I think a lot of the robustness issues could be addressed by providing a more low-level serialize/deserialize API that package authors can hook into for their specific types? Seems like compatibility for custom types should be handled by the package authors? I guess I see the benefit of being able to load with just the base types vs custom types, but I feel like requiring an explicit schema to be declared by the end user isn't the answer either...","user":"U695B1S2X","ts":"1614280187.077100","team":"T68168MUP","edited":{"user":"U695B1S2X","ts":"1614281794.000000"},"blocks":[{"type":"rich_text","block_id":"GgojL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm not sure I'm seeing the issue with the "},{"type":"text","text":"registertype!","style":{"code":true}},{"type":"text","text":" API "},{"type":"emoji","name":"confused"},{"type":"text","text":" I feel like having package authors register their types is nice for the end users who just need to have the package loaded and don't want to worry about explicit conversions/schemas. I think a lot of the robustness issues could be addressed by providing a more low-level serialize/deserialize API that package authors can hook into for their specific types? Seems like compatibility for custom types should be handled by the package authors? I guess I see the benefit of being able to load with just the base types vs custom types, but I feel like requiring an explicit schema to be declared by the end user isn't the answer either..."}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87"},{"client_msg_id":"039deef8-5086-473e-8830-6bc301a765bb","type":"message","text":"second <@U9VG1AYSG>, I bet this went through ROOT's dev's head and eventually for some reason they went on with supporting 100% self-contained and arbitrary C++ class/struct/function/you-name-it monstrosity","user":"UH8A351DJ","ts":"1614310276.078500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DrhcW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"second "},{"type":"user","user_id":"U9VG1AYSG"},{"type":"text","text":", I bet this went through ROOT's dev's head and eventually for some reason they went on with supporting 100% self-contained and arbitrary C++ class/struct/function/you-name-it monstrosity"}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87"},{"client_msg_id":"128164ad-9c3a-4302-8142-46d6a74a9667","type":"message","text":"&gt; <@U679T6QF7> maybe you have some comments around Intervals?\nBased upon the issues I've seen I think we mainly just need callbacks to do transforms for serialization/deserialization. Some of the stuff done in Intervals.jl is a bit non-standard and it could be addressed by modifying what's being stored in Arrow.\n\nI'm under the impression Arrow.jl just stores the eltype of an array when storing array data. For eltypes using non-concrete types we probably should be storing the type for each element as the default. That or require custom types to handle this using callbacks","user":"U679T6QF7","ts":"1614350032.079000","team":"T68168MUP","edited":{"user":"U679T6QF7","ts":"1614350279.000000"},"blocks":[{"type":"rich_text","block_id":"TVQF","elements":[{"type":"rich_text_quote","elements":[{"type":"user","user_id":"U679T6QF7"},{"type":"text","text":" maybe you have some comments around Intervals?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nBased upon the issues I've seen I think we mainly just need callbacks to do transforms for serialization/deserialization. Some of the stuff done in Intervals.jl is a bit non-standard and it could be addressed by modifying what's being stored in Arrow.\n\nI'm under the impression Arrow.jl just stores the eltype of an array when storing array data. For eltypes using non-concrete types we probably should be storing the type for each element as the default. That or require custom types to handle this using callbacks"}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87","reactions":[{"name":"+1","users":["U695B1S2X"],"count":1}]},{"client_msg_id":"819aaa84-c711-46a3-b319-b4040a1eba62","type":"message","text":"Something else that occurs to me: we should definitely have some kind of warning in place if we serialize custom types and information could be lost (e.g. arrays with non-concrete eltypes).","user":"U679T6QF7","ts":"1614350447.079300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Qhz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Something else that occurs to me: we should definitely have some kind of warning in place if we serialize custom types and information could be lost (e.g. arrays with non-concrete eltypes)."}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87"},{"client_msg_id":"b7ac83ff-ae77-4ac1-8f38-6ff15c4d43ab","type":"message","text":"i echo <@U695B1S2X> points of having seamless serialization/deserialization where the schema specific to the data should be automatically loaded without the user tracking it. if you create a complicated structure/type, the corresponding schema which contains the detail should be hidden away from the user. i would think that the schema is part of the data and not part of the argument loading the data. you will have issue of incompatibility of schema if they are treated separately.","user":"U6SHSF4R0","ts":"1614429188.096200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SmG7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"i echo "},{"type":"user","user_id":"U695B1S2X"},{"type":"text","text":" points of having seamless serialization/deserialization where the schema specific to the data should be automatically loaded without the user tracking it. if you create a complicated structure/type, the corresponding schema which contains the detail should be hidden away from the user. i would think that the schema is part of the data and not part of the argument loading the data. you will have issue of incompatibility of schema if they are treated separately."}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87"},{"client_msg_id":"90e5f538-e4a6-4e94-be55-37d7ac7b415f","type":"message","text":"maybe there should be an api to extract the schema of the data if the user wants to scrutinize it but i think schema and data should go and sync together. changing the data type should automatically change the schema describing the data.","user":"U6SHSF4R0","ts":"1614429459.096400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ddXEb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"maybe there should be an api to extract the schema of the data if the user wants to scrutinize it but i think schema and data should go and sync together. changing the data type should automatically change the schema describing the data."}]}]}],"thread_ts":"1614228333.053300","parent_user_id":"U681ELA87"}]