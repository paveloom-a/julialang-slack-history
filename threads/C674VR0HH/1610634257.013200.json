[{"client_msg_id":"fca8c4a5-2e74-49f0-afdd-cfa4c7fca580","type":"message","text":"Given where we currently are on `leftjoin` performance, should I have any hope for `leftjoin(df1, df2)` with `size(df1) == (31635463, 7)` and `size(df2) == (564537, 2)`?","user":"U7JQGPGCQ","ts":"1610634257.013200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TXUuH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Given where we currently are on "},{"type":"text","text":"leftjoin","style":{"code":true}},{"type":"text","text":" performance, should I have any hope for "},{"type":"text","text":"leftjoin(df1, df2)","style":{"code":true}},{"type":"text","text":" with "},{"type":"text","text":"size(df1) == (31635463, 7)","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"size(df2) == (564537, 2)","style":{"code":true}},{"type":"text","text":"?"}]}]}],"thread_ts":"1610634257.013200","reply_count":9,"reply_users_count":3,"latest_reply":"1610636547.015600","reply_users":["U67431ELR","U7JQGPGCQ","U6A936746"],"subscribed":false},{"client_msg_id":"1e743153-1d6a-4335-8b8b-2c8abf264438","type":"message","text":"AFAIK we're not fast, but the algorithm is reasonably efficient so everything should work. Just try with random data? :-)","user":"U67431ELR","ts":"1610634329.013300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CcvW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"AFAIK we're not fast, but the algorithm is reasonably efficient so everything should work. Just try with random data? :-)"}]}]}],"thread_ts":"1610634257.013200","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"6a94b844-f502-4984-a6d8-e0be1aaf257f","type":"message","text":"On my actual data it's now been running for 10 minutes plus, two complications might be that (a) the joining column is a 10-20 character string and (b) I'm using `matchmissing = :equal`","user":"U7JQGPGCQ","ts":"1610634731.013500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jHkh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"On my actual data it's now been running for 10 minutes plus, two complications might be that (a) the joining column is a 10-20 character string and (b) I'm using "},{"type":"text","text":"matchmissing = :equal","style":{"code":true}}]}]}],"thread_ts":"1610634257.013200","parent_user_id":"U7JQGPGCQ","reactions":[{"name":"fearful","users":["UBF9YRB6H"],"count":1}]},{"client_msg_id":"70f02584-3c04-4fa8-8716-b689c0bc9db9","type":"message","text":"From the resource monitor the operation might be memory limited somehow? Memory goes back and forth between ~17 and 19 GB (I have 48GB on this machine)","user":"U7JQGPGCQ","ts":"1610634770.013800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cZH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"From the resource monitor the operation might be memory limited somehow? Memory goes back and forth between ~17 and 19 GB (I have 48GB on this machine)"}]}]}],"thread_ts":"1610634257.013200","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"0f699109-7f49-499a-8af6-2edffb89c100","type":"message","text":"You could convert columns first to `PooledArray` to separate that step and see which step hangs.","user":"U67431ELR","ts":"1610634830.014400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"z0SyE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You could convert columns first to "},{"type":"text","text":"PooledArray","style":{"code":true}},{"type":"text","text":" to separate that step and see which step hangs."}]}]}],"thread_ts":"1610634257.013200","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"45f7740b-6317-4a3a-8212-19faad9b39df","type":"message","text":"If the machine has free memory, then it's not the problem. But I may have been overoptimistic about our implementation. :stuck_out_tongue:","user":"U67431ELR","ts":"1610634884.014600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6mJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If the machine has free memory, then it's not the problem. But I may have been overoptimistic about our implementation. "},{"type":"emoji","name":"stuck_out_tongue"}]}]}],"thread_ts":"1610634257.013200","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"7cbaa105-168c-40ee-a553-414ab0df0548","type":"message","text":"I would love to see a branchmark against\n<https://github.com/JuliaData/SplitApplyCombine.jl>\nthough idk that it has a purely left join","user":"U6A936746","ts":"1610634926.014800","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1610634986.000000"},"blocks":[{"type":"rich_text","block_id":"yFS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I would love to see a branchmark against\n"},{"type":"link","url":"https://github.com/JuliaData/SplitApplyCombine.jl"},{"type":"text","text":"\nthough idk that it has a purely left join"}]}]}],"thread_ts":"1610634257.013200","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"f51b0aec-08b2-4128-b1ab-6e94f18e6cb4","type":"message","text":"I don't think it has - there was some discussion here (<https://github.com/JuliaData/DataFrames.jl/issues/2340>) about making it the backend for DataFrame joins, but that's WIP it seems","user":"U7JQGPGCQ","ts":"1610635479.015200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WMkf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't think it has - there was some discussion here ("},{"type":"link","url":"https://github.com/JuliaData/DataFrames.jl/issues/2340"},{"type":"text","text":") about making it the backend for DataFrame joins, but that's WIP it seems"}]}]}],"thread_ts":"1610634257.013200","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"7db3c32f-e869-4a32-a7ba-eb52c06a1ac8","type":"message","text":"Ah, my bad - `PooledArray` creation only takes 2-3 seconds for either of the joining columns, but testing on smaller subsest I notice that the `leftjoin` creates a ton of duplicates, so the final table would probably be hundreds of millions of rows...","user":"U7JQGPGCQ","ts":"1610635965.015400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TNbK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah, my bad - "},{"type":"text","text":"PooledArray","style":{"code":true}},{"type":"text","text":" creation only takes 2-3 seconds for either of the joining columns, but testing on smaller subsest I notice that the "},{"type":"text","text":"leftjoin","style":{"code":true}},{"type":"text","text":" creates a ton of duplicates, so the final table would probably be hundreds of millions of rows..."}]}]}],"thread_ts":"1610634257.013200","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"211b5487-ee18-4598-a429-de97dacc19a0","type":"message","text":"And indeed once the source of the duplicates is dealt with the right hand side df collapses to 18k rows, and I can `leftjoin` those 18k rows onto the 31m row df in ~1 minute","user":"U7JQGPGCQ","ts":"1610636547.015600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IKXL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And indeed once the source of the duplicates is dealt with the right hand side df collapses to 18k rows, and I can "},{"type":"text","text":"leftjoin","style":{"code":true}},{"type":"text","text":" those 18k rows onto the 31m row df in ~1 minute"}]}]}],"thread_ts":"1610634257.013200","parent_user_id":"U7JQGPGCQ"}]