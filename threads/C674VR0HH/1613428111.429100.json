[{"client_msg_id":"508a0373-dc67-4ea6-89bc-c7bf8f74a015","type":"message","text":"I have been thinking of how the evaluation of some of the quantities in the iteratively reweighted least squares (IRLS) algorithm for fitting glm's in the GLM package can be accelerated.  One of the tasks in every iteration is, starting from the linear predictor vector, evaluate the mean vector, the derivative of the mean w.r.t the lin. pred., etc. until you have the working weights and the working residuals, which are used in a weighted least squares calculation.  The `GlmResp` struct contains several vectors of the same length that are used in these calculations.  All of this was formulated long before Tables.jl, fused broadcasting, etc. came on the scene and it seems reasonable that using some of the new technologies there could be gains in speed.\n\nSo, starting with something like a column table (where all the columns are of the same floating point type) we want to evaluate and store several quantities in each row from other values in the same row.  Is there anything to be gained by a `Tables.rows` iterator or are those values immutable?  I have the feeling that there should be some aspects of the Tables package that can be used here but I haven't quite worked it out.","user":"UBGRZ7FSP","ts":"1613428111.429100","team":"T68168MUP","edited":{"user":"UBGRZ7FSP","ts":"1613428162.000000"},"blocks":[{"type":"rich_text","block_id":"q6Sn6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have been thinking of how the evaluation of some of the quantities in the iteratively reweighted least squares (IRLS) algorithm for fitting glm's in the GLM package can be accelerated.  One of the tasks in every iteration is, starting from the linear predictor vector, evaluate the mean vector, the derivative of the mean w.r.t the lin. pred., etc. until you have the working weights and the working residuals, which are used in a weighted least squares calculation.  The "},{"type":"text","text":"GlmResp","style":{"code":true}},{"type":"text","text":" struct contains several vectors of the same length that are used in these calculations.  All of this was formulated long before Tables.jl, fused broadcasting, etc. came on the scene and it seems reasonable that using some of the new technologies there could be gains in speed.\n\nSo, starting with something like a column table (where all the columns are of the same floating point type) we want to evaluate and store several quantities in each row from other values in the same row.  Is there anything to be gained by a "},{"type":"text","text":"Tables.rows","style":{"code":true}},{"type":"text","text":" iterator or are those values immutable?  I have the feeling that there should be some aspects of the Tables package that can be used here but I haven't quite worked it out."}]}]}],"thread_ts":"1613428111.429100","reply_count":5,"reply_users_count":3,"latest_reply":"1613506950.486300","reply_users":["UBF9YRB6H","UBGRZ7FSP","U67431ELR"],"subscribed":false},{"client_msg_id":"ab8c91d2-b287-4b93-af9b-93a6001346c4","type":"message","text":"Are you saying that having everything be a `Matrix` might not be faster than, say, a `Vector{NamedTuple}`?\n\niirc `Tables.rows` makes no guarantee about immutability. But `Tables.rowtable` does cause it creates a vector of named tuples","user":"UBF9YRB6H","ts":"1613488394.443200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VvFib","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are you saying that having everything be a "},{"type":"text","text":"Matrix","style":{"code":true}},{"type":"text","text":" might not be faster than, say, a "},{"type":"text","text":"Vector{NamedTuple}","style":{"code":true}},{"type":"text","text":"?\n\niirc "},{"type":"text","text":"Tables.rows","style":{"code":true}},{"type":"text","text":" makes no guarantee about immutability. But "},{"type":"text","text":"Tables.rowtable","style":{"code":true}},{"type":"text","text":" does cause it creates a vector of named tuples"}]}]}],"thread_ts":"1613428111.429100","parent_user_id":"UBGRZ7FSP"},{"client_msg_id":"55779a22-901e-40f8-8988-3ac506100934","type":"message","text":"On thinking about this I also came to the conclusion that writing the struct with the required vectors gathered into a matrix is probably the best way forward.  There are some vectors, `wts` and `offset` that can be empty, indicating that they are not used, so they probably should be kept as separate vectors.\n\nAnd it is easy to make a `Table` out of a `Matrix`  and a vector of names.","user":"UBGRZ7FSP","ts":"1613494364.443900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Yy6E","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"On thinking about this I also came to the conclusion that writing the struct with the required vectors gathered into a matrix is probably the best way forward.  There are some vectors, "},{"type":"text","text":"wts","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"offset","style":{"code":true}},{"type":"text","text":" that can be empty, indicating that they are not used, so they probably should be kept as separate vectors.\n\nAnd it is easy to make a "},{"type":"text","text":"Table","style":{"code":true}},{"type":"text","text":" out of a "},{"type":"text","text":"Matrix","style":{"code":true}},{"type":"text","text":"  and a vector of names."}]}]}],"thread_ts":"1613428111.429100","parent_user_id":"UBGRZ7FSP"},{"client_msg_id":"9dc2ff7a-1eb0-421c-8153-e44bab39f97d","type":"message","text":"Isn't that the current implementation? `wts` and `offset` are by default empty and there are just checks for `isempty` etc.","user":"UBF9YRB6H","ts":"1613494456.444300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OcmEZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Isn't that the current implementation? "},{"type":"text","text":"wts","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"offset","style":{"code":true}},{"type":"text","text":" are by default empty and there are just checks for "},{"type":"text","text":"isempty","style":{"code":true}},{"type":"text","text":" etc."}]}]}],"thread_ts":"1613428111.429100","parent_user_id":"UBGRZ7FSP"},{"client_msg_id":"6e89e146-6e81-4592-bfa5-5d5747ce297e","type":"message","text":"Why would Tables.jl be useful here? Once you have a matrix it sounds simpler to work with it. Cc: <@U66M57AN4>","user":"U67431ELR","ts":"1613497895.475100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5t3z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Why would Tables.jl be useful here? Once you have a matrix it sounds simpler to work with it. Cc: "},{"type":"user","user_id":"U66M57AN4"}]}]}],"thread_ts":"1613428111.429100","parent_user_id":"UBGRZ7FSP"},{"client_msg_id":"632b04c5-81d2-4cef-8133-d74345ed4857","type":"message","text":"I am referring to the response struct, `GLM.GlmResp` which, at present, has several, informally related, vectors.  The advantage of gathering these into a matrix and also storing a `Table.MatrixTable` is that you can continue to treat them as distinct vectors, `y`, `η`, `μ`, etc. but have the storage localized\n\nThe good news is that it works.  The bad news is that it doesn't really make that much of a difference in the update time - less than a 10% difference even for a response vector of length 1,000,000.","user":"UBGRZ7FSP","ts":"1613506950.486300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AEMPu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am referring to the response struct, "},{"type":"text","text":"GLM.GlmResp","style":{"code":true}},{"type":"text","text":" which, at present, has several, informally related, vectors.  The advantage of gathering these into a matrix and also storing a "},{"type":"text","text":"Table.MatrixTable","style":{"code":true}},{"type":"text","text":" is that you can continue to treat them as distinct vectors, "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":", "},{"type":"text","text":"η","style":{"code":true}},{"type":"text","text":", "},{"type":"text","text":"μ","style":{"code":true}},{"type":"text","text":", etc. but have the storage localized\n\nThe good news is that it works.  The bad news is that it doesn't really make that much of a difference in the update time - less than a 10% difference even for a response vector of length 1,000,000."}]}]}],"thread_ts":"1613428111.429100","parent_user_id":"UBGRZ7FSP"}]