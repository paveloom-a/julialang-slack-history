[{"client_msg_id":"7b0c6faf-6c6b-4549-a7a5-8a5424e923a1","type":"message","text":"Is it possible to read a csv.gz file in a \"streaming\" fashion? That is, without loading the whole uncompressed file as a bytes array. As I understand, the example from CSV.jl docs `CSV.File(transcode(GzipDecompressor, Mmap.mmap(\"a.csv.gz\"))) |&gt; DataFrame` materializes complete uncompressed file in memory.","user":"UGTUKUHLN","ts":"1610052147.358400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lWDY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it possible to read a csv.gz file in a \"streaming\" fashion? That is, without loading the whole uncompressed file as a bytes array. As I understand, the example from CSV.jl docs "},{"type":"text","text":"CSV.File(transcode(GzipDecompressor, Mmap.mmap(\"a.csv.gz\"))) |> DataFrame","style":{"code":true}},{"type":"text","text":" materializes complete uncompressed file in memory."}]}]}],"thread_ts":"1610052147.358400","reply_count":7,"reply_users_count":2,"latest_reply":"1610127748.377000","reply_users":["U681ELA87","UGTUKUHLN"],"subscribed":false},{"client_msg_id":"268961e2-87bb-499d-ad32-0e92e6e37359","type":"message","text":"You're correct; the best you could probably do is call `gunzip [file]` to unzip the file yourself out-of-process, then do regular `CSV.File(file)` which will mmap the file by default to give \"streaming\"-like performance.","user":"U681ELA87","ts":"1610052405.358600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zGm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You're correct; the best you could probably do is call "},{"type":"text","text":"gunzip [file]","style":{"code":true}},{"type":"text","text":" to unzip the file yourself out-of-process, then do regular "},{"type":"text","text":"CSV.File(file)","style":{"code":true}},{"type":"text","text":" which will mmap the file by default to give \"streaming\"-like performance."}]}]}],"thread_ts":"1610052147.358400","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"eebcb651-e577-40ad-970e-5f2623d563fb","type":"message","text":"Is there a specific reason why streamed reading is difficult here? I tried `eachline` and other stuff for `GzipDecompressorStream` and everything seems to work.","user":"UGTUKUHLN","ts":"1610052728.358800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"34rZx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there a specific reason why streamed reading is difficult here? I tried "},{"type":"text","text":"eachline","style":{"code":true}},{"type":"text","text":" and other stuff for "},{"type":"text","text":"GzipDecompressorStream","style":{"code":true}},{"type":"text","text":" and everything seems to work."}]}]}],"thread_ts":"1610052147.358400","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"d94b3387-3de6-41c6-ae3d-3e893268c0c1","type":"message","text":"Also if I'm not mistaken CSV.jl supported streamed reading before, but at some point it started giving a deprecation warning...","user":"UGTUKUHLN","ts":"1610052757.359000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n+eM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also if I'm not mistaken CSV.jl supported streamed reading before, but at some point it started giving a deprecation warning..."}]}]}],"thread_ts":"1610052147.358400","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"c0ab73c3-bd50-41be-9708-851319bd55d9","type":"message","text":"In the past, if you provided an `IO` input, CSV.jl just called `read(io)` anyway, so it was all materialized in memory anyway. Now, it's just more explicit to the user.","user":"U681ELA87","ts":"1610052814.359200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wvQV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In the past, if you provided an "},{"type":"text","text":"IO","style":{"code":true}},{"type":"text","text":" input, CSV.jl just called "},{"type":"text","text":"read(io)","style":{"code":true}},{"type":"text","text":" anyway, so it was all materialized in memory anyway. Now, it's just more explicit to the user."}]}]}],"thread_ts":"1610052147.358400","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"7283e754-6595-431b-8f55-ca591e94bb21","type":"message","text":"And why is it impossible/difficult (?) for CSV.jl to rely on functions like `eachline` so that to support any reasonable IO stream?","user":"UGTUKUHLN","ts":"1610105639.361800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+CbV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And why is it impossible/difficult (?) for CSV.jl to rely on functions like "},{"type":"text","text":"eachline","style":{"code":true}},{"type":"text","text":" so that to support any reasonable IO stream?"}]}]}],"thread_ts":"1610052147.358400","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"fc67ce18-c1c2-40d1-9eb8-f2b8e1e2d4ca","type":"message","text":"It's just an architectural decision made in CSV.jl; it relies on having a single `Vector{UInt8}` to do all parsing, so any input needs to be transformed into that form. There's a whole history of what led to that architectural decision, but mainly it's because doing direct IO primitive operations like `read(io, UInt8)` or `eachline` is fundamentally slower than processing an input as a byte vector. And the ability to use `mmap` on file inputs makes this a very viable solution since mmapping essentially allows treating a file as `Vector{UInt8}` while also getting the benefits of \"streaming\", i.e. the entire file isn't brought into memory at once.","user":"U681ELA87","ts":"1610122986.372800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Xf2h","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's just an architectural decision made in CSV.jl; it relies on having a single "},{"type":"text","text":"Vector{UInt8}","style":{"code":true}},{"type":"text","text":" to do all parsing, so any input needs to be transformed into that form. There's a whole history of what led to that architectural decision, but mainly it's because doing direct IO primitive operations like "},{"type":"text","text":"read(io, UInt8)","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"eachline","style":{"code":true}},{"type":"text","text":" is fundamentally slower than processing an input as a byte vector. And the ability to use "},{"type":"text","text":"mmap","style":{"code":true}},{"type":"text","text":" on file inputs makes this a very viable solution since mmapping essentially allows treating a file as "},{"type":"text","text":"Vector{UInt8}","style":{"code":true}},{"type":"text","text":" while also getting the benefits of \"streaming\", i.e. the entire file isn't brought into memory at once."}]}]}],"thread_ts":"1610052147.358400","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"f672d7ae-1ee0-4795-a0ed-2a6573f0ac41","type":"message","text":"I just find it uncommon to have large uncompressed csv files. They compress very well, so it makes sense to keep a 1 Gb csv.gz instead of a 10 Gb csv. Compressed reading should also be faster from anything but for fast SSDs.","user":"UGTUKUHLN","ts":"1610127748.377000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YgIRe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I just find it uncommon to have large uncompressed csv files. They compress very well, so it makes sense to keep a 1 Gb csv.gz instead of a 10 Gb csv. Compressed reading should also be faster from anything but for fast SSDs."}]}]}],"thread_ts":"1610052147.358400","parent_user_id":"UGTUKUHLN"}]