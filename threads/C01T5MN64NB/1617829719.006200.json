[{"client_msg_id":"fcf401cf-8a1f-481a-9242-5060e6f21f1f","type":"message","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?","user":"UDGT4PM41","ts":"1617829719.006200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"S=K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?"}]}]}],"thread_ts":"1617829719.006200","reply_count":25,"reply_users_count":7,"latest_reply":"1617911759.029300","reply_users":["UC6SUUPRC","U6A0PD8CR","U67BJLYCS","UM30MT6RF","UDGT4PM41","U68A3ASP9","UKA81L34J"],"is_locked":false,"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"~I’m working on my finals~ three things on my side related to compilers, one is the YaoComipler that aims to compile Julia code to  quantum hardwares. We have a working pure Julia version that has some limitations on const prop etc. so now working with <@U67BJLYCS> and <@UN3KKRCRJ> to compile the high level IR (defined using CodeInfo/IRCode) in Julia to MLIR, and planning to plugin this with what  <@UKA81L34J> is doing with brutus\n\nBQCESubroutine aims to generate optimal CPU/CUDA kernels for quantum circuit emulator or tensor network contraction (so that I don’t need to fix my manual ones inside YaoArrayRegister), It has a working version 0.1, but I’m planning to try out <@U01K2JB9GPJ>’s metatheory on this and replace my poorman’s term rewrite engine with metatheory to make the code cleaner.\n\nThere are some other interesting compiler infras such as graph rewrite engine in Julia for our Quon and ZX calculus optimizer (where people have tried such thing on mathematica) but we don’t have enough man power working on this direction at the moment in the Yao ecosystem…so we currently just use a manual schedule for the rules which seems fine given there is not much rules at the moment. but it could be necessary in the future (if we find someone working on this).","user":"UC6SUUPRC","ts":"1617831398.014400","thread_ts":"1617829719.006200","root":{"client_msg_id":"fcf401cf-8a1f-481a-9242-5060e6f21f1f","type":"message","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?","user":"UDGT4PM41","ts":"1617829719.006200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"S=K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?"}]}]}],"thread_ts":"1617829719.006200","reply_count":25,"reply_users_count":7,"latest_reply":"1617911759.029300","reply_users":["UC6SUUPRC","U6A0PD8CR","U67BJLYCS","UM30MT6RF","UDGT4PM41","U68A3ASP9","UKA81L34J"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"Y/eRO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m working on my finals","style":{"strike":true}},{"type":"text","text":" three things on my side related to compilers, one is the YaoComipler that aims to compile Julia code to  quantum hardwares. We have a working pure Julia version that has some limitations on const prop etc. so now working with "},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":" and "},{"type":"user","user_id":"UN3KKRCRJ"},{"type":"text","text":" to compile the high level IR (defined using CodeInfo/IRCode) in Julia to MLIR, and planning to plugin this with what  "},{"type":"user","user_id":"UKA81L34J"},{"type":"text","text":" is doing with brutus\n\nBQCESubroutine aims to generate optimal CPU/CUDA kernels for quantum circuit emulator or tensor network contraction (so that I don’t need to fix my manual ones inside YaoArrayRegister), It has a working version 0.1, but I’m planning to try out "},{"type":"user","user_id":"U01K2JB9GPJ"},{"type":"text","text":"’s metatheory on this and replace my poorman’s term rewrite engine with metatheory to make the code cleaner.\n\nThere are some other interesting compiler infras such as graph rewrite engine in Julia for our Quon and ZX calculus optimizer (where people have tried such thing on mathematica) but we don’t have enough man power working on this direction at the moment in the Yao ecosystem…so we currently just use a manual schedule for the rules which seems fine given there is not much rules at the moment. but it could be necessary in the future (if we find someone working on this)."}]}]}],"client_msg_id":"61c3dbee-65d1-4201-985a-392b001801af","edited":{"user":"UC6SUUPRC","ts":"1617831612.000000"}},{"type":"message","subtype":"thread_broadcast","text":"I'm working on eBPF codegen for Julia, which lets us run basic Julia code within the Linux kernel pretty easily. A user recently commented/requested that we be able to run a full REPL in the kernel, which is an insane idea, but I might just implement some parts of that functionality for fun and profit.","user":"U6A0PD8CR","ts":"1617832965.015200","thread_ts":"1617829719.006200","root":{"client_msg_id":"fcf401cf-8a1f-481a-9242-5060e6f21f1f","type":"message","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?","user":"UDGT4PM41","ts":"1617829719.006200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"S=K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?"}]}]}],"thread_ts":"1617829719.006200","reply_count":25,"reply_users_count":7,"latest_reply":"1617911759.029300","reply_users":["UC6SUUPRC","U6A0PD8CR","U67BJLYCS","UM30MT6RF","UDGT4PM41","U68A3ASP9","UKA81L34J"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"Fu2S0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm working on eBPF codegen for Julia, which lets us run basic Julia code within the Linux kernel pretty easily. A user recently commented/requested that we be able to run a full REPL in the kernel, which is an insane idea, but I might just implement some parts of that functionality for fun and profit."}]}]}],"client_msg_id":"e38ec545-d32c-4ca3-a3ff-3270cd39ff40"},{"type":"message","subtype":"thread_broadcast","text":"I nerdsnipe people","user":"U67BJLYCS","ts":"1617833062.015500","thread_ts":"1617829719.006200","root":{"client_msg_id":"fcf401cf-8a1f-481a-9242-5060e6f21f1f","type":"message","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?","user":"UDGT4PM41","ts":"1617829719.006200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"S=K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?"}]}]}],"thread_ts":"1617829719.006200","reply_count":25,"reply_users_count":7,"latest_reply":"1617911759.029300","reply_users":["UC6SUUPRC","U6A0PD8CR","U67BJLYCS","UM30MT6RF","UDGT4PM41","U68A3ASP9","UKA81L34J"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"DvpZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I nerdsnipe people"}]}]}],"client_msg_id":"e18c201b-9af8-4814-8980-632f2297c490","reactions":[{"name":"point_up","users":["UC6SUUPRC","UKA81L34J","UMY1LV01G","UH1BLK14H","U01K2JB9GPJ"],"count":5},{"name":"juliaspinner","users":["UC6SUUPRC","U6A0PD8CR"],"count":2},{"name":"troll","users":["UMY1LV01G"],"count":1}]},{"type":"message","subtype":"thread_broadcast","text":"I am still getting my feet wet a bit with AbstractInterpreters and Julia's middle end in general. If anyone has some ideas/issues regarding the afromentioned projects that aren't too vast in scope, I'd very much like to talk.","user":"UM30MT6RF","ts":"1617908687.024500","thread_ts":"1617829719.006200","root":{"client_msg_id":"fcf401cf-8a1f-481a-9242-5060e6f21f1f","type":"message","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?","user":"UDGT4PM41","ts":"1617829719.006200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"S=K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?"}]}]}],"thread_ts":"1617829719.006200","reply_count":25,"reply_users_count":7,"latest_reply":"1617911759.029300","reply_users":["UC6SUUPRC","U6A0PD8CR","U67BJLYCS","UM30MT6RF","UDGT4PM41","U68A3ASP9","UKA81L34J"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"gg=/p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am still getting my feet wet a bit with AbstractInterpreters and Julia's middle end in general. If anyone has some ideas/issues regarding the afromentioned projects that aren't too vast in scope, I'd very much like to talk."}]}]}],"client_msg_id":"8a4afc08-8ef2-41a6-aaee-0488e6402b4d"},{"client_msg_id":"87e1ff4d-ce17-4b9a-a497-ef1647036a6b","type":"message","text":"<@UM30MT6RF>- <@U01K2JB9GPJ> is looking for someone to help with loading IR into egraphs using the generic terms interface","user":"UDGT4PM41","ts":"1617908762.024800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MlR7","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UM30MT6RF"},{"type":"text","text":"- "},{"type":"user","user_id":"U01K2JB9GPJ"},{"type":"text","text":" is looking for someone to help with loading IR into egraphs using the generic terms interface"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"268ff5a1-8caa-4d2a-aaf6-555fc7a41076","type":"message","text":"I must admit that I know embarrassingly little about egraphs, so I am a bit unsure what would be required there and how hard this would be.","user":"UM30MT6RF","ts":"1617908987.025000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Pwy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I must admit that I know embarrassingly little about egraphs, so I am a bit unsure what would be required there and how hard this would be."}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"1f4ad1f3-8ebf-4720-a3fb-cd3640a73dcd","type":"message","text":"getting rid of `@nospecialize` for GPU code, although there might be a codegen part too, I'm not sure","user":"U68A3ASP9","ts":"1617909699.025200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sO=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"getting rid of "},{"type":"text","text":"@nospecialize","style":{"code":true}},{"type":"text","text":" for GPU code, although there might be a codegen part too, I'm not sure"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"a3e3953d-95ca-4fd1-a831-1a49be665683","type":"message","text":"What is the reason this is required in the first place? Is this related to <https://github.com/JuliaLang/julia/pull/39697|https://github.com/JuliaLang/julia/pull/39697>, or is that mostly orthogonal?","user":"UM30MT6RF","ts":"1617909964.025400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nOl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is the reason this is required in the first place? Is this related to "},{"type":"link","url":"https://github.com/JuliaLang/julia/pull/39697","text":"https://github.com/JuliaLang/julia/pull/39697"},{"type":"text","text":", or is that mostly orthogonal?"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"422795b4-bd87-4a16-b99b-1248b467e9f2","type":"message","text":"no that's orthogonal. `@nospecialize` results in boxed arguments, and a `jl_invoke` to call the function, both of which aren't really nice for static compilation (like GPU compilation)","user":"U68A3ASP9","ts":"1617910189.025600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2WvP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"no that's orthogonal. "},{"type":"text","text":"@nospecialize","style":{"code":true}},{"type":"text","text":" results in boxed arguments, and a "},{"type":"text","text":"jl_invoke","style":{"code":true}},{"type":"text","text":" to call the function, both of which aren't really nice for static compilation (like GPU compilation)"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"adb46420-ba1f-4265-8aa2-f4491ac5245c","type":"message","text":"```julia&gt; @noinline foo(i)=i+1\nfoo (generic function with 1 method)\n\njulia&gt; @noinline bar(@nospecialize(i))=i+1\nbar (generic function with 1 method)\n\njulia&gt; qux(f,i)=f(i)\nqux (generic function with 1 method)\n\njulia&gt; @code_llvm qux(foo,42)\n\n;  @ REPL[8]:1 within `qux'\ndefine i64 @julia_qux_162(i64) {\ntop:\n  %1 = call i64 @j_foo_163(i64 %0)\n  ret i64 %1\n}\n\njulia&gt; @code_llvm qux(bar,42)\n\n;  @ REPL[8]:1 within `qux'\ndefine i64 @julia_qux_171(i64) {\ntop:\n  %1 = alloca %jl_value_t*\n  %gcframe = alloca %jl_value_t*, i32 3, align 16\n  %2 = bitcast %jl_value_t** %gcframe to i8*\n  call void @llvm.memset.p0i8.i32(i8* align 16 %2, i8 0, i32 24, i1 false)\n  %thread_ptr = call i8* asm \"movq %fs:0, $0\", \"=r\"()\n  %ptls_i8 = getelementptr i8, i8* %thread_ptr, i64 -15720\n  %ptls = bitcast i8* %ptls_i8 to %jl_value_t***\n  %3 = getelementptr %jl_value_t*, %jl_value_t** %gcframe, i32 0\n  %4 = bitcast %jl_value_t** %3 to i64*\n  store i64 4, i64* %4\n  %5 = getelementptr %jl_value_t**, %jl_value_t*** %ptls, i32 0\n  %6 = getelementptr %jl_value_t*, %jl_value_t** %gcframe, i32 1\n  %7 = bitcast %jl_value_t** %6 to %jl_value_t***\n  %8 = load %jl_value_t**, %jl_value_t*** %5\n  store %jl_value_t** %8, %jl_value_t*** %7\n  %9 = bitcast %jl_value_t*** %5 to %jl_value_t***\n  store %jl_value_t** %gcframe, %jl_value_t*** %9\n  %10 = call %jl_value_t* @jl_box_int64(i64 signext %0)\n  %11 = getelementptr %jl_value_t*, %jl_value_t** %gcframe, i32 2\n  store %jl_value_t* %10, %jl_value_t** %11\n  %12 = getelementptr %jl_value_t*, %jl_value_t** %1, i32 0\n  store %jl_value_t* %10, %jl_value_t** %12\n  %13 = call nonnull %jl_value_t* @jl_invoke(%jl_value_t* inttoptr (i64 140443855585464 to %jl_value_t*), %jl_value_t** %1, i32 1, %jl_value_t* inttoptr (i64 140443864352528 to %jl_value_t*))\n  %14 = bitcast %jl_value_t* %13 to i64*\n  %15 = load i64, i64* %14, align 8\n  %16 = getelementptr %jl_value_t*, %jl_value_t** %gcframe, i32 1\n  %17 = load %jl_value_t*, %jl_value_t** %16\n  %18 = getelementptr %jl_value_t**, %jl_value_t*** %ptls, i32 0\n  %19 = bitcast %jl_value_t*** %18 to %jl_value_t**\n  store %jl_value_t* %17, %jl_value_t** %19\n  ret i64 %15\n}```","user":"U68A3ASP9","ts":"1617910276.025800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CcH","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @noinline foo(i)=i+1\nfoo (generic function with 1 method)\n\njulia> @noinline bar(@nospecialize(i))=i+1\nbar (generic function with 1 method)\n\njulia> qux(f,i)=f(i)\nqux (generic function with 1 method)\n\njulia> @code_llvm qux(foo,42)\n\n;  @ REPL[8]:1 within `qux'\ndefine i64 @julia_qux_162(i64) {\ntop:\n  %1 = call i64 @j_foo_163(i64 %0)\n  ret i64 %1\n}\n\njulia> @code_llvm qux(bar,42)\n\n;  @ REPL[8]:1 within `qux'\ndefine i64 @julia_qux_171(i64) {\ntop:\n  %1 = alloca %jl_value_t*\n  %gcframe = alloca %jl_value_t*, i32 3, align 16\n  %2 = bitcast %jl_value_t** %gcframe to i8*\n  call void @llvm.memset.p0i8.i32(i8* align 16 %2, i8 0, i32 24, i1 false)\n  %thread_ptr = call i8* asm \"movq %fs:0, $0\", \"=r\"()\n  %ptls_i8 = getelementptr i8, i8* %thread_ptr, i64 -15720\n  %ptls = bitcast i8* %ptls_i8 to %jl_value_t***\n  %3 = getelementptr %jl_value_t*, %jl_value_t** %gcframe, i32 0\n  %4 = bitcast %jl_value_t** %3 to i64*\n  store i64 4, i64* %4\n  %5 = getelementptr %jl_value_t**, %jl_value_t*** %ptls, i32 0\n  %6 = getelementptr %jl_value_t*, %jl_value_t** %gcframe, i32 1\n  %7 = bitcast %jl_value_t** %6 to %jl_value_t***\n  %8 = load %jl_value_t**, %jl_value_t*** %5\n  store %jl_value_t** %8, %jl_value_t*** %7\n  %9 = bitcast %jl_value_t*** %5 to %jl_value_t***\n  store %jl_value_t** %gcframe, %jl_value_t*** %9\n  %10 = call %jl_value_t* @jl_box_int64(i64 signext %0)\n  %11 = getelementptr %jl_value_t*, %jl_value_t** %gcframe, i32 2\n  store %jl_value_t* %10, %jl_value_t** %11\n  %12 = getelementptr %jl_value_t*, %jl_value_t** %1, i32 0\n  store %jl_value_t* %10, %jl_value_t** %12\n  %13 = call nonnull %jl_value_t* @jl_invoke(%jl_value_t* inttoptr (i64 140443855585464 to %jl_value_t*), %jl_value_t** %1, i32 1, %jl_value_t* inttoptr (i64 140443864352528 to %jl_value_t*))\n  %14 = bitcast %jl_value_t* %13 to i64*\n  %15 = load i64, i64* %14, align 8\n  %16 = getelementptr %jl_value_t*, %jl_value_t** %gcframe, i32 1\n  %17 = load %jl_value_t*, %jl_value_t** %16\n  %18 = getelementptr %jl_value_t**, %jl_value_t*** %ptls, i32 0\n  %19 = bitcast %jl_value_t*** %18 to %jl_value_t**\n  store %jl_value_t* %17, %jl_value_t** %19\n  ret i64 %15\n}"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"7a1bda27-4688-4359-9114-e2073f6762ed","type":"message","text":"Ah, I see. What would need to be done still to eliminate this requirement?","user":"UM30MT6RF","ts":"1617910348.026000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DQQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah, I see. What would need to be done still to eliminate this requirement?"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"106a4419-3979-4d72-90f9-2882068b1d73","type":"message","text":"figure out which part of the middle end needs to be parameterized on the GPUCompiler's AbstractInterpreter to get rid of whatever `@nospecialize` does :-)","user":"U68A3ASP9","ts":"1617910461.026200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"b5Ik","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"figure out which part of the middle end needs to be parameterized on the GPUCompiler's AbstractInterpreter to get rid of whatever "},{"type":"text","text":"@nospecialize","style":{"code":true}},{"type":"text","text":" does :-)"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"0cd3d41d-3e42-4ddc-9b55-1ef07e69cb92","type":"message","text":"I haven't really looked at it yet","user":"U68A3ASP9","ts":"1617910527.026400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Uaz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I haven't really looked at it yet"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"a0892183-bd5b-4237-bacd-07a4f2781cb6","type":"message","text":"for static compilation, we basically want to ignore `@nospecialize` and specialize regardless","user":"U68A3ASP9","ts":"1617910649.026600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sfwWu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"for static compilation, we basically want to ignore "},{"type":"text","text":"@nospecialize","style":{"code":true}},{"type":"text","text":" and specialize regardless"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"c164cf99-84fd-4e4e-bee4-af8354e63940","type":"message","text":"If you have some initial pointers for me and don't mind me bothering you with dumb questions, I could certainly give it a stab.","user":"UM30MT6RF","ts":"1617910742.026800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5CD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you have some initial pointers for me and don't mind me bothering you with dumb questions, I could certainly give it a stab."}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"fac14c19-f160-4aca-8553-cf31609c7427","type":"message","text":"yeah sure, I'll create an issue with some more details tomorrow. you don't have to do this of course, it was just a thought :slightly_smiling_face: regardless, GPUCompiler.jl might be an interesting starting point since it has many of the AbstractInterpreter parts hooked up in a ready-to-use manner:\n```~/Julia/pkg/GPUCompiler$ jl --project -L test/definitions/native.jl\njulia&gt; @noinline foo(i) = i+1\nfoo (generic function with 1 method)\n\njulia&gt; @noinline bar(@nospecialize(i)) = i+1\nbar (generic function with 1 method)\n\njulia&gt; qux(f,i)=f(i)\nqux (generic function with 1 method)\n\njulia&gt; native_code_llvm(qux, Tuple{typeof(foo),Int})\n;  @ REPL[3]:1 within `qux'\ndefine i64 @julia_qux_685(i64 signext %0) local_unnamed_addr {\ntop:\n  %1 = call fastcc i64 @julia_foo_688(i64 signext %0)\n  ret i64 %1\n}\n\njulia&gt; native_code_llvm(qux, Tuple{typeof(bar),Int})\n;  @ REPL[3]:1 within `qux'\ndefine i64 @julia_qux_2130(i64 signext %0) local_unnamed_addr {\ntop:\n  %1 = alloca {}*, align 8\n  %2 = call fastcc nonnull {}* @jl_box_int64(i64 signext %0)\n  %3 = getelementptr inbounds {}*, {}** %1, i32 0\n  store {}* %2, {}** %3, align 8\n  %4 = call nonnull {}* @jl_invoke({}* inttoptr (i64 140434338236720 to {}*), {}** %1, i32 1, {}* inttoptr (i64 140434302870528 to {}*))\n  %5 = bitcast {}* %4 to i64*\n  %6 = load i64, i64* %5, align 8\n  ret i64 %6\n}```","user":"U68A3ASP9","ts":"1617911222.027000","team":"T68168MUP","edited":{"user":"U68A3ASP9","ts":"1617911235.000000"},"blocks":[{"type":"rich_text","block_id":"6ScB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah sure, I'll create an issue with some more details tomorrow. you don't have to do this of course, it was just a thought "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" regardless, GPUCompiler.jl might be an interesting starting point since it has many of the AbstractInterpreter parts hooked up in a ready-to-use manner:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"~/Julia/pkg/GPUCompiler$ jl --project -L test/definitions/native.jl\njulia> @noinline foo(i) = i+1\nfoo (generic function with 1 method)\n\njulia> @noinline bar(@nospecialize(i)) = i+1\nbar (generic function with 1 method)\n\njulia> qux(f,i)=f(i)\nqux (generic function with 1 method)\n\njulia> native_code_llvm(qux, Tuple{typeof(foo),Int})\n;  @ REPL[3]:1 within `qux'\ndefine i64 @julia_qux_685(i64 signext %0) local_unnamed_addr {\ntop:\n  %1 = call fastcc i64 @julia_foo_688(i64 signext %0)\n  ret i64 %1\n}\n\njulia> native_code_llvm(qux, Tuple{typeof(bar),Int})\n;  @ REPL[3]:1 within `qux'\ndefine i64 @julia_qux_2130(i64 signext %0) local_unnamed_addr {\ntop:\n  %1 = alloca {}*, align 8\n  %2 = call fastcc nonnull {}* @jl_box_int64(i64 signext %0)\n  %3 = getelementptr inbounds {}*, {}** %1, i32 0\n  store {}* %2, {}** %3, align 8\n  %4 = call nonnull {}* @jl_invoke({}* inttoptr (i64 140434338236720 to {}*), {}** %1, i32 1, {}* inttoptr (i64 140434302870528 to {}*))\n  %5 = bitcast {}* %4 to i64*\n  %6 = load i64, i64* %5, align 8\n  ret i64 %6\n}"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41","reactions":[{"name":"heart","users":["UM30MT6RF"],"count":1}]},{"client_msg_id":"f2259dfa-3082-46d5-9755-05f090c8c009","type":"message","text":"So what I would do is search `base/compiler` for `:nospecialize`, notice that it doesn't use that at all and then look in `src/`... showing that is is implemented in scheme and method.c","user":"U67BJLYCS","ts":"1617911274.027400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RBQS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So what I would do is search "},{"type":"text","text":"base/compiler","style":{"code":true}},{"type":"text","text":" for "},{"type":"text","text":":nospecialize","style":{"code":true}},{"type":"text","text":", notice that it doesn't use that at all and then look in "},{"type":"text","text":"src/","style":{"code":true}},{"type":"text","text":"... showing that is is implemented in scheme and method.c"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"5e5f6589-d6a4-4484-ab60-7e7865373fd6","type":"message","text":"so `nospecialize` sets a flag on on the method","user":"U67BJLYCS","ts":"1617911309.027600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"R+aq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so "},{"type":"text","text":"nospecialize","style":{"code":true}},{"type":"text","text":" sets a flag on on the method"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"6f06f208-87dc-4cb2-b7a7-fa0ecaeed259","type":"message","text":"and then checked in `gf.c`","user":"U67BJLYCS","ts":"1617911400.027800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Qy8k","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and then checked in "},{"type":"text","text":"gf.c","style":{"code":true}}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"2c05bbb0-155e-4a9f-b8cb-487cba46bb1a","type":"message","text":"now the issue is that it is on the `jl_method_t` and that is shared between the GPU compiler and Julia base","user":"U67BJLYCS","ts":"1617911442.028000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6J5Q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"now the issue is that it is on the "},{"type":"text","text":"jl_method_t","style":{"code":true}},{"type":"text","text":" and that is shared between the GPU compiler and Julia base"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"0f52aeca-3fca-46f5-b372-7f9919648290","type":"message","text":"ah crap","user":"U68A3ASP9","ts":"1617911531.028300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TpxF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ah crap"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"client_msg_id":"973f8832-69f6-45fa-aa8a-bb6cd1c4ac13","type":"message","text":"Did I just nerd snipe the nerd sniper? :troll:","user":"UM30MT6RF","ts":"1617911570.028500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PsJF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Did I just nerd snipe the nerd sniper? "},{"type":"emoji","name":"troll"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41","reactions":[{"name":"smile","users":["U68A3ASP9"],"count":1}]},{"client_msg_id":"ba95f896-3264-4b5a-996d-6ed299317308","type":"message","text":"haha... no I was trying to but breadcrumbs ontop your path","user":"U67BJLYCS","ts":"1617911599.028800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kvSsL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"haha... no I was trying to but breadcrumbs ontop your path"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41","reactions":[{"name":"heart","users":["UM30MT6RF"],"count":1}]},{"client_msg_id":"26fa45da-72df-40c6-ba4e-9e6c0e07c096","type":"message","text":"Definitely appreciated!","user":"UM30MT6RF","ts":"1617911636.029000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XVWN4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Definitely appreciated!"}]}]}],"thread_ts":"1617829719.006200","parent_user_id":"UDGT4PM41"},{"type":"message","subtype":"thread_broadcast","text":"Re — messing around with infra: I recently setup a small package which uses `GPUCompiler.jl` interfaces + `AbstractInterpreter` to setup a pipeline with a hook into `InferenceState` — this allows you to see and transform `CodeInfo` before the lowered code is inferred: <https://github.com/femtomc/Mixtape.jl>\n\nI’ve been thinking about this as a “static” Cassette-like thing — but there’s issues. It obviously requires static compilation (as `GPUCompiler` does). Using `AbstractInterpreter` doesn’t compose well with other packages which use it — like I can’t figure out a way to compose this package with something like `JET.jl` for example.\n\nOn the other hand, there are benefits:\n1. Doesn’t pollute the call stack with `overdub`\n2. Doesn’t rely on generated functions or recursively expand them on the call stack at runtime.\nI think potentially exposing the hook in `InferenceState` in such a way that it is agnostic of the `AbstractInterpreter` might be interesting.","user":"UKA81L34J","ts":"1617911759.029300","thread_ts":"1617829719.006200","root":{"client_msg_id":"fcf401cf-8a1f-481a-9242-5060e6f21f1f","type":"message","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?","user":"UDGT4PM41","ts":"1617829719.006200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"S=K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe everyone wants to go around and talk about what they're working on, interests and questions?"}]}]}],"thread_ts":"1617829719.006200","reply_count":25,"reply_users_count":7,"latest_reply":"1617911759.029300","reply_users":["UC6SUUPRC","U6A0PD8CR","U67BJLYCS","UM30MT6RF","UDGT4PM41","U68A3ASP9","UKA81L34J"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"ZYR","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Re — messing around with infra: I recently setup a small package which uses "},{"type":"text","text":"GPUCompiler.jl","style":{"code":true}},{"type":"text","text":" interfaces + "},{"type":"text","text":"AbstractInterpreter","style":{"code":true}},{"type":"text","text":" to setup a pipeline with a hook into "},{"type":"text","text":"InferenceState","style":{"code":true}},{"type":"text","text":" — this allows you to see and transform "},{"type":"text","text":"CodeInfo","style":{"code":true}},{"type":"text","text":" before the lowered code is inferred: "},{"type":"link","url":"https://github.com/femtomc/Mixtape.jl"},{"type":"text","text":"\n\nI’ve been thinking about this as a “static” Cassette-like thing — but there’s issues. It obviously requires static compilation (as "},{"type":"text","text":"GPUCompiler","style":{"code":true}},{"type":"text","text":" does). Using "},{"type":"text","text":"AbstractInterpreter","style":{"code":true}},{"type":"text","text":" doesn’t compose well with other packages which use it — like I can’t figure out a way to compose this package with something like "},{"type":"text","text":"JET.jl","style":{"code":true}},{"type":"text","text":" for example.\n\nOn the other hand, there are benefits:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Doesn’t pollute the call stack with "},{"type":"text","text":"overdub","style":{"code":true}}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Doesn’t rely on generated functions or recursively expand them on the call stack at runtime."}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"\nI think potentially exposing the hook in "},{"type":"text","text":"InferenceState","style":{"code":true}},{"type":"text","text":" in such a way that it is agnostic of the "},{"type":"text","text":"AbstractInterpreter","style":{"code":true}},{"type":"text","text":" might be interesting."}]}]}],"client_msg_id":"c73af863-b16a-474f-a124-ae0d3dd97602","edited":{"user":"UKA81L34J","ts":"1617911893.000000"}}]