[{"client_msg_id":"db9c79d6-c647-42ec-a4ee-c77ea92ad623","type":"message","text":"If I were to make a 3d navigation game, something like <https://www.youtube.com/watch?v=M40rN7afngY> , how should I begin? I am a complete newbie to such a project, having no clue about 3d rendering or how to handle user input. The main purpose of this project is to use this game as an environment for reinforcement learning. This is more like a simulator, as opposed to a \"game\" that can be played and enjoyed by humans like normal games. But I would like to have interactivity via keyboard inputs.\n\nWhat is the quickest way to prototype such a simulator? Should I use Makie.jl for this purpose?\n\nThanks in advance!","user":"U0190AJCYK0","ts":"1617910640.016900","team":"T68168MUP","attachments":[{"service_name":"YouTube","service_url":"https://www.youtube.com/","title":"DeepMind Lab - Nav Maze Level 1","title_link":"https://www.youtube.com/watch?v=M40rN7afngY","author_name":"DeepMind","author_link":"https://www.youtube.com/c/DeepMind","thumb_url":"https://i.ytimg.com/vi/M40rN7afngY/hqdefault.jpg","thumb_width":480,"thumb_height":360,"fallback":"YouTube Video: DeepMind Lab - Nav Maze Level 1","video_html":"<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/M40rN7afngY?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","video_html_width":400,"video_html_height":225,"from_url":"https://www.youtube.com/watch?v=M40rN7afngY","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png","id":1,"original_url":"https://www.youtube.com/watch?v=M40rN7afngY"}],"blocks":[{"type":"rich_text","block_id":"djI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If I were to make a 3d navigation game, something like "},{"type":"link","url":"https://www.youtube.com/watch?v=M40rN7afngY"},{"type":"text","text":" , how should I begin? I am a complete newbie to such a project, having no clue about 3d rendering or how to handle user input. The main purpose of this project is to use this game as an environment for reinforcement learning. This is more like a simulator, as opposed to a \"game\" that can be played and enjoyed by humans like normal games. But I would like to have interactivity via keyboard inputs.\n\nWhat is the quickest way to prototype such a simulator? Should I use Makie.jl for this purpose?\n\nThanks in advance!"}]}]}],"thread_ts":"1617910640.016900","reply_count":8,"reply_users_count":3,"latest_reply":"1617984815.019200","reply_users":["U9MD78Z9N","UQMHE3ER4","U0190AJCYK0"],"is_locked":false,"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"Makie doesn't seem that appropriate. Let me ask some questions:\n - Do you want the renderer to be differentiable or not?\n - Do you want to pre render some frames offline and use them to in training or do you want the network to be trained while it's interacting with the environment?\n - Are you familiar with GPU programming?\n - Are you more CPU or GPU constrained?\n - Do the objects have to be 3d or would 2d shapes always visible for the player also be sufficient?\n - How many frames per second do you expect your network to eat?\n - What resolution will your network eat?\n\nMy general recommendation would be to write stand alone render code (rendering into an buffer) and tie that up with game logic. You can later use this bundle from your  training loop or take something like GameZero, throw your buffer to the screen and record input from the player. I would go with fixed time steps. As for how to accomplish this graphics style, it is awfully simiöar to Wolfenstein3d, here is a video with the ideas how to implement it <https://www.youtube.com/watch?v=eOCQfxRQ2pY>\n\nOh yeah a straightforward math implemenation should be good enough on modern processors","user":"U9MD78Z9N","ts":"1617912516.017200","thread_ts":"1617910640.016900","root":{"client_msg_id":"db9c79d6-c647-42ec-a4ee-c77ea92ad623","type":"message","text":"If I were to make a 3d navigation game, something like <https://www.youtube.com/watch?v=M40rN7afngY> , how should I begin? I am a complete newbie to such a project, having no clue about 3d rendering or how to handle user input. The main purpose of this project is to use this game as an environment for reinforcement learning. This is more like a simulator, as opposed to a \"game\" that can be played and enjoyed by humans like normal games. But I would like to have interactivity via keyboard inputs.\n\nWhat is the quickest way to prototype such a simulator? Should I use Makie.jl for this purpose?\n\nThanks in advance!","user":"U0190AJCYK0","ts":"1617910640.016900","team":"T68168MUP","attachments":[{"service_name":"YouTube","service_url":"https://www.youtube.com/","title":"DeepMind Lab - Nav Maze Level 1","title_link":"https://www.youtube.com/watch?v=M40rN7afngY","author_name":"DeepMind","author_link":"https://www.youtube.com/c/DeepMind","thumb_url":"https://i.ytimg.com/vi/M40rN7afngY/hqdefault.jpg","thumb_width":480,"thumb_height":360,"fallback":"YouTube Video: DeepMind Lab - Nav Maze Level 1","video_html":"<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/M40rN7afngY?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","video_html_width":400,"video_html_height":225,"from_url":"https://www.youtube.com/watch?v=M40rN7afngY","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png","id":1,"original_url":"https://www.youtube.com/watch?v=M40rN7afngY"}],"blocks":[{"type":"rich_text","block_id":"djI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If I were to make a 3d navigation game, something like "},{"type":"link","url":"https://www.youtube.com/watch?v=M40rN7afngY"},{"type":"text","text":" , how should I begin? I am a complete newbie to such a project, having no clue about 3d rendering or how to handle user input. The main purpose of this project is to use this game as an environment for reinforcement learning. This is more like a simulator, as opposed to a \"game\" that can be played and enjoyed by humans like normal games. But I would like to have interactivity via keyboard inputs.\n\nWhat is the quickest way to prototype such a simulator? Should I use Makie.jl for this purpose?\n\nThanks in advance!"}]}]}],"thread_ts":"1617910640.016900","reply_count":8,"reply_users_count":3,"latest_reply":"1617984815.019200","reply_users":["U9MD78Z9N","UQMHE3ER4","U0190AJCYK0"],"is_locked":false,"subscribed":false},"attachments":[{"service_name":"YouTube","service_url":"https://www.youtube.com/","title":"Wolfenstein 3D's map renderer","title_link":"https://www.youtube.com/watch?v=eOCQfxRQ2pY","author_name":"Matt Godbolt","author_link":"https://www.youtube.com/c/MattGodbolt","thumb_url":"https://i.ytimg.com/vi/eOCQfxRQ2pY/hqdefault.jpg","thumb_width":480,"thumb_height":360,"fallback":"YouTube Video: Wolfenstein 3D's map renderer","video_html":"<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/eOCQfxRQ2pY?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","video_html_width":400,"video_html_height":225,"from_url":"https://www.youtube.com/watch?v=eOCQfxRQ2pY","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png","id":1,"original_url":"https://www.youtube.com/watch?v=eOCQfxRQ2pY"}],"edited":{"user":"U9MD78Z9N","ts":"1617913064.000000"}},{"type":"message","text":"There is also <https://www.youtube.com/watch?v=cdwLJCb45Kk>","user":"U9MD78Z9N","ts":"1617913602.017900","team":"T68168MUP","attachments":[{"service_name":"YouTube","service_url":"https://www.youtube.com/","title":"JuliaCon 2019 | Differentiable Rendering and its Applications in Deep Learning | Avik Pal","title_link":"https://www.youtube.com/watch?v=cdwLJCb45Kk","author_name":"The Julia Programming Language","author_link":"https://www.youtube.com/user/JuliaLanguage","thumb_url":"https://i.ytimg.com/vi/cdwLJCb45Kk/hqdefault.jpg","thumb_width":480,"thumb_height":360,"fallback":"YouTube Video: JuliaCon 2019 | Differentiable Rendering and its Applications in Deep Learning | Avik Pal","video_html":"<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/cdwLJCb45Kk?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","video_html_width":400,"video_html_height":225,"from_url":"https://www.youtube.com/watch?v=cdwLJCb45Kk","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png","id":1,"original_url":"https://www.youtube.com/watch?v=cdwLJCb45Kk"}],"thread_ts":"1617910640.016900","parent_user_id":"U0190AJCYK0"},{"client_msg_id":"397e884d-e67f-4843-b050-3fa1917d11e5","type":"message","text":"If you were to do what the video does in Makie:\n• You'd probably need to write your own 3d camera. One that reacts to key inputs rather than mouse inputs, has view bobbing and otherwise stays at a set height. This is probably not that hard, you can copy and paste what's there and adjust it to your needs.\n• You probably want to avoid figures and axes and whatnot and just work with two overlapping `Scene()`s. One in pixel space (pixel camera), one in world space (3d camera) and the child one with `clear = false` so it doesn't draw over the other. Every plot should have `show_axis = false` (or `raw = false`?) to avoid creating axes. \n• If your inputs get complex and you need blocking inputs/events you may want to work with <https://github.com/JuliaPlots/AbstractPlotting.jl/pull/634> \n• Regarding plotting function it's probably just `mesh!` and m`eshscatter!` . Animated textures should work via observables, though that's probably not very efficient. \n• You can use `colorbuffer(screen)` and `depthbuffer(screen)` where `screen = display(scene)` if you need them. If you need/want the gl buffers you can get them from `screen.framebuffer.buffers`\n• if you want to do things for each frame you can react to `screen.render_tick` ","user":"UQMHE3ER4","ts":"1617914155.018200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"M6t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you were to do what the video does in Makie:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You'd probably need to write your own 3d camera. One that reacts to key inputs rather than mouse inputs, has view bobbing and otherwise stays at a set height. This is probably not that hard, you can copy and paste what's there and adjust it to your needs."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"You probably want to avoid figures and axes and whatnot and just work with two overlapping "},{"type":"text","text":"Scene()","style":{"code":true}},{"type":"text","text":"s. One in pixel space (pixel camera), one in world space (3d camera) and the child one with "},{"type":"text","text":"clear = false","style":{"code":true}},{"type":"text","text":" so it doesn't draw over the other. Every plot should have "},{"type":"text","text":"show_axis = false","style":{"code":true}},{"type":"text","text":" (or "},{"type":"text","text":"raw = false","style":{"code":true}},{"type":"text","text":"?) to avoid creating axes. "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"If your inputs get complex and you need blocking inputs/events you may want to work with "},{"type":"link","url":"https://github.com/JuliaPlots/AbstractPlotting.jl/pull/634"},{"type":"text","text":" "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Regarding plotting function it's probably just "},{"type":"text","text":"mesh!","style":{"code":true}},{"type":"text","text":" and m"},{"type":"text","text":"eshscatter!","style":{"code":true}},{"type":"text","text":" . Animated textures should work via observables, though that's probably not very efficient. "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"You can use "},{"type":"text","text":"colorbuffer(screen)","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"depthbuffer(screen)","style":{"code":true}},{"type":"text","text":" where "},{"type":"text","text":"screen = display(scene)","style":{"code":true}},{"type":"text","text":" if you need them. If you need/want the gl buffers you can get them from "},{"type":"text","text":"screen.framebuffer.buffers","style":{"code":true}}]},{"type":"rich_text_section","elements":[{"type":"text","text":"if you want to do things for each frame you can react to "},{"type":"text","text":"screen.render_tick","style":{"code":true}},{"type":"text","text":" "}]}],"style":"bullet","indent":0}]}],"thread_ts":"1617910640.016900","parent_user_id":"U0190AJCYK0"},{"client_msg_id":"48e4df9e-7bf8-4413-ba94-3483f0863154","type":"message","text":"Thank you <@U9MD78Z9N> for your suggestions!\n\n&gt; Do you want the renderer to be differentiable or not?\nSince I hardy have any idea about 3d rendering, let alone what it even means to differentiate through a renderer, I think we can skip this one for now and just focus on a simple renderer.\n&gt; Do you want to pre render some frames offline and use them to in training or do you want the network to be trained while it's interacting with the environment?\nFrom what I can imagine, it will be action1 -&gt; simulate1 -&gt; render1 -&gt; action2 -&gt; simulate2 -&gt; render2 ... and so on. So it seems more appropriate to do an interactive version I think. Once I run a trajectory, I should be able to store the sequence of actions and frames and use this dataset in an offline setting later.\n&gt; Are you familiar with GPU programming?\nNot at all familiar with GPU programming. I would prefer everything to be on the CPU, at least for now. Learning GPU programming would add another layer of complexity that I don't want to deal with at the prototype stage. I hope this is a simple enough application to be run on the CPU, with a small neural network at least?\n&gt; Are you more CPU or GPU constrained?\nI don't have a GPU. I am using `CPU: Intel(R) Core(TM) i7-6500U CPU @ 2.50GHz`\n&gt; Do the objects have to be 3d or would 2d shapes always visible for the player also be sufficient?\nI haven't thought about this. Do the flat plain walls in the deepmind lab video count as \"2d shapes\"? If so, maybe initially we can skip 3d objects for now if it is too complicated. Stickers on walls and floors might be enough to act as targets to be reached by the agent.\n&gt; How many frames per second do you expect your network to eat?\n&gt; What resolution will your network eat?\nI haven't thought about these. Please feel free to suggest any reasonable numbers that a CPU can handle :sweat_smile:\n\n&gt; My general recommendation would be to write stand alone render code (rendering into an buffer) and tie that up with game logic. You can later use this bundle from your  training loop or take something like GameZero, throw your buffer to the screen and record input from the player.\nWhat should I use to open a window and draw graphics on it, if not `Makie.jl`? Should I be using <https://github.com/JuliaMultimedia/SimpleDirectMediaLayer.jl>?\n&gt; Makie doesn't seem that appropriate.\nAlso, could you explain why Makie.jl wouldn't be appropriate for this? Would it be too slow/bloated for my specific purpose?","user":"U0190AJCYK0","ts":"1617968902.018400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WqGB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you "},{"type":"user","user_id":"U9MD78Z9N"},{"type":"text","text":" for your suggestions!\n\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"Do you want the renderer to be differentiable or not?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Since I hardy have any idea about 3d rendering, let alone what it even means to differentiate through a renderer, I think we can skip this one for now and just focus on a simple renderer.\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"Do you want to pre render some frames offline and use them to in training or do you want the network to be trained while it's interacting with the environment?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"From what I can imagine, it will be action1 -> simulate1 -> render1 -> action2 -> simulate2 -> render2 ... and so on. So it seems more appropriate to do an interactive version I think. Once I run a trajectory, I should be able to store the sequence of actions and frames and use this dataset in an offline setting later.\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"Are you familiar with GPU programming?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Not at all familiar with GPU programming. I would prefer everything to be on the CPU, at least for now. Learning GPU programming would add another layer of complexity that I don't want to deal with at the prototype stage. I hope this is a simple enough application to be run on the CPU, with a small neural network at least?\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"Are you more CPU or GPU constrained?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I don't have a GPU. I am using "},{"type":"text","text":"CPU: Intel(R) Core(TM) i7-6500U CPU @ 2.50GHz","style":{"code":true}},{"type":"text","text":"\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"Do the objects have to be 3d or would 2d shapes always visible for the player also be sufficient?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I haven't thought about this. Do the flat plain walls in the deepmind lab video count as \"2d shapes\"? If so, maybe initially we can skip 3d objects for now if it is too complicated. Stickers on walls and floors might be enough to act as targets to be reached by the agent.\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"How many frames per second do you expect your network to eat?\nWhat resolution will your network eat?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I haven't thought about these. Please feel free to suggest any reasonable numbers that a CPU can handle "},{"type":"emoji","name":"sweat_smile"},{"type":"text","text":"\n\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"My general recommendation would be to write stand alone render code (rendering into an buffer) and tie that up with game logic. You can later use this bundle from your  training loop or take something like GameZero, throw your buffer to the screen and record input from the player."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"What should I use to open a window and draw graphics on it, if not "},{"type":"text","text":"Makie.jl","style":{"code":true}},{"type":"text","text":"? Should I be using "},{"type":"link","url":"https://github.com/JuliaMultimedia/SimpleDirectMediaLayer.jl"},{"type":"text","text":"?\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"Makie doesn't seem that appropriate."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Also, could you explain why Makie.jl wouldn't be appropriate for this? Would it be too slow/bloated for my specific purpose?"}]}]}],"thread_ts":"1617910640.016900","parent_user_id":"U0190AJCYK0"},{"client_msg_id":"15215482-edec-40d2-af7a-925cc8abadf1","type":"message","text":"Thank you <@UQMHE3ER4> for your suggestions!\n&gt; If you were to do what the video does in Makie:\n&gt; ...\nIf I end up using Makie.jl, this will certainly help. I'll save these somewhere in case slack removes my old messages :smile:","user":"U0190AJCYK0","ts":"1617969056.018600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xWkA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you "},{"type":"user","user_id":"UQMHE3ER4"},{"type":"text","text":" for your suggestions!\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"If you were to do what the video does in Makie:\n..."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"If I end up using Makie.jl, this will certainly help. I'll save these somewhere in case slack removes my old messages "},{"type":"emoji","name":"smile"}]}]}],"thread_ts":"1617910640.016900","parent_user_id":"U0190AJCYK0"},{"client_msg_id":"7206eea4-6e95-45b1-845a-3d3ecf1afb60","type":"message","text":"Also, for the CPU vs. GPU point, I would like to do my development of this package on CPU since I am going to be training only very trivial networks just to ensure that everything works correctly, but later on, when people actually use this for training more serious networks, it is likely that they may want to speed things up by using a GPU. Hopefully, the GPU enabling can be added later on without too much hassle?","user":"U0190AJCYK0","ts":"1617970501.018800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8Icm/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also, for the CPU vs. GPU point, I would like to do my development of this package on CPU since I am going to be training only very trivial networks just to ensure that everything works correctly, but later on, when people actually use this for training more serious networks, it is likely that they may want to speed things up by using a GPU. Hopefully, the GPU enabling can be added later on without too much hassle?"}]}]}],"thread_ts":"1617910640.016900","parent_user_id":"U0190AJCYK0"},{"type":"message","text":"2d vs 3d shapes, the rotating apple in googles video is 3d shape, the enemy charcters in Wolfenstein are 2d.","user":"U9MD78Z9N","ts":"1617981815.019000","team":"T68168MUP","thread_ts":"1617910640.016900","parent_user_id":"U0190AJCYK0"},{"type":"message","text":"If the renderer in the JuliaCon video doesn't work for you/is to expensive or you want to write your own, here is what i would do:\nMake a wolfenstein style renderer, but store whether walls exist between cells rather than whether cells are solid to get thin walls.\nWhen rendering a texture using something you index into with floating point numbers to get the color to draw. Even better if this functions has a continous derivatives. This will make it very easy to make most of the picture to have a meaningfull gradient which will help you with training.\nRun on fixed time steps.\nGive your network analog input (floats betweeen 0.0 to 0.1) as input\nA naive implementation of a wolfenstein style renderer should give you hunders or even thousands of renders per second. I could also imagine that certain parts vectorize really well if more performance is necessary. Im not aware of any GPU accelerated renders that would work for Wolfenstein, mostly because there is no need to have a expensive piece of hardware produce tens of thouands of frames per second but depending on your training that might become necessary if you run have multiple GPUs running your network.\nI think implementing a differentiable renderer in a wolfenstein style could be a weekend project in particular since \"Game Engine Black Book Wolfenstein 3D\" exists. \nIn fact to simplify things even further you could make a 1d game (the camera returns a 1d array like here: <https://www.youtube.com/watch?v=3xx7sgNVE-A> to get started faster and have less network inputs","user":"U9MD78Z9N","ts":"1617984815.019200","team":"T68168MUP","attachments":[{"service_name":"YouTube","service_url":"https://www.youtube.com/","title":"I Made a 1D Game 🎮","title_link":"https://www.youtube.com/watch?v=3xx7sgNVE-A","author_name":"Mashpoe","author_link":"https://www.youtube.com/c/Mashpoe","thumb_url":"https://i.ytimg.com/vi/3xx7sgNVE-A/hqdefault.jpg","thumb_width":480,"thumb_height":360,"fallback":"YouTube Video: I Made a 1D Game 🎮","video_html":"<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/3xx7sgNVE-A?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","video_html_width":400,"video_html_height":225,"from_url":"https://www.youtube.com/watch?v=3xx7sgNVE-A","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png","id":1,"original_url":"https://www.youtube.com/watch?v=3xx7sgNVE-A"}],"thread_ts":"1617910640.016900","parent_user_id":"U0190AJCYK0"}]