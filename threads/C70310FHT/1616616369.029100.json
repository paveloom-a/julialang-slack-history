[{"client_msg_id":"ee11666e-5a80-4b90-95e7-dd6744487365","type":"message","text":"Hey <@U69F2VCFJ>, I am looking for some wayout to replicate the following behaviour with Transformers.jl:\n\n```output, new_past = model(embeddings, past=past) # model -&gt; gpt2 LMhead model\n```\nCan you suggest how this can be done? I was trying to do it with Transformers.HuggingFace gpt2 model, but was facing some errors.","user":"US6KB42UW","ts":"1616616369.029100","team":"T68168MUP","edited":{"user":"US6KB42UW","ts":"1616616512.000000"},"blocks":[{"type":"rich_text","block_id":"aTLsL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey "},{"type":"user","user_id":"U69F2VCFJ"},{"type":"text","text":", I am looking for some wayout to replicate the following behaviour with Transformers.jl:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"output, new_past = model(embeddings, past=past) # model -> gpt2 LMhead model\n"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nCan you suggest how this can be done? I was trying to do it with Transformers.HuggingFace gpt2 model, but was facing some errors."}]}]}],"thread_ts":"1616616369.029100","reply_count":7,"reply_users_count":3,"latest_reply":"1616748236.043400","reply_users":["U01HPCV8GTW","US6KB42UW","U69F2VCFJ"],"is_locked":false,"subscribed":false},{"client_msg_id":"1c9d3a0c-54b6-4a56-b6f6-1e85d9376a84","type":"message","text":"Hey, you might wanna check out this for reference <https://chengchingwen.github.io/Transformers.jl/dev/stacks/>","user":"U01HPCV8GTW","ts":"1616648439.031000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"feLEN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey, you might wanna check out this for reference "},{"type":"link","url":"https://chengchingwen.github.io/Transformers.jl/dev/stacks/"}]}]}],"thread_ts":"1616616369.029100","parent_user_id":"US6KB42UW"},{"client_msg_id":"18dd82cf-7e41-4b38-b6f5-4d43a9c92e5f","type":"message","text":"Thanks <@U01HPCV8GTW>, I will check out that.","user":"US6KB42UW","ts":"1616654609.031400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fxy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks "},{"type":"user","user_id":"U01HPCV8GTW"},{"type":"text","text":", I will check out that."}]}]}],"thread_ts":"1616616369.029100","parent_user_id":"US6KB42UW"},{"client_msg_id":"AA4977B6-F67C-4876-B234-FF657DFA741F","type":"message","text":"Hi <@US6KB42UW>, I’m not sure what are you trying to do, maybe you can provide more detail like what’s the outcome you want or what error are you facing?","user":"U69F2VCFJ","ts":"1616678638.034500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KX2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi "},{"type":"user","user_id":"US6KB42UW"},{"type":"text","text":", I’m not sure what are you trying to do, maybe you can provide more detail like what’s the outcome you want or what error are you facing?"}]}]}],"thread_ts":"1616616369.029100","parent_user_id":"US6KB42UW"},{"client_msg_id":"13da11d6-a21a-441a-ab8b-2ca20919cfb0","type":"message","text":"I want to explicity pass the \"past key values\" which are to be used while computing by GPT2 model.","user":"US6KB42UW","ts":"1616678954.034700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jycc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I want to explicity pass the \"past key values\" which are to be used while computing by GPT2 model."}]}]}],"thread_ts":"1616616369.029100","parent_user_id":"US6KB42UW"},{"client_msg_id":"9fa75000-35a1-4b37-8330-3c2b7ebd9b70","type":"message","text":"I was trying to use HuggingFace HGFGPT2 LMHead model, but don't know what input shape it expects, and hence was getting `MethodError: no matching method ....`","user":"US6KB42UW","ts":"1616679145.034900","team":"T68168MUP","edited":{"user":"US6KB42UW","ts":"1616679219.000000"},"blocks":[{"type":"rich_text","block_id":"43b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was trying to use HuggingFace HGFGPT2 LMHead model, but don't know what input shape it expects, and hence was getting "},{"type":"text","text":"MethodError: no matching method ....","style":{"code":true}}]}]}],"thread_ts":"1616616369.029100","parent_user_id":"US6KB42UW"},{"client_msg_id":"3A7D0D98-29E4-4181-9368-650E15206CD1","type":"message","text":"The signature should match the huggingface/transformers one but in column major order.","user":"U69F2VCFJ","ts":"1616735918.036800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tXyMn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The signature should match the huggingface/transformers one but in column major order."}]}]}],"thread_ts":"1616616369.029100","parent_user_id":"US6KB42UW"},{"client_msg_id":"741832ba-3b61-4f78-a480-062d1fd1c34b","type":"message","text":"Thanks <@U69F2VCFJ>, but I am still getting an error with following code:\n```model = hgf\"gpt2:lmheadmodel\"\noutputs = model(input, position_ids = position_ids, token_type_ids = token_type_ids,                past_key_values=nothing,                  attention_mask=nothing,               output_attentions=true,                  output_hidden_states=true,\n                  use_cache=true)\n\n# input, position_ids, token_type_ids -&gt; 15×1 Array{Int64,2}```\nError :\n`MethodError: no method matching`\n`(::Transformers.HuggingFace.HGFGPT2LMHeadModel......`\n`(::Array{Int64,2}, ::Array{Int64,2}, ::Array{Int64,2}, ::Nothing, ::Nothing, ::Nothing, ::Val{true}, ::Val{true}, ::Val{true})`\n\n However, if I do the following, this works:\n```output = model.transformer(input, position_ids, token_type_ids, nothing, nothing,Val(true),Val(true),Val(true))```","user":"US6KB42UW","ts":"1616748236.043400","team":"T68168MUP","edited":{"user":"US6KB42UW","ts":"1616749460.000000"},"blocks":[{"type":"rich_text","block_id":"r3Mp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks "},{"type":"user","user_id":"U69F2VCFJ"},{"type":"text","text":", but I am still getting an error with following code:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"model = hgf\"gpt2:lmheadmodel\"\noutputs = model(input, position_ids = position_ids, token_type_ids = token_type_ids,                past_key_values=nothing,                  attention_mask=nothing,               output_attentions=true,                  output_hidden_states=true,\n                  use_cache=true)\n\n# input, position_ids, token_type_ids -> 15×1 Array{Int64,2}"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Error :\n"},{"type":"text","text":"MethodError: no method matching","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"(::Transformers.HuggingFace.HGFGPT2LMHeadModel......","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"(::Array{Int64,2}, ::Array{Int64,2}, ::Array{Int64,2}, ::Nothing, ::Nothing, ::Nothing, ::Val{true}, ::Val{true}, ::Val{true})","style":{"code":true}},{"type":"text","text":"\n\n However, if I do the following, this works:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"output = model.transformer(input, position_ids, token_type_ids, nothing, nothing,Val(true),Val(true),Val(true))"}]}]}],"thread_ts":"1616616369.029100","parent_user_id":"US6KB42UW"}]