[{"client_msg_id":"523a6a68-6fd3-4ae4-b261-8bd74e7a7817","type":"message","text":"<https://twitter.com/spacy_io/status/1356238587545575427?s=19|https://twitter.com/spacy_io/status/1356238587545575427?s=19>","user":"UDGT4PM41","ts":"1612208497.001500","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/spacy_io|@spacy_io>: Today we're releasing spaCy v3.0!\n\n:flying_saucer: Transformer-based pipelines for SOTA models\n:gear: New training and config system\nüß¨ Models using any framework\nü™ê Manage end-to-end workflows\n:fire: New and improved APIs, components &amp; more\n\n<https://github.com/explosion/spaCy/releases/tag/v3.0.0/>","ts":1612187451,"author_name":"spaCy","author_link":"https://twitter.com/spacy_io/status/1356238587545575427","author_icon":"https://pbs.twimg.com/profile_images/699256981287100416/7-7zis8f_normal.png","author_subname":"@spacy_io","text":"Today we're releasing spaCy v3.0!\n\n:flying_saucer: Transformer-based pipelines for SOTA models\n:gear: New training and config system\nüß¨ Models using any framework\nü™ê Manage end-to-end workflows\n:fire: New and improved APIs, components &amp; more\n\n<https://github.com/explosion/spaCy/releases/tag/v3.0.0/>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/spacy_io/status/1356238587545575427?s=19","id":1,"original_url":"https://twitter.com/spacy_io/status/1356238587545575427?s=19","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"x69oz","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://twitter.com/spacy_io/status/1356238587545575427?s=19","text":"https://twitter.com/spacy_io/status/1356238587545575427?s=19"}]}]}],"thread_ts":"1612208497.001500","reply_count":4,"reply_users_count":2,"latest_reply":"1612468811.004400","reply_users":["U013KHU2XC1","U01CCE4QQV9"],"subscribed":false},{"client_msg_id":"e0bed89f-fa52-4445-a41e-65e0621edde4","type":"message","text":"It would be really good to reuse spacy's NN models with Julia. But in the case of classic NLP methods, Spacy is really slow. E.g. sentence splitting is almost 30 times slower than NLTK","user":"U013KHU2XC1","ts":"1612262476.001700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"v4u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It would be really good to reuse spacy's NN models with Julia. But in the case of classic NLP methods, Spacy is really slow. E.g. sentence splitting is almost 30 times slower than NLTK"}]}]}],"thread_ts":"1612208497.001500","parent_user_id":"UDGT4PM41"},{"client_msg_id":"7330dd5e-b724-44a0-a784-ec65da78b40e","type":"message","text":"<@U013KHU2XC1> I've seen blazing fast performance with spaCy on sentence segmentation, MUCH faster than NLTK.\n\nHave you tried disabling/enabling pipeline components in spaCy? If you load a language model and disable the parser, tagger and NER components, it just uses the tokenizer, which is all you need for sentence segmentation. Then later, when you need the other components, you just enable them again. Hope that makes sense!","user":"U01CCE4QQV9","ts":"1612286851.002100","team":"T68168MUP","edited":{"user":"U01CCE4QQV9","ts":"1612286884.000000"},"blocks":[{"type":"rich_text","block_id":"KbF2","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U013KHU2XC1"},{"type":"text","text":" I've seen blazing fast performance with spaCy on sentence segmentation, MUCH faster than NLTK.\n\nHave you tried disabling/enabling pipeline components in spaCy? If you load a language model and disable the parser, tagger and NER components, it just uses the tokenizer, which is all you need for sentence segmentation. Then later, when you need the other components, you just enable them again. Hope that makes sense!"}]}]}],"thread_ts":"1612208497.001500","parent_user_id":"UDGT4PM41"},{"client_msg_id":"ac00633c-8050-4d38-98ea-1abb8187fd6b","type":"message","text":"We used the following code:\n```    name = \"Spacy\"\n    spacy = pyimport(\"spacy\")\n    nlp = spacy.load(joinpath(project_root, \"lib\", \"en_core_web_sm/en_core_web_sm-2.3.1\"))\n    b = @benchmarkable $nlp($text) samples=times seconds=sec\n    bch = run(b)```\nChecking how to minimize the pipeline.","user":"U013KHU2XC1","ts":"1612292467.002400","team":"T68168MUP","edited":{"user":"U013KHU2XC1","ts":"1612295756.000000"},"blocks":[{"type":"rich_text","block_id":"I2IlE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We used the following code:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"    name = \"Spacy\"\n    spacy = pyimport(\"spacy\")\n    nlp = spacy.load(joinpath(project_root, \"lib\", \"en_core_web_sm/en_core_web_sm-2.3.1\"))\n    b = @benchmarkable $nlp($text) samples=times seconds=sec\n    bch = run(b)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Checking how to minimize the pipeline."}]}]}],"thread_ts":"1612208497.001500","parent_user_id":"UDGT4PM41"},{"client_msg_id":"4078e17b-28eb-4bad-bd3c-79b9acc526c5","type":"message","text":"Hi <@U01CCE4QQV9>, we checked two options of spacy2. Spacy 3 is not available yet in Conda. And in both cases, we got results much slower than NLTK.\nSpacy Dependency parser is ok in terms of quality of sentence splitting but more than 20 times slower NLTK. Rule-based splitter is inaccurate and ~3 times slower NLTK.\n\n```    spacy = pyimport(\"spacy\")\n    spacy_model = joinpath(project_root, \"lib\", \"en_core_web_sm\", \"en_core_web_sm-2.3.1\")\n    nlp = spacy.load(spacy_model, disable = [\"tagger\", \"parser\", \"ner\"])\n    nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n    b = @benchmarkable $nlp($text) samples=times seconds=sec\n    bch = run(b)```\n```    spacy = pyimport(\"spacy\")\n    spacy_model = joinpath(project_root, \"lib\", \"en_core_web_sm\", \"en_core_web_sm-2.3.1\")\n    nlp = spacy.load(spacy_model, disable = [\"tagger\", \"ner\"])\n    b = @benchmarkable $nlp($text) samples=times seconds=sec\n    bch = run(b)```\n","user":"U013KHU2XC1","ts":"1612468811.004400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BZY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi "},{"type":"user","user_id":"U01CCE4QQV9"},{"type":"text","text":", we checked two options of spacy2. Spacy 3 is not available yet in Conda. And in both cases, we got results much slower than NLTK.\nSpacy Dependency parser is ok in terms of quality of sentence splitting but more than 20 times slower NLTK. Rule-based splitter is inaccurate and ~3 times slower NLTK.\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"    spacy = pyimport(\"spacy\")\n    spacy_model = joinpath(project_root, \"lib\", \"en_core_web_sm\", \"en_core_web_sm-2.3.1\")\n    nlp = spacy.load(spacy_model, disable = [\"tagger\", \"parser\", \"ner\"])\n    nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n    b = @benchmarkable $nlp($text) samples=times seconds=sec\n    bch = run(b)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"    spacy = pyimport(\"spacy\")\n    spacy_model = joinpath(project_root, \"lib\", \"en_core_web_sm\", \"en_core_web_sm-2.3.1\")\n    nlp = spacy.load(spacy_model, disable = [\"tagger\", \"ner\"])\n    b = @benchmarkable $nlp($text) samples=times seconds=sec\n    bch = run(b)"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1612208497.001500","parent_user_id":"UDGT4PM41"}]