[{"client_msg_id":"0be344a8-3da1-4127-be2e-0b452c04e8b2","type":"message","text":"Not from me. Via hackernews\n\n<https://github.com/JuliaOptics/About>\n```This organization and its repositories have been abandoned.  The About section below is left intact.  The work was abandoned for the following reasons:\n\n* Julia does not offer significant acceleration over the numpy code of [prysm](<https://github.com/brandondube/prysm>) -- only about 20%\n* writing performant julia is significantly more difficult than writing performant numpy.  The base language emits unvectorized code which is slower than numpy, the `@avx` macro is unstable and often crashes the interpreter, the allocator is much slower than numpy or even matlab, and `.` and `!` are quasi-white space symbols that are far too important to the performance of an algorithm.  `@.` prefixes to a line are slower than hand placing the `.`, so that is not a solution\n* the language itself, as well as its tooling, is too immature, with poor documentation and many bugs or sharp edges\n* errors in Julia are severely cluttered by multiple line long type information which does not aid clarity```","user":"USU9FRPEU","ts":"1616432092.068900","team":"T68168MUP","edited":{"user":"USU9FRPEU","ts":"1616432226.000000"},"blocks":[{"type":"rich_text","block_id":"QeZw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not from me. Via hackernews\n\n"},{"type":"link","url":"https://github.com/JuliaOptics/About"},{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"This organization and its repositories have been abandoned.  The About section below is left intact.  The work was abandoned for the following reasons:\n\n* Julia does not offer significant acceleration over the numpy code of [prysm]("},{"type":"link","url":"https://github.com/brandondube/prysm"},{"type":"text","text":") -- only about 20%\n* writing performant julia is significantly more difficult than writing performant numpy.  The base language emits unvectorized code which is slower than numpy, the `@avx` macro is unstable and often crashes the interpreter, the allocator is much slower than numpy or even matlab, and `.` and `!` are quasi-white space symbols that are far too important to the performance of an algorithm.  `@.` prefixes to a line are slower than hand placing the `.`, so that is not a solution\n* the language itself, as well as its tooling, is too immature, with poor documentation and many bugs or sharp edges\n* errors in Julia are severely cluttered by multiple line long type information which does not aid clarity"}]}]}],"thread_ts":"1616432092.068900","reply_count":7,"reply_users_count":4,"latest_reply":"1616432808.071200","reply_users":["U7JQGPGCQ","USU9FRPEU","U67D54KS8","U6QGE7S86"],"subscribed":false},{"client_msg_id":"e920bbe4-89eb-4c16-937d-e0e9a4fd2dfe","type":"message","text":"That `@.` point is weird - how would manually typed dots perform differently from dots inserted by a macro?","user":"U7JQGPGCQ","ts":"1616432210.069500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/r56B","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That "},{"type":"text","text":"@.","style":{"code":true}},{"type":"text","text":" point is weird - how would manually typed dots perform differently from dots inserted by a macro?"}]}]}],"thread_ts":"1616432092.068900","parent_user_id":"USU9FRPEU"},{"client_msg_id":"5cc594a6-0d83-4753-ae31-4b1db21f1d75","type":"message","text":"<https://news.ycombinator.com/item?id=26540953>","user":"USU9FRPEU","ts":"1616432231.069800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"18sje","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://news.ycombinator.com/item?id=26540953"}]}]}],"thread_ts":"1616432092.068900","parent_user_id":"USU9FRPEU"},{"client_msg_id":"c6ab7912-3b96-4513-bc31-fae8cc74af27","type":"message","text":"&gt;  how would manually typed dots perform differently from dots inserted by a macro?\nI know about <https://github.com/JuliaLang/julia/issues/29120>","user":"U67D54KS8","ts":"1616432246.070000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ig/C/","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":" how would manually typed dots perform differently from dots inserted by a macro?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nI know about "},{"type":"link","url":"https://github.com/JuliaLang/julia/issues/29120"}]}]}],"thread_ts":"1616432092.068900","parent_user_id":"USU9FRPEU","reactions":[{"name":"today-i-learned","users":["U7JQGPGCQ","UGU761DU2","UKG4WF8PJ"],"count":3}]},{"client_msg_id":"cae3c2b0-1766-4ebd-96bc-081e72752503","type":"message","text":"Not sure it would make things slower though","user":"U67D54KS8","ts":"1616432305.070200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LISt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not sure it would make things slower though"}]}]}],"thread_ts":"1616432092.068900","parent_user_id":"USU9FRPEU"},{"client_msg_id":"4e7bb78c-d1fc-4d27-862e-1a706074826d","type":"message","text":"Oh, I didn't see <https://julialang.slack.com/archives/C67910KEH/p1616424972227800>","user":"USU9FRPEU","ts":"1616432469.070400","team":"T68168MUP","attachments":[{"from_url":"https://julialang.slack.com/archives/C67910KEH/p1616424972227800","fallback":"[March 22nd, 2021 7:56 AM] arikatzpro: Mentioned in the hn thread is  <https://github.com/JuliaOptics/About|https://github.com/JuliaOptics/About>\n&gt; Julia does not offer significant acceleration over the numpy code of prysm -- only about 20%\n&gt; writing performant julia is significantly more difficult than writing performant numpy. The base language emits unvectorized code which is slower than numpy, the @avx macro is unstable and often crashes the interpreter, the allocator is much slower than numpy or even...","ts":"1616424972.227800","author_id":"UDGT4PM41","author_subname":"Ari Katz","channel_id":"C67910KEH","channel_name":"general","is_msg_unfurl":true,"is_thread_root_unfurl":true,"text":"Mentioned in the hn thread is  <https://github.com/JuliaOptics/About|https://github.com/JuliaOptics/About>\n&gt; Julia does not offer significant acceleration over the numpy code of prysm -- only about 20%\n&gt; writing performant julia is significantly more difficult than writing performant numpy. The base language emits unvectorized code which is slower than numpy, the @avx macro is unstable and often crashes the interpreter, the allocator is much slower than numpy or even...","author_name":"Ari Katz","author_link":"https://julialang.slack.com/team/UDGT4PM41","author_icon":"https://secure.gravatar.com/avatar/a9e84ba6e7b9db667ae3371c11a07dfe.jpg?s=48&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-48.png","mrkdwn_in":["text"],"id":1,"original_url":"https://julialang.slack.com/archives/C67910KEH/p1616424972227800","footer":"Thread in #general"}],"blocks":[{"type":"rich_text","block_id":"dKn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh, I didn't see "},{"type":"link","url":"https://julialang.slack.com/archives/C67910KEH/p1616424972227800"}]}]}],"thread_ts":"1616432092.068900","parent_user_id":"USU9FRPEU"},{"client_msg_id":"779b09da-ba29-4e67-a2bf-60e3e53aafbe","type":"message","text":"FWIW an alternative algorithmic approach to many of those Orthogonal Polynomials they have to calculate them is to use generated functions to create the polynomials at compile time (because they don't change once you set certain parameters) and then have it pay off in the long run. That's assuming that you don't have to compile oodles of different generated functions, but the ApproxFun.jl people will likely be able to comment better.","user":"U6QGE7S86","ts":"1616432477.070700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xdT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"FWIW an alternative algorithmic approach to many of those Orthogonal Polynomials they have to calculate them is to use generated functions to create the polynomials at compile time (because they don't change once you set certain parameters) and then have it pay off in the long run. That's assuming that you don't have to compile oodles of different generated functions, but the ApproxFun.jl people will likely be able to comment better."}]}]}],"thread_ts":"1616432092.068900","parent_user_id":"USU9FRPEU","reactions":[{"name":"+1","users":["UGU761DU2","UKG4WF8PJ"],"count":2}]},{"client_msg_id":"a4225b78-ed58-47fd-86c5-24ca9047f6e4","type":"message","text":"If those functions are the bottleneck, having an optimized polynomial evaluation that is straight Fused Multiply Adds can be about 200x faster than having to do the recurrence division and all that, because your evaluation time is O(n), where n = order of the polynomial, and every line is an FMA.","user":"U6QGE7S86","ts":"1616432808.071200","team":"T68168MUP","edited":{"user":"U6QGE7S86","ts":"1616432858.000000"},"blocks":[{"type":"rich_text","block_id":"r4n","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If those functions are the bottleneck, having an optimized polynomial evaluation that is straight Fused Multiply Adds can be about 200x faster than having to do the recurrence division and all that, because your evaluation time is O(n), where n = order of the polynomial, and every line is an FMA."}]}]}],"thread_ts":"1616432092.068900","parent_user_id":"USU9FRPEU"}]