[{"client_msg_id":"e6b257d3-cf7e-4737-b274-9511bd567a2b","type":"message","text":"I need to numerically integrate a slightly complicated function many times, so I'm trying to find a fast way to do it. I don't necessarily need super high precision (ideally beyond 1e-5 but I could make do with less)\n\nI'm currently trying the following with `FastGaussQuadrature` . Might anyone have a suggestion for how to improve performance?\n```function fastgq(f, a, b)\n    nodes, weights = gausslegendre( 10000 );\n    \n    x = 0.5*((b .- a).*nodes .+ (b.+a))\n    \n    out = 0.5*(b.-a)*dot( weights, f.(x) )\n    \n    return(out)\nend```","user":"U91Q3595Y","ts":"1613615785.248800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+0fn9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I need to numerically integrate a slightly complicated function many times, so I'm trying to find a fast way to do it. I don't necessarily need super high precision (ideally beyond 1e-5 but I could make do with less)\n\nI'm currently trying the following with "},{"type":"text","text":"FastGaussQuadrature","style":{"code":true}},{"type":"text","text":" . Might anyone have a suggestion for how to improve performance?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function fastgq(f, a, b)\n    nodes, weights = gausslegendre( 10000 );\n    \n    x = 0.5*((b .- a).*nodes .+ (b.+a))\n    \n    out = 0.5*(b.-a)*dot( weights, f.(x) )\n    \n    return(out)\nend"}]}]}],"thread_ts":"1613615785.248800","reply_count":44,"reply_users_count":6,"latest_reply":"1613744413.264100","reply_users":["U0179G7FG4F","U91Q3595Y","U6C82JCSK","U67D54KS8","UAUPJLBQX","U68QW0PUZ"],"subscribed":false},{"client_msg_id":"d50031eb-9538-48ce-9629-987b2d8c912e","type":"message","text":"I think you might want `fastgq(f::F, a, b) where F&lt;:Function` since function types aren't automatically specialized on.","user":"U0179G7FG4F","ts":"1613616291.248900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/XeN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think you might want "},{"type":"text","text":"fastgq(f::F, a, b) where F<:Function","style":{"code":true}},{"type":"text","text":" since function types aren't automatically specialized on."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"662c3275-f821-4461-98d5-d4be3e360500","type":"message","text":"Do I need to declare `F&lt;:Function` somewhere?","user":"U91Q3595Y","ts":"1613616341.249100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NbWG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Do I need to declare "},{"type":"text","text":"F<:Function","style":{"code":true}},{"type":"text","text":" somewhere?"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"8922e223-a050-47dc-bae5-a7f17ee7f986","type":"message","text":"(sorry for the naive question)","user":"U91Q3595Y","ts":"1613616357.249300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"i/qt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(sorry for the naive question)"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"265a3684-a359-44d6-9d27-e305aeee3ee0","type":"message","text":"would this work?\n```function fastgq(f::Function, a, b)\n    nodes, weights = gausslegendre( 10000 );\n    \n    x = 0.5*((b .- a).*nodes .+ (b.+a))\n    \n    out = 0.5*(b.-a)*dot( weights, f.(x) )\n    \n    return(out)\nend```","user":"U91Q3595Y","ts":"1613616455.249500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1Gwal","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"would this work?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function fastgq(f::Function, a, b)\n    nodes, weights = gausslegendre( 10000 );\n    \n    x = 0.5*((b .- a).*nodes .+ (b.+a))\n    \n    out = 0.5*(b.-a)*dot( weights, f.(x) )\n    \n    return(out)\nend"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"ae55b208-7f6b-438a-9751-6cc063d2c1e0","type":"message","text":"no, <https://docs.julialang.org/en/v1/manual/performance-tips/#Be-aware-of-when-Julia-avoids-specializing>","user":"U0179G7FG4F","ts":"1613616526.249700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9B=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"no, "},{"type":"link","url":"https://docs.julialang.org/en/v1/manual/performance-tips/#Be-aware-of-when-Julia-avoids-specializing"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"a67022a1-d764-487e-ae22-3d1c48270f24","type":"message","text":"Also, I think changing where you apply `f` will save you an allocation.\n\n```function fastgq(f::F, a, b) where {F}\n    nodes, weights = gausslegendre( 10000 );\n    fx = @. f(0.5*((b - a)*nodes + (b+a)))\n    out = 0.5.*(b.-a)*dot( weights, fx )\n    return(out)\nend```\n","user":"U0179G7FG4F","ts":"1613616696.249900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CQli","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also, I think changing where you apply "},{"type":"text","text":"f","style":{"code":true}},{"type":"text","text":" will save you an allocation.\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function fastgq(f::F, a, b) where {F}\n    nodes, weights = gausslegendre( 10000 );\n    fx = @. f(0.5*((b - a)*nodes + (b+a)))\n    out = 0.5.*(b.-a)*dot( weights, fx )\n    return(out)\nend"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y","reactions":[{"name":"pray","users":["U91Q3595Y"],"count":1}]},{"client_msg_id":"61079a38-9bab-4b58-98dc-eb461e7053a8","type":"message","text":"Thanks!","user":"U91Q3595Y","ts":"1613616845.250100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bmWz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks!"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"e2dbf70e-45c2-4c57-8977-9362b73677e5","type":"message","text":"So you'd suggest something like the following?\n```h_func(h::H, num) where {H} = ntuple(h, div(num, 2))```\n","user":"U91Q3595Y","ts":"1613616854.250300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DUeXl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So you'd suggest something like the following?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"h_func(h::H, num) where {H} = ntuple(h, div(num, 2))"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"2348aa87-d993-4ddc-9a6d-90962a9965b9","type":"message","text":"if it's performance critical, yes. Specialization can be fairly important","user":"U0179G7FG4F","ts":"1613616936.250500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KDmid","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if it's performance critical, yes. Specialization can be fairly important"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"25265a87-0922-4751-a80d-0ac4860a3ba2","type":"message","text":"You might want to also consider pre-allocating the nodes and weights arrays especially if you will be reusing them (unless you are already doing that, of course)","user":"U6C82JCSK","ts":"1613623865.250700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"h+U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You might want to also consider pre-allocating the nodes and weights arrays especially if you will be reusing them (unless you are already doing that, of course)"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y","reactions":[{"name":"pray","users":["U91Q3595Y","UKG4WF8PJ","U0179G7FG4F"],"count":3},{"name":"heavy_check_mark","users":["UAUPJLBQX"],"count":1}]},{"client_msg_id":"ee16f55d-f35c-4b01-b432-3d5a6039ed2f","type":"message","text":"&gt; I think you might want fastgq(f::F, a, b) where F&lt;:Function since function types aren't automatically specialized on.\nThat's only true if the function isn't called in the body, but this one is.","user":"U67D54KS8","ts":"1613631435.251300","team":"T68168MUP","edited":{"user":"U67D54KS8","ts":"1613631489.000000"},"blocks":[{"type":"rich_text","block_id":"9V2","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"I think you might want fastgq(f::F, a, b) where F<:Function since function types aren't automatically specialized on."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"That's only true if the function isn't called in the body, but this one is."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"5818446a-085c-47c0-9537-9c923be6b1f1","type":"message","text":"It might be better to use some adaptive quadrature, e.g. <https://github.com/JuliaMath/QuadGK.jl>","user":"U67D54KS8","ts":"1613631475.251500","team":"T68168MUP","edited":{"user":"U67D54KS8","ts":"1613631539.000000"},"blocks":[{"type":"rich_text","block_id":"FQeC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It might be better to use some adaptive quadrature, e.g. "},{"type":"link","url":"https://github.com/JuliaMath/QuadGK.jl"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"08b735a4-2354-42ae-9235-127604c24e59","type":"message","text":"Is `f` being called in the body? Does broadcasting count?\n```julia&gt; Meta.@lower f.(x)\n:($(Expr(:thunk, CodeInfo(\n    @ none within `top-level scope'\n1 ─ %1 = Base.broadcasted(f, x)\n│   %2 = Base.materialize(%1)\n└──      return %2\n))))```","user":"UAUPJLBQX","ts":"1613631997.251900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SaB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is "},{"type":"text","text":"f","style":{"code":true}},{"type":"text","text":" being called in the body? Does broadcasting count?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> Meta.@lower f.(x)\n:($(Expr(:thunk, CodeInfo(\n    @ none within `top-level scope'\n1 ─ %1 = Base.broadcasted(f, x)\n│   %2 = Base.materialize(%1)\n└──      return %2\n))))"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"eb5032bb-de02-44f3-8d01-066f803dd404","type":"message","text":"Maybe not, but the function is \"slightly complicated\" so it is unlikely that specialization will matter much anyway, and if it is called with broadcasting, the one time call to `Base.broadcasted` will be insignificant.","user":"U67D54KS8","ts":"1613638636.252400","team":"T68168MUP","edited":{"user":"U67D54KS8","ts":"1613638666.000000"},"blocks":[{"type":"rich_text","block_id":"b96X","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe not, but the function is \"slightly complicated\" so it is unlikely that specialization will matter much anyway, and if it is called with broadcasting, the one time call to "},{"type":"text","text":"Base.broadcasted","style":{"code":true}},{"type":"text","text":" will be insignificant."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"6b19c0b7-eac6-45c2-8187-980f0bfd34ab","type":"message","text":"Yes, it'd be insignificant compared to applying `f` on a vector of length `10_000`. Preallocating the nodes, and then also temporaries (or cutting them down, e.g. by replacing `dot` with a loop) would yield a bigger benefit.","user":"UAUPJLBQX","ts":"1613665629.252800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SUHdI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, it'd be insignificant compared to applying "},{"type":"text","text":"f","style":{"code":true}},{"type":"text","text":" on a vector of length "},{"type":"text","text":"10_000","style":{"code":true}},{"type":"text","text":". Preallocating the nodes, and then also temporaries (or cutting them down, e.g. by replacing "},{"type":"text","text":"dot","style":{"code":true}},{"type":"text","text":" with a loop) would yield a bigger benefit."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"b6959adf-7e3e-46e8-9cbf-df613e78fe21","type":"message","text":"I still think looking at the actual integration algorithm is much much more important (assuming `f` is written with decent performance).","user":"U67D54KS8","ts":"1613665773.253000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6A=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I still think looking at the actual integration algorithm is much much more important (assuming "},{"type":"text","text":"f","style":{"code":true}},{"type":"text","text":" is written with decent performance)."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y","reactions":[{"name":"thumbsup_all","users":["U0179G7FG4F","UAUPJLBQX"],"count":2}]},{"client_msg_id":"2fb4acb9-40fb-41ba-97cf-e8b53d50d732","type":"message","text":"Thanks for thinking about this, everyone. I'm a bit confused atm though. <@UAUPJLBQX> is a loop really faster than a vectorized operation? I'm used to thinking about it going the other way","user":"U91Q3595Y","ts":"1613667895.253300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vPo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for thinking about this, everyone. I'm a bit confused atm though. "},{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":" is a loop really faster than a vectorized operation? I'm used to thinking about it going the other way"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"8972dc81-3425-4337-972b-97667bc8ab83","type":"message","text":"Here's what I'm looking at atm\n```gnodes, gweights = gausslegendre( 10000 );\nfunction fastgq(f::F, a, b) where {F}\n    fx = @. f(0.5*((b - a)*gnodes .+ (b+a)))\n    out = 0.5.*(b.-a)*dot( gweights, fx )\n    return(out)\nend```","user":"U91Q3595Y","ts":"1613668189.253500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fpa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Here's what I'm looking at atm\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"gnodes, gweights = gausslegendre( 10000 );\nfunction fastgq(f::F, a, b) where {F}\n    fx = @. f(0.5*((b - a)*gnodes .+ (b+a)))\n    out = 0.5.*(b.-a)*dot( gweights, fx )\n    return(out)\nend"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"4466f515-2740-4c0c-8606-d6b21fdedba1","type":"message","text":"I was surprised but quadgk is actually performing a lot faster. It seems like the main difference is that my `fastgq` function is making millions more allocations. But I'm not sure why it's doing that given that I'm preallocating the nodes and weights. Is there a good way to fix this?","user":"U91Q3595Y","ts":"1613668786.253700","team":"T68168MUP","edited":{"user":"U91Q3595Y","ts":"1613668807.000000"},"blocks":[{"type":"rich_text","block_id":"beH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was surprised but quadgk is actually performing a lot faster. It seems like the main difference is that my "},{"type":"text","text":"fastgq","style":{"code":true}},{"type":"text","text":" function is making millions more allocations. But I'm not sure why it's doing that given that I'm preallocating the nodes and weights. Is there a good way to fix this?"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"42f625de-7cf9-4f11-adf5-8e0d42e8a344","type":"message","text":"I would do either\n```const gnodes, gweights = gausslegendre( 10000 );```\nOr maybe\n```const NODESWEIGHTS = Ref(gausslegendre( 10000 ));```\nso that you can swap them out with\n```NODESWEIGHTS[] = ausslegendre( 100 )```\nthen inside your function, you'd do\n```function fastgq(...)\n    gnones, gweights = NODESWEIGHTS[]\n    ...\nend```","user":"UAUPJLBQX","ts":"1613669638.254200","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1613669677.000000"},"blocks":[{"type":"rich_text","block_id":"zSE6P","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I would do either\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"const gnodes, gweights = gausslegendre( 10000 );"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Or maybe\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"const NODESWEIGHTS = Ref(gausslegendre( 10000 ));"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"so that you can swap them out with\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"NODESWEIGHTS[] = ausslegendre( 100 )"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"then inside your function, you'd do\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function fastgq(...)\n    gnones, gweights = NODESWEIGHTS[]\n    ...\nend"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"d1d005ac-4a55-4ed0-977f-310ba0038920","type":"message","text":"interesting. I'll try that. Thanks!","user":"U91Q3595Y","ts":"1613669694.254500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kKv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"interesting. I'll try that. Thanks!"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"0ede3a12-11fd-4737-8ad1-24b2867bebec","type":"message","text":"as Kristoffer noted, I'd focus more on the integration algorithm","user":"UAUPJLBQX","ts":"1613669705.254700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hEq16","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"as Kristoffer noted, I'd focus more on the integration algorithm"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"2f194ed0-f371-4cba-bd9f-5c1d74d21ad4","type":"message","text":"In particular, do you need that many nodes and weights for accuracy?","user":"UAUPJLBQX","ts":"1613669721.254900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zh0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In particular, do you need that many nodes and weights for accuracy?"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"5c603f75-f2c7-40d9-9527-7bcf75225f87","type":"message","text":"Right. I can do some tests. Would you also recommend replacing the `dot`?","user":"U91Q3595Y","ts":"1613669745.255100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"B5ul","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Right. I can do some tests. Would you also recommend replacing the "},{"type":"text","text":"dot","style":{"code":true}},{"type":"text","text":"?"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"3b76cead-94c2-4f11-aea2-04fa29245e85","type":"message","text":"If your function is reasonably smooth, Chebyshev often reaches almost the exact answer with 20 or less.\nObviously, using 20 instead of 10_000 is a good way to get a 500x speedup.","user":"UAUPJLBQX","ts":"1613669821.255300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"II1Gd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If your function is reasonably smooth, Chebyshev often reaches almost the exact answer with 20 or less.\nObviously, using 20 instead of 10_000 is a good way to get a 500x speedup."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"0b6655c0-a0bf-48ab-b5e2-ace1cb6bd1c8","type":"message","text":"Replacing the dot won't buy you 500x :wink:","user":"UAUPJLBQX","ts":"1613669832.255500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"21bbw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Replacing the dot won't buy you 500x "},{"type":"emoji","name":"wink"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"3e0c495e-ad6e-45db-b01a-dea54dfdc7d2","type":"message","text":"But yes, replacing the dot will reduce the allocations.","user":"UAUPJLBQX","ts":"1613669855.255700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Dv1T","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But yes, replacing the dot will reduce the allocations."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"d96ca164-2a7e-4f9f-90bc-334b52a0e331","type":"message","text":"As will avoiding the use of non-const globals (hence why I added `const` in my examples of pulling the nodes and weights out)","user":"UAUPJLBQX","ts":"1613669880.255900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V96mO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"As will avoiding the use of non-const globals (hence why I added "},{"type":"text","text":"const","style":{"code":true}},{"type":"text","text":" in my examples of pulling the nodes and weights out)"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"f363700e-39aa-427e-aad8-9ff90ca81200","type":"message","text":"Got it. Thanks again","user":"U91Q3595Y","ts":"1613669920.256100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zcg83","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Got it. Thanks again"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"d56237c5-c1b0-4e14-9628-c0a7cc5754ab","type":"message","text":"\"vectorized\" statements in languages like Python/R/MATLAB almost always turn into loops somewhere","user":"UAUPJLBQX","ts":"1613669935.256300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RFN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"\"vectorized\" statements in languages like Python/R/MATLAB almost always turn into loops somewhere"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"be7c2ac5-6f55-4722-b7a1-39276391ae87","type":"message","text":"haha right","user":"U91Q3595Y","ts":"1613669980.256500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nFw3G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"haha right"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"1af5220a-3e8c-4bfb-bd82-b2417b73b38f","type":"message","text":"is vectorization ever more efficient in julia?","user":"U91Q3595Y","ts":"1613670003.256700","team":"T68168MUP","edited":{"user":"U91Q3595Y","ts":"1613670007.000000"},"blocks":[{"type":"rich_text","block_id":"ah0u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is vectorization ever more efficient in julia?"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"cc634627-0860-4097-acd1-c67e4c8c226e","type":"message","text":"but because each operation has a lot of overhead in those languages, it is often faster to do something \"vectorized\", which then calls a loop written in C/Fortran.\nJulia loops are just as fast, so you can use a Julia loop directly with the same performance.","user":"UAUPJLBQX","ts":"1613670020.257000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n+z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but because each operation has a lot of overhead in those languages, it is often faster to do something \"vectorized\", which then calls a loop written in C/Fortran.\nJulia loops are just as fast, so you can use a Julia loop directly with the same performance."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"7b4f4772-cf5b-4c61-9e7e-9082ddfc25b0","type":"message","text":"Vectorization in Julia is often more efficient than it is in Python/R/MATLAB","user":"UAUPJLBQX","ts":"1613670033.257200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yrG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Vectorization in Julia is often more efficient than it is in Python/R/MATLAB"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"9b87786c-a96e-4bf3-8c89-0b8a08642ef7","type":"message","text":"thanks largely to the possibility of fusion:\n<https://julialang.org/blog/2017/01/moredots/>","user":"UAUPJLBQX","ts":"1613670057.257400","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1613670063.000000"},"blocks":[{"type":"rich_text","block_id":"vSy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thanks largely to the possibility of fusion:\n"},{"type":"link","url":"https://julialang.org/blog/2017/01/moredots/"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"016166ae-65d3-42fd-9097-a028322fbdf4","type":"message","text":"but not necessarily that much faster than looping in julia?","user":"U91Q3595Y","ts":"1613670108.257800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MxmUh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but not necessarily that much faster than looping in julia?"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"3b3fd918-9d39-4e5d-a4f8-e9ed770e97ad","type":"message","text":"While vectorization in those other languages calls a C/Fortran loop, in Julia it calls a Julia-loop","user":"UAUPJLBQX","ts":"1613670140.258000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=Lds","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"While vectorization in those other languages calls a C/Fortran loop, in Julia it calls a Julia-loop"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"2ff77bf3-6f73-4910-bfb8-63c159a3e5ec","type":"message","text":"Broadcasting can be a function barrier, meaning if you have type unstable code, it'll do a dynamic dispatch on the broadcast, and then the loop inside it will be type stable and fast.\nVs a type unstable loop.\nThis is important for DataFrames, for example","user":"UAUPJLBQX","ts":"1613670259.258200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bCh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Broadcasting can be a function barrier, meaning if you have type unstable code, it'll do a dynamic dispatch on the broadcast, and then the loop inside it will be type stable and fast.\nVs a type unstable loop.\nThis is important for DataFrames, for example"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"7d35e117-e6e7-450d-a180-9fd9e59c9ba6","type":"message","text":"Broadcast loops also use annotations like `@inbounds @simd` , so they'll generally be faster than code that did use macros like these.\nBut depending on what `f` is, these macros probably won't make a difference.","user":"UAUPJLBQX","ts":"1613670383.258400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EW9A","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Broadcast loops also use annotations like "},{"type":"text","text":"@inbounds @simd","style":{"code":true}},{"type":"text","text":" , so they'll generally be faster than code that did use macros like these.\nBut depending on what "},{"type":"text","text":"f","style":{"code":true}},{"type":"text","text":" is, these macros probably won't make a difference."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"3bc614c2-6769-41cb-b20d-2ea8e4bad6ca","type":"message","text":"Got it, I think I understand. Thanks for the tutorial :slightly_smiling_face:","user":"U91Q3595Y","ts":"1613670635.258600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2Lk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Got it, I think I understand. Thanks for the tutorial "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y","reactions":[{"name":"+1","users":["UAUPJLBQX"],"count":1}]},{"client_msg_id":"651ea0ed-b732-4c06-a1d8-aa5525e73e7a","type":"message","text":"Last question <@UAUPJLBQX> -- might you have a reference for the idea that Chebyshev can typically do well with ~20? (Also if there's an example I could look at that, would be appreciated)","user":"U91Q3595Y","ts":"1613672342.258900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H0R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Last question "},{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":" -- might you have a reference for the idea that Chebyshev can typically do well with ~20? (Also if there's an example I could look at that, would be appreciated)"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"d072088f-3a17-419e-ae38-1addd7d89cb6","type":"message","text":"It of course depends a lot on the problem, so I just meant to give a ball park figure, suggesting that you'll likely be able to see good results with many times less function evaluations.\nYou should pick the kind such that `f(x)/w(x)` produces the simplest curve to interpolate with a polynomial (and then you'd dot the weights with `f.(nodes)./w.(nodes)` (or the equivalent in a loop), and then see how many nodes it takes to reliably hit your error targets over a range of inputs (assuming `f` is a closure over data, or there are some other parameters).\n\nIf you can't do that, quadgk will probably be faster because it's adaptive; it evaluates more and more nodes, updating old estimates until it seems to have converged. It doesn't use Gauss-rules for that, but rules with nested nodes so that it can reuse old function evaluations.\nHowever, those rules are less accurate given the same number of function evaluations, which is why if you can manually \"adapt\" your integrator for a problem, you should be able to perform better.\n\nI found 16 was enough for a problem I'd worked on a couple years ago.\nI'm far from an expert on polynomials or numerical analysis, so don't take my word for it. A quick google found this paper, which looks worth looking at if you're interested\n<https://www.polyu.edu.hk/ama/staff/xjchen/nums6025revision20100415.pdf>\nAlso, <https://github.com/JuliaApproximation/ApproxFun.jl|ApproxFun> is a fun package that builds accurate polynomial approximations of functions:\n```julia&gt; using Distributions, ApproxFun\n\njulia&gt; g(x) = pdf(Gamma(6, 0.5), x)\ng (generic function with 1 method)\n\njulia&gt; f = Fun(g, 0..10)\nFun(Chebyshev(0..10),[0.07383343431465757, -0.06303621335028847, -0.07564345602034618, 0.10480224355111896, -0.03041224962775558, -0.03709190959187927, 0.043380534257035246, -0.01544751811119255, -0.006661793839106563, 0.011095138758795196  …  -5.749430522623553e-10, 1.2833774400866666e-10, -2.7310148875682686e-11, 5.554934418197897e-12, -1.0824806194837952e-12, 2.0251618621301728e-13, -3.64448017529865e-14, 6.3186020932931434e-15, -1.0655887180783737e-15, 1.796531312973637e-16])\n\njulia&gt; length(f.coefficients)\n38\n\njulia&gt; f(3.4) - g(3.4) # it targets low error\n5.551115123125783e-17\n\njulia&gt; f(3.8) - g(3.8)\n-8.326672684688674e-17\n\njulia&gt; f(7.8) - g(7.8)\n4.85722573273506e-17\n\njulia&gt; sum(f) # integrate the approximation over the full range we gave it (0..10)\n0.9999280911594715\n\njulia&gt; F = cumsum(f); # define function that is the integral of the approximation\n\njulia&gt; F(7) - F(5) # integrate from 5 to 7\n0.06155391318133174\n\njulia&gt; cdf(Gamma(6,0.5), 7) - cdf(Gamma(6,0.5), 5)\n0.06155391318133163```\nThis example used 38 coefficients, but if it can't choose the kind correctly (for example), it likely needs to use more than you would.\nI'm not recomending the above as an approach -- it'll almost certainly be slower -- but it's a fun example showing the power of polynomial-based approximations.","user":"UAUPJLBQX","ts":"1613677998.259100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VQI2g","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It of course depends a lot on the problem, so I just meant to give a ball park figure, suggesting that you'll likely be able to see good results with many times less function evaluations.\nYou should pick the kind such that "},{"type":"text","text":"f(x)/w(x)","style":{"code":true}},{"type":"text","text":" produces the simplest curve to interpolate with a polynomial (and then you'd dot the weights with "},{"type":"text","text":"f.(nodes)./w.(nodes)","style":{"code":true}},{"type":"text","text":" (or the equivalent in a loop), and then see how many nodes it takes to reliably hit your error targets over a range of inputs (assuming "},{"type":"text","text":"f","style":{"code":true}},{"type":"text","text":" is a closure over data, or there are some other parameters).\n\nIf you can't do that, quadgk will probably be faster because it's adaptive; it evaluates more and more nodes, updating old estimates until it seems to have converged. It doesn't use Gauss-rules for that, but rules with nested nodes so that it can reuse old function evaluations.\nHowever, those rules are less accurate given the same number of function evaluations, which is why if you can manually \"adapt\" your integrator for a problem, you should be able to perform better.\n\nI found 16 was enough for a problem I'd worked on a couple years ago.\nI'm far from an expert on polynomials or numerical analysis, so don't take my word for it. A quick google found this paper, which looks worth looking at if you're interested\n"},{"type":"link","url":"https://www.polyu.edu.hk/ama/staff/xjchen/nums6025revision20100415.pdf"},{"type":"text","text":"\nAlso, "},{"type":"link","url":"https://github.com/JuliaApproximation/ApproxFun.jl","text":"ApproxFun"},{"type":"text","text":" is a fun package that builds accurate polynomial approximations of functions:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> using Distributions, ApproxFun\n\njulia> g(x) = pdf(Gamma(6, 0.5), x)\ng (generic function with 1 method)\n\njulia> f = Fun(g, 0..10)\nFun(Chebyshev(0..10),[0.07383343431465757, -0.06303621335028847, -0.07564345602034618, 0.10480224355111896, -0.03041224962775558, -0.03709190959187927, 0.043380534257035246, -0.01544751811119255, -0.006661793839106563, 0.011095138758795196  …  -5.749430522623553e-10, 1.2833774400866666e-10, -2.7310148875682686e-11, 5.554934418197897e-12, -1.0824806194837952e-12, 2.0251618621301728e-13, -3.64448017529865e-14, 6.3186020932931434e-15, -1.0655887180783737e-15, 1.796531312973637e-16])\n\njulia> length(f.coefficients)\n38\n\njulia> f(3.4) - g(3.4) # it targets low error\n5.551115123125783e-17\n\njulia> f(3.8) - g(3.8)\n-8.326672684688674e-17\n\njulia> f(7.8) - g(7.8)\n4.85722573273506e-17\n\njulia> sum(f) # integrate the approximation over the full range we gave it (0..10)\n0.9999280911594715\n\njulia> F = cumsum(f); # define function that is the integral of the approximation\n\njulia> F(7) - F(5) # integrate from 5 to 7\n0.06155391318133174\n\njulia> cdf(Gamma(6,0.5), 7) - cdf(Gamma(6,0.5), 5)\n0.06155391318133163"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"This example used 38 coefficients, but if it can't choose the kind correctly (for example), it likely needs to use more than you would.\nI'm not recomending the above as an approach -- it'll almost certainly be slower -- but it's a fun example showing the power of polynomial-based approximations."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"7caf6781-12a1-485f-a157-1e94bf718c2a","type":"message","text":"Thank you <@UAUPJLBQX>. I really appreciate it","user":"U91Q3595Y","ts":"1613689032.260100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QIis","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you "},{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":". I really appreciate it"}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y"},{"client_msg_id":"5f7391b3-b669-4403-a968-193f364efb6e","type":"message","text":"When developing accurate _piecewise_ polynomial approximations to (`exp`, `cos`, `atan` ...) with the help of good minimax curve fitter, I used 18-25 coefficients.","user":"U68QW0PUZ","ts":"1613744413.264100","team":"T68168MUP","edited":{"user":"U68QW0PUZ","ts":"1613748496.000000"},"blocks":[{"type":"rich_text","block_id":"hY9u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"When developing accurate "},{"type":"text","text":"piecewise","style":{"italic":true}},{"type":"text","text":" polynomial approximations to ("},{"type":"text","text":"exp","style":{"code":true}},{"type":"text","text":", "},{"type":"text","text":"cos","style":{"code":true}},{"type":"text","text":", "},{"type":"text","text":"atan","style":{"code":true}},{"type":"text","text":" ...) with the help of good minimax curve fitter, I used 18-25 coefficients."}]}]}],"thread_ts":"1613615785.248800","parent_user_id":"U91Q3595Y","reactions":[{"name":"fire","users":["U91Q3595Y"],"count":1}]}]