[{"client_msg_id":"e8021019-3541-4b03-88a9-066e151c22b4","type":"message","text":"Hmm ... this is a bit disappointing ... I prefer the vector-like notation, but I would like to have the BLAS speed\n```julia&gt; @benchmark axpy!(-a, $v1, $v2)\nBenchmarkTools.Trial: \n  memory estimate:  16 bytes\n  allocs estimate:  1\n  --------------\n  minimum time:     23.732 μs (0.00% GC)\n  median time:      25.812 μs (0.00% GC)\n  mean time:        26.578 μs (0.00% GC)\n  maximum time:     403.066 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1\n\njulia&gt; @benchmark @avx $v2 .-= a.*$v1\nBenchmarkTools.Trial: \n  memory estimate:  128 bytes\n  allocs estimate:  4\n  --------------\n  minimum time:     317.518 μs (0.00% GC)\n  median time:      323.328 μs (0.00% GC)\n  mean time:        325.628 μs (0.00% GC)\n  maximum time:     676.790 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1\n\njulia&gt; @benchmark $v2 .-= a.*$v1\nBenchmarkTools.Trial: \n  memory estimate:  128 bytes\n  allocs estimate:  4\n  --------------\n  minimum time:     445.999 μs (0.00% GC)\n  median time:      460.991 μs (0.00% GC)\n  mean time:        473.982 μs (0.00% GC)\n  maximum time:     7.687 ms (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1\n\njulia&gt; v1 |&gt; length\n1000000```","user":"U013V2CFZAN","ts":"1617350999.094900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3YiUa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hmm ... this is a bit disappointing ... I prefer the vector-like notation, but I would like to have the BLAS speed\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @benchmark axpy!(-a, $v1, $v2)\nBenchmarkTools.Trial: \n  memory estimate:  16 bytes\n  allocs estimate:  1\n  --------------\n  minimum time:     23.732 μs (0.00% GC)\n  median time:      25.812 μs (0.00% GC)\n  mean time:        26.578 μs (0.00% GC)\n  maximum time:     403.066 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1\n\njulia> @benchmark @avx $v2 .-= a.*$v1\nBenchmarkTools.Trial: \n  memory estimate:  128 bytes\n  allocs estimate:  4\n  --------------\n  minimum time:     317.518 μs (0.00% GC)\n  median time:      323.328 μs (0.00% GC)\n  mean time:        325.628 μs (0.00% GC)\n  maximum time:     676.790 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1\n\njulia> @benchmark $v2 .-= a.*$v1\nBenchmarkTools.Trial: \n  memory estimate:  128 bytes\n  allocs estimate:  4\n  --------------\n  minimum time:     445.999 μs (0.00% GC)\n  median time:      460.991 μs (0.00% GC)\n  mean time:        473.982 μs (0.00% GC)\n  maximum time:     7.687 ms (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1\n\njulia> v1 |> length\n1000000"}]}]}],"thread_ts":"1617350999.094900","reply_count":36,"reply_users_count":4,"latest_reply":"1617358466.105100","reply_users":["UH24GRBLL","U013V2CFZAN","UAUPJLBQX","UJ7DVTVQ8"],"is_locked":false,"subscribed":false},{"client_msg_id":"fb400ecb-debc-4ebd-9d8f-a4a7bc9e287f","type":"message","text":"why not interpolate `a` as well?","user":"UH24GRBLL","ts":"1617351236.095000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Q0Hrb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"why not interpolate "},{"type":"text","text":"a","style":{"code":true}},{"type":"text","text":" as well?"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"ec956f53-b9b1-4ec5-b092-e178ae57c741","type":"message","text":"oh ... I missed that","user":"U013V2CFZAN","ts":"1617351291.095200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=BNE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oh ... I missed that"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"dcc6cd42-4fc5-4752-9876-7a34afed8056","type":"message","text":"you may also want to wrap that in a small function, just to be sure it behaves the same as  `axpy!`","user":"UH24GRBLL","ts":"1617351311.095400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uQeH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you may also want to wrap that in a small function, just to be sure it behaves the same as  "},{"type":"text","text":"axpy!","style":{"code":true}}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"65b53b54-2582-485c-aed2-5e6f2d612b63","type":"message","text":"good idea!","user":"U013V2CFZAN","ts":"1617351356.095600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"a4fkt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"good idea!"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"f3df56d5-283e-489d-ba62-93ad90cc7077","type":"message","text":"the name suggests some reference is passed to some internal, compiled routine, so wrapping in a function seems appropriate","user":"UH24GRBLL","ts":"1617351358.095800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hS7r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the name suggests some reference is passed to some internal, compiled routine, so wrapping in a function seems appropriate"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"961b8d10-476d-4288-bd79-ae40f206f14f","type":"message","text":"(you'll still have to interpolate all of it though)","user":"UH24GRBLL","ts":"1617351374.096000","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1617351377.000000"},"blocks":[{"type":"rich_text","block_id":"1ZgO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(you'll still have to interpolate all of it though)"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"c83d03c2-c844-4f68-87dd-f9fe93361ef9","type":"message","text":"```julia&gt; my_axpy!(v2, a, v1) = v2 .-= a.*v1\nmy_axpy! (generic function with 1 method)\n\njulia&gt; my_avx_axpy!(v2, a, v1) = @avx v2 .-= a.*v1\nmy_avx_axpy! (generic function with 1 method)\n\njulia&gt; @benchmark my_axpy!($v2, $a, $v1)\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     305.626 μs (0.00% GC)\n  median time:      311.777 μs (0.00% GC)\n  mean time:        314.091 μs (0.00% GC)\n  maximum time:     648.636 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1\n\njulia&gt; @benchmark my_avx_axpy!($v2, $a, $v1)\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     304.046 μs (0.00% GC)\n  median time:      319.618 μs (0.00% GC)\n  mean time:        323.309 μs (0.00% GC)\n  maximum time:     4.906 ms (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1```","user":"U013V2CFZAN","ts":"1617351531.096700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H/UL","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> my_axpy!(v2, a, v1) = v2 .-= a.*v1\nmy_axpy! (generic function with 1 method)\n\njulia> my_avx_axpy!(v2, a, v1) = @avx v2 .-= a.*v1\nmy_avx_axpy! (generic function with 1 method)\n\njulia> @benchmark my_axpy!($v2, $a, $v1)\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     305.626 μs (0.00% GC)\n  median time:      311.777 μs (0.00% GC)\n  mean time:        314.091 μs (0.00% GC)\n  maximum time:     648.636 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1\n\njulia> @benchmark my_avx_axpy!($v2, $a, $v1)\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     304.046 μs (0.00% GC)\n  median time:      319.618 μs (0.00% GC)\n  mean time:        323.309 μs (0.00% GC)\n  maximum time:     4.906 ms (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"126fb8ed-16cd-4a6e-bade-33dde2c1480b","type":"message","text":"How many BLAS threads?","user":"UAUPJLBQX","ts":"1617351751.096900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"q6HyJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How many BLAS threads?"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"02b86672-1157-4c4e-b0d4-44698f0dbc20","type":"message","text":"vs single threaded in the Julia implementations","user":"UAUPJLBQX","ts":"1617351764.097100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lrz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"vs single threaded in the Julia implementations"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"e198fac1-b8d5-499e-9c2c-9173a1a45be4","type":"message","text":"axpy should be totally memory bound, so I wouldn't expect there's much to optimize.","user":"UAUPJLBQX","ts":"1617351797.097300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MWiw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"axpy should be totally memory bound, so I wouldn't expect there's much to optimize."}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"f6f3bae1-1917-44aa-89df-204ca58667a6","type":"message","text":"of course!! I always forget that BLAS uses more than one thread! :picard_facepalm:","user":"U013V2CFZAN","ts":"1617351934.097500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PgVo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"of course!! I always forget that BLAS uses more than one thread! "},{"type":"emoji","name":"picard_facepalm"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"8d5f1b84-0946-4b44-8b26-aa8f43966250","type":"message","text":"```julia&gt; BLAS.set_num_threads(1)\n\njulia&gt; @benchmark axpy!(-a, $v1, $v2)\nBenchmarkTools.Trial: \n  memory estimate:  16 bytes\n  allocs estimate:  1\n  --------------\n  minimum time:     321.589 μs (0.00% GC)\n  median time:      328.390 μs (0.00% GC)\n  mean time:        332.620 μs (0.00% GC)\n  maximum time:     791.057 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1```","user":"U013V2CFZAN","ts":"1617351959.097700","team":"T68168MUP","edited":{"user":"U013V2CFZAN","ts":"1617351974.000000"},"blocks":[{"type":"rich_text","block_id":"VSWCW","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> BLAS.set_num_threads(1)\n\njulia> @benchmark axpy!(-a, $v1, $v2)\nBenchmarkTools.Trial: \n  memory estimate:  16 bytes\n  allocs estimate:  1\n  --------------\n  minimum time:     321.589 μs (0.00% GC)\n  median time:      328.390 μs (0.00% GC)\n  mean time:        332.620 μs (0.00% GC)\n  maximum time:     791.057 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"23a0ab61-2c02-498b-962b-85b263adaf7e","type":"message","text":"You could also try `@avxt` to see how it fairs against multithreaded BLAS","user":"UAUPJLBQX","ts":"1617351989.098000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NVQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You could also try "},{"type":"text","text":"@avxt","style":{"code":true}},{"type":"text","text":" to see how it fairs against multithreaded BLAS"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN","reactions":[{"name":"+1","users":["U013V2CFZAN"],"count":1}]},{"client_msg_id":"9e100e35-ff54-4597-b490-bfad9ec93b42","type":"message","text":"```julia&gt; my_avxt_axpy!(v2, a, v1) = @avxt v2 .-= a.*v1\nmy_avxt_axpy! (generic function with 1 method)\n\njulia&gt; @benchmark my_avxt_axpy!($v2, $a, $v1)\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     17.221 μs (0.00% GC)\n  median time:      21.041 μs (0.00% GC)\n  mean time:        21.573 μs (0.00% GC)\n  maximum time:     313.430 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1```","user":"U013V2CFZAN","ts":"1617352061.098300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"avj3","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> my_avxt_axpy!(v2, a, v1) = @avxt v2 .-= a.*v1\nmy_avxt_axpy! (generic function with 1 method)\n\njulia> @benchmark my_avxt_axpy!($v2, $a, $v1)\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     17.221 μs (0.00% GC)\n  median time:      21.041 μs (0.00% GC)\n  mean time:        21.573 μs (0.00% GC)\n  maximum time:     313.430 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN","reactions":[{"name":"+1","users":["UAUPJLBQX"],"count":1}]},{"client_msg_id":"95973d49-8b56-4cf2-9ce9-6cfc39dce2f8","type":"message","text":"I always learn a lot in this channel :smile:","user":"U013V2CFZAN","ts":"1617352079.098500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6Lbq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I always learn a lot in this channel "},{"type":"emoji","name":"smile"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"7da5073b-a2b1-4c1e-b56e-c65003037187","type":"message","text":"OpenBLAS also defaults to 8 threads","user":"UAUPJLBQX","ts":"1617352112.098800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tKolJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"OpenBLAS also defaults to 8 threads"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"f4e25f19-6392-4298-8b8d-4526a2622544","type":"message","text":"so maybe `axpy!` will match `my_avxt_axpy!` if you set BLAS threads to match the number of physical cores","user":"UAUPJLBQX","ts":"1617352148.099000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BxyI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so maybe "},{"type":"text","text":"axpy!","style":{"code":true}},{"type":"text","text":" will match "},{"type":"text","text":"my_avxt_axpy!","style":{"code":true}},{"type":"text","text":" if you set BLAS threads to match the number of physical cores"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"be9d2e47-9476-4d7d-906a-778f97e4ce10","type":"message","text":"Although I'm quite happy with LoopVectorization being the fastest :wink:","user":"UAUPJLBQX","ts":"1617352170.099200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+xJ6e","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Although I'm quite happy with LoopVectorization being the fastest "},{"type":"emoji","name":"wink"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"e8d359b3-e6b0-4431-a87f-48358ee8e156","type":"message","text":"```julia&gt; BLAS.set_num_threads(12)\n\njulia&gt; @benchmark axpy!(-a, $v1, $v2)\nBenchmarkTools.Trial: \n  memory estimate:  16 bytes\n  allocs estimate:  1\n  --------------\n  minimum time:     20.542 μs (0.00% GC)\n  median time:      24.771 μs (0.00% GC)\n  mean time:        25.774 μs (0.00% GC)\n  maximum time:     598.511 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1```","user":"U013V2CFZAN","ts":"1617352193.099600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Z3Ejs","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> BLAS.set_num_threads(12)\n\njulia> @benchmark axpy!(-a, $v1, $v2)\nBenchmarkTools.Trial: \n  memory estimate:  16 bytes\n  allocs estimate:  1\n  --------------\n  minimum time:     20.542 μs (0.00% GC)\n  median time:      24.771 μs (0.00% GC)\n  mean time:        25.774 μs (0.00% GC)\n  maximum time:     598.511 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"b3826270-7ea1-416d-808e-f285560572b1","type":"message","text":"`@avxt` is faster","user":"U013V2CFZAN","ts":"1617352210.099800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZhsW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"@avxt","style":{"code":true}},{"type":"text","text":" is faster"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN","reactions":[{"name":"sonic","users":["UH24GRBLL","UAUPJLBQX"],"count":2}]},{"client_msg_id":"e1b428a7-16a4-4d12-81d6-a9ef529d20af","type":"message","text":"How come the threaded versions are so much faster for this computation if it's memory bound?","user":"UJ7DVTVQ8","ts":"1617355354.101000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6+I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How come the threaded versions are so much faster for this computation if it's memory bound?"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"58848c18-3a1d-45ba-ac45-a761008de729","type":"message","text":"`v1` and `v2` combined are about 15 MiB:\n```julia&gt; 1_000_000 * 2 * sizeof(Float64) / (1 &lt;&lt; 20)\n15.2587890625```\nI don't know what computer <@U013V2CFZAN> is using, but basically any Ryzen CPU and high core count Intel CPUs will have more L3 cache than that.","user":"UAUPJLBQX","ts":"1617356951.101500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jRitB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"v1","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"v2","style":{"code":true}},{"type":"text","text":" combined are about 15 MiB:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> 1_000_000 * 2 * sizeof(Float64) / (1 << 20)\n15.2587890625"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I don't know what computer "},{"type":"user","user_id":"U013V2CFZAN"},{"type":"text","text":" is using, but basically any Ryzen CPU and high core count Intel CPUs will have more L3 cache than that."}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"74a626f6-cba6-4f2d-abb4-66f0aaa98f76","type":"message","text":"Ryzen 3900XT","user":"U013V2CFZAN","ts":"1617357440.102100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Fp1g","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ryzen 3900XT"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"50125334-e743-49ce-a8bf-f421d02b21c8","type":"message","text":"Maybe I should also try in on my crappy work laptop :sweat_smile:","user":"U013V2CFZAN","ts":"1617357485.102300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=pmC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe I should also try in on my crappy work laptop "},{"type":"emoji","name":"sweat_smile"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"486afd8e-c246-421d-8add-040309e34e45","type":"message","text":"you can also increase matrix size","user":"UH24GRBLL","ts":"1617357557.102600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"U2iy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you can also increase matrix size"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"7fae2e08-904d-471e-ad02-846e9154d7da","type":"message","text":"that I can do","user":"U013V2CFZAN","ts":"1617357629.102900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2qWmu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that I can do"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"cdb7b5b9-41b5-4ccc-85cc-4ae323af4c25","type":"message","text":"let me check max cache of my CPU","user":"U013V2CFZAN","ts":"1617357656.103100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"z/IX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"let me check max cache of my CPU"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"161a0779-be00-407a-b6ec-fd3d168d774c","type":"message","text":"4X16MB","user":"U013V2CFZAN","ts":"1617357705.103300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bkSK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"4X16MB"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"c33d4ee0-ded8-44ce-8d75-498b46c94da5","type":"message","text":"per core?","user":"UH24GRBLL","ts":"1617357928.103500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"r7bM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"per core?"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"39017908-5d7e-4e43-ad43-e4ad263cb503","type":"message","text":"as in, 16MB/core","user":"UH24GRBLL","ts":"1617357934.103700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JuK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"as in, 16MB/core"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"2d5c8a6a-6491-4581-b082-a5924030d882","type":"message","text":"No, 16MB per core complex","user":"UAUPJLBQX","ts":"1617357971.103900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3eps6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"No, 16MB per core complex"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"974bd07c-6aa7-4d2d-b701-b3b114ca8e9c","type":"message","text":"the 3900XT has 4 separate L3 caches, shared by 3 cores (it has 12 cores total)","user":"UAUPJLBQX","ts":"1617357981.104100","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1617358034.000000"},"blocks":[{"type":"rich_text","block_id":"XiMI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the 3900XT has 4 separate L3 caches, shared by 3 cores (it has 12 cores total)"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"9509f2be-5b99-4ed9-8c25-52358c2b7288","type":"message","text":"each of those 4 is 16 MiB","user":"UAUPJLBQX","ts":"1617357989.104300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aPn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"each of those 4 is 16 MiB"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"03cb56e5-9a19-4da2-b37f-1530891e154f","type":"message","text":"I see - then I guess a matrix &gt;64MiB is necessary to fully rely on memory","user":"UH24GRBLL","ts":"1617358157.104700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4QWD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I see - then I guess a matrix >64MiB is necessary to fully rely on memory"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"39fca15c-7d14-41a4-8051-b1e19ba1cc95","type":"message","text":"```julia&gt; @benchmark axpy!(-$a, $v1, $v2)\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.191 ms (0.00% GC)\n  median time:      2.661 ms (0.00% GC)\n  mean time:        2.672 ms (0.00% GC)\n  maximum time:     3.508 ms (0.00% GC)\n  --------------\n  samples:          1859\n  evals/sample:     1\n\njulia&gt; @benchmark @avx $v2 .-= $a.*$v1\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     3.514 ms (0.00% GC)\n  median time:      3.575 ms (0.00% GC)\n  mean time:        3.606 ms (0.00% GC)\n  maximum time:     4.880 ms (0.00% GC)\n  --------------\n  samples:          1379\n  evals/sample:     1\n\n\njulia&gt; @benchmark @avxt $v2 .-= $a.*$v1\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.289 ms (0.00% GC)\n  median time:      2.730 ms (0.00% GC)\n  mean time:        2.735 ms (0.00% GC)\n  maximum time:     3.732 ms (0.00% GC)\n  --------------\n  samples:          1816\n  evals/sample:     1\n\njulia&gt; v1 |&gt; length\n5000000\n\njulia&gt; length(v1) * 2 * sizeof(Float64) / (1 &lt;&lt; 20)\n76.2939453125```","user":"U013V2CFZAN","ts":"1617358339.104900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iEoZ","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @benchmark axpy!(-$a, $v1, $v2)\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.191 ms (0.00% GC)\n  median time:      2.661 ms (0.00% GC)\n  mean time:        2.672 ms (0.00% GC)\n  maximum time:     3.508 ms (0.00% GC)\n  --------------\n  samples:          1859\n  evals/sample:     1\n\njulia> @benchmark @avx $v2 .-= $a.*$v1\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     3.514 ms (0.00% GC)\n  median time:      3.575 ms (0.00% GC)\n  mean time:        3.606 ms (0.00% GC)\n  maximum time:     4.880 ms (0.00% GC)\n  --------------\n  samples:          1379\n  evals/sample:     1\n\n\njulia> @benchmark @avxt $v2 .-= $a.*$v1\nBenchmarkTools.Trial: \n  memory estimate:  0 bytes\n  allocs estimate:  0\n  --------------\n  minimum time:     2.289 ms (0.00% GC)\n  median time:      2.730 ms (0.00% GC)\n  mean time:        2.735 ms (0.00% GC)\n  maximum time:     3.732 ms (0.00% GC)\n  --------------\n  samples:          1816\n  evals/sample:     1\n\njulia> v1 |> length\n5000000\n\njulia> length(v1) * 2 * sizeof(Float64) / (1 << 20)\n76.2939453125"}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"},{"client_msg_id":"239d970e-be97-4669-a441-3e88644bbff7","type":"message","text":"100-200µs difference seems pretty good, considering the `@avxt` version presumably is much more generic than `axpy!`","user":"UH24GRBLL","ts":"1617358466.105100","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1617358472.000000"},"blocks":[{"type":"rich_text","block_id":"mrj/C","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"100-200µs difference seems pretty good, considering the "},{"type":"text","text":"@avxt","style":{"code":true}},{"type":"text","text":" version presumably is much more generic than "},{"type":"text","text":"axpy!","style":{"code":true}}]}]}],"thread_ts":"1617350999.094900","parent_user_id":"U013V2CFZAN"}]