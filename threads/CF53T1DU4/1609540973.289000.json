[{"client_msg_id":"36d87105-e9da-4cc1-b965-26d187398af0","type":"message","text":"Hi all. I have a question about getting good performance out of threading. I don't have a really minimal example, but can point you to a repo with the code (~200 lines):\n\n<https://github.com/vancleve/threading_example>\n\nOn my macbookpro, running the `@time evolve_replicates!(pop, rp)` from <https://github.com/vancleve/threading_example/blob/master/popsim.jl#L30>\nI get something like (after running once to compile)\nno threads  `3.936467 seconds (7.94 M allocations: 4.620 GiB, 14.60% gc time)`\n1 thread      `3.890999 seconds (7.94 M allocations: 4.620 GiB, 16.57% gc time)`\n2 threads    `2.340651 seconds (7.94 M allocations: 4.620 GiB, 25.03% gc time)`\n4 threads    `1.786248 seconds (7.94 M allocations: 4.620 GiB, 41.74% gc time)`\n8 threads    `1.658927 seconds (7.96 M allocations: 4.621 GiB, 58.21% gc time)`\n\nHere are flame graphs for 1 thread (left) and 8 threads (right).\n\nI know I have to reduce allocations, but was hoping to get some advice how best to do this since quite of a bit of the allocation time is coming in basic linear algebra stuff like matrix division and using `I` as identity matrix.\n\nI've also thought about using `Distributed` but I ran into world age issues when passing functions to the workers...","user":"UKFUT8N5A","ts":"1609540973.289000","team":"T68168MUP","edited":{"user":"UKFUT8N5A","ts":"1609541695.000000"},"blocks":[{"type":"rich_text","block_id":"UGvV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all. I have a question about getting good performance out of threading. I don't have a really minimal example, but can point you to a repo with the code (~200 lines):\n\n"},{"type":"link","url":"https://github.com/vancleve/threading_example"},{"type":"text","text":"\n\nOn my macbookpro, running the "},{"type":"text","text":"@time evolve_replicates!(pop, rp)","style":{"code":true}},{"type":"text","text":" from "},{"type":"link","url":"https://github.com/vancleve/threading_example/blob/master/popsim.jl#L30"},{"type":"text","text":"\nI get something like (after running once to compile)\nno threads  "},{"type":"text","text":"3.936467 seconds (7.94 M allocations: 4.620 GiB, 14.60% gc time)","style":{"code":true}},{"type":"text","text":"\n1 thread      "},{"type":"text","text":"3.890999 seconds (7.94 M allocations: 4.620 GiB, 16.57% gc time)","style":{"code":true}},{"type":"text","text":"\n2 threads    "},{"type":"text","text":"2.340651 seconds (7.94 M allocations: 4.620 GiB, 25.03% gc time)","style":{"code":true}},{"type":"text","text":"\n4 threads    "},{"type":"text","text":"1.786248 seconds (7.94 M allocations: 4.620 GiB, 41.74% gc time)","style":{"code":true}},{"type":"text","text":"\n8 threads    "},{"type":"text","text":"1.658927 seconds (7.96 M allocations: 4.621 GiB, 58.21% gc time)","style":{"code":true}},{"type":"text","text":"\n\nHere are flame graphs for 1 thread (left) and 8 threads (right).\n\nI know I have to reduce allocations, but was hoping to get some advice how best to do this since quite of a bit of the allocation time is coming in basic linear algebra stuff like matrix division and using "},{"type":"text","text":"I","style":{"code":true}},{"type":"text","text":" as identity matrix.\n\nI've also thought about using "},{"type":"text","text":"Distributed","style":{"code":true}},{"type":"text","text":" but I ran into world age issues when passing functions to the workers..."}]}]}],"thread_ts":"1609540973.289000","reply_count":5,"reply_users_count":3,"latest_reply":"1609579942.292400","reply_users":["UJ7DVTVQ8","UKFUT8N5A","UH24GRBLL"],"subscribed":false},{"client_msg_id":"f6130b2e-237d-4100-b721-b9b80d1b2e4f","type":"message","text":"Your threading might interfere with Blas threading, try setting the number of Blas threads to 1, that can sometimes make it go faster.","user":"UJ7DVTVQ8","ts":"1609568448.290500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gWX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Your threading might interfere with Blas threading, try setting the number of Blas threads to 1, that can sometimes make it go faster."}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"4FFD22FF-3D28-4A7E-AF57-43DBC01B5810","type":"message","text":"Yes it definitely helped but these timings already have that factored in: <https://github.com/vancleve/threading_example/blob/a21fd4a18085c6c281796088cba5c540eab83516/popsim.jl#L8|https://github.com/vancleve/threading_example/blob/a21fd4a18085c6c281796088cba5c540eab83516/popsim.jl#L8>","user":"UKFUT8N5A","ts":"1609569754.291800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"a=0t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes it definitely helped but these timings already have that factored in: "},{"type":"link","url":"https://github.com/vancleve/threading_example/blob/a21fd4a18085c6c281796088cba5c540eab83516/popsim.jl#L8","text":"https://github.com/vancleve/threading_example/blob/a21fd4a18085c6c281796088cba5c540eab83516/popsim.jl#L8"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"6cdfacd3-68c5-4eab-8667-29e8eee45f31","type":"message","text":"In general, code that allocates can often lead to worse performance when multithreading it","user":"UH24GRBLL","ts":"1609579852.292000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yBe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In general, code that allocates can often lead to worse performance when multithreading it"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"dbd95e6b-68ea-40b4-bee9-759916f607c0","type":"message","text":"this happens because you basically multiply the number of allocations &amp; required memory by the number of threads you're using","user":"UH24GRBLL","ts":"1609579888.292200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DN8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this happens because you basically multiply the number of allocations & required memory by the number of threads you're using"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"6d446236-46c4-4229-88ec-96e095dafd96","type":"message","text":"if you're using a lot of BLAS, you might want to use mutating versions of the BLAS functions you're calling, like `mul!` and the like","user":"UH24GRBLL","ts":"1609579942.292400","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1609579953.000000"},"blocks":[{"type":"rich_text","block_id":"iW3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if you're using a lot of BLAS, you might want to use mutating versions of the BLAS functions you're calling, like "},{"type":"text","text":"mul!","style":{"code":true}},{"type":"text","text":" and the like"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"}]