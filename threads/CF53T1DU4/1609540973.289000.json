[{"client_msg_id":"36d87105-e9da-4cc1-b965-26d187398af0","type":"message","text":"Hi all. I have a question about getting good performance out of threading. I don't have a really minimal example, but can point you to a repo with the code (~200 lines):\n\n<https://github.com/vancleve/threading_example>\n\nOn my macbookpro, running the `@time evolve_replicates!(pop, rp)` from <https://github.com/vancleve/threading_example/blob/master/popsim.jl#L30>\nI get something like (after running once to compile)\nno threads  `3.936467 seconds (7.94 M allocations: 4.620 GiB, 14.60% gc time)`\n1 thread      `3.890999 seconds (7.94 M allocations: 4.620 GiB, 16.57% gc time)`\n2 threads    `2.340651 seconds (7.94 M allocations: 4.620 GiB, 25.03% gc time)`\n4 threads    `1.786248 seconds (7.94 M allocations: 4.620 GiB, 41.74% gc time)`\n8 threads    `1.658927 seconds (7.96 M allocations: 4.621 GiB, 58.21% gc time)`\n\nHere are flame graphs for 1 thread (left) and 8 threads (right).\n\nI know I have to reduce allocations, but was hoping to get some advice how best to do this since quite of a bit of the allocation time is coming in basic linear algebra stuff like matrix division and using `I` as identity matrix.\n\nI've also thought about using `Distributed` but I ran into world age issues when passing functions to the workers...","user":"UKFUT8N5A","ts":"1609540973.289000","team":"T68168MUP","edited":{"user":"UKFUT8N5A","ts":"1609541695.000000"},"blocks":[{"type":"rich_text","block_id":"UGvV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all. I have a question about getting good performance out of threading. I don't have a really minimal example, but can point you to a repo with the code (~200 lines):\n\n"},{"type":"link","url":"https://github.com/vancleve/threading_example"},{"type":"text","text":"\n\nOn my macbookpro, running the "},{"type":"text","text":"@time evolve_replicates!(pop, rp)","style":{"code":true}},{"type":"text","text":" from "},{"type":"link","url":"https://github.com/vancleve/threading_example/blob/master/popsim.jl#L30"},{"type":"text","text":"\nI get something like (after running once to compile)\nno threads  "},{"type":"text","text":"3.936467 seconds (7.94 M allocations: 4.620 GiB, 14.60% gc time)","style":{"code":true}},{"type":"text","text":"\n1 thread      "},{"type":"text","text":"3.890999 seconds (7.94 M allocations: 4.620 GiB, 16.57% gc time)","style":{"code":true}},{"type":"text","text":"\n2 threads    "},{"type":"text","text":"2.340651 seconds (7.94 M allocations: 4.620 GiB, 25.03% gc time)","style":{"code":true}},{"type":"text","text":"\n4 threads    "},{"type":"text","text":"1.786248 seconds (7.94 M allocations: 4.620 GiB, 41.74% gc time)","style":{"code":true}},{"type":"text","text":"\n8 threads    "},{"type":"text","text":"1.658927 seconds (7.96 M allocations: 4.621 GiB, 58.21% gc time)","style":{"code":true}},{"type":"text","text":"\n\nHere are flame graphs for 1 thread (left) and 8 threads (right).\n\nI know I have to reduce allocations, but was hoping to get some advice how best to do this since quite of a bit of the allocation time is coming in basic linear algebra stuff like matrix division and using "},{"type":"text","text":"I","style":{"code":true}},{"type":"text","text":" as identity matrix.\n\nI've also thought about using "},{"type":"text","text":"Distributed","style":{"code":true}},{"type":"text","text":" but I ran into world age issues when passing functions to the workers..."}]}]}],"thread_ts":"1609540973.289000","reply_count":13,"reply_users_count":3,"latest_reply":"1609675787.294500","reply_users":["UJ7DVTVQ8","UKFUT8N5A","UH24GRBLL"],"subscribed":false},{"client_msg_id":"f6130b2e-237d-4100-b721-b9b80d1b2e4f","type":"message","text":"Your threading might interfere with Blas threading, try setting the number of Blas threads to 1, that can sometimes make it go faster.","user":"UJ7DVTVQ8","ts":"1609568448.290500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gWX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Your threading might interfere with Blas threading, try setting the number of Blas threads to 1, that can sometimes make it go faster."}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"4FFD22FF-3D28-4A7E-AF57-43DBC01B5810","type":"message","text":"Yes it definitely helped but these timings already have that factored in: <https://github.com/vancleve/threading_example/blob/a21fd4a18085c6c281796088cba5c540eab83516/popsim.jl#L8|https://github.com/vancleve/threading_example/blob/a21fd4a18085c6c281796088cba5c540eab83516/popsim.jl#L8>","user":"UKFUT8N5A","ts":"1609569754.291800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"a=0t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes it definitely helped but these timings already have that factored in: "},{"type":"link","url":"https://github.com/vancleve/threading_example/blob/a21fd4a18085c6c281796088cba5c540eab83516/popsim.jl#L8","text":"https://github.com/vancleve/threading_example/blob/a21fd4a18085c6c281796088cba5c540eab83516/popsim.jl#L8"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"6cdfacd3-68c5-4eab-8667-29e8eee45f31","type":"message","text":"In general, code that allocates can often lead to worse performance when multithreading it","user":"UH24GRBLL","ts":"1609579852.292000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yBe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In general, code that allocates can often lead to worse performance when multithreading it"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A","reactions":[{"name":"100","users":["UJ7DVTVQ8"],"count":1}]},{"client_msg_id":"dbd95e6b-68ea-40b4-bee9-759916f607c0","type":"message","text":"this happens because you basically multiply the number of allocations &amp; required memory by the number of threads you're using","user":"UH24GRBLL","ts":"1609579888.292200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DN8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this happens because you basically multiply the number of allocations & required memory by the number of threads you're using"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"6d446236-46c4-4229-88ec-96e095dafd96","type":"message","text":"if you're using a lot of BLAS, you might want to use mutating versions of the BLAS functions you're calling, like `mul!` and the like","user":"UH24GRBLL","ts":"1609579942.292400","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1609579953.000000"},"blocks":[{"type":"rich_text","block_id":"iW3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if you're using a lot of BLAS, you might want to use mutating versions of the BLAS functions you're calling, like "},{"type":"text","text":"mul!","style":{"code":true}},{"type":"text","text":" and the like"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"fe377501-ded1-4faf-8bb5-5275febd3b46","type":"message","text":"thanks <@UH24GRBLL>, good advice.\n\nI'm a little confused about the intuition for why more allocations happen in threads compared to single threaded apps. Wouldn't roughly the same amount of memory be allocated, just across multiple threads instead of in a single thread (e.g., the total allocated didn't vary much between 1 and 8 threads in my runs).","user":"UKFUT8N5A","ts":"1609625010.292800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NMMY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thanks "},{"type":"user","user_id":"UH24GRBLL"},{"type":"text","text":", good advice.\n\nI'm a little confused about the intuition for why more allocations happen in threads compared to single threaded apps. Wouldn't roughly the same amount of memory be allocated, just across multiple threads instead of in a single thread (e.g., the total allocated didn't vary much between 1 and 8 threads in my runs)."}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"098f5d06-62fb-4772-8e03-51e42b3ed719","type":"message","text":"depends on when the allocations happen and why they happen","user":"UH24GRBLL","ts":"1609625056.293000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7YQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"depends on when the allocations happen and why they happen"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"80858195-69a8-4201-913a-2a7e80bb1cd0","type":"message","text":"if they happen because you slice an array depending on the number threads, they'll roughly allocate the same memory","user":"UH24GRBLL","ts":"1609625090.293200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vpra","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if they happen because you slice an array depending on the number threads, they'll roughly allocate the same memory"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"55461abe-305c-4958-b0e4-4160ae1d87a6","type":"message","text":"however, if you create ever more arrays &amp; subarrays, you'll need the same total amount of memory in a shorter amount of time, which can lead to it using more in a sort of spike","user":"UH24GRBLL","ts":"1609625132.293400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Zl6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"however, if you create ever more arrays & subarrays, you'll need the same total amount of memory in a shorter amount of time, which can lead to it using more in a sort of spike"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A","reactions":[{"name":"+1","users":["UKFUT8N5A"],"count":1}]},{"client_msg_id":"15a7815f-a71c-45b2-9dda-1911f1bc047a","type":"message","text":"ah interesting.","user":"UKFUT8N5A","ts":"1609631407.293600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1QO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ah interesting."}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"7c6be644-52cd-4d33-8a38-4bc3f5c7a16a","type":"message","text":"so does this have to do with memory management not being as parallelized using threads as the other computations?","user":"UKFUT8N5A","ts":"1609631619.293900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aJ8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so does this have to do with memory management not being as parallelized using threads as the other computations?"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"42725126-1735-4d98-b18e-a126011eae90","type":"message","text":"No, it's because more threads asking for the same ressources leads to more total memory being used because you usually have to copy it around to be thread safe and avoid data races","user":"UH24GRBLL","ts":"1609675725.294200","team":"T68168MUP","edited":{"user":"UH24GRBLL","ts":"1609675751.000000"},"blocks":[{"type":"rich_text","block_id":"qLx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"No, it's because more threads asking for the same ressources leads to more total memory being used because you usually have to copy it around to be thread safe and avoid data races"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"},{"client_msg_id":"f4fbc278-8b0a-4cae-a0e3-dc69bdef8f26","type":"message","text":"or use locks, but depending on the algorithm and data, that could kill performance","user":"UH24GRBLL","ts":"1609675787.294500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FzvA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"or use locks, but depending on the algorithm and data, that could kill performance"}]}]}],"thread_ts":"1609540973.289000","parent_user_id":"UKFUT8N5A"}]