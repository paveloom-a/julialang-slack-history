[{"client_msg_id":"a99abd34-4cae-4948-8432-ff4cd2fce29c","type":"message","text":"<@UEP056STX> and I have been doing some benchmarking of the `ShallowWaterModel` on `CPU`s vs `GPU`s.  After learning more about benchmarking than we had anticpated, we have the following results to share, which were run on a Tesla V100-SXM2-32GB machine.\n```        Shallow water model CPU -&gt; GPU speedup\n┌─────────────┬───────┬──────────┬─────────┬─────────┐\n│ Float_types │    Ns │  speedup │  memory │  allocs │\n├─────────────┼───────┼──────────┼─────────┼─────────┤\n│     Float64 │    32 │ 0.697116 │ 2.09724 │ 2.97978 │\n│     Float64 │    64 │  1.02927 │ 2.15944 │ 2.97029 │\n│     Float64 │   128 │  2.42711 │ 2.27406 │ 2.97029 │\n│     Float64 │   256 │  7.32025 │ 2.52177 │ 2.97029 │\n│     Float64 │   512 │  28.1914 │ 2.98971 │  2.9174 │\n│     Float64 │  1024 │  112.326 │ 3.93542 │ 2.93495 │\n│     Float64 │  2048 │  175.735 │ 5.81322 │ 2.98141 │\n│     Float64 │  4096 │  183.947 │ 9.58727 │ 2.96283 │\n│     Float64 │  8192 │  189.795 │  17.139 │ 2.96283 │\n│     Float64 │ 16384 │  186.833 │ 32.2437 │ 2.97419 │\n└─────────────┴───────┴──────────┴─────────┴─────────┘```\nWe weren't able to go any higher than this resolution, so we must be close to the 32GB of memory limit.  When we start testing `MultiGPU` (or `MPI_GPU`) we should be able to raise the wall and do even higher resolutions on two or more GPUs.\n\nThe punchline is that starting at `1024^2` we get a speed up of over `100` and it nearly doubles to `190`  at `4096^2`. To put this in context, to get something compariable, we would need `190` CPUs with MPI running at perfect efficiency.  Our eficiency performances of MPI showed that after 32 cores we had an efficiency of just over 80%.  I supsect we would need a lot more than 256 cores on the MPI code to run this quicky, but this is not something that we have checked (yet).  One GPU does a rather amazing job and should probably be used instead.","user":"U01FBLBCP7S","ts":"1616770712.035600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PG5","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UEP056STX"},{"type":"text","text":" and I have been doing some benchmarking of the "},{"type":"text","text":"ShallowWaterModel","style":{"code":true}},{"type":"text","text":" on `CPU`s vs `GPU`s.  After learning more about benchmarking than we had anticpated, we have the following results to share, which were run on a Tesla V100-SXM2-32GB machine.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"        Shallow water model CPU -> GPU speedup\n┌─────────────┬───────┬──────────┬─────────┬─────────┐\n│ Float_types │    Ns │  speedup │  memory │  allocs │\n├─────────────┼───────┼──────────┼─────────┼─────────┤\n│     Float64 │    32 │ 0.697116 │ 2.09724 │ 2.97978 │\n│     Float64 │    64 │  1.02927 │ 2.15944 │ 2.97029 │\n│     Float64 │   128 │  2.42711 │ 2.27406 │ 2.97029 │\n│     Float64 │   256 │  7.32025 │ 2.52177 │ 2.97029 │\n│     Float64 │   512 │  28.1914 │ 2.98971 │  2.9174 │\n│     Float64 │  1024 │  112.326 │ 3.93542 │ 2.93495 │\n│     Float64 │  2048 │  175.735 │ 5.81322 │ 2.98141 │\n│     Float64 │  4096 │  183.947 │ 9.58727 │ 2.96283 │\n│     Float64 │  8192 │  189.795 │  17.139 │ 2.96283 │\n│     Float64 │ 16384 │  186.833 │ 32.2437 │ 2.97419 │\n└─────────────┴───────┴──────────┴─────────┴─────────┘"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"We weren't able to go any higher than this resolution, so we must be close to the 32GB of memory limit.  When we start testing "},{"type":"text","text":"MultiGPU","style":{"code":true}},{"type":"text","text":" (or "},{"type":"text","text":"MPI_GPU","style":{"code":true}},{"type":"text","text":") we should be able to raise the wall and do even higher resolutions on two or more GPUs.\n\nThe punchline is that starting at "},{"type":"text","text":"1024^2","style":{"code":true}},{"type":"text","text":" we get a speed up of over "},{"type":"text","text":"100","style":{"code":true}},{"type":"text","text":" and it nearly doubles to "},{"type":"text","text":"190","style":{"code":true}},{"type":"text","text":"  at "},{"type":"text","text":"4096^2","style":{"code":true}},{"type":"text","text":". To put this in context, to get something compariable, we would need "},{"type":"text","text":"190","style":{"code":true}},{"type":"text","text":" CPUs with MPI running at perfect efficiency.  Our eficiency performances of MPI showed that after 32 cores we had an efficiency of just over 80%.  I supsect we would need a lot more than 256 cores on the MPI code to run this quicky, but this is not something that we have checked (yet).  One GPU does a rather amazing job and should probably be used instead."}]}]}],"thread_ts":"1616770712.035600","reply_count":9,"reply_users_count":3,"latest_reply":"1617042256.040100","reply_users":["U67BJLYCS","U01FBLBCP7S","U010LHCP277"],"is_locked":false,"subscribed":false,"reactions":[{"name":"rocket","users":["UEP056STX","U01E0U2RJJ2"],"count":2},{"name":"+1","users":["U01G39CC63F"],"count":1}]},{"client_msg_id":"60bf303c-0a6f-4f95-b3fa-2219af84d306","type":"message","text":"Nice! I usually keep an eye on `nvidia-smi` to gauge the memory usage of a code","user":"U67BJLYCS","ts":"1616773586.035700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CVXL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Nice! I usually keep an eye on "},{"type":"text","text":"nvidia-smi","style":{"code":true}},{"type":"text","text":" to gauge the memory usage of a code"}]}]}],"thread_ts":"1616770712.035600","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"4f9e3d98-b7ec-4a3a-9d22-c2a1845f9c10","type":"message","text":"Thanks for the suggestion <@U67BJLYCS>, I will try and find that and give it a try.  That would be most helpful","user":"U01FBLBCP7S","ts":"1616777071.036200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xNJEb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for the suggestion "},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":", I will try and find that and give it a try.  That would be most helpful"}]}]}],"thread_ts":"1616770712.035600","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"ba5d2bad-d451-4338-b167-f08eadccc59f","type":"message","text":"<@U01FBLBCP7S>, <@UEP056STX> and <@U67BJLYCS> it might be interesting to try KA at 32 threads on CPU. we don't have to share the results - but I would interested in how it currently does.","user":"U010LHCP277","ts":"1617040777.038800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iji","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U01FBLBCP7S"},{"type":"text","text":", "},{"type":"user","user_id":"UEP056STX"},{"type":"text","text":" and "},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":" it might be interesting to try KA at 32 threads on CPU. we don't have to share the results - but I would interested in how it currently does."}]}]}],"thread_ts":"1616770712.035600","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"9fd3ae5b-6b99-468c-bc63-ae241e61dc0b","type":"message","text":"Thanks for the suggestion <@U010LHCP277>.  In this not so old PR we did some MPI cpu tests going up to 32 cores.  <https://github.com/CliMA/Oceananigans.jl/pull/1505>","user":"U01FBLBCP7S","ts":"1617040932.039100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T5y","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for the suggestion "},{"type":"user","user_id":"U010LHCP277"},{"type":"text","text":".  In this not so old PR we did some MPI cpu tests going up to 32 cores.  "},{"type":"link","url":"https://github.com/CliMA/Oceananigans.jl/pull/1505"}]}]}],"thread_ts":"1616770712.035600","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"5d781308-4535-4331-8e30-9e3cc9a8d20f","type":"message","text":"Is this what you had in mind, or did I misunderstand something?","user":"U01FBLBCP7S","ts":"1617040944.039300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"c4T+U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is this what you had in mind, or did I misunderstand something?"}]}]}],"thread_ts":"1616770712.035600","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"15c616fc-7841-4729-88eb-ee71ca750ecc","type":"message","text":"No Chris wnats to set `JULIA_NUM_THREADS=32`","user":"U67BJLYCS","ts":"1617040967.039500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sWy60","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"No Chris wnats to set "},{"type":"text","text":"JULIA_NUM_THREADS=32","style":{"code":true}}]}]}],"thread_ts":"1616770712.035600","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"1807d60e-a770-4ed4-b451-0b957a3c75db","type":"message","text":"and see if CPU parallelism with KernelAbstractions scale okay","user":"U67BJLYCS","ts":"1617040987.039700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Thby","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and see if CPU parallelism with KernelAbstractions scale okay"}]}]}],"thread_ts":"1616770712.035600","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"28996f7d-1156-4904-91b1-3f37af7bcbca","type":"message","text":"<@U01FBLBCP7S> thanks, its not urgent - just interested in how KA is doing.","user":"U010LHCP277","ts":"1617042142.039900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PPFyc","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U01FBLBCP7S"},{"type":"text","text":" thanks, its not urgent - just interested in how KA is doing."}]}]}],"thread_ts":"1616770712.035600","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"a5ca2945-4d36-4613-9ece-26a6fa391014","type":"message","text":"Ah, thanks for explaining <@U67BJLYCS>.  I have never actually tried running Oceananigans with threads so that will be a good learning experience.","user":"U01FBLBCP7S","ts":"1617042256.040100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"k1b","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah, thanks for explaining "},{"type":"user","user_id":"U67BJLYCS"},{"type":"text","text":".  I have never actually tried running Oceananigans with threads so that will be a good learning experience."}]}]}],"thread_ts":"1616770712.035600","parent_user_id":"U01FBLBCP7S"}]