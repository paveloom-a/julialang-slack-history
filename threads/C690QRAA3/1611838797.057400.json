[{"client_msg_id":"dd1f97e2-1f26-4987-834d-69c6f75b6424","type":"message","text":"So, I'm trying to implement a GAN using Flux. I got the code from the model_zoo, and was adapting to make it similar to what I already had programmed in Python. But it seems that my Generator is not being trained properly. The generated images are just noise, while in Python, things seems to start \"moving\" after the first epoch. Here is the code for the generator network and training:\n```function Generator(latent_dim::Int = 100) # latent_dim is the size of the vector noise. The default is 100\n    return Chain(\n            Dense(latent_dim, 256,x-&gt;leakyrelu.(x, 0.2f0)),\n            Dense(256, 512,x-&gt;leakyrelu.(x, 0.2f0)),\n            Dense(512, 1024,x-&gt;leakyrelu.(x, 0.2f0)),\n            Dense(1024,784,x-&gt;σ.(x))\n            )\nend\ngenerator_loss(fake_output) = logitbinarycrossentropy(fake_output, 1)\nfunction train_generator!(gen, dscr, x, opt_gen, hparams)\n    noise = randn!(similar(x, (hparams.latent_dim, hparams.batch_size)))\n    ps = Flux.params(gen)    \n    # pullback(ps,value) returns ps and the gradient of ps, where loss = ps, and back(value) = ∇ps(value)\n    # Taking gradient\n    loss, back = Flux.pullback(ps) do \n        generator_loss(dscr(gen(noise))) # Thithe generator_loss\n    end\n    grad = back(1f0)\n    update!(opt_gen, ps, grad)\n    return loss\nend```\nAny ideas on why this might be happening? I'm training on MNIST using the 60.000 images.","user":"U01CMBH4MQE","ts":"1611838797.057400","team":"T68168MUP","edited":{"user":"U01CMBH4MQE","ts":"1611838828.000000"},"blocks":[{"type":"rich_text","block_id":"5ZKE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So, I'm trying to implement a GAN using Flux. I got the code from the model_zoo, and was adapting to make it similar to what I already had programmed in Python. But it seems that my Generator is not being trained properly. The generated images are just noise, while in Python, things seems to start \"moving\" after the first epoch. Here is the code for the generator network and training:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function Generator(latent_dim::Int = 100) # latent_dim is the size of the vector noise. The default is 100\n    return Chain(\n            Dense(latent_dim, 256,x->leakyrelu.(x, 0.2f0)),\n            Dense(256, 512,x->leakyrelu.(x, 0.2f0)),\n            Dense(512, 1024,x->leakyrelu.(x, 0.2f0)),\n            Dense(1024,784,x->σ.(x))\n            )\nend\ngenerator_loss(fake_output) = logitbinarycrossentropy(fake_output, 1)\nfunction train_generator!(gen, dscr, x, opt_gen, hparams)\n    noise = randn!(similar(x, (hparams.latent_dim, hparams.batch_size)))\n    ps = Flux.params(gen)    \n    # pullback(ps,value) returns ps and the gradient of ps, where loss = ps, and back(value) = ∇ps(value)\n    # Taking gradient\n    loss, back = Flux.pullback(ps) do \n        generator_loss(dscr(gen(noise))) # Thithe generator_loss\n    end\n    grad = back(1f0)\n    update!(opt_gen, ps, grad)\n    return loss\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Any ideas on why this might be happening? I'm training on MNIST using the 60.000 images."}]}]}],"thread_ts":"1611838797.057400","reply_count":18,"reply_users_count":2,"latest_reply":"1611863275.064400","reply_users":["UMY1LV01G","U01CMBH4MQE"],"subscribed":false},{"client_msg_id":"44ace138-f541-4345-9f77-dea0898b32bf","type":"message","text":"How do the gradients look? I would compare magnitudes (e.g. norms) between Keras and Flux to make sure everything isn't just 0","user":"UMY1LV01G","ts":"1611861567.061000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZOv9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How do the gradients look? I would compare magnitudes (e.g. norms) between Keras and Flux to make sure everything isn't just 0"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"ac401797-7431-49e1-8043-793e1f44773a","type":"message","text":"Norms of the gradients?","user":"U01CMBH4MQE","ts":"1611862129.061200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"12z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Norms of the gradients?"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"385bea5d-2d0a-4ce4-a8cf-d5db02a2d020","type":"message","text":"The generator changing, but it gives the same blur for all samples, and after a while, it get's stuck. I'll try to look at the gradients.","user":"U01CMBH4MQE","ts":"1611862200.061400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/cF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The generator changing, but it gives the same blur for all samples, and after a while, it get's stuck. I'll try to look at the gradients."}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"99f7214b-30a0-45b7-b5b5-f96603d82f73","type":"message","text":"Yeah, l2 norm for each gradient parameter you're interested in. If they're close to 0 then you don't have any gradients, but if there's some signal you should be able to see it","user":"UMY1LV01G","ts":"1611862206.061600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lUQa/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, l2 norm for each gradient parameter you're interested in. If they're close to 0 then you don't have any gradients, but if there's some signal you should be able to see it"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"c34ac868-5e08-46a8-ac1a-0a73f9b883f3","type":"message","text":"It will probably be easier to start from the model zoo version if that already works for you","user":"UMY1LV01G","ts":"1611862229.061800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YG8w","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It will probably be easier to start from the model zoo version if that already works for you"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"41750c7d-7bf8-4e59-9948-1775e4497142","type":"message","text":"The odd thing is that it \"should\" be working. Since it is the same model, with same parameters as Keras. I'm using ADAM on both, same architecture, same activation, same dataset...","user":"U01CMBH4MQE","ts":"1611862257.062000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TxG/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The odd thing is that it \"should\" be working. Since it is the same model, with same parameters as Keras. I'm using ADAM on both, same architecture, same activation, same dataset..."}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"1476c10d-1f4b-4697-a2dd-dedd5698e0d9","type":"message","text":"\"It will probably be easier to start from the model zoo version if that already works for you\". That's what I did, but the model there was not working.","user":"U01CMBH4MQE","ts":"1611862284.062200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vJst4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"\"It will probably be easier to start from the model zoo version if that already works for you\". That's what I did, but the model there was not working."}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"765c7317-0330-4d3a-901d-8a56fe0da14a","type":"message","text":"It was also no creating the proper generator, and it was way larger (it uses convolutions).","user":"U01CMBH4MQE","ts":"1611862305.062400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fsE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It was also no creating the proper generator, and it was way larger (it uses convolutions)."}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"f63dacc5-3824-4503-afdf-465a5c290ba8","type":"message","text":"Mine is simpler, with only simple neural nets","user":"U01CMBH4MQE","ts":"1611862319.062600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KYyB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Mine is simpler, with only simple neural nets"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"98110c36-fb6a-48c2-877d-ebf28a695790","type":"message","text":"I'll try to model something even simpler, like a 1D distribution, and see if I can get it working... :confused:","user":"U01CMBH4MQE","ts":"1611862350.062800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uAu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'll try to model something even simpler, like a 1D distribution, and see if I can get it working... "},{"type":"emoji","name":"confused"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"0c3e9b04-e47f-4099-9297-b2dde85585b9","type":"message","text":"GANs are notoriously unstable and difficult to train. A convnet works well because it's a good inductive prior","user":"UMY1LV01G","ts":"1611862353.063000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u9QP7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"GANs are notoriously unstable and difficult to train. A convnet works well because it's a good inductive prior"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"4f7c2323-19dd-4b9e-b708-e5974939f18e","type":"message","text":"You may want to see if <https://github.com/FluxML/model-zoo/pull/269> works","user":"UMY1LV01G","ts":"1611862394.063200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u+BUG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You may want to see if "},{"type":"link","url":"https://github.com/FluxML/model-zoo/pull/269"},{"type":"text","text":" works"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"7a1b156e-140d-4c2c-a85b-9329e2e9caeb","type":"message","text":"Thanks, although I think I'm already using this described in the pull request","user":"U01CMBH4MQE","ts":"1611862491.063400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F41+4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks, although I think I'm already using this described in the pull request"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"3f0be12c-cf30-4084-af5c-094f1eb30060","type":"message","text":"But with Dense layers in place of the conv layers? Does the keras version use conv layers too? If not, can you link it?","user":"UMY1LV01G","ts":"1611862540.063600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uQsa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But with Dense layers in place of the conv layers? Does the keras version use conv layers too? If not, can you link it?"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"5abdbe3e-aad3-4fe4-a4fd-06c77a3e27ad","type":"message","text":"My Keras uses only Dense, and works. I got from this lab <https://harvard-iacs.github.io/2019-CS109B/labs/lab11/GANS-sol/>","user":"U01CMBH4MQE","ts":"1611862590.063800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tpqDM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My Keras uses only Dense, and works. I got from this lab "},{"type":"link","url":"https://harvard-iacs.github.io/2019-CS109B/labs/lab11/GANS-sol/"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"f16511fe-1937-4c6d-b02e-2e699c6ad01f","type":"message","text":"Sorry, Dense + Dropout","user":"U01CMBH4MQE","ts":"1611862617.064000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hXdz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sorry, Dense + Dropout"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"adb52b87-31dc-4d47-8d6c-5df779159417","type":"message","text":"I'd recommend you start a discourse topic with the full running (but not training) code so more pairs of eyes can look at it. As-is it's difficult to pinpoint anything without that","user":"UMY1LV01G","ts":"1611862805.064200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m0G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd recommend you start a discourse topic with the full running (but not training) code so more pairs of eyes can look at it. As-is it's difficult to pinpoint anything without that"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"},{"client_msg_id":"649eb47f-be49-4873-896d-1c480d4f56a1","type":"message","text":"thanks a lot, <@UMY1LV01G>, really appreciate the help","user":"U01CMBH4MQE","ts":"1611863275.064400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"goWkq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thanks a lot, "},{"type":"user","user_id":"UMY1LV01G"},{"type":"text","text":", really appreciate the help"}]}]}],"thread_ts":"1611838797.057400","parent_user_id":"U01CMBH4MQE"}]