[{"client_msg_id":"87105fab-cf26-4386-b596-bd0385e866b0","type":"message","text":"Hi all. Conceptual question; In <#C690QRAA3|machine-learning>, whenever we refer to learning rate (η) we consider this to be the step-size of the sum of changes that we apply to the current weight-change. However, we are never consistent with math. Not even Hinton himself was: <https://www.nature.com/articles/323533a0.pdf> he included the term ϵ  (=η) out-of-nowhere realizing that the gradient descent should be a slow change of an amount proportional to the accumulated: η*dE/dw. In reality, what I think its happening, is that η = dw = step-size of the update in the numerical simulation. In physical units, we need to consider that if the weights had units, we can't just do Δw = -η*dE/dw and hope it makes physical sense (most of our models can spare of this but lack mathematical consistency)... in fact, if you look at the way Hinton establishes his cost function (total error), the actual units of the cost function are the same as the weights. Therefore, to be consistent with math, should he just say that \"for numerical simulations, we tune the derivative step to achieve convergence such that Δw = -η*dE. What are your thoughts?","user":"ULKN4RKAR","ts":"1615361914.020100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kFJC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all. Conceptual question; In "},{"type":"channel","channel_id":"C690QRAA3"},{"type":"text","text":", whenever we refer to learning rate (η) we consider this to be the step-size of the sum of changes that we apply to the current weight-change. However, we are never consistent with math. Not even Hinton himself was: "},{"type":"link","url":"https://www.nature.com/articles/323533a0.pdf"},{"type":"text","text":" he included the term ϵ  (=η) out-of-nowhere realizing that the gradient descent should be a slow change of an amount proportional to the accumulated: η*dE/dw. In reality, what I think its happening, is that η = dw = step-size of the update in the numerical simulation. In physical units, we need to consider that if the weights had units, we can't just do Δw = -η*dE/dw and hope it makes physical sense (most of our models can spare of this but lack mathematical consistency)... in fact, if you look at the way Hinton establishes his cost function (total error), the actual units of the cost function are the same as the weights. Therefore, to be consistent with math, should he just say that \"for numerical simulations, we tune the derivative step to achieve convergence such that Δw = -η*dE. What are your thoughts?"}]}]}],"thread_ts":"1615361914.020100","reply_count":1,"reply_users_count":1,"latest_reply":"1615362532.020200","reply_users":["ULKN4RKAR"],"subscribed":false},{"client_msg_id":"ded4a5e3-fa27-4830-8c5b-8f29bdbe099a","type":"message","text":"For anyone wondering what the heck is this dude thinking about; I just want some math consistency with the sudden plucking in a learning rate when in reality we might be just doing Euler integration in our numerical simulations and calling learning rate our dw.","user":"ULKN4RKAR","ts":"1615362532.020200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lUu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For anyone wondering what the heck is this dude thinking about; I just want some math consistency with the sudden plucking in a learning rate when in reality we might be just doing Euler integration in our numerical simulations and calling learning rate our dw."}]}]}],"thread_ts":"1615361914.020100","parent_user_id":"ULKN4RKAR"}]