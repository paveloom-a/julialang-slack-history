[{"client_msg_id":"c67f59ec-72ed-4c8f-89ea-a54abe9674ea","type":"message","text":"Any ideas on how to make a gpu-friendly layer that outputs just a striding? I.e. if the layer has a stride of 2 and the input is 32x32x3x8, then the output should be 16x16x3x8. The value of the output doesn't matter as it will be zeroed anyway.","user":"U01EK81V5GF","ts":"1610995134.030600","team":"T68168MUP","edited":{"user":"U01EK81V5GF","ts":"1610995153.000000"},"blocks":[{"type":"rich_text","block_id":"KEty","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any ideas on how to make a gpu-friendly layer that outputs just a striding? I.e. if the layer has a stride of 2 and the input is 32x32x3x8, then the output should be 16x16x3x8. The value of the output doesn't matter as it will be zeroed anyway."}]}]}],"thread_ts":"1610995134.030600","reply_count":9,"reply_users_count":2,"latest_reply":"1611067664.036000","reply_users":["UD0NS8PDF","U01EK81V5GF"],"subscribed":false},{"client_msg_id":"26a816a4-8e88-4e3c-ab82-bdf9e6313daf","type":"message","text":"Maybe just `similar`, if you don’t care what it contains at all:\n```julia&gt; small(n) = x -&gt; similar(x, size(x,1)÷n, size(x,2)÷n, size(x)[3:end]...)\nsmall (generic function with 1 method)\n\njulia&gt; small(2)(ones(32,32,3,8)) |&gt; size\n(16, 16, 3, 8)```","user":"UD0NS8PDF","ts":"1610996145.030800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"B2G+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe just "},{"type":"text","text":"similar","style":{"code":true}},{"type":"text","text":", if you don’t care what it contains at all:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> small(n) = x -> similar(x, size(x,1)÷n, size(x,2)÷n, size(x)[3:end]...)\nsmall (generic function with 1 method)\n\njulia> small(2)(ones(32,32,3,8)) |> size\n(16, 16, 3, 8)"}]}]}],"thread_ts":"1610995134.030600","parent_user_id":"U01EK81V5GF"},{"client_msg_id":"883a9214-b0ed-404f-9e2f-ff99df3d4959","type":"message","text":"I don't think that is differentiable though?","user":"U01EK81V5GF","ts":"1611001010.031000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mHiL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't think that is differentiable though?"}]}]}],"thread_ts":"1610995134.030600","parent_user_id":"U01EK81V5GF"},{"client_msg_id":"6586b130-4028-4c17-8509-19ffb71f4213","type":"message","text":"How are you going to zero it?","user":"UD0NS8PDF","ts":"1611001223.031200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qhf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How are you going to zero it?"}]}]}],"thread_ts":"1610995134.030600","parent_user_id":"U01EK81V5GF"},{"client_msg_id":"f75b6f44-4485-47c1-9774-3c4841ceb982","type":"message","text":"Just multiply element-wise by 0. Any other idea for doing it?","user":"U01EK81V5GF","ts":"1611001790.031400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hwdhD","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just multiply element-wise by 0. Any other idea for doing it?"}]}]}],"thread_ts":"1610995134.030600","parent_user_id":"U01EK81V5GF"},{"client_msg_id":"dd22aacc-ce6c-41d0-8ddb-502e690d8324","type":"message","text":"Firstly be warned that similar may produce NaN etc, and thus `all(all(iszero, similar([1.0], 10) .* 0.0) for _ in 1:1000)` tends to be false, but multiplying by `false` cures this.","user":"UD0NS8PDF","ts":"1611002865.031600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"J6S4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Firstly be warned that similar may produce NaN etc, and thus "},{"type":"text","text":"all(all(iszero, similar([1.0], 10) .* 0.0) for _ in 1:1000)","style":{"code":true}},{"type":"text","text":" tends to be false, but multiplying by "},{"type":"text","text":"false","style":{"code":true}},{"type":"text","text":" cures this."}]}]}],"thread_ts":"1610995134.030600","parent_user_id":"U01EK81V5GF"},{"client_msg_id":"d7140a5a-8075-4ad6-b9c0-9505b2540c07","type":"message","text":"However, this allocates a whole new array, so it would be better to say `similar(x, 100) .= 0`. But then Zygote will complain. So you will need `@nograd small` to tell it not to look inside the function where you do this.","user":"UD0NS8PDF","ts":"1611002936.031800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qhdyX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"However, this allocates a whole new array, so it would be better to say "},{"type":"text","text":"similar(x, 100) .= 0","style":{"code":true}},{"type":"text","text":". But then Zygote will complain. So you will need "},{"type":"text","text":"@nograd small","style":{"code":true}},{"type":"text","text":" to tell it not to look inside the function where you do this."}]}]}],"thread_ts":"1610995134.030600","parent_user_id":"U01EK81V5GF"},{"client_msg_id":"08de4a5b-f4e6-4173-9e34-584c073c5709","type":"message","text":"But maybe even better would be to immediately generate data the shape you want, not just zeros?","user":"UD0NS8PDF","ts":"1611003025.032000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kbZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But maybe even better would be to immediately generate data the shape you want, not just zeros?"}]}]}],"thread_ts":"1610995134.030600","parent_user_id":"U01EK81V5GF"},{"client_msg_id":"ad46a45d-9f4d-45e3-b03d-3d98e7c98239","type":"message","text":"I actually want zeros as the output of this operation. The simplest I could come up with is `Chain(MeanPool((1, 1), stride = stride), x -&gt; 0*x)`","user":"U01EK81V5GF","ts":"1611045626.032200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZfaXm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I actually want zeros as the output of this operation. The simplest I could come up with is "},{"type":"text","text":"Chain(MeanPool((1, 1), stride = stride), x -> 0*x)","style":{"code":true}}]}]}],"thread_ts":"1610995134.030600","parent_user_id":"U01EK81V5GF"},{"client_msg_id":"f4717bff-8425-406c-a965-e2ebe7da660a","type":"message","text":"For context, I am implementing the following pytorch layers in Flux. Initially, I naively used scalar indexing as is done in this python version, but I am trying to figure out faster implementations. `Zero` is the operator I originally asked about, while `FactorizedReduce` is meant to be a type of Identity function for specifically when the both spatial dimensions are cut in half and the channel dimension is doubled.\n```class Zero(nn.Module):\n\n  def __init__(self, stride):\n    super(Zero, self).__init__()\n    self.stride = stride\n\n  def forward(self, x):\n    if self.stride == 1:\n      return x.mul(0.)\n    return x[:,:,::self.stride,::self.stride].mul(0.)\n\n\nclass FactorizedReduce(nn.Module):\n\n  def __init__(self, C_in, C_out, affine=True):\n    super(FactorizedReduce, self).__init__()\n    assert C_out % 2 == 0\n    self.relu = nn.ReLU(inplace=False)\n    self.conv_1 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False)\n    self.conv_2 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False) \n    <http://self.bn|self.bn> = nn.BatchNorm2d(C_out, affine=affine)\n\n  def forward(self, x):\n    x = self.relu(x)\n    out = <http://torch.cat|torch.cat>([self.conv_1(x), self.conv_2(x[:,:,1:,1:])], dim=1)\n    out = <http://self.bn|self.bn>(out)\n    return out```\nThe stride is usually 1 and occasionally 2 in my current experiments, but may have different values in the future","user":"U01EK81V5GF","ts":"1611067664.036000","team":"T68168MUP","edited":{"user":"U01EK81V5GF","ts":"1611067859.000000"},"blocks":[{"type":"rich_text","block_id":"wMgCY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For context, I am implementing the following pytorch layers in Flux. Initially, I naively used scalar indexing as is done in this python version, but I am trying to figure out faster implementations. "},{"type":"text","text":"Zero","style":{"code":true}},{"type":"text","text":" is the operator I originally asked about, while "},{"type":"text","text":"FactorizedReduce","style":{"code":true}},{"type":"text","text":" is meant to be a type of Identity function for specifically when the both spatial dimensions are cut in half and the channel dimension is doubled.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"class Zero(nn.Module):\n\n  def __init__(self, stride):\n    super(Zero, self).__init__()\n    self.stride = stride\n\n  def forward(self, x):\n    if self.stride == 1:\n      return x.mul(0.)\n    return x[:,:,::self.stride,::self.stride].mul(0.)\n\n\nclass FactorizedReduce(nn.Module):\n\n  def __init__(self, C_in, C_out, affine=True):\n    super(FactorizedReduce, self).__init__()\n    assert C_out % 2 == 0\n    self.relu = nn.ReLU(inplace=False)\n    self.conv_1 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False)\n    self.conv_2 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False) \n    self.bn = nn.BatchNorm2d(C_out, affine=affine)\n\n  def forward(self, x):\n    x = self.relu(x)\n    out = torch.cat([self.conv_1(x), self.conv_2(x[:,:,1:,1:])], dim=1)\n    out = self.bn(out)\n    return out"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"The stride is usually 1 and occasionally 2 in my current experiments, but may have different values in the future"}]}]}],"thread_ts":"1610995134.030600","parent_user_id":"U01EK81V5GF"}]