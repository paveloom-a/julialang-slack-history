[{"client_msg_id":"e7003cd6-1fa6-4d31-a7b1-5aa70295b605","type":"message","text":"Hey folks, I was hoping someone might help resolve an ambiguity in some of the Flux and Zygote documentation. So in the `Zygote` docs it says that using implicit parameters works, but is not the recommended method. By implicit parameters, the docs seem to refer to notation like this with the zero argument anonymous function\n```grads = gradient(() -&gt; sum(linear(x)), Params([W, b]))```\n But the docs say `However, implicit parameters exist mainly for compatibility with Flux's current AD; it's recommended to use the other approaches unless you need this.`\nHowever, the `Flux` tutorial uses this type of implicit parameter approach in their 60 minute blitz--provided below. And I see this type of notation popping up everywhere, including the DiffEqFlux docs. So what is the right answer--meaning if the implicit parameter approach is not recommended then it seems to get used a lot ??\n\nHere is the example from the 60 minute blitz\n```using Flux: params\n\nW = randn(3, 5)\nb = zeros(3)\nx = rand(5)\n\ny(x) = sum(W * x .+ b)\n\ngrads = gradient(()-&gt;y(x), params([W, b]))\n\ngrads[W], grads[b]```\nMaybe I am missing something or worrying about something that is not a big deal. Just figured I would check.","user":"UDDSTBX19","ts":"1613411344.151200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2QK2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hey folks, I was hoping someone might help resolve an ambiguity in some of the Flux and Zygote documentation. So in the "},{"type":"text","text":"Zygote","style":{"code":true}},{"type":"text","text":" docs it says that using implicit parameters works, but is not the recommended method. By implicit parameters, the docs seem to refer to notation like this with the zero argument anonymous function\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"grads = gradient(() -> sum(linear(x)), Params([W, b]))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":" But the docs say "},{"type":"text","text":"However, implicit parameters exist mainly for compatibility with Flux's current AD; it's recommended to use the other approaches unless you need this.","style":{"code":true}},{"type":"text","text":"\nHowever, the "},{"type":"text","text":"Flux","style":{"code":true}},{"type":"text","text":" tutorial uses this type of implicit parameter approach in their 60 minute blitz--provided below. And I see this type of notation popping up everywhere, including the DiffEqFlux docs. So what is the right answer--meaning if the implicit parameter approach is not recommended then it seems to get used a lot ??\n\nHere is the example from the 60 minute blitz\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Flux: params\n\nW = randn(3, 5)\nb = zeros(3)\nx = rand(5)\n\ny(x) = sum(W * x .+ b)\n\ngrads = gradient(()->y(x), params([W, b]))\n\ngrads[W], grads[b]"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe I am missing something or worrying about something that is not a big deal. Just figured I would check."}]}]}],"thread_ts":"1613411344.151200","reply_count":10,"reply_users_count":2,"latest_reply":"1613417902.153100","reply_users":["UH9KWTTD3","UDDSTBX19"],"subscribed":false},{"client_msg_id":"3ae1de9d-0627-44bf-85fc-535baff61ac7","type":"message","text":"The short answer is that it isn’t a big deal. As you can probably tell from the tutorial and various other docs, we haven’t really made the transition completely to explicit parameters ubiquitously. There are variety of reasons for this. But for your use-case, I guess it depends on the context. If you are taking the gradient of a deep NN with respect to the weights, then it is probably easies to use the implicit. Most docs and tutorials still use this format, so things will carry over better. If you are taking the gradient of a smaller model or with respect to something other than the weights, it would be worth it to do the explicit version.","user":"UH9KWTTD3","ts":"1613412120.151300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gzpl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The short answer is that it isn’t a big deal. As you can probably tell from the tutorial and various other docs, we haven’t really made the transition completely to explicit parameters ubiquitously. There are variety of reasons for this. But for your use-case, I guess it depends on the context. If you are taking the gradient of a deep NN with respect to the weights, then it is probably easies to use the implicit. Most docs and tutorials still use this format, so things will carry over better. If you are taking the gradient of a smaller model or with respect to something other than the weights, it would be worth it to do the explicit version."}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"},{"client_msg_id":"9ea74380-43fd-435e-aaf9-5151a3769f9a","type":"message","text":"<@UH9KWTTD3> Oh thanks so much for the clarifications. I am still just trying to learn Flux, so little things like this probably throw off noobs more than more seasoned folks. But thanks for the clarification. That makes a lot more sense. I will try to keep both syntaxes in mind. Thanks again for your insights.","user":"UDDSTBX19","ts":"1613412331.151500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"djWA3","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UH9KWTTD3"},{"type":"text","text":" Oh thanks so much for the clarifications. I am still just trying to learn Flux, so little things like this probably throw off noobs more than more seasoned folks. But thanks for the clarification. That makes a lot more sense. I will try to keep both syntaxes in mind. Thanks again for your insights."}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"},{"client_msg_id":"dd1cb99a-6227-49d9-a0fb-180a2d69ec62","type":"message","text":"No problem! Also, if you are manipulating the params/gradients extensively with some custom code, then explicit tends to be more flexible. Implicit can almost always be made to work, but it just won’t work with the first way you think of writing the code in my experience.","user":"UH9KWTTD3","ts":"1613412463.151700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VfHsN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"No problem! Also, if you are manipulating the params/gradients extensively with some custom code, then explicit tends to be more flexible. Implicit can almost always be made to work, but it just won’t work with the first way you think of writing the code in my experience."}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"},{"client_msg_id":"c936bf95-0c22-44a4-91f9-8c302613b394","type":"message","text":"Oh yes. I will keep that in mind. I am working with some LSTMs so those are a bit more manual with respect to passing hidden states and all. Oh yes, and is there a difference between implicit and explicit with respect to \"inplace\" operations? I know some of the differential equations solvers use a lot of inplace operations for performance, but sometimes inplace operations can mess up the gradients. Is that just a general issue, or is the explicit better than the implicit for something like that.","user":"UDDSTBX19","ts":"1613412997.151900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6xd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh yes. I will keep that in mind. I am working with some LSTMs so those are a bit more manual with respect to passing hidden states and all. Oh yes, and is there a difference between implicit and explicit with respect to \"inplace\" operations? I know some of the differential equations solvers use a lot of inplace operations for performance, but sometimes inplace operations can mess up the gradients. Is that just a general issue, or is the explicit better than the implicit for something like that."}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"},{"client_msg_id":"ae193f4c-cd4e-4080-9cda-fd954d08c790","type":"message","text":"The main issues are getting the parameter/gradient associated with a particular weight. For example `gs[1]` where `gs` is the gradients returned by implicit parameters will not work. You need to do something like `gs[m[1].weight]` where `m` is the `Chain` model for example. It’s a bit opaque, but the basic difference is that implicit parameters and their gradients are indexed by the variable itself (e.g. `gs[W]`) instead of an integer. As long as whatever you do iterates over the gradients (e.g. `for g in gs`) then it won’t make a difference whether it is explicit or implicit. The iterator will take care of the correct style of indexing.","user":"UH9KWTTD3","ts":"1613417284.152100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"B1G","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The main issues are getting the parameter/gradient associated with a particular weight. For example "},{"type":"text","text":"gs[1]","style":{"code":true}},{"type":"text","text":" where "},{"type":"text","text":"gs","style":{"code":true}},{"type":"text","text":" is the gradients returned by implicit parameters will not work. You need to do something like "},{"type":"text","text":"gs[m[1].weight]","style":{"code":true}},{"type":"text","text":" where "},{"type":"text","text":"m","style":{"code":true}},{"type":"text","text":" is the "},{"type":"text","text":"Chain","style":{"code":true}},{"type":"text","text":" model for example. It’s a bit opaque, but the basic difference is that implicit parameters and their gradients are indexed by the variable itself (e.g. "},{"type":"text","text":"gs[W]","style":{"code":true}},{"type":"text","text":") instead of an integer. As long as whatever you do iterates over the gradients (e.g. "},{"type":"text","text":"for g in gs","style":{"code":true}},{"type":"text","text":") then it won’t make a difference whether it is explicit or implicit. The iterator will take care of the correct style of indexing."}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"},{"client_msg_id":"9116b202-1f76-423d-9bf3-ab5df02771a6","type":"message","text":"But once you access the specific gradient array that you want to apply in-place updates to, it doesn’t matter whether you are using explicit or implicit. They are both referencing the same array structure, it’s how you actually access that reference that’s subtly different between the two forms.","user":"UH9KWTTD3","ts":"1613417353.152300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Jrlu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But once you access the specific gradient array that you want to apply in-place updates to, it doesn’t matter whether you are using explicit or implicit. They are both referencing the same array structure, it’s how you actually access that reference that’s subtly different between the two forms."}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"},{"client_msg_id":"daecc336-1209-4d91-8920-914a7d55020b","type":"message","text":"Most stuff in DiffEqFlux should work with implicit just fine. The SciML packages use the functions `restructure`/`destructure` or `FastDense`/etc. to take care of mapping between the format that the DE solver understands and the format that Flux understands. I would say just follow what’s in the SciML docs and you’ll be fine.","user":"UH9KWTTD3","ts":"1613417468.152500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hoQP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Most stuff in DiffEqFlux should work with implicit just fine. The SciML packages use the functions "},{"type":"text","text":"restructure","style":{"code":true}},{"type":"text","text":"/"},{"type":"text","text":"destructure","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"FastDense","style":{"code":true}},{"type":"text","text":"/etc. to take care of mapping between the format that the DE solver understands and the format that Flux understands. I would say just follow what’s in the SciML docs and you’ll be fine."}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"},{"client_msg_id":"4d10b86b-7e41-4313-81c3-259bd3dfec07","type":"message","text":"You can always ask in <#C7T968HRU|diffeq-bridged> or <#CN04R7WKE|sciml> if you face a particular issue that requires you to switch to explicit and it throws an error.","user":"UH9KWTTD3","ts":"1613417501.152700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lne6h","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can always ask in "},{"type":"channel","channel_id":"C7T968HRU"},{"type":"text","text":" or "},{"type":"channel","channel_id":"CN04R7WKE"},{"type":"text","text":" if you face a particular issue that requires you to switch to explicit and it throws an error."}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"},{"client_msg_id":"19fab7ad-f428-4f6e-9ff3-5287c4fb1816","type":"message","text":"That is very very helpful. I doubt I would have gathered that much from the docs, so thanks for such a detailed explanation. I will try fire up a notebook and check out what you describe here, it makes a lot more sense when you explain the implementations. There was an issue on the <#CN04R7WKE|sciml> thread just a few days ago dealing with inplace operations, so I had that on my mind. I actually ran into a similar issue using pytorch. So it is basically about how to access the references to the gradients. Thanks again for your help.","user":"UDDSTBX19","ts":"1613417708.152900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oqk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That is very very helpful. I doubt I would have gathered that much from the docs, so thanks for such a detailed explanation. I will try fire up a notebook and check out what you describe here, it makes a lot more sense when you explain the implementations. There was an issue on the "},{"type":"channel","channel_id":"CN04R7WKE"},{"type":"text","text":" thread just a few days ago dealing with inplace operations, so I had that on my mind. I actually ran into a similar issue using pytorch. So it is basically about how to access the references to the gradients. Thanks again for your help."}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"},{"client_msg_id":"345d10db-eeaa-479a-8a20-ef6166d3ad8c","type":"message","text":"No problem. If it helps, here is the source code in Zygote that defines the structures that store implicit parameters and their gradients. <https://github.com/FluxML/Zygote.jl/blob/956cbcf3c572c0eb09c146189bb38b1b434634ff/src/compiler/interface.jl#L66>\n<https://github.com/FluxML/Zygote.jl/blob/956cbcf3c572c0eb09c146189bb38b1b434634ff/src/compiler/interface.jl#L135>","user":"UH9KWTTD3","ts":"1613417902.153100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MSsaY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"No problem. If it helps, here is the source code in Zygote that defines the structures that store implicit parameters and their gradients. "},{"type":"link","url":"https://github.com/FluxML/Zygote.jl/blob/956cbcf3c572c0eb09c146189bb38b1b434634ff/src/compiler/interface.jl#L66"},{"type":"text","text":"\n"},{"type":"link","url":"https://github.com/FluxML/Zygote.jl/blob/956cbcf3c572c0eb09c146189bb38b1b434634ff/src/compiler/interface.jl#L135"}]}]}],"thread_ts":"1613411344.151200","parent_user_id":"UDDSTBX19"}]