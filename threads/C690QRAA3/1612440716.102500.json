[{"type":"message","text":"I was looking at some ml paper (<https://arxiv.org/pdf/1206.6483.pdf> ). There they report the classification accuracy their methods.\n\nIn the paper they mentioned that they used cross-validation to select the parameters, but they never mention creating a test set (they mention a training set though) Now I was wondering, are such reported results usually just the output of crossvalidation (and the ± is just the estimated standard deviation?). Or is using a test set for reporting so common, that it does not have to be mentioned?","files":[{"id":"F01LJK6S3AB","created":1612440353,"timestamp":1612440353,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"UBEF50B7C","editable":false,"size":76567,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01LJK6S3AB/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01LJK6S3AB/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_360.png","thumb_360_w":360,"thumb_360_h":137,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_480.png","thumb_480_w":480,"thumb_480_h":183,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_720.png","thumb_720_w":720,"thumb_720_h":274,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01LJK6S3AB-707e711940/image_800.png","thumb_800_w":800,"thumb_800_h":305,"original_w":888,"original_h":338,"thumb_tiny":"AwASADDSJpMn3/KlP3vwpuTigBefU/lRz6n8qTPFGTQAuT7/AJUoPPem5OaVTzQA6jFFFABRiiigAooooA//2Q==","permalink":"https://julialang.slack.com/files/UBEF50B7C/F01LJK6S3AB/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01LJK6S3AB-c3f67c00fb","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"km75/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was looking at some ml paper ("},{"type":"link","url":"https://arxiv.org/pdf/1206.6483.pdf"},{"type":"text","text":" ). There they report the classification accuracy their methods.\n\nIn the paper they mentioned that they used cross-validation to select the parameters, but they never mention creating a test set (they mention a training set though) Now I was wondering, are such reported results usually just the output of crossvalidation (and the ± is just the estimated standard deviation?). Or is using a test set for reporting so common, that it does not have to be mentioned?"}]}]}],"user":"UBEF50B7C","display_as_bot":false,"ts":"1612440716.102500","thread_ts":"1612440716.102500","reply_count":4,"reply_users_count":2,"latest_reply":"1612455756.103700","reply_users":["UMY1LV01G","UBEF50B7C"],"subscribed":false},{"client_msg_id":"4e293119-7821-471a-8b4d-2e3c9cd0ccef","type":"message","text":"This is somewhat common for low-data regimes. In short, they tune hyperparams on the train set in each split and don't have a dedicated validation split or separate hold-out test set","user":"UMY1LV01G","ts":"1612455383.103100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6F/Y3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This is somewhat common for low-data regimes. In short, they tune hyperparams on the train set in each split and don't have a dedicated validation split or separate hold-out test set"}]}]}],"thread_ts":"1612440716.102500","parent_user_id":"UBEF50B7C"},{"client_msg_id":"1efe0e28-8008-4c7b-b9cc-49fc5a133bc2","type":"message","text":"The assumption is that the train and test sets for each split will be iid, which is reasonable if you've split them from one set in the first place.","user":"UMY1LV01G","ts":"1612455500.103300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ic+Kf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The assumption is that the train and test sets for each split will be iid, which is reasonable if you've split them from one set in the first place."}]}]}],"thread_ts":"1612440716.102500","parent_user_id":"UBEF50B7C"},{"client_msg_id":"06f5fec7-8cc5-4cb0-bc88-ceab92cc8cbc","type":"message","text":"Looking at 4.1, the +- is standard deviation","user":"UMY1LV01G","ts":"1612455551.103500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7a+xL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looking at 4.1, the +- is standard deviation"}]}]}],"thread_ts":"1612440716.102500","parent_user_id":"UBEF50B7C"},{"client_msg_id":"597c5309-d128-45ec-95d6-e5fe284b76a1","type":"message","text":"hmm I mean makes sense, MUTAG has onl 188 samples and ENZYME has 600 - I still would imagine that some overfitting is happening especially when they tune the hyperparameters there","user":"UBEF50B7C","ts":"1612455756.103700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LGI4K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hmm I mean makes sense, MUTAG has onl 188 samples and ENZYME has 600 - I still would imagine that some overfitting is happening especially when they tune the hyperparameters there"}]}]}],"thread_ts":"1612440716.102500","parent_user_id":"UBEF50B7C"}]