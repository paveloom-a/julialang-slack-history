[{"type":"message","text":"","user":"U011V2YN59N","ts":"1617931720.127400","team":"T68168MUP","attachments":[{"fallback":"[April 8th, 2021 9:08 PM] pjentsch: <https://arxiv.org/abs/1903.03129>\nedit: this is the new paper <https://arxiv.org/abs/2103.10891>\ncurrently on the orange website, claims huge speedups for training neural nets on the CPU vs  on GPUs","ts":"1617930530.229000","author_id":"U011V2YN59N","author_subname":"Peter J","channel_id":"C680MM7D4","channel_name":"random","is_msg_unfurl":true,"is_thread_root_unfurl":true,"text":"<https://arxiv.org/abs/1903.03129>\nedit: this is the new paper <https://arxiv.org/abs/2103.10891>\ncurrently on the orange website, claims huge speedups for training neural nets on the CPU vs  on GPUs","author_name":"Peter J","author_link":"https://julialang.slack.com/team/U011V2YN59N","author_icon":"https://avatars.slack-edge.com/2020-04-22/1103390456848_2f885299664a3012f2e3_48.jpg","mrkdwn_in":["text"],"color":"D0D0D0","from_url":"https://julialang.slack.com/archives/C680MM7D4/p1617930530229000?thread_ts=1617930530229000&cid=C680MM7D4","is_share":true,"footer":"Thread in #random"}],"thread_ts":"1617931720.127400","reply_count":5,"reply_users_count":4,"latest_reply":"1617973778.130600","reply_users":["U9RDM8ZGT","U6YRZ18GZ","UPUBAM63X","U01J62981NK"],"is_locked":false,"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"LoL, I was just about to post this.\n\"SLIDE is a C++ implementation of a sparse hash table based back-propagation\" - I wonder how hard this would be to implement in Julia/Flux/Zygote? Seems like multiple dispatch would be a win here.","user":"U9RDM8ZGT","ts":"1617931871.127600","thread_ts":"1617931720.127400","root":{"type":"message","text":"","user":"U011V2YN59N","ts":"1617931720.127400","team":"T68168MUP","attachments":[{"fallback":"[April 8th, 2021 9:08 PM] pjentsch: <https://arxiv.org/abs/1903.03129>\nedit: this is the new paper <https://arxiv.org/abs/2103.10891>\ncurrently on the orange website, claims huge speedups for training neural nets on the CPU vs  on GPUs","ts":"1617930530.229000","author_id":"U011V2YN59N","author_subname":"Peter J","channel_id":"C680MM7D4","channel_name":"random","is_msg_unfurl":true,"is_thread_root_unfurl":true,"text":"<https://arxiv.org/abs/1903.03129>\nedit: this is the new paper <https://arxiv.org/abs/2103.10891>\ncurrently on the orange website, claims huge speedups for training neural nets on the CPU vs  on GPUs","author_name":"Peter J","author_link":"https://julialang.slack.com/team/U011V2YN59N","author_icon":"https://avatars.slack-edge.com/2020-04-22/1103390456848_2f885299664a3012f2e3_48.jpg","mrkdwn_in":["text"],"color":"D0D0D0","from_url":"https://julialang.slack.com/archives/C680MM7D4/p1617930530229000?thread_ts=1617930530229000&cid=C680MM7D4","is_share":true,"footer":"Thread in #random"}],"thread_ts":"1617931720.127400","reply_count":5,"reply_users_count":4,"latest_reply":"1617973778.130600","reply_users":["U9RDM8ZGT","U6YRZ18GZ","UPUBAM63X","U01J62981NK"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"vsT1s","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"LoL, I was just about to post this.\n\"SLIDE is a C++ implementation of a sparse hash table based back-propagation\" - I wonder how hard this would be to implement in Julia/Flux/Zygote? Seems like multiple dispatch would be a win here."}]}]}],"client_msg_id":"615d6cf9-d1f2-41e8-94ce-549893098063","edited":{"user":"U9RDM8ZGT","ts":"1617932215.000000"},"reactions":[{"name":"+1","users":["UC4QQPG4A"],"count":1}]},{"client_msg_id":"93fa1274-cc80-4236-97db-8f684b4ae96d","type":"message","text":"My friend who is big in sparse numerical libraries (he is sold to c++ unfortunately) recommended me the 1st version of the paper and asked me, if it is worth to look. My main problem is that they test the solution on three datasets which is not that popular in ML literature. In my opinion, unless they use some advanced architectures (Convolution / transformers), it will be unnoticed. But it might be a big benefit in our Mill.jl / JsonGrinder.jl libs, because we rely on feedforward neural networks.","user":"U6YRZ18GZ","ts":"1617951700.129700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NPT7q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My friend who is big in sparse numerical libraries (he is sold to c++ unfortunately) recommended me the 1st version of the paper and asked me, if it is worth to look. My main problem is that they test the solution on three datasets which is not that popular in ML literature. In my opinion, unless they use some advanced architectures (Convolution / transformers), it will be unnoticed. But it might be a big benefit in our Mill.jl / JsonGrinder.jl libs, because we rely on feedforward neural networks."}]}]}],"thread_ts":"1617931720.127400","parent_user_id":"U011V2YN59N"},{"client_msg_id":"1e2a1518-59e9-40d0-bcb2-57d2afcd5650","type":"message","text":"someone like <@UAUPJLBQX> would probably have good opinions on this :smile:","user":"UPUBAM63X","ts":"1617971630.130200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LNQO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"someone like "},{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":" would probably have good opinions on this "},{"type":"emoji","name":"smile"}]}]}],"thread_ts":"1617931720.127400","parent_user_id":"U011V2YN59N"},{"client_msg_id":"c1e8d8e6-b513-4cfc-aebf-e55926bb27ca","type":"message","text":"I think multilayer percepteron implementations would already see good uptake in the Julia community, since MLPs are widely used in scientific machine learning (e.g. they are the dominant architectures in physics informed neural networks).","user":"U01J62981NK","ts":"1617973333.130400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cIBo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think multilayer percepteron implementations would already see good uptake in the Julia community, since MLPs are widely used in scientific machine learning (e.g. they are the dominant architectures in physics informed neural networks)."}]}]}],"thread_ts":"1617931720.127400","parent_user_id":"U011V2YN59N"},{"client_msg_id":"360c1de0-8cc7-40e5-9ac9-5d9b300e7dc3","type":"message","text":"That would be sufficient for our Mill / JsonGrinder.","user":"U6YRZ18GZ","ts":"1617973778.130600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uoa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That would be sufficient for our Mill / JsonGrinder."}]}]}],"thread_ts":"1617931720.127400","parent_user_id":"U011V2YN59N"}]