[{"client_msg_id":"f98488d0-494a-4bd4-bc78-87c0b18ef06f","type":"message","text":"Yeah, I don't really understand what their rule 10 is trying to say","user":"U674T3KB3","ts":"1612729732.301600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"N4t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, I don't really understand what their rule 10 is trying to say"}]}]}],"thread_ts":"1612729732.301600","reply_count":4,"reply_users_count":2,"latest_reply":"1612730920.303200","reply_users":["UM6JW2SF9","UMDEUKM29"],"subscribed":false},{"client_msg_id":"fcb89137-7ef2-4b5c-b6eb-ad49dfda8872","type":"message","text":"The book context is \"In other words, nested adjoints can be evaluated as directional derivatives of a single adjoint\"","user":"UM6JW2SF9","ts":"1612729910.302100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G04","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The book context is \"In other words, nested adjoints can be evaluated as directional derivatives of a single adjoint\""}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3"},{"client_msg_id":"4b780029-847b-4d26-8874-983da00932a1","type":"message","text":"is it just that when you transpose something twice you get the original thing back?","user":"UMDEUKM29","ts":"1612730220.302600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RV1VG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is it just that when you transpose something twice you get the original thing back?"}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3"},{"client_msg_id":"6759f778-230c-408a-8bb6-be1ae03c5f17","type":"message","text":"I think it relies on permutation symmetry in higher order partial derivatives for sufficiently smooth functions","user":"UM6JW2SF9","ts":"1612730692.303000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H3tDb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think it relies on permutation symmetry in higher order partial derivatives for sufficiently smooth functions"}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3"},{"client_msg_id":"1fdc22fc-fe91-4ad1-bb12-7e817f1af850","type":"message","text":"A few pages later they also mention the double-transpose (section \"Adjoints of adjoints\") where there is also some more context: \"While second derivative matrices are crucial in optimization and other numerical applications, complete third and higher derivative tensors are rarely of practical interest (in our experience).  Moreover, as we observed at the beginning of this chapter, the repeated forward and backward sweeping caused by adjoining an evaluation program more than once (with fixed weight vectors) can always be avoided. Loosely speaking, a sequence of combined forward and return sweeps can be replaced by one such pair, with higher derivatives being propagated in both directions.  As a consequence, the computational complex-\nity of higher derivatives grows quadratically rather than exponentially with its degree.  Moreover the corresponding memory requirement grows only linearly with the degree.  Also, we may uniquely specify all derivative quantities using only one overbar and arbitrarily many dots. These claims will be substantiated\nin Chapter 13 on Taylors and tensors.\" (p. 96)","user":"UM6JW2SF9","ts":"1612730920.303200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m7I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"A few pages later they also mention the double-transpose (section \"Adjoints of adjoints\") where there is also some more context: \"While second derivative matrices are crucial in optimization and other numerical applications, complete third and higher derivative tensors are rarely of practical interest (in our experience).  Moreover, as we observed at the beginning of this chapter, the repeated forward and backward sweeping caused by adjoining an evaluation program more than once (with fixed weight vectors) can always be avoided. Loosely speaking, a sequence of combined forward and return sweeps can be replaced by one such pair, with higher derivatives being propagated in both directions.  As a consequence, the computational complex-\nity of higher derivatives grows quadratically rather than exponentially with its degree.  Moreover the corresponding memory requirement grows only linearly with the degree.  Also, we may uniquely specify all derivative quantities using only one overbar and arbitrarily many dots. These claims will be substantiated\nin Chapter 13 on Taylors and tensors.\" (p. 96)"}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3","reactions":[{"name":"+1","users":["U6A936746"],"count":1}]}]