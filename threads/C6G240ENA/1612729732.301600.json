[{"client_msg_id":"f98488d0-494a-4bd4-bc78-87c0b18ef06f","type":"message","text":"Yeah, I don't really understand what their rule 10 is trying to say","user":"U674T3KB3","ts":"1612729732.301600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"N4t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, I don't really understand what their rule 10 is trying to say"}]}]}],"thread_ts":"1612729732.301600","reply_count":6,"reply_users_count":4,"latest_reply":"1612733396.304100","reply_users":["UM6JW2SF9","UMDEUKM29","U6A936746","U674T3KB3"],"subscribed":false},{"client_msg_id":"fcb89137-7ef2-4b5c-b6eb-ad49dfda8872","type":"message","text":"The book context is \"In other words, nested adjoints can be evaluated as directional derivatives of a single adjoint\"","user":"UM6JW2SF9","ts":"1612729910.302100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G04","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The book context is \"In other words, nested adjoints can be evaluated as directional derivatives of a single adjoint\""}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3"},{"client_msg_id":"4b780029-847b-4d26-8874-983da00932a1","type":"message","text":"is it just that when you transpose something twice you get the original thing back?","user":"UMDEUKM29","ts":"1612730220.302600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RV1VG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"is it just that when you transpose something twice you get the original thing back?"}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3"},{"client_msg_id":"6759f778-230c-408a-8bb6-be1ae03c5f17","type":"message","text":"I think it relies on permutation symmetry in higher order partial derivatives for sufficiently smooth functions","user":"UM6JW2SF9","ts":"1612730692.303000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H3tDb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think it relies on permutation symmetry in higher order partial derivatives for sufficiently smooth functions"}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3"},{"client_msg_id":"1fdc22fc-fe91-4ad1-bb12-7e817f1af850","type":"message","text":"A few pages later they also mention the double-transpose (section \"Adjoints of adjoints\") where there is also some more context: \"While second derivative matrices are crucial in optimization and other numerical applications, complete third and higher derivative tensors are rarely of practical interest (in our experience).  Moreover, as we observed at the beginning of this chapter, the repeated forward and backward sweeping caused by adjoining an evaluation program more than once (with fixed weight vectors) can always be avoided. Loosely speaking, a sequence of combined forward and return sweeps can be replaced by one such pair, with higher derivatives being propagated in both directions.  As a consequence, the computational complex-\nity of higher derivatives grows quadratically rather than exponentially with its degree.  Moreover the corresponding memory requirement grows only linearly with the degree.  Also, we may uniquely specify all derivative quantities using only one overbar and arbitrarily many dots. These claims will be substantiated\nin Chapter 13 on Taylors and tensors.\" (p. 96)","user":"UM6JW2SF9","ts":"1612730920.303200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m7I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"A few pages later they also mention the double-transpose (section \"Adjoints of adjoints\") where there is also some more context: \"While second derivative matrices are crucial in optimization and other numerical applications, complete third and higher derivative tensors are rarely of practical interest (in our experience).  Moreover, as we observed at the beginning of this chapter, the repeated forward and backward sweeping caused by adjoining an evaluation program more than once (with fixed weight vectors) can always be avoided. Loosely speaking, a sequence of combined forward and return sweeps can be replaced by one such pair, with higher derivatives being propagated in both directions.  As a consequence, the computational complex-\nity of higher derivatives grows quadratically rather than exponentially with its degree.  Moreover the corresponding memory requirement grows only linearly with the degree.  Also, we may uniquely specify all derivative quantities using only one overbar and arbitrarily many dots. These claims will be substantiated\nin Chapter 13 on Taylors and tensors.\" (p. 96)"}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3","reactions":[{"name":"+1","users":["U6A936746"],"count":1}]},{"client_msg_id":"ca332608-abbc-4d91-bbb5-83b82d245d9f","type":"message","text":"Without even looking at math and just at a high level:\nYou have all the information you could ever want about the code after doing a single pass.\nYou have seen it all.\nAnd used it to generate the code that a single evaluation will give you the first derivative.\n\nThere is nothing more to be gained from looking at code you generated there by doing another pass through that code.\nYou already have all the information  about the primal function that you want the second derivative of.\n*And* you even know everything about the code you generated to get first derivative, cos you generated it.\nWe don't need a trace of it","user":"U6A936746","ts":"1612732584.303500","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1612732608.000000"},"blocks":[{"type":"rich_text","block_id":"3rRh1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Without even looking at math and just at a high level:\nYou have all the information you could ever want about the code after doing a single pass.\nYou have seen it all.\nAnd used it to generate the code that a single evaluation will give you the first derivative.\n\nThere is nothing more to be gained from looking at code you generated there by doing another pass through that code.\nYou already have all the information  about the primal function that you want the second derivative of.\n"},{"type":"text","text":"And ","style":{"bold":true}},{"type":"text","text":"you even know everything about the code you generated to get first derivative, cos you generated it.\nWe don't need a trace of it"}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3"},{"client_msg_id":"3a3c217a-21cb-4cff-9452-000e4bb1b4ed","type":"message","text":"Yeah, sure, but the structure of your accumulation may still look like going back and forth","user":"U674T3KB3","ts":"1612733396.304100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EZN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, sure, but the structure of your accumulation may still look like going back and forth"}]}]}],"thread_ts":"1612729732.301600","parent_user_id":"U674T3KB3"}]