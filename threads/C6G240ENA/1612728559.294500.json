[{"client_msg_id":"842ed6c9-b2a6-466d-85a9-fc9d0f85dde4","type":"message","text":"Hi ! I'm excited since watching <@U674T3KB3>'s talk in November and looking at the gist. Among other things, I've been doing higher-order derivatives over a first-order reverse pass in jax so far,\n1. Is forward mode AD also in scope for Diffractor?\n2. Are there opinions on \"Rule 10: never go back more than once, after all weight vectors are known\" (from the Griewank&amp;Walther book) and how it compares to the higher-order simplification approach of Diffractor (or if there's any connection at all) ?","user":"UM6JW2SF9","ts":"1612728559.294500","team":"T68168MUP","edited":{"user":"UM6JW2SF9","ts":"1612728673.000000"},"blocks":[{"type":"rich_text","block_id":"bTsKl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi ! I'm excited since watching "},{"type":"user","user_id":"U674T3KB3"},{"type":"text","text":"'s talk in November and looking at the gist. Among other things, I've been doing higher-order derivatives over a first-order reverse pass in jax so far,\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is forward mode AD also in scope for Diffractor?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Are there opinions on \"Rule 10: never go back more than once, after all weight vectors are known\" (from the Griewank&Walther book) and how it compares to the higher-order simplification approach of Diffractor (or if there's any connection at all) ?"}]}],"style":"ordered","indent":0}]}],"thread_ts":"1612728559.294500","reply_count":6,"reply_users_count":2,"latest_reply":"1612742069.304900","reply_users":["UM6JW2SF9","U6A936746"],"subscribed":false,"reactions":[{"name":"100","users":["U6A936746"],"count":1}]},{"client_msg_id":"c686a987-57ae-4a8e-a6a2-3e852611462c","type":"message","text":"Context about the quote: \"In other words, nested adjoints can be evaluated as directional derivatives of a single adjoint\"","user":"UM6JW2SF9","ts":"1612729255.295900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=eyiT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Context about the quote: \"In other words, nested adjoints can be evaluated as directional derivatives of a single adjoint\""}]}]}],"thread_ts":"1612728559.294500","parent_user_id":"UM6JW2SF9","reactions":[{"name":"heavy_check_mark","users":["U6A936746"],"count":1}]},{"client_msg_id":"a6f1b2cc-e7d2-47fc-a9c0-004dba163b2d","type":"message","text":"I am not directly involved but from what I understand.\n\n1. Yes. It's on the long term roadmap. But won't be part of initial release.","user":"U6A936746","ts":"1612729307.296200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8OK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am not directly involved but from what I understand.\n\n1. Yes. It's on the long term roadmap. But won't be part of initial release."}]}]}],"thread_ts":"1612728559.294500","parent_user_id":"UM6JW2SF9","reactions":[{"name":"+1","users":["UM6JW2SF9"],"count":1}]},{"client_msg_id":"7eb950ad-af7c-4838-be52-30206f305a0f","type":"message","text":"My opinion.\n2. Yes. You shouldn't nest reverse mode exactly like Griewank and Walther say. You only need (at most) 1 reverse and after that you can nest forwards, or use taylor mode (chapter 13 same book).\nIt's why I (personal) think efficient nesting reverse is a novelty.\n(Pretty sure others disagree).\nIt's main use there is accidentally nesting AD.\nWhere you don't know what happens in the code you are calling, but turns out it uses AD.\nThat should still work with sensible efficiency. Even though it's not the theoretically optimal approach you would take if you were willing to rewrite the problem from scratch.\n\nMore interesting to me is Diffractor will generally optimize a lot better.\nUsing the same features.\nE.g. by moving code out of reverse pass and into forwards pass, (often saving memory) then optimize that together.\n\nAnd one day will better nest forward mode.\nWith expodential amounts of difficult common subexpression elimination you can recover taylor mode (chapter 13) from nested forward.\nWhich is probably pretty practically up to some useful level.\n\n\nAlso having deep ChainRules integration, including inplace gradient accumulation to massively decrease allocations (am working on that for Zygote also)..","user":"U6A936746","ts":"1612730141.302300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5Dcl1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My opinion.\n2. Yes. You shouldn't nest reverse mode exactly like Griewank and Walther say. You only need (at most) 1 reverse and after that you can nest forwards, or use taylor mode (chapter 13 same book).\nIt's why I (personal) think efficient nesting reverse is a novelty.\n(Pretty sure others disagree).\nIt's main use there is accidentally nesting AD.\nWhere you don't know what happens in the code you are calling, but turns out it uses AD.\nThat should still work with sensible efficiency. Even though it's not the theoretically optimal approach you would take if you were willing to rewrite the problem from scratch.\n\nMore interesting to me is Diffractor will generally optimize a lot better.\nUsing the same features.\nE.g. by moving code out of reverse pass and into forwards pass, (often saving memory) then optimize that together.\n\nAnd one day will better nest forward mode.\nWith expodential amounts of difficult common subexpression elimination you can recover taylor mode (chapter 13) from nested forward.\nWhich is probably pretty practically up to some useful level.\n\n\nAlso having deep ChainRules integration, including inplace gradient accumulation to massively decrease allocations (am working on that for Zygote also).."}]}]}],"thread_ts":"1612728559.294500","parent_user_id":"UM6JW2SF9"},{"client_msg_id":"4b8bd93f-d468-4fdf-aeb2-1ce10c27e77c","type":"message","text":"Thanks for the thorough reply! The nested ad-callee example also sounds quite compelling. Can't wait to see the performance implications in practice :slightly_smiling_face:","user":"UM6JW2SF9","ts":"1612739795.304400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2JmO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for the thorough reply! The nested ad-callee example also sounds quite compelling. Can't wait to see the performance implications in practice "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"thread_ts":"1612728559.294500","parent_user_id":"UM6JW2SF9"},{"client_msg_id":"d445d972-255e-41e6-a4a8-52103be8c5eb","type":"message","text":"Inplace gradient accumuluation as a mutating pullback ?","user":"UM6JW2SF9","ts":"1612740207.304700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LzdT+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Inplace gradient accumuluation as a mutating pullback ?"}]}]}],"thread_ts":"1612728559.294500","parent_user_id":"UM6JW2SF9"},{"client_msg_id":"dc3f9774-f574-43f9-93a1-68941b058da6","type":"message","text":"I wrote the explanation up fully and stuck it in the docs\n<https://juliadiff.org/ChainRulesCore.jl/dev/gradient_accumulation.html|https://juliadiff.org/ChainRulesCore.jl/dev/gradient_accumulation.html>","user":"U6A936746","ts":"1612742069.304900","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1612742080.000000"},"blocks":[{"type":"rich_text","block_id":"5m+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I wrote the explanation up fully and stuck it in the docs\n"},{"type":"link","url":"https://juliadiff.org/ChainRulesCore.jl/dev/gradient_accumulation.html","text":"https://juliadiff.org/ChainRulesCore.jl/dev/gradient_accumulation.html"}]}]}],"thread_ts":"1612728559.294500","parent_user_id":"UM6JW2SF9"}]