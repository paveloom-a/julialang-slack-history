[{"client_msg_id":"865232ee-c16a-498b-8906-3c53af6a9d74","type":"message","text":"The bugged code (if I try to force covariance matrix to be symmetry and positive definite externally) and its error message attaches:\n```using Random\nusing DifferentialEquations\nusing GenericLinearAlgebra\nusing Statistics\nusing Distributions\nusing Turing\n# data\nu_account = [1.0; 2.0];\n@model bayes_lna(y) = begin\n    log_delta ~ Normal(0.0,1.0) \n    delta = [exp(log_delta)]\n    phi = [delta  0; 10^-7 delta] # covariance matrix \n    D,V = GenericLinearAlgebra.eigen(GenericLinearAlgebra.Symmetric(phi))  # get eigen-values and eigen-vectos\n    D .= max.(D,1e-12) # force eigen values to be positive\n    phi_new = V*GenericLinearAlgebra.Diagonal(D)*V' # create new symmetry and positive definite matrix\n    y[:] ~ MvNormal([0.0,0.0],GenericLinearAlgebra.Symmetric(phi_new))\nend\nRandom.seed!(87654)\niterations = 20\nchain = sample(bayes_lna(u_account), NUTS(0.65),iterations)```","user":"U01Q398M3QB","ts":"1616578091.056700","team":"T68168MUP","edited":{"user":"U01Q398M3QB","ts":"1616578570.000000"},"blocks":[{"type":"rich_text","block_id":"Ynsh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The bugged code (if I try to force covariance matrix to be symmetry and positive definite externally) and its error message attaches:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Random\nusing DifferentialEquations\nusing GenericLinearAlgebra\nusing Statistics\nusing Distributions\nusing Turing\n# data\nu_account = [1.0; 2.0];\n@model bayes_lna(y) = begin\n    log_delta ~ Normal(0.0,1.0) \n    delta = [exp(log_delta)]\n    phi = [delta  0; 10^-7 delta] # covariance matrix \n    D,V = GenericLinearAlgebra.eigen(GenericLinearAlgebra.Symmetric(phi))  # get eigen-values and eigen-vectos\n    D .= max.(D,1e-12) # force eigen values to be positive\n    phi_new = V*GenericLinearAlgebra.Diagonal(D)*V' # create new symmetry and positive definite matrix\n    y[:] ~ MvNormal([0.0,0.0],GenericLinearAlgebra.Symmetric(phi_new))\nend\nRandom.seed!(87654)\niterations = 20\nchain = sample(bayes_lna(u_account), NUTS(0.65),iterations)"}]}]}],"thread_ts":"1616578091.056700","reply_count":5,"reply_users_count":2,"latest_reply":"1616615322.070900","reply_users":["U8T9JUA5R","U01Q398M3QB"],"is_locked":false,"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"I don't have any experience with ProximalOperators.jl, so I can't comment on this part. In general, if you have full control over the model and work with custom distributions, probably it would be much more efficient if you do not work with the covariance matrix `C` directly but instead with the lower-triangular matrix `L` in its decomposition `C = LL'`. In the example you show `phi` is actually already a lower-triangular matrix. Generally, you then just have to enforce that the diagonal entries of `L` are non-negative (e.g., by using `exp` or `log1pexp` ), the off-diagonal elements of `L` can be arbitrary. BTW I am a bit surprised you have to use `GenericLinearAlgebra` here - at least `Symmetric`  and `Diagonal` from `LinearAlgebra` should work fine with dual numbers (so maybe it is just due to `eigen`?). In fact, AFAIK PDMats (which is used by the constructors of `MvNormal`) only defines special dispatches for `LinearAlgebra.Symmetric` but not GenericLinearAlgebra.","user":"U8T9JUA5R","ts":"1616580167.061100","thread_ts":"1616578091.056700","root":{"client_msg_id":"865232ee-c16a-498b-8906-3c53af6a9d74","type":"message","text":"The bugged code (if I try to force covariance matrix to be symmetry and positive definite externally) and its error message attaches:\n```using Random\nusing DifferentialEquations\nusing GenericLinearAlgebra\nusing Statistics\nusing Distributions\nusing Turing\n# data\nu_account = [1.0; 2.0];\n@model bayes_lna(y) = begin\n    log_delta ~ Normal(0.0,1.0) \n    delta = [exp(log_delta)]\n    phi = [delta  0; 10^-7 delta] # covariance matrix \n    D,V = GenericLinearAlgebra.eigen(GenericLinearAlgebra.Symmetric(phi))  # get eigen-values and eigen-vectos\n    D .= max.(D,1e-12) # force eigen values to be positive\n    phi_new = V*GenericLinearAlgebra.Diagonal(D)*V' # create new symmetry and positive definite matrix\n    y[:] ~ MvNormal([0.0,0.0],GenericLinearAlgebra.Symmetric(phi_new))\nend\nRandom.seed!(87654)\niterations = 20\nchain = sample(bayes_lna(u_account), NUTS(0.65),iterations)```","user":"U01Q398M3QB","ts":"1616578091.056700","team":"T68168MUP","edited":{"user":"U01Q398M3QB","ts":"1616578570.000000"},"blocks":[{"type":"rich_text","block_id":"Ynsh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The bugged code (if I try to force covariance matrix to be symmetry and positive definite externally) and its error message attaches:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Random\nusing DifferentialEquations\nusing GenericLinearAlgebra\nusing Statistics\nusing Distributions\nusing Turing\n# data\nu_account = [1.0; 2.0];\n@model bayes_lna(y) = begin\n    log_delta ~ Normal(0.0,1.0) \n    delta = [exp(log_delta)]\n    phi = [delta  0; 10^-7 delta] # covariance matrix \n    D,V = GenericLinearAlgebra.eigen(GenericLinearAlgebra.Symmetric(phi))  # get eigen-values and eigen-vectos\n    D .= max.(D,1e-12) # force eigen values to be positive\n    phi_new = V*GenericLinearAlgebra.Diagonal(D)*V' # create new symmetry and positive definite matrix\n    y[:] ~ MvNormal([0.0,0.0],GenericLinearAlgebra.Symmetric(phi_new))\nend\nRandom.seed!(87654)\niterations = 20\nchain = sample(bayes_lna(u_account), NUTS(0.65),iterations)"}]}]}],"thread_ts":"1616578091.056700","reply_count":5,"reply_users_count":2,"latest_reply":"1616615322.070900","reply_users":["U8T9JUA5R","U01Q398M3QB"],"is_locked":false,"subscribed":false},"blocks":[{"type":"rich_text","block_id":"05o","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't have any experience with ProximalOperators.jl, so I can't comment on this part. In general, if you have full control over the model and work with custom distributions, probably it would be much more efficient if you do not work with the covariance matrix "},{"type":"text","text":"C","style":{"code":true}},{"type":"text","text":" directly but instead with the lower-triangular matrix "},{"type":"text","text":"L","style":{"code":true}},{"type":"text","text":" in its decomposition "},{"type":"text","text":"C = LL'","style":{"code":true}},{"type":"text","text":". In the example you show "},{"type":"text","text":"phi","style":{"code":true}},{"type":"text","text":" is actually already a lower-triangular matrix. Generally, you then just have to enforce that the diagonal entries of "},{"type":"text","text":"L","style":{"code":true}},{"type":"text","text":" are non-negative (e.g., by using "},{"type":"text","text":"exp","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"log1pexp","style":{"code":true}},{"type":"text","text":" ), the off-diagonal elements of "},{"type":"text","text":"L","style":{"code":true}},{"type":"text","text":" can be arbitrary. BTW I am a bit surprised you have to use "},{"type":"text","text":"GenericLinearAlgebra","style":{"code":true}},{"type":"text","text":" here - at least "},{"type":"text","text":"Symmetric","style":{"code":true}},{"type":"text","text":"  and "},{"type":"text","text":"Diagonal","style":{"code":true}},{"type":"text","text":" from "},{"type":"text","text":"LinearAlgebra","style":{"code":true}},{"type":"text","text":" should work fine with dual numbers (so maybe it is just due to "},{"type":"text","text":"eigen","style":{"code":true}},{"type":"text","text":"?). In fact, AFAIK PDMats (which is used by the constructors of "},{"type":"text","text":"MvNormal","style":{"code":true}},{"type":"text","text":") only defines special dispatches for "},{"type":"text","text":"LinearAlgebra.Symmetric","style":{"code":true}},{"type":"text","text":" but not GenericLinearAlgebra."}]}]}],"client_msg_id":"9b05f06e-d571-4bcc-8abc-95ddaceacc68"},{"type":"message","text":"<@U8T9JUA5R> Hi! David, thanks for replying so quickly. In my original code. The covariance matrix *C* is calculated by an ODE function which might become not symmetry nor positive definite due to the numerical errors. I do not have a good way to get its lower triangular decomposition *L*. I will change GenericLinearAlgebra back into LinearAlgebra.\n\nI just checked the matrix factorizations in LinearAlgebra.jl   I feel that if I could use the SVD decomposition to replace the cholesky decomposition in MvNomral(). Then, I do not need to make the matrix to be symmetry and positive definite. Is this achievable?","files":[{"id":"F01S9C3RSQ3","created":1616581526,"timestamp":1616581526,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01Q398M3QB","editable":false,"size":83242,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01S9C3RSQ3/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01S9C3RSQ3/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01S9C3RSQ3-c3ec7b227d/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01S9C3RSQ3-c3ec7b227d/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01S9C3RSQ3-c3ec7b227d/image_360.png","thumb_360_w":360,"thumb_360_h":340,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01S9C3RSQ3-c3ec7b227d/image_480.png","thumb_480_w":480,"thumb_480_h":453,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01S9C3RSQ3-c3ec7b227d/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01S9C3RSQ3-c3ec7b227d/image_720.png","thumb_720_w":720,"thumb_720_h":680,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01S9C3RSQ3-c3ec7b227d/image_800.png","thumb_800_w":800,"thumb_800_h":755,"original_w":826,"original_h":780,"thumb_tiny":"AwAtADC5KszMRGwUY6n1p0KuqYkIJzxing806gBv8XTNKc560YyTzQaADPtS0gHvS0ANHNLTQPQ06gA5z/8AWoPWkzyecUpoAOaUU3jvinZFADBmnUxTk4p9ACYOTj9aGXJ6n8DTDIMn5f1pVcEgbf1oAUIOuW/M0/AznHNGBRQB/9k=","permalink":"https://julialang.slack.com/files/U01Q398M3QB/F01S9C3RSQ3/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01S9C3RSQ3-d5f96acf1e","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"PnmQ","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U8T9JUA5R"},{"type":"text","text":" Hi! David, thanks for replying so quickly. In my original code. The covariance matrix "},{"type":"text","text":"C","style":{"bold":true}},{"type":"text","text":" is calculated by an ODE function which might become not symmetry nor positive definite due to the numerical errors. I do not have a good way to get its lower triangular decomposition "},{"type":"text","text":"L","style":{"bold":true}},{"type":"text","text":". I will change GenericLinearAlgebra back into LinearAlgebra.\n\nI just checked the matrix factorizations in LinearAlgebra.jl   I feel that if I could use the SVD decomposition to replace the cholesky decomposition in MvNomral(). Then, I do not need to make the matrix to be symmetry and positive definite. Is this achievable?"}]}]}],"user":"U01Q398M3QB","display_as_bot":false,"ts":"1616581529.062700","edited":{"user":"U01Q398M3QB","ts":"1616581563.000000"},"thread_ts":"1616578091.056700","parent_user_id":"U01Q398M3QB"},{"client_msg_id":"b71cdd99-c6f9-43e8-9b9c-1e97ab40fea0","type":"message","text":"OK, so if you can't work with the decomposition directly, you have to avoid the numerical issues in some way. If you want to use `MvNormal` with SVD, you would have to write your own subtype of `AbstractPDMat` (from PDMats) that uses SVD. I guess you could implement a custom `AbstractMvNormal` distribution instead equally well. Maybe PositiveFactorizations could be an alternative to ProximalOperators, one could consider the closest psd matrix in the Frobenius norm (<http://www.sciencedirect.com/science/article/pii/0024379588902236>; polar decomposition is available e.g. in MatrixFactorizations.jl), some other regularized covariance estimation methods (as e.g. in CovarianceEstimation.jl), or alternatively just some manual regularization with a diagonal matrix (but the other approaches might be more sophisticated). In any case, the main problem/difficulty will be that the functions (the factorizations and logpdf evaluations) should be differentiable, either with AD directly or by using some custom gradient implementation, to be able to use NUTS. I know that e.g. ChainRules contains a adjoint definition for `svd` , so you should be able to use Zygote (at least for this part).","user":"U8T9JUA5R","ts":"1616590269.064600","team":"T68168MUP","attachments":[{"title":"Computing a nearest symmetric positive semidefinite matrix","title_link":"http://www.sciencedirect.com/science/article/pii/0024379588902236","text":"The nearest symmetric positive semidefinite matrix in the Frobenius norm to an arbitrary real matrix A is shown to be (B + H)/2, where H is the symmet…","fallback":"Computing a nearest symmetric positive semidefinite matrix","from_url":"http://www.sciencedirect.com/science/article/pii/0024379588902236","thumb_url":"https://ars.els-cdn.com/content/image/1-s2.0-S0024379521X00067-cov150h.gif","thumb_width":103,"thumb_height":150,"service_icon":"https://www.sciencedirect.com/favicon.ico","service_name":"sciencedirect.com","id":1,"original_url":"http://www.sciencedirect.com/science/article/pii/0024379588902236"}],"blocks":[{"type":"rich_text","block_id":"o7X","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"OK, so if you can't work with the decomposition directly, you have to avoid the numerical issues in some way. If you want to use "},{"type":"text","text":"MvNormal","style":{"code":true}},{"type":"text","text":" with SVD, you would have to write your own subtype of "},{"type":"text","text":"AbstractPDMat","style":{"code":true}},{"type":"text","text":" (from PDMats) that uses SVD. I guess you could implement a custom "},{"type":"text","text":"AbstractMvNormal","style":{"code":true}},{"type":"text","text":" distribution instead equally well. Maybe PositiveFactorizations could be an alternative to ProximalOperators, one could consider the closest psd matrix in the Frobenius norm ("},{"type":"link","url":"http://www.sciencedirect.com/science/article/pii/0024379588902236"},{"type":"text","text":"; polar decomposition is available e.g. in MatrixFactorizations.jl), some other regularized covariance estimation methods (as e.g. in CovarianceEstimation.jl), or alternatively just some manual regularization with a diagonal matrix (but the other approaches might be more sophisticated). In any case, the main problem/difficulty will be that the functions (the factorizations and logpdf evaluations) should be differentiable, either with AD directly or by using some custom gradient implementation, to be able to use NUTS. I know that e.g. ChainRules contains a adjoint definition for "},{"type":"text","text":"svd","style":{"code":true}},{"type":"text","text":" , so you should be able to use Zygote (at least for this part)."}]}]}],"thread_ts":"1616578091.056700","parent_user_id":"U01Q398M3QB"},{"type":"message","text":"<@U8T9JUA5R> Thanks very much David. However, by using polar decomposition in MatrixFactorizations.jl to formulate nearest symmetry positive semidefinite matrix and then add small positive definite matrix to make it positive definite still doesn't work well all the time due to the numerical errors.\n\nI test 2000 iterations in Julia 1.6.0 since polar decomposition in  MatrixFactorizations.jl does not work in Julia 1.5\n\nTest 1 (set small positive definite matrix be 1e-12*Matrix(1.0*I,2,2) )\n```using Random\nusing LinearAlgebra\nusing Statistics\nusing Distributions\nusing Turing\nusing MatrixFactorizations\n\n# data\nu_account = [1.0; 2.0];\n@model bayes_lna(y) = begin\n    log_delta ~ Normal(0.0,1.0) \n    delta = [exp(log_delta)]\n    phi = [delta  0; 10^-7 delta]\n    B = (phi+phi')/2\n    H = polar(B,alg=:newton).H\n    phi_new = (B+H)/2 + 1e-12*Matrix(1.0*I,2,2)\n    y[:] ~ MvNormal([0.0,0.0],phi_new) \nend\nRandom.seed!(87654)\niterations = 2000\nchain = sample(bayes_lna(u_account), NUTS(0.65),iterations)```\nThen the code could work well.\n```┌ Info: Found initial step size\n│   ϵ = 0.8\n└ @ Turing.Inference C:\\Users\\Yushang\\.julia\\packages\\Turing\\uAz5c\\src\\inference\\hmc.jl:195\nSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\nChains MCMC chain (2000×13×1 Array{Float64, 3}):\n\nIterations        = 1:2000\nThinning interval = 1\nChains            = 1\nSamples per chain = 2000\nparameters        = log_delta\ninternals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, max_hamiltonian_energy_error, n_steps, nom_step_size, numerical_error, step_size, tree_depth\n\nSummary Statistics\n  parameters      mean       std   naive_se      mcse        ess      rhat \n      Symbol   Float64   Float64    Float64   Float64    Float64   Float64 \n\n   log_delta    0.6325    0.6441     0.0144    0.0215   809.5618    1.0000\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n   log_delta   -0.5494    0.1965    0.5782    1.0488    2.0147```\nTest 2 ((set small positive definite matrix be 1e-10*Matrix(1.0*I,2,2) ))\n```using Random\nusing LinearAlgebra\nusing Statistics\nusing Distributions\nusing Turing\nusing MatrixFactorizations\n\n# data\nu_account = [1.0; 2.0];\n@model bayes_lna(y) = begin\n    log_delta ~ Normal(0.0,1.0) \n    delta = [exp(log_delta)]\n    phi = [delta  0; 10^-7 delta]\n    B = (phi+phi')/2\n    H = polar(B,alg=:newton).H\n    phi_new = (B+H)/2 + 1e-10*Matrix(1.0*I,2,2)\n    y[:] ~ MvNormal([0.0,0.0],phi_new) \nend\nRandom.seed!(87654)\niterations = 2000\nchain = sample(bayes_lna(u_account), NUTS(0.65),iterations)```\nThen, it will lead to positive definite errors: (error messages attaches). Could you help me with this?","files":[{"id":"F01SBHH5GQ3","created":1616612483,"timestamp":1616612483,"name":"error message.pdf","title":"error message.pdf","mimetype":"application/pdf","filetype":"pdf","pretty_type":"PDF","user":"U01Q398M3QB","editable":false,"size":38269,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01SBHH5GQ3/error_message.pdf","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01SBHH5GQ3/download/error_message.pdf","thumb_pdf":"https://files.slack.com/files-tmb/T68168MUP-F01SBHH5GQ3-2a71ff1730/error_message_thumb_pdf.png","thumb_pdf_w":935,"thumb_pdf_h":1210,"permalink":"https://julialang.slack.com/files/U01Q398M3QB/F01SBHH5GQ3/error_message.pdf","permalink_public":"https://slack-files.com/T68168MUP-F01SBHH5GQ3-36f1e5d5b2","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"R59","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U8T9JUA5R"},{"type":"text","text":" Thanks very much David. However, by using polar decomposition in MatrixFactorizations.jl to formulate nearest symmetry positive semidefinite matrix and then add small positive definite matrix to make it positive definite still doesn't work well all the time due to the numerical errors.\n\nI test 2000 iterations in Julia 1.6.0 since polar decomposition in  MatrixFactorizations.jl does not work in Julia 1.5\n\nTest 1 (set small positive definite matrix be 1e-12*Matrix(1.0*I,2,2) )\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Random\nusing LinearAlgebra\nusing Statistics\nusing Distributions\nusing Turing\nusing MatrixFactorizations\n\n# data\nu_account = [1.0; 2.0];\n@model bayes_lna(y) = begin\n    log_delta ~ Normal(0.0,1.0) \n    delta = [exp(log_delta)]\n    phi = [delta  0; 10^-7 delta]\n    B = (phi+phi')/2\n    H = polar(B,alg=:newton).H\n    phi_new = (B+H)/2 + 1e-12*Matrix(1.0*I,2,2)\n    y[:] ~ MvNormal([0.0,0.0],phi_new) \nend\nRandom.seed!(87654)\niterations = 2000\nchain = sample(bayes_lna(u_account), NUTS(0.65),iterations)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Then the code could work well.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"┌ Info: Found initial step size\n│   ϵ = 0.8\n└ @ Turing.Inference C:\\Users\\Yushang\\.julia\\packages\\Turing\\uAz5c\\src\\inference\\hmc.jl:195\nSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\nChains MCMC chain (2000×13×1 Array{Float64, 3}):\n\nIterations        = 1:2000\nThinning interval = 1\nChains            = 1\nSamples per chain = 2000\nparameters        = log_delta\ninternals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, max_hamiltonian_energy_error, n_steps, nom_step_size, numerical_error, step_size, tree_depth\n\nSummary Statistics\n  parameters      mean       std   naive_se      mcse        ess      rhat \n      Symbol   Float64   Float64    Float64   Float64    Float64   Float64 \n\n   log_delta    0.6325    0.6441     0.0144    0.0215   809.5618    1.0000\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n   log_delta   -0.5494    0.1965    0.5782    1.0488    2.0147"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nTest 2 ((set small positive definite matrix be 1e-10*Matrix(1.0*I,2,2) ))\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Random\nusing LinearAlgebra\nusing Statistics\nusing Distributions\nusing Turing\nusing MatrixFactorizations\n\n# data\nu_account = [1.0; 2.0];\n@model bayes_lna(y) = begin\n    log_delta ~ Normal(0.0,1.0) \n    delta = [exp(log_delta)]\n    phi = [delta  0; 10^-7 delta]\n    B = (phi+phi')/2\n    H = polar(B,alg=:newton).H\n    phi_new = (B+H)/2 + 1e-10*Matrix(1.0*I,2,2)\n    y[:] ~ MvNormal([0.0,0.0],phi_new) \nend\nRandom.seed!(87654)\niterations = 2000\nchain = sample(bayes_lna(u_account), NUTS(0.65),iterations)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Then, it will lead to positive definite errors: (error messages attaches). Could you help me with this?"}]}]}],"user":"U01Q398M3QB","display_as_bot":false,"ts":"1616612512.070100","edited":{"user":"U01Q398M3QB","ts":"1616612614.000000"},"thread_ts":"1616578091.056700","parent_user_id":"U01Q398M3QB"},{"client_msg_id":"db71265f-42eb-453b-a2b3-8e66b7b12aea","type":"message","text":"<@U8T9JUA5R> <@U6C937ENB> <@UHDNY2YMA> <@U6H9SJKCH> @Hi! Daivd, Moritz, Tor and Kai,  I'm not very clear about how to create subtype of Distributions.AbstractMvNormal  by replacing the original build-in Cholesky() decomposition in MvNormal()  with a new svd() decomposition in ChainRule.jl rrule. Could you you help me with this?\n\nAcutally, I'm very curious about how the Julia Gaussian process promises its covariance matrixes are symmetry and positive definite. Could we apply the similar tactic here? Thanks a lot in advance!\n\nSome possible useful disclosures and package attaches.\n\nChainRule.jl     svd\n<https://github.com/JuliaDiff/ChainRules.jl/blob/master/src/rulesets/LinearAlgebra/factorization.jl>\n\n*<https://discourse.julialang.org/t/using-flux-to-optimize-a-function-of-the-singular-values/39687/3|Using Flux to optimize a function of the Singular Values>*\n<https://discourse.julialang.org/t/using-flux-to-optimize-a-function-of-the-singular-values/39687/3>\n\nAuto differentiation over linear algebras (a Zygote extension)\n<https://github.com/GiggleLiu/BackwardsLinalg.jl>","user":"U01Q398M3QB","ts":"1616615322.070900","team":"T68168MUP","attachments":[{"service_name":"JuliaLang","title":"Using Flux to optimize a function of the Singular Values","title_link":"https://discourse.julialang.org/t/using-flux-to-optimize-a-function-of-the-singular-values/39687/3","text":"It appears that you are using a very old version of Flux, later versions do not use TrackedArrays anymore. Maybe you could try to update Flux to the latest version?","fallback":"JuliaLang: Using Flux to optimize a function of the Singular Values","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1589799658,"from_url":"https://discourse.julialang.org/t/using-flux-to-optimize-a-function-of-the-singular-values/39687/3","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/using-flux-to-optimize-a-function-of-the-singular-values/39687/3"}],"blocks":[{"type":"rich_text","block_id":"eXbzR","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U8T9JUA5R"},{"type":"text","text":" "},{"type":"user","user_id":"U6C937ENB"},{"type":"text","text":" "},{"type":"user","user_id":"UHDNY2YMA"},{"type":"text","text":" "},{"type":"user","user_id":"U6H9SJKCH"},{"type":"text","text":" @Hi! Daivd, Moritz, Tor and Kai,  I'm not very clear about how to create subtype of Distributions.AbstractMvNormal  by replacing the original build-in Cholesky() decomposition in MvNormal()  with a new svd() decomposition in ChainRule.jl rrule. Could you you help me with this?\n\nAcutally, I'm very curious about how the Julia Gaussian process promises its covariance matrixes are symmetry and positive definite. Could we apply the similar tactic here? Thanks a lot in advance!\n\nSome possible useful disclosures and package attaches.\n\nChainRule.jl     svd\n"},{"type":"link","url":"https://github.com/JuliaDiff/ChainRules.jl/blob/master/src/rulesets/LinearAlgebra/factorization.jl"},{"type":"text","text":"\n\n"},{"type":"link","url":"https://discourse.julialang.org/t/using-flux-to-optimize-a-function-of-the-singular-values/39687/3","text":"Using Flux to optimize a function of the Singular Values","style":{"bold":true}},{"type":"text","text":"\n"},{"type":"link","url":"https://discourse.julialang.org/t/using-flux-to-optimize-a-function-of-the-singular-values/39687/3"},{"type":"text","text":"\n\nAuto differentiation over linear algebras (a Zygote extension)\n"},{"type":"link","url":"https://github.com/GiggleLiu/BackwardsLinalg.jl"}]}]}],"thread_ts":"1616578091.056700","parent_user_id":"U01Q398M3QB"}]