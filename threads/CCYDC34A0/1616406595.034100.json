[{"client_msg_id":"5873a25a-8a1b-4da1-8968-8d7b40e746ef","type":"message","text":"Does anyone have suggestions for debugging poor sampler performance? I have a relatively simply multivariate regression (all covariates are computed independently) and it's really ridiculously slow with NUTS and makes an enormous number of allocations.","user":"U01H36BUDJB","ts":"1616406595.034100","team":"T68168MUP","edited":{"user":"U01H36BUDJB","ts":"1616406607.000000"},"blocks":[{"type":"rich_text","block_id":"j+V","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does anyone have suggestions for debugging poor sampler performance? I have a relatively simply multivariate regression (all covariates are computed independently) and it's really ridiculously slow with NUTS and makes an enormous number of allocations."}]}]}],"thread_ts":"1616406595.034100","reply_count":7,"reply_users_count":2,"latest_reply":"1616408569.036400","reply_users":["UC0SY9JFP","U01H36BUDJB"],"subscribed":false},{"client_msg_id":"F914A91B-41AB-4D65-8732-59AE50C70930","type":"message","text":"Have you had a look at the performance tips on <http://turing.ml|turing.ml>?","user":"UC0SY9JFP","ts":"1616407242.034800","team":"T68168MUP","edited":{"user":"UC0SY9JFP","ts":"1616407256.000000"},"blocks":[{"type":"rich_text","block_id":"Xbh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Have you had a look at the performance tips on turing.ml?"}]}]}],"thread_ts":"1616406595.034100","parent_user_id":"U01H36BUDJB"},{"client_msg_id":"6de416c9-6f39-4eef-b0a9-6934d0efecbb","type":"message","text":"Yes.","user":"U01H36BUDJB","ts":"1616407364.035100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PI=/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes."}]}]}],"thread_ts":"1616406595.034100","parent_user_id":"U01H36BUDJB"},{"client_msg_id":"C04BBBB0-112F-4C49-8AB7-1EB2C05BB47B","type":"message","text":"Is it possible to post the model? ","user":"UC0SY9JFP","ts":"1616407435.035600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uXIv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it possible to post the model? "}]}]}],"thread_ts":"1616406595.034100","parent_user_id":"U01H36BUDJB"},{"client_msg_id":"2d0ef142-44eb-4ce0-b78b-5499cf97a93a","type":"message","text":"It seems to be much faster to fit separate linear regression models for each variable individually than it is to fit one model for all at once, despite all variables being independent.","user":"U01H36BUDJB","ts":"1616407460.035800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MsgO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It seems to be much faster to fit separate linear regression models for each variable individually than it is to fit one model for all at once, despite all variables being independent."}]}]}],"thread_ts":"1616406595.034100","parent_user_id":"U01H36BUDJB"},{"client_msg_id":"fe7286e2-f663-461b-98ca-bf0c45966dd5","type":"message","text":"Sure.\n```@model function multi_linreg(x, y, ::Type{T} = Float64; σᵦ=1.0,σ₀=10.0,a=2,b=3,β=missing,β₀=missing,ν=missing,\n        nobsv=missing, nvars=missing) where {T}\n    \"\"\"\n    Fits a separate linear regression model with homeoscedastic variance for each column X, Y.\n    \"\"\"\n    @assert !ismissing(x)\n    @assert !ismissing(y) || (!ismissing(nobsv) &amp;&amp; !ismissing(nvars))\n    if ismissing(y)\n        y = Matrix{T}(undef,nobsv,nvars)\n    else\n        nobsv = size(y,1)\n        nvars = size(y,2)\n    end\n    # set a tight prior on coeffs since we do not expect large rates of annual change\n    β ~ MvNormal(zeros(nvars),σᵦ)\n    β₀ ~ MvNormal(zeros(nvars),σ₀)\n    # assume diagonal variance of observation noise; likely not true!\n    ν ~ filldist(InverseGamma(a,b), nvars)\n    for i in 1:nobsv\n#         y[i,:] ~ MvNormal(β₀ .+ β.*x[i], ν)\n        for j in 1:nvars\n            y[i,j] ~ Normal(β₀[j] + β[j]*x[i,j], sqrt(ν[j]))\n        end\n    end\n    return y\nend```","user":"U01H36BUDJB","ts":"1616407488.036000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"J5wH=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sure.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"@model function multi_linreg(x, y, ::Type{T} = Float64; σᵦ=1.0,σ₀=10.0,a=2,b=3,β=missing,β₀=missing,ν=missing,\n        nobsv=missing, nvars=missing) where {T}\n    \"\"\"\n    Fits a separate linear regression model with homeoscedastic variance for each column X, Y.\n    \"\"\"\n    @assert !ismissing(x)\n    @assert !ismissing(y) || (!ismissing(nobsv) && !ismissing(nvars))\n    if ismissing(y)\n        y = Matrix{T}(undef,nobsv,nvars)\n    else\n        nobsv = size(y,1)\n        nvars = size(y,2)\n    end\n    # set a tight prior on coeffs since we do not expect large rates of annual change\n    β ~ MvNormal(zeros(nvars),σᵦ)\n    β₀ ~ MvNormal(zeros(nvars),σ₀)\n    # assume diagonal variance of observation noise; likely not true!\n    ν ~ filldist(InverseGamma(a,b), nvars)\n    for i in 1:nobsv\n#         y[i,:] ~ MvNormal(β₀ .+ β.*x[i], ν)\n        for j in 1:nvars\n            y[i,j] ~ Normal(β₀[j] + β[j]*x[i,j], sqrt(ν[j]))\n        end\n    end\n    return y\nend"}]}]}],"thread_ts":"1616406595.034100","parent_user_id":"U01H36BUDJB"},{"client_msg_id":"9a851b52-4234-46e1-9333-78f491a84744","type":"message","text":"Note that `y[i,:] ~ MvNormal(β₀ .+ β.*x[i], ν)` doesn't work due to a bug with Turing's missing value handling. There is no MvNormal likelihood for type `Union{Missing,T}` . I meant to post an issue about that a while ago, but I think I forgot...","user":"U01H36BUDJB","ts":"1616407573.036200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7cKi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Note that "},{"type":"text","text":"y[i,:] ~ MvNormal(β₀ .+ β.*x[i], ν)","style":{"code":true}},{"type":"text","text":" doesn't work due to a bug with Turing's missing value handling. There is no MvNormal likelihood for type "},{"type":"text","text":"Union{Missing,T}","style":{"code":true}},{"type":"text","text":" . I meant to post an issue about that a while ago, but I think I forgot..."}]}]}],"thread_ts":"1616406595.034100","parent_user_id":"U01H36BUDJB"},{"client_msg_id":"c09ad390-6930-4783-9018-9b4ba630c28b","type":"message","text":"I'm guessing this has to do with the fact that the output is Matrix-valued, which probably slows down autodiff when building the Jacobian. In this specific case, the Jacobian should actually be very sparse, but I'm not sure how to take advantage of that through Turing.","user":"U01H36BUDJB","ts":"1616408569.036400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TBfZI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm guessing this has to do with the fact that the output is Matrix-valued, which probably slows down autodiff when building the Jacobian. In this specific case, the Jacobian should actually be very sparse, but I'm not sure how to take advantage of that through Turing."}]}]}],"thread_ts":"1616406595.034100","parent_user_id":"U01H36BUDJB"}]