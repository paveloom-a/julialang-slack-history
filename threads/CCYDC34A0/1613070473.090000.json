[{"client_msg_id":"e103a083-9064-40e0-872e-3b8bd7befdee","type":"message","text":"quick question: can variational inference benefit from multithreading?","user":"U01M641BZEY","ts":"1613070473.090000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"W+YL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"quick question: can variational inference benefit from multithreading?"}]}]}],"thread_ts":"1613070473.090000","reply_count":6,"reply_users_count":3,"latest_reply":"1613072924.091600","reply_users":["UC0SY9JFP","UHDNY2YMA","U01M641BZEY"],"subscribed":false},{"client_msg_id":"A6E5492D-A1B6-4FD2-9F62-865143726474","type":"message","text":"cc: <@UHDNY2YMA> ","user":"UC0SY9JFP","ts":"1613071706.090400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6LLY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"cc: "},{"type":"user","user_id":"UHDNY2YMA"},{"type":"text","text":" "}]}]}],"thread_ts":"1613070473.090000","parent_user_id":"U01M641BZEY"},{"client_msg_id":"29631b82-ba40-41ea-9d85-0435a60a61bd","type":"message","text":"If you are using multithreading in your model, yes! This will make the evaluation of the logjoint and its gradient faster.","user":"UHDNY2YMA","ts":"1613071770.090600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cOCA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you are using multithreading in your model, yes! This will make the evaluation of the logjoint and its gradient faster."}]}]}],"thread_ts":"1613070473.090000","parent_user_id":"U01M641BZEY"},{"client_msg_id":"5deddd7e-54fc-4fb9-aabe-e20deede8b4a","type":"message","text":"Thanks! I don’t believe I have anything explicitly specified in my model for multithreading, but I’m pretty new to Turing. The model is below, is there anything that would make sense to multithread? The ODE solve, perhaps?\n```@model function fit(data, problem)\n    σ ~ InverseGamma(2, 3)\n    k ~ truncated(Normal(5,10.0),0.0,10)\n    a ~ truncated(Normal(5,10.0),0.0,10)\n    u ~ filldist(truncated(Normal(0.5,2.0),0.0,1.0), 5)\n\n    p = [k, a] \n\n    prob = remake(problem, u0=u, p=p)\n\n    predicted = solve(prob, Tsit5(), saveat=0.05)\n\n    for i ∈ 1:length(predicted)\n        data[:,i] ~ MvNormal(predicted[i], σ)\n    end \nend```\n","user":"U01M641BZEY","ts":"1613072213.090800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F/N","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks! I don’t believe I have anything explicitly specified in my model for multithreading, but I’m pretty new to Turing. The model is below, is there anything that would make sense to multithread? The ODE solve, perhaps?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"@model function fit(data, problem)\n    σ ~ InverseGamma(2, 3)\n    k ~ truncated(Normal(5,10.0),0.0,10)\n    a ~ truncated(Normal(5,10.0),0.0,10)\n    u ~ filldist(truncated(Normal(0.5,2.0),0.0,1.0), 5)\n\n    p = [k, a] \n\n    prob = remake(problem, u0=u, p=p)\n\n    predicted = solve(prob, Tsit5(), saveat=0.05)\n\n    for i ∈ 1:length(predicted)\n        data[:,i] ~ MvNormal(predicted[i], σ)\n    end \nend"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1613070473.090000","parent_user_id":"U01M641BZEY"},{"client_msg_id":"079f2515-48b0-47ae-b486-82b507c6eaa3","type":"message","text":"Essentially anything inside of your model, so if you can multithread the odesolve, then yes that's a good idea; uncertain how you'd do that though given it's sequential nature.\nTypically, since we usually work with independently assumed observations, it's often practical to use multithreading for the observations, e.g. <https://github.com/cambridge-mlg/Covid19/blob/3b1644701ef32063a65fbbc72332ba0eaa22f82b/src/imperial-report13/models.jl#L605-L612>.","user":"UHDNY2YMA","ts":"1613072440.091000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H0ts=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Essentially anything inside of your model, so if you can multithread the odesolve, then yes that's a good idea; uncertain how you'd do that though given it's sequential nature.\nTypically, since we usually work with independently assumed observations, it's often practical to use multithreading for the observations, e.g. "},{"type":"link","url":"https://github.com/cambridge-mlg/Covid19/blob/3b1644701ef32063a65fbbc72332ba0eaa22f82b/src/imperial-report13/models.jl#L605-L612"},{"type":"text","text":"."}]}]}],"thread_ts":"1613070473.090000","parent_user_id":"U01M641BZEY","reactions":[{"name":"heart","users":["U01M641BZEY"],"count":1}]},{"client_msg_id":"1716a8a6-9b84-4371-bd58-3b35060ea8ce","type":"message","text":"This can be extremely useful if you have a large number of observations.","user":"UHDNY2YMA","ts":"1613072466.091200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+3tx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This can be extremely useful if you have a large number of observations."}]}]}],"thread_ts":"1613070473.090000","parent_user_id":"U01M641BZEY","reactions":[{"name":"heart","users":["U01M641BZEY"],"count":1}]},{"client_msg_id":"df9293af-ee30-4ec4-9e74-509466afb591","type":"message","text":"Thanks! I’ll try this out. Presumably @threads macro spreads across the available threads set with the main environment variable, right?","user":"U01M641BZEY","ts":"1613072924.091600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zwj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks! I’ll try this out. Presumably @threads macro spreads across the available threads set with the main environment variable, right?"}]}]}],"thread_ts":"1613070473.090000","parent_user_id":"U01M641BZEY"}]