[{"client_msg_id":"d0e26400-7390-4850-bcd5-0fabb6ee3d61","type":"message","text":"Are there any examples floating around of doing prior updating with Turing? i.e. it's not clear to me how I would use my previous posterior samples to specify the priors of a subsequent fit.","user":"U01H36BUDJB","ts":"1615884517.003400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2rZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Are there any examples floating around of doing prior updating with Turing? i.e. it's not clear to me how I would use my previous posterior samples to specify the priors of a subsequent fit."}]}]}],"thread_ts":"1615884517.003400","reply_count":4,"reply_users_count":2,"latest_reply":"1615893831.005700","reply_users":["U6H9SJKCH","U01H36BUDJB"],"subscribed":false},{"client_msg_id":"b972b0dd-98de-4bca-a75c-889e8029ced2","type":"message","text":"Something like this?\n```@model function gdemo(x, prior)\n    μ ~ prior\n    for i in eachindex(x)\n        x[i] ~ Normal(μ, 1)\n    end\nend\n\ndata = rand(Normal(10, 1), 100)\nmcmc = HMC(0.1, 10)\n\ninitial_prior = Normal(0, 10)\nchain = sample(gdemo(data, initial_prior), mcmc, 100)\n\nupdated_prior = fit_mle(Normal, collect(chain[:μ]))\nanother_chain = sample(gdemo(data, updated_prior), mcmc, 100)```","user":"U6H9SJKCH","ts":"1615892040.004900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=3/GT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Something like this?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"@model function gdemo(x, prior)\n    μ ~ prior\n    for i in eachindex(x)\n        x[i] ~ Normal(μ, 1)\n    end\nend\n\ndata = rand(Normal(10, 1), 100)\nmcmc = HMC(0.1, 10)\n\ninitial_prior = Normal(0, 10)\nchain = sample(gdemo(data, initial_prior), mcmc, 100)\n\nupdated_prior = fit_mle(Normal, collect(chain[:μ]))\nanother_chain = sample(gdemo(data, updated_prior), mcmc, 100)"}]}]}],"thread_ts":"1615884517.003400","parent_user_id":"U01H36BUDJB"},{"client_msg_id":"2acce834-78ee-4514-90aa-d8a102bbdd99","type":"message","text":"PS: `fit_mle` is from Distributions.jl but you can do whatever way to update the prior there","user":"U6H9SJKCH","ts":"1615892066.005100","team":"T68168MUP","edited":{"user":"U6H9SJKCH","ts":"1615892096.000000"},"blocks":[{"type":"rich_text","block_id":"ovr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"PS: "},{"type":"text","text":"fit_mle","style":{"code":true}},{"type":"text","text":" is from Distributions.jl but you can do whatever way to update the prior there"}]}]}],"thread_ts":"1615884517.003400","parent_user_id":"U01H36BUDJB"},{"client_msg_id":"c643bbcc-8789-463e-82e7-a57dbd6cd674","type":"message","text":"yeah I suppose this is one way to do it. I guess you could also supply the prior hyperparameters as arguments and specify them using the result of `fit_mle` ? I was hoping for a slightly easier and more standard way of doing it though. I think in pymc3 one uses kernel density estimates. See here: <https://docs.pymc.io/notebooks/updating_priors.html>","user":"U01H36BUDJB","ts":"1615892763.005400","team":"T68168MUP","edited":{"user":"U01H36BUDJB","ts":"1615892887.000000"},"blocks":[{"type":"rich_text","block_id":"8CBp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah I suppose this is one way to do it. I guess you could also supply the prior hyperparameters as arguments and specify them using the result of "},{"type":"text","text":"fit_mle","style":{"code":true}},{"type":"text","text":" ? I was hoping for a slightly easier and more standard way of doing it though. I think in pymc3 one uses kernel density estimates. See here: "},{"type":"link","url":"https://docs.pymc.io/notebooks/updating_priors.html"}]}]}],"thread_ts":"1615884517.003400","parent_user_id":"U01H36BUDJB"},{"client_msg_id":"ef955608-bcb2-412c-8fd1-41268fc7e804","type":"message","text":"&gt; yeah I suppose this is one way to do it. I guess you could also supply the prior hyperparameters as arguments\nYes you can also just pass in parameters but the updated prior isn’t necessary to be the same distribution family, thus why I code the example like above. You can actually do something fancy like using Bijectors.jl + Flux.jl to fit a normalising flow as the updated prior.\n\n&gt; I was hoping for a slightly easier and more standard way of doing it though. I think in pymc3 one uses kernel density estimates\nIt could be done with <https://github.com/JuliaStats/KernelDensity.jl> I suppose. I guess what you are asking by “standard” way is to have something similar to `Interpolated` in the PyMC3 example?","user":"U6H9SJKCH","ts":"1615893831.005700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eii","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"yeah I suppose this is one way to do it. I guess you could also supply the prior hyperparameters as arguments"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Yes you can also just pass in parameters but the updated prior isn’t necessary to be the same distribution family, thus why I code the example like above. You can actually do something fancy like using Bijectors.jl + Flux.jl to fit a normalising flow as the updated prior.\n\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"I was hoping for a slightly easier and more standard way of doing it though. I think in pymc3 one uses kernel density estimates"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"It could be done with "},{"type":"link","url":"https://github.com/JuliaStats/KernelDensity.jl"},{"type":"text","text":" I suppose. I guess what you are asking by “standard” way is to have something similar to "},{"type":"text","text":"Interpolated","style":{"code":true}},{"type":"text","text":" in the PyMC3 example?"}]}]}],"thread_ts":"1615884517.003400","parent_user_id":"U01H36BUDJB"}]