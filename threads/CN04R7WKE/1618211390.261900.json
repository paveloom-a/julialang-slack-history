[{"client_msg_id":"14e080b6-dc87-4d35-93b8-864b01e27a90","type":"message","text":"Hi all,\n\nI decided to post this question in this channel since it is not a general Julia question. I was using SteadyStateAdjoint(), and got this error. Any help would be appreciated---\nError evaluating DEQ.jl\nLoadError: TypeError: in TrackedReal, in V, expected V&lt;:Real, got Type{Any}\nin expression starting at /Users/qiyaowei/DiffEqFlux.jl/DEQ.jl:65\nReverseDiff.TrackedArray(value::Vector{Any}, deriv::Vector{Float64}, tape::Vector{ReverseDiff.AbstractInstruction}) at tracked.jl:86\ntrack(x::Vector{Any}, ::Type{Float64}, tp::Vector{ReverseDiff.AbstractInstruction}) at tracked.jl:452\n(::ReverseDiff.var\"#657#658\"{Float64, Vector{ReverseDiff.AbstractInstruction}})(x::Vector{Any}) at Config.jl:46\nmap at tuple.jl:214 [inlined]\nReverseDiff.GradientConfig(input::Tuple{Vector{Float64}, Vector{Any}}, ::Type{Float64}, tp::Vector{ReverseDiff.AbstractInstruction}) at Config.jl:46\nReverseDiff.GradientConfig(input::Tuple{Vector{Float64}, Vector{Any}}, tp::Vector{ReverseDiff.AbstractInstruction}) at Config.jl:37\nReverseDiff.GradientConfig(input::Tuple{Vector{Float64}, Vector{Any}}) at Config.jl:37\nReverseDiff.GradientTape(f::Function, input::Tuple{Vector{Float64}, Vector{Any}}) at tape.jl:204\nadjointdiffcache(g::Nothing, sensealg::SteadyStateAdjoint{0, true, Val{:central}, Bool, DefaultLinSolve}, discrete::Bool, sol::SciMLBase.NonlinearSolution{Float64, 1, Vector{Float64}, Vector{Float64}, SteadyStateProblem{Matrix{Float64}, true, Vector{Any}, ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}}, SSRootfind{SteadyStateDiffEq.var\"#2#4\"}, Nothing, Nothing}, dg::Vector{Float64}, f::ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}; quad::Bool, noiseterm::Bool) at adjoint_common.jl:111\nadjointdiffcache at adjoint_common.jl:27 [inlined]\nDiffEqSensitivity.SteadyStateAdjointSensitivityFunction(g::Nothing, sensealg::SteadyStateAdjoint{0, true, Val{:central}, Bool, DefaultLinSolve}, discrete::Bool, sol::SciMLBase.NonlinearSolution{Float64, 1, Vector{Float64}, Vector{Float64}, SteadyStateProblem{Matrix{Float64}, true, Vector{Any}, ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}}, SSRootfind{SteadyStateDiffEq.var\"#2#4\"}, Nothing, Nothing}, dg::Vector{Float64}, colorvec::Nothing) at steadystate_adjoint.jl:18\nSteadyStateAdjointProblem(sol::SciMLBase.NonlinearSolution{Float64, 1, Vector{Float64}, Vector{Float64}, SteadyStateProblem{Matrix{Float64}, true, Vector{Any}, ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}}, SSRootfind{SteadyStateDiffEq.var\"#2#4\"}, Nothing, Nothing}, sensealg::SteadyStateAdjoint{0, true, Val{:central}, Bool, DefaultLinSolve}, g::Nothing, dg::Vector{Float64}; save_idxs::Nothing) at steadystate_adjoint.jl:33\nSteadyStateAdjointProblem at steadystate_adjoint.jl:27 [inlined]\n#_adjoint_sensitivities#45 at sensitivity_interface.jl:57 [inlined]\n_adjoint_sensitivities at sensitivity_interface.jl:57 [inlined]\n#adjoint_sensitivities#42 at sensitivity_interface.jl:6 [inlined]\nadjoint_sensitivities at sensitivity_interface.jl:6 [inlined]\nsteadystatebackpass at concrete_solve.jl:437 [inlined]\n#93#back at adjoint.jl:59 [inlined]\n#178 at lib.jl:194 [inlined]\n(::Zygote.var\"#1686#back#180\"{Zygote.var\"#178#179\"{Tuple{NTuple{4, Nothing}, Tuple{Nothing}}, DiffEqBase.var\"#93#back#73\"{DiffEqSensitivity.var\"#steadystatebackpass#187\"{Nothing, Tsit5, SteadyStateAdjoint{0, true, Val{:central}, Bool, DefaultLinSolve}, Tuple{}, SciMLBase.NonlinearSolution{Float64, 1, Vector{Float64}, Vector{Float64}, SteadyStateProblem{Matrix{Float64}, true, Vector{Any}, ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}}, SSRootfind{SteadyStateDiffEq.var\"#2#4\"}, Nothing, Nothing}}}}})(Δ::Vector{Float64}) at adjoint.jl:59\nPullback at solve.jl:70 [inlined]\n(::typeof(∂(#solve#57)))(Δ::Vector{Float64}) at interface2.jl:0\n(::Zygote.var\"#178#179\"{Tuple{NTuple{6, Nothing}, Tuple{Nothing}}, typeof(∂(#solve#57))})(Δ::Vector{Float64}) at lib.jl:194\n(::Zygote.var\"#1686#back#180\"{Zygote.var\"#178#179\"{Tuple{NTuple{6, Nothing}, Tuple{Nothing}}, typeof(∂(#solve#57))}})(Δ::Vector{Float64}) at adjoint.jl:59\nPullback at solve.jl:68 [inlined]\n(::typeof(∂(solve##kw)))(Δ::Vector{Float64}) at interface2.jl:0\nPullback at DEQ.jl:30 [inlined]\n(::typeof(∂(predict)))(Δ::Vector{Float64}) at interface2.jl:0\nPullback at DEQ.jl:59 [inlined]\n#178 at lib.jl:194 [inlined]\n#1686#back at adjoint.jl:59 [inlined]\nPullback at train.jl:102 [inlined]\n(::typeof(∂(λ)))(Δ::Float64) at interface2.jl:0\n(::Zygote.var\"#69#70\"{Zygote.Params, typeof(∂(λ)), Zygote.Context})(Δ::Float64) at interface.jl:252\ngradient(f::Function, args::Zygote.Params) at interface.jl:59\nmacro expansion at train.jl:101 [inlined]\nmacro expansion at progress.jl:119 [inlined]\ntrain!(loss::Function, ps::Zygote.Params, data::Flux.Data.DataLoader{Tuple{Matrix{Float64}, Matrix{Float64}}, Random._GLOBAL_RNG}, opt::Descent; cb::Flux.Optimise.var\"#40#46\") at train.jl:99\ntrain!(loss::Function, ps::Zygote.Params, data::Flux.Data.DataLoader{Tuple{Matrix{Float64}, Matrix{Float64}}, Random._GLOBAL_RNG}, opt::Descent) at train.jl:97\ntop-level scope at DEQ.jl:66\neval at boot.jl:360 [inlined]\ninclude_string(mapexpr::typeof(identity), mod::Module, code::String, filename::String) at loading.jl:1094","user":"U01T9S7EMGE","ts":"1618211390.261900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nF1N","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi all,\n\nI decided to post this question in this channel since it is not a general Julia question. I was using SteadyStateAdjoint(), and got this error. Any help would be appreciated---\nError evaluating DEQ.jl\nLoadError: TypeError: in TrackedReal, in V, expected V<:Real, got Type{Any}\nin expression starting at /Users/qiyaowei/DiffEqFlux.jl/DEQ.jl:65\nReverseDiff.TrackedArray(value::Vector{Any}, deriv::Vector{Float64}, tape::Vector{ReverseDiff.AbstractInstruction}) at tracked.jl:86\ntrack(x::Vector{Any}, ::Type{Float64}, tp::Vector{ReverseDiff.AbstractInstruction}) at tracked.jl:452\n(::ReverseDiff.var\"#657#658\"{Float64, Vector{ReverseDiff.AbstractInstruction}})(x::Vector{Any}) at Config.jl:46\nmap at tuple.jl:214 [inlined]\nReverseDiff.GradientConfig(input::Tuple{Vector{Float64}, Vector{Any}}, ::Type{Float64}, tp::Vector{ReverseDiff.AbstractInstruction}) at Config.jl:46\nReverseDiff.GradientConfig(input::Tuple{Vector{Float64}, Vector{Any}}, tp::Vector{ReverseDiff.AbstractInstruction}) at Config.jl:37\nReverseDiff.GradientConfig(input::Tuple{Vector{Float64}, Vector{Any}}) at Config.jl:37\nReverseDiff.GradientTape(f::Function, input::Tuple{Vector{Float64}, Vector{Any}}) at tape.jl:204\nadjointdiffcache(g::Nothing, sensealg::SteadyStateAdjoint{0, true, Val{:central}, Bool, DefaultLinSolve}, discrete::Bool, sol::SciMLBase.NonlinearSolution{Float64, 1, Vector{Float64}, Vector{Float64}, SteadyStateProblem{Matrix{Float64}, true, Vector{Any}, ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}}, SSRootfind{SteadyStateDiffEq.var\"#2#4\"}, Nothing, Nothing}, dg::Vector{Float64}, f::ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}; quad::Bool, noiseterm::Bool) at adjoint_common.jl:111\nadjointdiffcache at adjoint_common.jl:27 [inlined]\nDiffEqSensitivity.SteadyStateAdjointSensitivityFunction(g::Nothing, sensealg::SteadyStateAdjoint{0, true, Val{:central}, Bool, DefaultLinSolve}, discrete::Bool, sol::SciMLBase.NonlinearSolution{Float64, 1, Vector{Float64}, Vector{Float64}, SteadyStateProblem{Matrix{Float64}, true, Vector{Any}, ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}}, SSRootfind{SteadyStateDiffEq.var\"#2#4\"}, Nothing, Nothing}, dg::Vector{Float64}, colorvec::Nothing) at steadystate_adjoint.jl:18\nSteadyStateAdjointProblem(sol::SciMLBase.NonlinearSolution{Float64, 1, Vector{Float64}, Vector{Float64}, SteadyStateProblem{Matrix{Float64}, true, Vector{Any}, ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}}, SSRootfind{SteadyStateDiffEq.var\"#2#4\"}, Nothing, Nothing}, sensealg::SteadyStateAdjoint{0, true, Val{:central}, Bool, DefaultLinSolve}, g::Nothing, dg::Vector{Float64}; save_idxs::Nothing) at steadystate_adjoint.jl:33\nSteadyStateAdjointProblem at steadystate_adjoint.jl:27 [inlined]\n#_adjoint_sensitivities#45 at sensitivity_interface.jl:57 [inlined]\n_adjoint_sensitivities at sensitivity_interface.jl:57 [inlined]\n#adjoint_sensitivities#42 at sensitivity_interface.jl:6 [inlined]\nadjoint_sensitivities at sensitivity_interface.jl:6 [inlined]\nsteadystatebackpass at concrete_solve.jl:437 [inlined]\n#93#back at adjoint.jl:59 [inlined]\n#178 at lib.jl:194 [inlined]\n(::Zygote.var\"#1686#back#180\"{Zygote.var\"#178#179\"{Tuple{NTuple{4, Nothing}, Tuple{Nothing}}, DiffEqBase.var\"#93#back#73\"{DiffEqSensitivity.var\"#steadystatebackpass#187\"{Nothing, Tsit5, SteadyStateAdjoint{0, true, Val{:central}, Bool, DefaultLinSolve}, Tuple{}, SciMLBase.NonlinearSolution{Float64, 1, Vector{Float64}, Vector{Float64}, SteadyStateProblem{Matrix{Float64}, true, Vector{Any}, ODEFunction{true, typeof(dudt_), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}}, SSRootfind{SteadyStateDiffEq.var\"#2#4\"}, Nothing, Nothing}}}}})(Δ::Vector{Float64}) at adjoint.jl:59\nPullback at solve.jl:70 [inlined]\n(::typeof(∂(#solve#57)))(Δ::Vector{Float64}) at interface2.jl:0\n(::Zygote.var\"#178#179\"{Tuple{NTuple{6, Nothing}, Tuple{Nothing}}, typeof(∂(#solve#57))})(Δ::Vector{Float64}) at lib.jl:194\n(::Zygote.var\"#1686#back#180\"{Zygote.var\"#178#179\"{Tuple{NTuple{6, Nothing}, Tuple{Nothing}}, typeof(∂(#solve#57))}})(Δ::Vector{Float64}) at adjoint.jl:59\nPullback at solve.jl:68 [inlined]\n(::typeof(∂(solve##kw)))(Δ::Vector{Float64}) at interface2.jl:0\nPullback at DEQ.jl:30 [inlined]\n(::typeof(∂(predict)))(Δ::Vector{Float64}) at interface2.jl:0\nPullback at DEQ.jl:59 [inlined]\n#178 at lib.jl:194 [inlined]\n#1686#back at adjoint.jl:59 [inlined]\nPullback at train.jl:102 [inlined]\n(::typeof(∂(λ)))(Δ::Float64) at interface2.jl:0\n(::Zygote.var\"#69#70\"{Zygote.Params, typeof(∂(λ)), Zygote.Context})(Δ::Float64) at interface.jl:252\ngradient(f::Function, args::Zygote.Params) at interface.jl:59\nmacro expansion at train.jl:101 [inlined]\nmacro expansion at progress.jl:119 [inlined]\ntrain!(loss::Function, ps::Zygote.Params, data::Flux.Data.DataLoader{Tuple{Matrix{Float64}, Matrix{Float64}}, Random._GLOBAL_RNG}, opt::Descent; cb::Flux.Optimise.var\"#40#46\") at train.jl:99\ntrain!(loss::Function, ps::Zygote.Params, data::Flux.Data.DataLoader{Tuple{Matrix{Float64}, Matrix{Float64}}, Random._GLOBAL_RNG}, opt::Descent) at train.jl:97\ntop-level scope at DEQ.jl:66\neval at boot.jl:360 [inlined]\ninclude_string(mapexpr::typeof(identity), mod::Module, code::String, filename::String) at loading.jl:1094"}]}]}],"thread_ts":"1618211390.261900","reply_count":4,"reply_users_count":2,"latest_reply":"1618229020.262900","reply_users":["UR75SQMCZ","U01T9S7EMGE"],"is_locked":false,"subscribed":false},{"client_msg_id":"ba17bb20-2f4b-4703-9a7b-0912081f4cd5","type":"message","text":"Do you have a MWE and are you on the most recent version of DiffEqSensitivity?  Adjoint_common.jl L111 is actually empty <https://github.com/SciML/DiffEqSensitivity.jl/blob/3a6cad542aa8143a76e2a6e928ad90e98f361a55/src/adjoint_common.jl#L111> . It looks like a type inference or a dimensionality problem on first sight to me.","user":"UR75SQMCZ","ts":"1618227821.262100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kDZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Do you have a MWE and are you on the most recent version of DiffEqSensitivity?  Adjoint_common.jl L111 is actually empty "},{"type":"link","url":"https://github.com/SciML/DiffEqSensitivity.jl/blob/3a6cad542aa8143a76e2a6e928ad90e98f361a55/src/adjoint_common.jl#L111"},{"type":"text","text":" . It looks like a type inference or a dimensionality problem on first sight to me."}]}]}],"thread_ts":"1618211390.261900","parent_user_id":"U01T9S7EMGE"},{"type":"message","text":"Sorry, but could you specify what you mean by MWE? I am using Julia 1.6, and I made sure to import the most recent version of DiffEqSensitivity. In addition, my code for using SteadyStateAdjoint() is here, I wonder if I'm using it incorrectly?","files":[{"id":"F01U036CKGT","created":1618228088,"timestamp":1618228088,"name":"Screen Shot 2021-04-12 at 7.46.52 PM.png","title":"Screen Shot 2021-04-12 at 7.46.52 PM.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01T9S7EMGE","editable":false,"size":71739,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01U036CKGT/screen_shot_2021-04-12_at_7.46.52_pm.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01U036CKGT/download/screen_shot_2021-04-12_at_7.46.52_pm.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01U036CKGT-c7a7d1f23b/screen_shot_2021-04-12_at_7.46.52_pm_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01U036CKGT-c7a7d1f23b/screen_shot_2021-04-12_at_7.46.52_pm_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01U036CKGT-c7a7d1f23b/screen_shot_2021-04-12_at_7.46.52_pm_360.png","thumb_360_w":360,"thumb_360_h":65,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01U036CKGT-c7a7d1f23b/screen_shot_2021-04-12_at_7.46.52_pm_480.png","thumb_480_w":480,"thumb_480_h":87,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01U036CKGT-c7a7d1f23b/screen_shot_2021-04-12_at_7.46.52_pm_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01U036CKGT-c7a7d1f23b/screen_shot_2021-04-12_at_7.46.52_pm_720.png","thumb_720_w":720,"thumb_720_h":131,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01U036CKGT-c7a7d1f23b/screen_shot_2021-04-12_at_7.46.52_pm_800.png","thumb_800_w":800,"thumb_800_h":145,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01U036CKGT-c7a7d1f23b/screen_shot_2021-04-12_at_7.46.52_pm_960.png","thumb_960_w":960,"thumb_960_h":174,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01U036CKGT-c7a7d1f23b/screen_shot_2021-04-12_at_7.46.52_pm_1024.png","thumb_1024_w":1024,"thumb_1024_h":186,"original_w":1586,"original_h":288,"thumb_tiny":"AwAIADCpn3oz7imnrRTAXk96KSigBce4ox9KSigD/9k=","permalink":"https://julialang.slack.com/files/U01T9S7EMGE/F01U036CKGT/screen_shot_2021-04-12_at_7.46.52_pm.png","permalink_public":"https://slack-files.com/T68168MUP-F01U036CKGT-501ca9dfac","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"fouos","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sorry, but could you specify what you mean by MWE? I am using Julia 1.6, and I made sure to import the most recent version of DiffEqSensitivity. In addition, my code for using SteadyStateAdjoint() is here, I wonder if I'm using it incorrectly?"}]}]}],"user":"U01T9S7EMGE","display_as_bot":false,"ts":"1618228116.262300","thread_ts":"1618211390.261900","parent_user_id":"U01T9S7EMGE"},{"client_msg_id":"83a3f58a-95e8-4eff-b092-9ab121267faa","type":"message","text":"MWE = minimal working example (like a few lines of code that one could copy and paste to run into the same error to better understand why the error is thrown)","user":"UR75SQMCZ","ts":"1618228852.262700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"osyT6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"MWE = minimal working example (like a few lines of code that one could copy and paste to run into the same error to better understand why the error is thrown)"}]}]}],"thread_ts":"1618211390.261900","parent_user_id":"U01T9S7EMGE"},{"client_msg_id":"e776b978-45ea-4f1e-b008-38f3745c00e4","type":"message","text":"Sure! This is my current attempt to create DEQ (Deep Equilibrium Model) using the SteadyStateProblem\n\n\n\nusing Flux\nusing DiffEqSensitivity\nusing SteadyStateDiffEq\n\nu0 = Float32[0.0; 0.0]\ntspan = (0.0f0, 10.0f0)\n\nW = rand(2, 2)\nb = rand(2)\nlayer1(x,z) = W * z .+ b\nlayer2(x,z) = x + σ.(layer1(x,z))\nlayer3(x,z) = z + σ.(layer2(x,z))\nann(x,z) = σ.(layer3(x,z))\n\np1, re = Flux.destructure(ann)\nps = Flux.params(p1)\n\nfunction dudt_(du, u, p, t)\n    z1, z2, x1, x2 = u\n    du[1] = re(p1)([x1;x2], [z1;z2])[1] - z1\n    du[2] = re(p1)([x1;x2], [z1;z2])[2] - z2\nend\n\npr = ODEProblem(dudt_, u0, tspan, p1)\nprob = SteadyStateProblem(pr)\n\nfunction predict(x)\n  Array(solve(prob, Tsit5(), u0 = [u0;x], p = p1, sensealg=SteadyStateAdjoint()))\nend\n\n# <https://medium.com/coffee-in-a-klein-bottle/deep-learning-with-julia-e7f15ad5080b>\n#Auxiliary functions for generating our data\nfunction generate_real_data(n)\n    x1 = rand(1,n) .- 0.5\n    x2 = (x1 .* x1)*3 .+ randn(1,n)*0.1\n    return vcat(x1,x2)\nend\nfunction generate_fake_data(n)\n    θ  = 2*π*rand(1,n)\n    r  = rand(1,n)/3\n    x1 = @. r*cos(θ)\n    x2 = @. r*sin(θ)+0.5\n    return vcat(x1,x2)\nend\n# Creating our data\ntrain_size = 5000\nreal = generate_real_data(train_size)\nfake = generate_fake_data(train_size)\n\n# Organizing the data in batches\nX    = hcat(real,fake)\nY    = vcat(ones(train_size),zeros(train_size))\ndata = Flux.Data.DataLoader((X, reshape(Y, 1, length(Y))), batchsize=1,shuffle=true)\nopt = Descent(0.05)\n\nfunction loss(x, y)\n  ŷ = predict(x)\n  sum((y .- ŷ).^2)\nend\n\n\nepochs = 100\nfor i in 1:epochs\n    Flux.train!(loss, ps, data, opt)\n    println(mean(ann(real)),mean(ann(fake))) # Print model prediction\nend","user":"U01T9S7EMGE","ts":"1618229020.262900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"E0k","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sure! This is my current attempt to create DEQ (Deep Equilibrium Model) using the SteadyStateProblem\n\n\n\nusing Flux\nusing DiffEqSensitivity\nusing SteadyStateDiffEq\n\nu0 = Float32[0.0; 0.0]\ntspan = (0.0f0, 10.0f0)\n\nW = rand(2, 2)\nb = rand(2)\nlayer1(x,z) = W * z .+ b\nlayer2(x,z) = x + σ.(layer1(x,z))\nlayer3(x,z) = z + σ.(layer2(x,z))\nann(x,z) = σ.(layer3(x,z))\n\np1, re = Flux.destructure(ann)\nps = Flux.params(p1)\n\nfunction dudt_(du, u, p, t)\n    z1, z2, x1, x2 = u\n    du[1] = re(p1)([x1;x2], [z1;z2])[1] - z1\n    du[2] = re(p1)([x1;x2], [z1;z2])[2] - z2\nend\n\npr = ODEProblem(dudt_, u0, tspan, p1)\nprob = SteadyStateProblem(pr)\n\nfunction predict(x)\n  Array(solve(prob, Tsit5(), u0 = [u0;x], p = p1, sensealg=SteadyStateAdjoint()))\nend\n\n# "},{"type":"link","url":"https://medium.com/coffee-in-a-klein-bottle/deep-learning-with-julia-e7f15ad5080b"},{"type":"text","text":"\n#Auxiliary functions for generating our data\nfunction generate_real_data(n)\n    x1 = rand(1,n) .- 0.5\n    x2 = (x1 .* x1)*3 .+ randn(1,n)*0.1\n    return vcat(x1,x2)\nend\nfunction generate_fake_data(n)\n    θ  = 2*π*rand(1,n)\n    r  = rand(1,n)/3\n    x1 = @. r*cos(θ)\n    x2 = @. r*sin(θ)+0.5\n    return vcat(x1,x2)\nend\n# Creating our data\ntrain_size = 5000\nreal = generate_real_data(train_size)\nfake = generate_fake_data(train_size)\n\n# Organizing the data in batches\nX    = hcat(real,fake)\nY    = vcat(ones(train_size),zeros(train_size))\ndata = Flux.Data.DataLoader((X, reshape(Y, 1, length(Y))), batchsize=1,shuffle=true)\nopt = Descent(0.05)\n\nfunction loss(x, y)\n  ŷ = predict(x)\n  sum((y .- ŷ).^2)\nend\n\n\nepochs = 100\nfor i in 1:epochs\n    Flux.train!(loss, ps, data, opt)\n    println(mean(ann(real)),mean(ann(fake))) # Print model prediction\nend"}]}]}],"thread_ts":"1618211390.261900","parent_user_id":"U01T9S7EMGE"}]