[{"client_msg_id":"8c321978-0126-4a9b-a007-ec8cfab38aaf","type":"message","text":"Does this seem like a fair test?\n```μ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nusing BenchmarkTools\nfunction time_normal(f)\n    function go(f, μ, σ, x, y)\n        for i in eachindex(x)\n            @inbounds y[i] = logdensity(f(μ[i], σ[i]), x[i])\n        end\n    end\n\n    @belapsed $go($f, $μ, $σ, $x, $y)\nend```\n```julia&gt; sμσ =  time_normal((μ,σ) -&gt; Dists.Normal(μ,σ; check_args=false)) / time_normal((μ,σ) -&gt; Normal(μ,σ))\n1.3814563928873838\n\njulia&gt; sμ1 =  time_normal((μ,σ) -&gt; Dists.Normal(μ,1.0; check_args=false)) / time_normal((μ,σ) -&gt; Normal(μ=μ))\n40.1426842474043\n\njulia&gt; s0σ =  time_normal((μ,σ) -&gt; Dists.Normal(0.0,σ; check_args=false)) / time_normal((μ,σ) -&gt; Normal(σ=σ))\n1.4177335229966808\n\njulia&gt; s01 =  time_normal((μ,σ) -&gt; Dists.Normal()) / time_normal((μ,σ) -&gt; Normal())\n42.33345406856929```\n`s` is for \"speedup\" (that's good enough for me!)","user":"U81PB6N77","ts":"1611956947.028900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"69dIH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does this seem like a fair test?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"μ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nusing BenchmarkTools\nfunction time_normal(f)\n    function go(f, μ, σ, x, y)\n        for i in eachindex(x)\n            @inbounds y[i] = logdensity(f(μ[i], σ[i]), x[i])\n        end\n    end\n\n    @belapsed $go($f, $μ, $σ, $x, $y)\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> sμσ =  time_normal((μ,σ) -> Dists.Normal(μ,σ; check_args=false)) / time_normal((μ,σ) -> Normal(μ,σ))\n1.3814563928873838\n\njulia> sμ1 =  time_normal((μ,σ) -> Dists.Normal(μ,1.0; check_args=false)) / time_normal((μ,σ) -> Normal(μ=μ))\n40.1426842474043\n\njulia> s0σ =  time_normal((μ,σ) -> Dists.Normal(0.0,σ; check_args=false)) / time_normal((μ,σ) -> Normal(σ=σ))\n1.4177335229966808\n\njulia> s01 =  time_normal((μ,σ) -> Dists.Normal()) / time_normal((μ,σ) -> Normal())\n42.33345406856929"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"},{"type":"text","text":"s","style":{"code":true}},{"type":"text","text":" is for \"speedup\" (that's good enough for me!)"}]}]}],"thread_ts":"1611956947.028900","reply_count":38,"reply_users_count":4,"latest_reply":"1612217001.040500","reply_users":["U81PB6N77","U019K6Q9N15","UHDQQ4GN6","U8T9JUA5R"],"subscribed":false},{"client_msg_id":"0730ced3-157e-4f1d-bf5f-9a015c877802","type":"message","text":"`Dists` uses Distributions.jl, otherwise it's MeasureTheory","user":"U81PB6N77","ts":"1611956992.029000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JOH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Dists","style":{"code":true}},{"type":"text","text":" uses Distributions.jl, otherwise it's MeasureTheory"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"type":"message","text":"","files":[{"id":"F01LE4WKHQT","created":1611962621,"timestamp":1611962621,"name":"normal.png","title":"normal.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U81PB6N77","editable":false,"size":39078,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01LE4WKHQT/normal.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01LE4WKHQT/download/normal.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01LE4WKHQT-f324b99370/normal_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01LE4WKHQT-f324b99370/normal_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01LE4WKHQT-f324b99370/normal_360.png","thumb_360_w":360,"thumb_360_h":234,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01LE4WKHQT-f324b99370/normal_480.png","thumb_480_w":480,"thumb_480_h":312,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01LE4WKHQT-f324b99370/normal_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01LE4WKHQT-f324b99370/normal_720.png","thumb_720_w":720,"thumb_720_h":469,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01LE4WKHQT-f324b99370/normal_800.png","thumb_800_w":800,"thumb_800_h":521,"thumb_960":"https://files.slack.com/files-tmb/T68168MUP-F01LE4WKHQT-f324b99370/normal_960.png","thumb_960_w":960,"thumb_960_h":625,"thumb_1024":"https://files.slack.com/files-tmb/T68168MUP-F01LE4WKHQT-f324b99370/normal_1024.png","thumb_1024_w":1024,"thumb_1024_h":666,"original_w":1034,"original_h":673,"thumb_tiny":"AwAfADDSbOODg9qYokx8zAmnE8E9xmorV2dW3HOKdtLivrYElZrkpn5QOlSNKqOFJOT04qmzFbhypwcmnOSZYSepA/nVWV7eRN2o38ya6dkQFSRzUsZzGpPUgVDef6tfrTbQksQSelJ7IaV5MsPwp+hqCy+631qwwJGKihiaLIBBz6ihPRoGtUyrJ/r3+pp7f6yH6D+dSPbEyFs9TnpStAdyEH7oA6U7rmv5Cs+W3mF5/q1+tMs/vn6VLLG0qAEgYOeKIITGc5zxipeyLjo2f//Z","permalink":"https://julialang.slack.com/files/U81PB6N77/F01LE4WKHQT/normal.png","permalink_public":"https://slack-files.com/T68168MUP-F01LE4WKHQT-5d3858300d","is_starred":false,"has_rich_preview":false}],"upload":false,"user":"U81PB6N77","display_as_bot":false,"ts":"1611962633.029200","thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77","subtype":"thread_broadcast","root":{"client_msg_id":"8c321978-0126-4a9b-a007-ec8cfab38aaf","type":"message","text":"Does this seem like a fair test?\n```μ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nusing BenchmarkTools\nfunction time_normal(f)\n    function go(f, μ, σ, x, y)\n        for i in eachindex(x)\n            @inbounds y[i] = logdensity(f(μ[i], σ[i]), x[i])\n        end\n    end\n\n    @belapsed $go($f, $μ, $σ, $x, $y)\nend```\n```julia&gt; sμσ =  time_normal((μ,σ) -&gt; Dists.Normal(μ,σ; check_args=false)) / time_normal((μ,σ) -&gt; Normal(μ,σ))\n1.3814563928873838\n\njulia&gt; sμ1 =  time_normal((μ,σ) -&gt; Dists.Normal(μ,1.0; check_args=false)) / time_normal((μ,σ) -&gt; Normal(μ=μ))\n40.1426842474043\n\njulia&gt; s0σ =  time_normal((μ,σ) -&gt; Dists.Normal(0.0,σ; check_args=false)) / time_normal((μ,σ) -&gt; Normal(σ=σ))\n1.4177335229966808\n\njulia&gt; s01 =  time_normal((μ,σ) -&gt; Dists.Normal()) / time_normal((μ,σ) -&gt; Normal())\n42.33345406856929```\n`s` is for \"speedup\" (that's good enough for me!)","user":"U81PB6N77","ts":"1611956947.028900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"69dIH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does this seem like a fair test?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"μ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nusing BenchmarkTools\nfunction time_normal(f)\n    function go(f, μ, σ, x, y)\n        for i in eachindex(x)\n            @inbounds y[i] = logdensity(f(μ[i], σ[i]), x[i])\n        end\n    end\n\n    @belapsed $go($f, $μ, $σ, $x, $y)\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> sμσ =  time_normal((μ,σ) -> Dists.Normal(μ,σ; check_args=false)) / time_normal((μ,σ) -> Normal(μ,σ))\n1.3814563928873838\n\njulia> sμ1 =  time_normal((μ,σ) -> Dists.Normal(μ,1.0; check_args=false)) / time_normal((μ,σ) -> Normal(μ=μ))\n40.1426842474043\n\njulia> s0σ =  time_normal((μ,σ) -> Dists.Normal(0.0,σ; check_args=false)) / time_normal((μ,σ) -> Normal(σ=σ))\n1.4177335229966808\n\njulia> s01 =  time_normal((μ,σ) -> Dists.Normal()) / time_normal((μ,σ) -> Normal())\n42.33345406856929"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"},{"type":"text","text":"s","style":{"code":true}},{"type":"text","text":" is for \"speedup\" (that's good enough for me!)"}]}]}],"thread_ts":"1611956947.028900","reply_count":38,"reply_users_count":4,"latest_reply":"1612217001.040500","reply_users":["U81PB6N77","U019K6Q9N15","UHDQQ4GN6","U8T9JUA5R"],"subscribed":false}},{"client_msg_id":"f92282de-5abd-436e-9a06-b2aa6416be7b","type":"message","text":"Get out of here","user":"U019K6Q9N15","ts":"1611962690.029600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MLpHB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Get out of here"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"3f10f0f2-1b75-454d-aa25-723dd009dabc","type":"message","text":"that's something ~lovely~ ~wild~ amazing!","user":"U019K6Q9N15","ts":"1611962708.029800","team":"T68168MUP","edited":{"user":"U019K6Q9N15","ts":"1611962759.000000"},"blocks":[{"type":"rich_text","block_id":"6QIxB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's something "},{"type":"text","text":"lovely","style":{"strike":true}},{"type":"text","text":" "},{"type":"text","text":"wild","style":{"strike":true}},{"type":"text","text":" amazing!"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77","reactions":[{"name":"grin","users":["U81PB6N77"],"count":1}]},{"client_msg_id":"4dce2cfa-c6ae-4be9-b422-a18f4ea5de05","type":"message","text":"That's really surprising. Where does the speedup come from?","user":"UHDQQ4GN6","ts":"1611962768.030300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Xmmc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's really surprising. Where does the speedup come from?"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"4a14cd3b-27f5-4dd8-8e5d-dbd57e27d240","type":"message","text":"We avoid checking if sigma&lt;0","user":"U81PB6N77","ts":"1611962800.030600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6k+Xv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"We avoid checking if sigma<0"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"754e29b6-0eda-44bb-8e58-ae297c810860","type":"message","text":"And if sigma=1 we don't mess with it at all","user":"U81PB6N77","ts":"1611962811.030800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"f6EjS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And if sigma=1 we don't mess with it at all"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"9e2d8969-1933-48fc-a7a2-6b718ce7f20d","type":"message","text":"Post coming soon :slightly_smiling_face:","user":"U81PB6N77","ts":"1611962837.031000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Bx6jg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Post coming soon "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"10da5f30-f68d-48b4-b239-de1d8d98a89e","type":"message","text":"Nice!","user":"UHDQQ4GN6","ts":"1611962850.031200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4NXZx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Nice!"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"2f90711d-efa4-47d5-b17b-8d95b76d9e3e","type":"message","text":"Does the test look reasonable?","user":"U81PB6N77","ts":"1611962879.031400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yEP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does the test look reasonable?"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"005c1576-dad9-474f-a953-0d2d51536d5e","type":"message","text":"I'd pass `x` and such to `time_normal` and define `go` outside of it in case that causes slowdowns. So something like this\n```using BenchmarkTools\n\nμ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nfunction go(f, μ, σ, x, y)\n    @inbounds for i in eachindex(μ, σ, x, y)\n        y[i] = logdensity(f(μ[i], σ[i]), x[i])\n    end\nend\n\ntime_normal(f, μ, σ, x, y) = @belapsed $go($f, $μ, $σ, $x, $y)```\nIs the purpose of looping over an array instead of evaluating at one value to cover the possibility of different runtimes for different input values?","user":"UHDQQ4GN6","ts":"1611963911.031600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RMqjH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd pass "},{"type":"text","text":"x","style":{"code":true}},{"type":"text","text":" and such to "},{"type":"text","text":"time_normal","style":{"code":true}},{"type":"text","text":" and define "},{"type":"text","text":"go","style":{"code":true}},{"type":"text","text":" outside of it in case that causes slowdowns. So something like this\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using BenchmarkTools\n\nμ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nfunction go(f, μ, σ, x, y)\n    @inbounds for i in eachindex(μ, σ, x, y)\n        y[i] = logdensity(f(μ[i], σ[i]), x[i])\n    end\nend\n\ntime_normal(f, μ, σ, x, y) = @belapsed $go($f, $μ, $σ, $x, $y)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Is the purpose of looping over an array instead of evaluating at one value to cover the possibility of different runtimes for different input values?"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"f345b9bd-2d0d-4a40-8d21-124e8d99f741","type":"message","text":"Yes, and to give it more to do to get more reliable timings","user":"U81PB6N77","ts":"1611963973.031800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1ME","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, and to give it more to do to get more reliable timings"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"ad804f14-5679-45e5-a5b5-b19935e31e21","type":"message","text":"The latter shouldn't be necessary. I believe `@belapsed` does that already, like `@btime`. `@elapsed` does not.","user":"UHDQQ4GN6","ts":"1611964031.032000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HFhS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The latter shouldn't be necessary. I believe "},{"type":"text","text":"@belapsed","style":{"code":true}},{"type":"text","text":" does that already, like "},{"type":"text","text":"@btime","style":{"code":true}},{"type":"text","text":". "},{"type":"text","text":"@elapsed","style":{"code":true}},{"type":"text","text":" does not."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"1bdf110d-9ecd-4598-a9c6-4088427cf8cc","type":"message","text":"Ok, but part you pointed out is still a concern","user":"U81PB6N77","ts":"1611964098.032200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SMMG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok, but part you pointed out is still a concern"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"d2652754-988b-43df-af7e-84eb204b468a","type":"message","text":"Yeah, makes sense.","user":"UHDQQ4GN6","ts":"1611964121.032400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CbA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, makes sense."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"4377d9ab-5cec-40fb-a0ab-5f594fb0a397","type":"message","text":"`go(f, μ, σ, x, y)` is a little too phonetic :joy:","user":"U81PB6N77","ts":"1611964320.032600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vo9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"go(f, μ, σ, x, y)","style":{"code":true}},{"type":"text","text":" is a little too phonetic "},{"type":"emoji","name":"joy"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77","reactions":[{"name":"joy","users":["UN97XTLCV","UHDQQ4GN6","UN45LV5K6"],"count":3},{"name":"shrugging","users":["UHDQQ4GN6"],"count":1}]},{"client_msg_id":"96f529ef-7761-468d-acb2-11063ab28d87","type":"message","text":"Oh! And we avoid messing with the normalization, that helps","user":"U81PB6N77","ts":"1611964573.033100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kMG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh! And we avoid messing with the normalization, that helps"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77","reactions":[{"name":"+1","users":["UHDQQ4GN6"],"count":1}]},{"type":"message","subtype":"thread_broadcast","text":"Still tweaking it a bit but\n<https://informativeprior.com/blog/2021/01-28-measure-theory/>","user":"U81PB6N77","ts":"1611965213.033400","thread_ts":"1611956947.028900","root":{"client_msg_id":"8c321978-0126-4a9b-a007-ec8cfab38aaf","type":"message","text":"Does this seem like a fair test?\n```μ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nusing BenchmarkTools\nfunction time_normal(f)\n    function go(f, μ, σ, x, y)\n        for i in eachindex(x)\n            @inbounds y[i] = logdensity(f(μ[i], σ[i]), x[i])\n        end\n    end\n\n    @belapsed $go($f, $μ, $σ, $x, $y)\nend```\n```julia&gt; sμσ =  time_normal((μ,σ) -&gt; Dists.Normal(μ,σ; check_args=false)) / time_normal((μ,σ) -&gt; Normal(μ,σ))\n1.3814563928873838\n\njulia&gt; sμ1 =  time_normal((μ,σ) -&gt; Dists.Normal(μ,1.0; check_args=false)) / time_normal((μ,σ) -&gt; Normal(μ=μ))\n40.1426842474043\n\njulia&gt; s0σ =  time_normal((μ,σ) -&gt; Dists.Normal(0.0,σ; check_args=false)) / time_normal((μ,σ) -&gt; Normal(σ=σ))\n1.4177335229966808\n\njulia&gt; s01 =  time_normal((μ,σ) -&gt; Dists.Normal()) / time_normal((μ,σ) -&gt; Normal())\n42.33345406856929```\n`s` is for \"speedup\" (that's good enough for me!)","user":"U81PB6N77","ts":"1611956947.028900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"69dIH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does this seem like a fair test?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"μ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nusing BenchmarkTools\nfunction time_normal(f)\n    function go(f, μ, σ, x, y)\n        for i in eachindex(x)\n            @inbounds y[i] = logdensity(f(μ[i], σ[i]), x[i])\n        end\n    end\n\n    @belapsed $go($f, $μ, $σ, $x, $y)\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> sμσ =  time_normal((μ,σ) -> Dists.Normal(μ,σ; check_args=false)) / time_normal((μ,σ) -> Normal(μ,σ))\n1.3814563928873838\n\njulia> sμ1 =  time_normal((μ,σ) -> Dists.Normal(μ,1.0; check_args=false)) / time_normal((μ,σ) -> Normal(μ=μ))\n40.1426842474043\n\njulia> s0σ =  time_normal((μ,σ) -> Dists.Normal(0.0,σ; check_args=false)) / time_normal((μ,σ) -> Normal(σ=σ))\n1.4177335229966808\n\njulia> s01 =  time_normal((μ,σ) -> Dists.Normal()) / time_normal((μ,σ) -> Normal())\n42.33345406856929"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"},{"type":"text","text":"s","style":{"code":true}},{"type":"text","text":" is for \"speedup\" (that's good enough for me!)"}]}]}],"thread_ts":"1611956947.028900","reply_count":38,"reply_users_count":4,"latest_reply":"1612217001.040500","reply_users":["U81PB6N77","U019K6Q9N15","UHDQQ4GN6","U8T9JUA5R"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"507Zq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Still tweaking it a bit but\n"},{"type":"link","url":"https://informativeprior.com/blog/2021/01-28-measure-theory/"}]}]}],"client_msg_id":"4d124591-b343-4081-92d3-96c7c119c0fc","reactions":[{"name":"+1","users":["UHDQQ4GN6","UE98VNG4U"],"count":2}]},{"client_msg_id":"e3042236-986d-422e-895c-99fe2736aaf2","type":"message","text":"Just a comment, should the normalization constant be defined using `//` to avoid type promotion? e.g.\n```@measure Normal(μ,σ) ≪ (1//sqrt2π) * Lebesgue(ℝ)```","user":"UHDQQ4GN6","ts":"1611966365.033700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gBW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just a comment, should the normalization constant be defined using "},{"type":"text","text":"//","style":{"code":true}},{"type":"text","text":" to avoid type promotion? e.g.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"@measure Normal(μ,σ) ≪ (1//sqrt2π) * Lebesgue(ℝ)"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"077bcbe8-9796-4660-aa3c-26a038e31c11","type":"message","text":"Looks good!","user":"UHDQQ4GN6","ts":"1611966372.034000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9/v","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looks good!"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"042d5271-c3a1-4189-95c5-7382049b9b76","type":"message","text":"I think promotion is ok, it will usually be irrational anyway. Maybe I'm missing something?","user":"U81PB6N77","ts":"1611966443.034200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Tn/FS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think promotion is ok, it will usually be irrational anyway. Maybe I'm missing something?"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"95ab9637-7356-4442-a7af-e173ab4c1590","type":"message","text":"Promotion of `logdensity` . `1 / sqrt2π` evaluates to a `Float64`. e.g. currently if you call `logdensity(Normal(), Lebesgue(ℝ), 1f0)` , is the output `Float32` or `Float64`? That's the promotion I am concerned about.","user":"UHDQQ4GN6","ts":"1611966589.034400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7kAF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Promotion of "},{"type":"text","text":"logdensity","style":{"code":true}},{"type":"text","text":" . "},{"type":"text","text":"1 / sqrt2π","style":{"code":true}},{"type":"text","text":" evaluates to a "},{"type":"text","text":"Float64","style":{"code":true}},{"type":"text","text":". e.g. currently if you call "},{"type":"text","text":"logdensity(Normal(), Lebesgue(ℝ), 1f0)","style":{"code":true}},{"type":"text","text":" , is the output "},{"type":"text","text":"Float32","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"Float64","style":{"code":true}},{"type":"text","text":"? That's the promotion I am concerned about."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"47eeb599-962b-4013-8312-92d6d7a514e0","type":"message","text":"Oh, right. Ok I think that's a good point","user":"U81PB6N77","ts":"1611966646.034600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"djeG1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh, right. Ok I think that's a good point"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"b41f4abb-1274-41d8-b438-e149a6ee0e09","type":"message","text":"Is it possible for the user to specify the log of a normalization constant? If not, maybe it would be worthwhile to include an irrational `Exp` that lazy-evaluates the exponential. Then when computing `logdensity`, it would just call `log(c)` , which could just unwrap the `Exp` .","user":"UHDQQ4GN6","ts":"1611966754.034800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"J22","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it possible for the user to specify the log of a normalization constant? If not, maybe it would be worthwhile to include an irrational "},{"type":"text","text":"Exp","style":{"code":true}},{"type":"text","text":" that lazy-evaluates the exponential. Then when computing "},{"type":"text","text":"logdensity","style":{"code":true}},{"type":"text","text":", it would just call "},{"type":"text","text":"log(c)","style":{"code":true}},{"type":"text","text":" , which could just unwrap the "},{"type":"text","text":"Exp","style":{"code":true}},{"type":"text","text":" ."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"a5e1ee05-6363-41d2-b9b8-7e03e94bf193","type":"message","text":"Yeah I wondered about that, just a matter of getting the right interface fo rit","user":"U81PB6N77","ts":"1611966826.035000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pod","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah I wondered about that, just a matter of getting the right interface fo rit"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"bb3cd741-31c3-4617-befe-718f6ef503e9","type":"message","text":"Yeah. I don't have a use case now, but just something to think about down the road.","user":"UHDQQ4GN6","ts":"1611966868.035200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"h2AL5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah. I don't have a use case now, but just something to think about down the road."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77","reactions":[{"name":"+1","users":["U81PB6N77"],"count":1}]},{"client_msg_id":"57e8e12e-50ae-4cb4-9f23-983f6e6cc37d","type":"message","text":"Not sure if it makes a difference, but the standard way to create a standard normal distribution with Distributions is `Normal()` . And normal distributions with standard deviation 1 are created by `Normal(mu)`. Both constructors hard code the parameters and don't check the standard deviation. These checks can be avoided even in the general case with `check_args = false`.","user":"U8T9JUA5R","ts":"1611999515.035600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"o20Qs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not sure if it makes a difference, but the standard way to create a standard normal distribution with Distributions is "},{"type":"text","text":"Normal()","style":{"code":true}},{"type":"text","text":" . And normal distributions with standard deviation 1 are created by "},{"type":"text","text":"Normal(mu)","style":{"code":true}},{"type":"text","text":". Both constructors hard code the parameters and don't check the standard deviation. These checks can be avoided even in the general case with "},{"type":"text","text":"check_args = false","style":{"code":true}},{"type":"text","text":"."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"37921f67-3835-4844-b85a-330357d853ee","type":"message","text":"Thanks <@U8T9JUA5R>, I did use Normal() and check_args=false. I want aware of the Normal(mu) formulation, I'll try changing that tomorrow","user":"U81PB6N77","ts":"1612063815.036800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hpls","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks "},{"type":"user","user_id":"U8T9JUA5R"},{"type":"text","text":", I did use Normal() and check_args=false. I want aware of the Normal(mu) formulation, I'll try changing that tomorrow"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"be150a02-b192-466e-95c5-a661520ed001","type":"message","text":"BTW do you actually compute the same thing in the benchmark? The MeasureTheory-approach does not return the normalized log density with respect to the Lebesgue measure but only the density with respect to the scaled base measure, it seems?","user":"U8T9JUA5R","ts":"1612075523.037000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BLp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"BTW do you actually compute the same thing in the benchmark? The MeasureTheory-approach does not return the normalized log density with respect to the Lebesgue measure but only the density with respect to the scaled base measure, it seems?"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"93c9ab07-40bd-4c23-ae2d-23e297894ff4","type":"message","text":"That's right. That's usually what you want, and you can get wrt Lebesgue after the fact. The whole point is, we should be working with measures instead of distributions, and here's a way to do it","user":"U81PB6N77","ts":"1612095187.037200","team":"T68168MUP","edited":{"user":"U81PB6N77","ts":"1612095213.000000"},"blocks":[{"type":"rich_text","block_id":"2Vgn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's right. That's usually what you want, and you can get wrt Lebesgue after the fact. The whole point is, we should be working with measures instead of distributions, and here's a way to do it"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"277a5431-2e01-45bd-bebc-bb0daaebafbc","type":"message","text":"Sure, I understand this. It just doesn't seem to be a fair comparison if the results are not the same.","user":"U8T9JUA5R","ts":"1612099421.037500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KYy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sure, I understand this. It just doesn't seem to be a fair comparison if the results are not the same."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"dc984630-5f7f-48c7-92ac-df7fd4187fa6","type":"message","text":"The goal here was to compare performance of computational kernels was you'd use them for something like MCMC. It would be strange to give Distributions some benefit for the fact that it does irrelevant calculations along the way.\n\nWhat so you think would be a more fair way to do this?","user":"U81PB6N77","ts":"1612102094.037700","team":"T68168MUP","edited":{"user":"U81PB6N77","ts":"1612102116.000000"},"blocks":[{"type":"rich_text","block_id":"myx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The goal here was to compare performance of computational kernels was you'd use them for something like MCMC. It would be strange to give Distributions some benefit for the fact that it does irrelevant calculations along the way.\n\nWhat so you think would be a more fair way to do this?"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"1649637c-7fe5-45df-a975-63cd675ea911","type":"message","text":"I've added some more discussion on this:\n\nTo be clear, Distributions is doing a little more work here, since it's including the normalization constant at each step. But that's exactly the point! For many computations like MCMC, there's no need to do this. Also, we're not really throwing away this constant; we can recover it later if we like by asking for the log-density with respect to Lebesgue measure.\n\nIf Distributions had a way to do this without including the normalization, that might be a more fair comparison. But it doesn't, so if you're choosing between Distributions and MeasureTheory for MCMC, the plot above is a reasonable representation of the core log-density computation.\n\nAlso worth noting is that gradient computations are often important for this work. MeasureTheory is designed to be relatively autodiff-friendly, by representing the log-density as a simple algebraic expression. For Distributions this is definitely not the case, and making AD work well required an entirely separate and significant effort, DistributionsAD.jl.","user":"U81PB6N77","ts":"1612105835.038000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nEm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I've added some more discussion on this:\n\nTo be clear, Distributions is doing a little more work here, since it's including the normalization constant at each step. But that's exactly the point! For many computations like MCMC, there's no need to do this. Also, we're not really throwing away this constant; we can recover it later if we like by asking for the log-density with respect to Lebesgue measure.\n\nIf Distributions had a way to do this without including the normalization, that might be a more fair comparison. But it doesn't, so if you're choosing between Distributions and MeasureTheory for MCMC, the plot above is a reasonable representation of the core log-density computation.\n\nAlso worth noting is that gradient computations are often important for this work. MeasureTheory is designed to be relatively autodiff-friendly, by representing the log-density as a simple algebraic expression. For Distributions this is definitely not the case, and making AD work well required an entirely separate and significant effort, DistributionsAD.jl."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"7fc534f0-3717-418a-903d-1ea1c78a6072","type":"message","text":"Sure, the advantages and use cases of unnormalized log densities are clear to me. It's just that a benchmark of two algorithms that each compute different things seems a bit strange and \"unfair\". So in my opinion, regardless of the use and advantages of unnormalized densitites, it would be more standard to compare the log densities with respect to the unscaled Lebesgue measure, using MeasureTheory.Normal, Distributions.Normal and possibly StatsFuns.normlogpdf. I think it's good that the more detailed explanations point out more clearly that the computations are different.\n\nBTW I don't think the last point on AD is correct. There's no good reason why Distributions couldn't be AD-friendly even without unnormalized densities. The constants disappear in the derivatives and probably neglected by AD backends anyway. Also in many cases custom differentiation rules are more efficient and hence it would make sense to define e.g. ChainRules-based rules. For other problems such as too restrictive types in Distributions and its dependencies, fixes (usually committing type piracy) just happened to end up in DistributionsAD even though they should actually be fixed in the upstream packages. More and more parts of DistributionsAD become obsolete by moving implementations to the upstream packages they belong to.","user":"U8T9JUA5R","ts":"1612179294.039300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"w5jg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sure, the advantages and use cases of unnormalized log densities are clear to me. It's just that a benchmark of two algorithms that each compute different things seems a bit strange and \"unfair\". So in my opinion, regardless of the use and advantages of unnormalized densitites, it would be more standard to compare the log densities with respect to the unscaled Lebesgue measure, using MeasureTheory.Normal, Distributions.Normal and possibly StatsFuns.normlogpdf. I think it's good that the more detailed explanations point out more clearly that the computations are different.\n\nBTW I don't think the last point on AD is correct. There's no good reason why Distributions couldn't be AD-friendly even without unnormalized densities. The constants disappear in the derivatives and probably neglected by AD backends anyway. Also in many cases custom differentiation rules are more efficient and hence it would make sense to define e.g. ChainRules-based rules. For other problems such as too restrictive types in Distributions and its dependencies, fixes (usually committing type piracy) just happened to end up in DistributionsAD even though they should actually be fixed in the upstream packages. More and more parts of DistributionsAD become obsolete by moving implementations to the upstream packages they belong to."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"type":"message","subtype":"thread_broadcast","text":"My goal with the performance comparison was to compare times _as people actually use the code_. I appreciate the suggestions you made earlier, but with those caveats I think it's now a fair comparison.\n\nReal fixes outside of Distributions.jl aren't possible, because the types are restricted in the structs themselves. I agree that a lot of this should really be fixed in Distributions itself. It seems to me packages like DistributionsAD come about because Distributions is so large and widely-used that even small changes require lots of negotiation, which slows down development.\n\n&gt; There's no good reason why Distributions couldn't be AD-friendly even without unnormalized densities.\nOf course Distributions _could_ be AD-friendly. Lots of things could be improved. It seems a little bit like the state of R before Hadley Wickham came along. Sure, you could get things to work, but it usually felt find of like a patchwork.\n\nMaybe that's what Distributions needs, corporate funding to fork the repo and smooth out all of the bumps. That would be great, but we don't currently have resources like that.","user":"U81PB6N77","ts":"1612191613.039500","thread_ts":"1611956947.028900","root":{"client_msg_id":"8c321978-0126-4a9b-a007-ec8cfab38aaf","type":"message","text":"Does this seem like a fair test?\n```μ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nusing BenchmarkTools\nfunction time_normal(f)\n    function go(f, μ, σ, x, y)\n        for i in eachindex(x)\n            @inbounds y[i] = logdensity(f(μ[i], σ[i]), x[i])\n        end\n    end\n\n    @belapsed $go($f, $μ, $σ, $x, $y)\nend```\n```julia&gt; sμσ =  time_normal((μ,σ) -&gt; Dists.Normal(μ,σ; check_args=false)) / time_normal((μ,σ) -&gt; Normal(μ,σ))\n1.3814563928873838\n\njulia&gt; sμ1 =  time_normal((μ,σ) -&gt; Dists.Normal(μ,1.0; check_args=false)) / time_normal((μ,σ) -&gt; Normal(μ=μ))\n40.1426842474043\n\njulia&gt; s0σ =  time_normal((μ,σ) -&gt; Dists.Normal(0.0,σ; check_args=false)) / time_normal((μ,σ) -&gt; Normal(σ=σ))\n1.4177335229966808\n\njulia&gt; s01 =  time_normal((μ,σ) -&gt; Dists.Normal()) / time_normal((μ,σ) -&gt; Normal())\n42.33345406856929```\n`s` is for \"speedup\" (that's good enough for me!)","user":"U81PB6N77","ts":"1611956947.028900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"69dIH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Does this seem like a fair test?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"μ = randn(1000)\nσ = rand(1000)\nx = randn(1000)\ny = randn(1000)\n\nusing BenchmarkTools\nfunction time_normal(f)\n    function go(f, μ, σ, x, y)\n        for i in eachindex(x)\n            @inbounds y[i] = logdensity(f(μ[i], σ[i]), x[i])\n        end\n    end\n\n    @belapsed $go($f, $μ, $σ, $x, $y)\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> sμσ =  time_normal((μ,σ) -> Dists.Normal(μ,σ; check_args=false)) / time_normal((μ,σ) -> Normal(μ,σ))\n1.3814563928873838\n\njulia> sμ1 =  time_normal((μ,σ) -> Dists.Normal(μ,1.0; check_args=false)) / time_normal((μ,σ) -> Normal(μ=μ))\n40.1426842474043\n\njulia> s0σ =  time_normal((μ,σ) -> Dists.Normal(0.0,σ; check_args=false)) / time_normal((μ,σ) -> Normal(σ=σ))\n1.4177335229966808\n\njulia> s01 =  time_normal((μ,σ) -> Dists.Normal()) / time_normal((μ,σ) -> Normal())\n42.33345406856929"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"},{"type":"text","text":"s","style":{"code":true}},{"type":"text","text":" is for \"speedup\" (that's good enough for me!)"}]}]}],"thread_ts":"1611956947.028900","reply_count":38,"reply_users_count":4,"latest_reply":"1612217001.040500","reply_users":["U81PB6N77","U019K6Q9N15","UHDQQ4GN6","U8T9JUA5R"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"POLBG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My goal with the performance comparison was to compare times "},{"type":"text","text":"as people actually use the code","style":{"italic":true}},{"type":"text","text":". I appreciate the suggestions you made earlier, but with those caveats I think it's now a fair comparison.\n\nReal fixes outside of Distributions.jl aren't possible, because the types are restricted in the structs themselves. I agree that a lot of this should really be fixed in Distributions itself. It seems to me packages like DistributionsAD come about because Distributions is so large and widely-used that even small changes require lots of negotiation, which slows down development.\n\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"There's no good reason why Distributions couldn't be AD-friendly even without unnormalized densities."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nOf course Distributions "},{"type":"text","text":"could","style":{"italic":true}},{"type":"text","text":" be AD-friendly. Lots of things could be improved. It seems a little bit like the state of R before Hadley Wickham came along. Sure, you could get things to work, but it usually felt find of like a patchwork.\n\nMaybe that's what Distributions needs, corporate funding to fork the repo and smooth out all of the bumps. That would be great, but we don't currently have resources like that."}]}]}],"client_msg_id":"6402671d-6599-41f7-9eca-8a67aa564ac7"},{"client_msg_id":"fcbdf16e-c245-47ab-8b18-00804dfd850d","type":"message","text":"&gt; BTW I don't think the last point on AD is correct. There's no good reason why Distributions couldn't be AD-friendly even without unnormalized densities. The constants disappear in the derivatives and probably neglected by AD backends anyway.\nJulia's AD engines have all kinds of rough edges. Zygote, for example, is really slow on any function that contains control flow or any element-wise array operations, and it cannot handle any function that mutates an array. Writing a package that just works:tm: well for AD usually requires consciously thinking about the patterns that one needs to avoid and adding explicit overloads (for operator overloading ADs) or adding `rrule`s (for Zygote and future ADs) wherever the pattern is unavoidable. It will be a long time before these rough edges disappear. Ideally, Distributions itself would be fixed to be more AD friendly. In the absence of that, a lighter weight package that is more AD-friendly by design seems like a good thing to have in the Julia ecosystem.","user":"UHDQQ4GN6","ts":"1612206905.039900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KPYXc","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"BTW I don't think the last point on AD is correct. There's no good reason why Distributions couldn't be AD-friendly even without unnormalized densities. The constants disappear in the derivatives and probably neglected by AD backends anyway."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nJulia's AD engines have all kinds of rough edges. Zygote, for example, is really slow on any function that contains control flow or any element-wise array operations, and it cannot handle any function that mutates an array. Writing a package that just works"},{"type":"emoji","name":"tm"},{"type":"text","text":" well for AD usually requires consciously thinking about the patterns that one needs to avoid and adding explicit overloads (for operator overloading ADs) or adding "},{"type":"text","text":"rrule","style":{"code":true}},{"type":"text","text":"s (for Zygote and future ADs) wherever the pattern is unavoidable. It will be a long time before these rough edges disappear. Ideally, Distributions itself would be fixed to be more AD friendly. In the absence of that, a lighter weight package that is more AD-friendly by design seems like a good thing to have in the Julia ecosystem."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77","reactions":[{"name":"+1","users":["U81PB6N77"],"count":1}]},{"client_msg_id":"1a62a6ac-18c4-4c01-bd8a-29f24bf8a6cc","type":"message","text":"I generally agree with this <@UHDQQ4GN6>. One interesting exception to the \"mutable operations are hard for AD\" rule is NiLang:\n<https://github.com/GiggleLiu/NiLang.jl>\n\nEverything mutated is both an argument and a return value, and reversibility makes it so you can reason about things. They have some nice performance results for AD:\n<https://arxiv.org/abs/2003.04617>","user":"U81PB6N77","ts":"1612216257.040200","team":"T68168MUP","attachments":[{"service_name":"arXiv.org","title":"Differentiate Everything with a Reversible Domain-Specific Language","title_link":"https://arxiv.org/abs/2003.04617","text":"Traditional machine instruction level reverse mode automatic differentiation (AD) faces the problem of having a space overhead that linear to time in order to trace back the computational state,...","fallback":"arXiv.org: Differentiate Everything with a Reversible Domain-Specific Language","from_url":"https://arxiv.org/abs/2003.04617","service_icon":"https://static.arxiv.org/static/browse/0.3.2.6/images/icons/favicon.ico","id":1,"original_url":"https://arxiv.org/abs/2003.04617"}],"blocks":[{"type":"rich_text","block_id":"uk7vF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I generally agree with this "},{"type":"user","user_id":"UHDQQ4GN6"},{"type":"text","text":". One interesting exception to the \"mutable operations are hard for AD\" rule is NiLang:\n"},{"type":"link","url":"https://github.com/GiggleLiu/NiLang.jl"},{"type":"text","text":"\n\nEverything mutated is both an argument and a return value, and reversibility makes it so you can reason about things. They have some nice performance results for AD:\n"},{"type":"link","url":"https://arxiv.org/abs/2003.04617"}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77"},{"client_msg_id":"fdcbea02-545b-448c-89b6-4578a34568a5","type":"message","text":"Yeah there's no inherent reason why we can't mutate in AD. An `rrule` for a mutating function would reverse the primal function, which in the worst case would require a cached copy of the original input but in many cases would be much better. IIUC, the reason why mutating is really hard to support in general is because of aliasing, but I haven't seen this written up anywhere. At some point in the future, at least some of Julia's generic reverse-mode AD packages will support it, but not soon.","user":"UHDQQ4GN6","ts":"1612217001.040500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cylo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah there's no inherent reason why we can't mutate in AD. An "},{"type":"text","text":"rrule","style":{"code":true}},{"type":"text","text":" for a mutating function would reverse the primal function, which in the worst case would require a cached copy of the original input but in many cases would be much better. IIUC, the reason why mutating is really hard to support in general is because of aliasing, but I haven't seen this written up anywhere. At some point in the future, at least some of Julia's generic reverse-mode AD packages will support it, but not soon."}]}]}],"thread_ts":"1611956947.028900","parent_user_id":"U81PB6N77","reactions":[{"name":"+1","users":["U81PB6N77"],"count":1}]}]