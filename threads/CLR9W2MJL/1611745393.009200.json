[{"client_msg_id":"d88ad074-0687-4257-add7-09c865d7f67f","type":"message","text":"Probably a stupid question but, since the markov chain created by the Metropolis-Hastings algorithm is ergodic, why can't we sample many chains in parallel for just few steps and then join the results together?","user":"UGB3MK8MC","ts":"1611745393.009200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MZwVn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Probably a stupid question but, since the markov chain created by the Metropolis-Hastings algorithm is ergodic, why can't we sample many chains in parallel for just few steps and then join the results together?"}]}]}],"thread_ts":"1611745393.009200","reply_count":12,"reply_users_count":4,"latest_reply":"1611828107.022100","reply_users":["UJ7DVTVQ8","U81PB6N77","UGB3MK8MC","U7THT3TM3"],"subscribed":false},{"client_msg_id":"8c3ec36c-e889-49ea-934f-77b9b49be5c6","type":"message","text":"Most frameworks have tools for making this easy. You need to discard the initial samples from all chains though, so there is a constant overhead per chain.","user":"UJ7DVTVQ8","ts":"1611749774.011100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sxKHa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Most frameworks have tools for making this easy. You need to discard the initial samples from all chains though, so there is a constant overhead per chain."}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC","reactions":[{"name":"+1","users":["U81PB6N77","U7THT3TM3"],"count":2}]},{"client_msg_id":"0ef4b95d-660a-461c-9652-79ff30517f8d","type":"message","text":"I think there's value in something like\n1. Approximate using variational inference\n2. Sample from result\n3. A few MCMC steps for each sample","user":"U81PB6N77","ts":"1611754547.011500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"y9/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think there's value in something like\n1. Approximate using variational inference\n2. Sample from result\n3. A few MCMC steps for each sample"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC","reactions":[{"name":"+1","users":["U7THT3TM3"],"count":1}]},{"client_msg_id":"d686d8f3-b096-4701-9eb7-c1acc782ca91","type":"message","text":"Thanks!","user":"UGB3MK8MC","ts":"1611756005.011700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Z/0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks!"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC"},{"client_msg_id":"25bf1290-db01-4659-9457-830577b58472","type":"message","text":"I have seen that most tools allow you to run one chain per core and then plot each chain separately. They don't actually seem to merge two chains and plot only the resulting one, is there a particular reason why?","user":"UGB3MK8MC","ts":"1611756104.011900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iyTki","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have seen that most tools allow you to run one chain per core and then plot each chain separately. They don't actually seem to merge two chains and plot only the resulting one, is there a particular reason why?"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC"},{"client_msg_id":"91d1d097-82b2-4306-9369-a90cca72eb19","type":"message","text":"I was thinking more about 100-1000 chains run on a GPU or something like that. I know of replica exchange but if I understood it correctly it's more about using multiple chains to explore multimodal distributions rather than using all of them to speed up the convergence","user":"UGB3MK8MC","ts":"1611756194.012100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LrrHW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was thinking more about 100-1000 chains run on a GPU or something like that. I know of replica exchange but if I understood it correctly it's more about using multiple chains to explore multimodal distributions rather than using all of them to speed up the convergence"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC"},{"client_msg_id":"27d87c0d-37f1-4413-af5f-6663b17a2b13","type":"message","text":"Keeping them separate lets you track autocorrelations, and also things like the R-hat statistic, which compares within-chain variance to between-chain variance","user":"U81PB6N77","ts":"1611767079.012900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ragd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Keeping them separate lets you track autocorrelations, and also things like the R-hat statistic, which compares within-chain variance to between-chain variance"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC","reactions":[{"name":"+1","users":["U7THT3TM3"],"count":1}]},{"client_msg_id":"1017A39B-EE9A-487F-ABB7-D53671D78410","type":"message","text":"Is it useful to have 100 chains just for r hat?","user":"UGB3MK8MC","ts":"1611780372.013800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WV6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it useful to have 100 chains just for r hat?"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC"},{"client_msg_id":"3bea63b0-1a95-4525-90fa-0469e8b6835c","type":"message","text":"I wouldn't think so, but maybe if there are lots of local regions it can get stuck in. I'd say warmup cost is the biggest trouble with lots of chains","user":"U81PB6N77","ts":"1611781528.014000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0SF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I wouldn't think so, but maybe if there are lots of local regions it can get stuck in. I'd say warmup cost is the biggest trouble with lots of chains"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC"},{"client_msg_id":"5315dbad-f581-4e31-b5eb-811b253c2195","type":"message","text":"All in all, my biggest question is, does sampling using many cores actually provide a linear speed up for probabilistic programming? And if yes, why is nobody doing it?\n\nWould it open the possibility of training a Bayesian NN using MCMC? Or having a turing model converge in milliseconds?","user":"UGB3MK8MC","ts":"1611781923.014200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"12Qa0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"All in all, my biggest question is, does sampling using many cores actually provide a linear speed up for probabilistic programming? And if yes, why is nobody doing it?\n\nWould it open the possibility of training a Bayesian NN using MCMC? Or having a turing model converge in milliseconds?"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC"},{"client_msg_id":"74A6CE60-DB70-402B-B52C-FA26F6BBB4BB","type":"message","text":"Well if you are doing a NN, your matmul is probably multithreaded, right? So you need multiple cores for a single chain.\n\nSo e.g. if you are doing NUTS for a Bayesian NN, and you have a 16 core machine, maybe you sample 4 chains at a time? Divide your 16 cores up into four groups? 4 cores per chain. So then your matmul for each chain gets 4 cores.\n\nI think <@UAUPJLBQX> had some thoughts on this recently?","user":"U7THT3TM3","ts":"1611802907.018600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mpxbp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Well if you are doing a NN, your matmul is probably multithreaded, right? So you need multiple cores for a single chain.\n"},{"type":"text","text":"\n"},{"type":"text","text":"So e.g. if you are doing NUTS for a Bayesian NN, and you have a 16 core machine, maybe you sample 4 chains at a time? Divide your 16 cores up into four groups? 4 cores per chain. So then your matmul for each chain gets 4 cores.\n"},{"type":"text","text":"\n"},{"type":"text","text":"I think "},{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":" had some thoughts on this recently?"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC"},{"client_msg_id":"5E9BF947-9902-486A-B4DB-1426E21FE451","type":"message","text":"That sounds like evaluating the likelihood in parallel, which I agree is useful. I think Stan is working on gpu support atm.","user":"UGB3MK8MC","ts":"1611828037.020300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vhp3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That sounds like evaluating the likelihood in parallel, which I agree is useful. I think Stan is working on gpu support atm."}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC","reactions":[{"name":"+1","users":["U7THT3TM3"],"count":1}]},{"client_msg_id":"CDD1AFA2-337D-4529-AB7F-FC68467E6134","type":"message","text":"I was wondering about evaluating many chains in parallel in order to speed up convergence. Especially for simple models like linear/logistic regressions/glms","user":"UGB3MK8MC","ts":"1611828107.022100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Xpu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I was wondering about evaluating many chains in parallel in order to speed up convergence. Especially for simple models like linear/logistic regressions/glms"}]}]}],"thread_ts":"1611745393.009200","parent_user_id":"UGB3MK8MC","reactions":[{"name":"+1","users":["U7THT3TM3"],"count":1}]}]