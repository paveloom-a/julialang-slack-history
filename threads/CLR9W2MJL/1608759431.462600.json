[{"client_msg_id":"9c03060f-9073-4987-9236-4405675d4047","type":"message","text":"<@UDGT4PM41> <@U66G4838Q>  to really understand this i need a toy example of a classifier that doesn't satisfy expression (1) and a demonstration of what the ||-operator does to it to make expression (2) hold\n\na typo i noticed on page 3 right hand column two thirds of the way down:\n&gt; with P being uniform a uniform measure over that hypercube\npage 4:\n&gt; However, this is a special case; for most distributional properties, most models do not possess a corresponding variable.\nif a model is parameterized then fixing a distributional property is tantamount to constraining the parameters to take values in some subset _S_, right? and if the parameters themselves have Bayesian-style prior distributions then conditioning on the distributional property taking that fixed value is tantamount to truncating the support of the prior to just _S_, right? what am i missing? i mean, this is a pain to do in particular cases so if all Omega does is make it easy in general that's fantastic, but i don't think this is going beyond what can already be expressed in Bayesian probability theory/data analysis\n\nif i'm right about that, then p-boxes are strictly more expressive since possibility theory is a generalization of probability theory (but i have yet to find myself reaching for that extra expressive power and am so far content being a Bayesian)","user":"U01FUDH45LN","ts":"1608759431.462600","team":"T68168MUP","edited":{"user":"U01FUDH45LN","ts":"1608759569.000000"},"blocks":[{"type":"rich_text","block_id":"kvFZ5","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UDGT4PM41"},{"type":"text","text":" "},{"type":"user","user_id":"U66G4838Q"},{"type":"text","text":"  to really understand this i need a toy example of a classifier that doesn't satisfy expression (1) and a demonstration of what the ||-operator does to it to make expression (2) hold\n\na typo i noticed on page 3 right hand column two thirds of the way down:\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"with P being uniform a uniform measure over that hypercube"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\npage 4:\n"}]},{"type":"rich_text_quote","elements":[{"type":"text","text":"However, this is a special case; for most distributional properties, most models do not possess a corresponding variable."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"if a model is parameterized then fixing a distributional property is tantamount to constraining the parameters to take values in some subset "},{"type":"text","text":"S","style":{"italic":true}},{"type":"text","text":", right? and if the parameters themselves have Bayesian-style prior distributions then conditioning on the distributional property taking that fixed value is tantamount to truncating the support of the prior to just "},{"type":"text","text":"S","style":{"italic":true}},{"type":"text","text":", right? what am i missing? i mean, this is a pain to do in particular cases so if all Omega does is make it easy in general that's fantastic, but i don't think this is going beyond what can already be expressed in Bayesian probability theory/data analysis\n\nif i'm right about that, then p-boxes are strictly more expressive since possibility theory is a generalization of probability theory (but i have yet to find myself reaching for that extra expressive power and am so far content being a Bayesian)"}]}]}],"thread_ts":"1608759431.462600","reply_count":1,"reply_users_count":1,"latest_reply":"1608809813.469800","reply_users":["UDGT4PM41"],"subscribed":false},{"client_msg_id":"107f6e67-40be-43d1-a22c-37729572c264","type":"message","text":"This definitely makes sense","user":"UDGT4PM41","ts":"1608809813.469800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EecK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This definitely makes sense"}]}]}],"thread_ts":"1608759431.462600","parent_user_id":"U01FUDH45LN"}]