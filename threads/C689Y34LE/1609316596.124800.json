[{"client_msg_id":"defccd65-9e93-4c2f-b405-238305991f94","type":"message","text":"I have a C program that uses CuFFT to perform long FFts on 8 bit (signed integer) data samples.  CuFFT doesn't support 8 bit integers natively, but to conserve GPU memory the program uses CuFFT callbacks to feed it normalized floats that are read though a texture memory object backed by an input buffer containing the 8-bit samples.  This texture memory object is setup using the \"CUDA Runtime API\" `cudaTextureDesc` structure, which has a `readMode` field that can be set to `cudaReadModeNormalizedFloat` to get a \"free\" on-the-fly conversion from 8 bit signed integer to normalized float, `[-1, +1]`.\n\nI'd like to replicate this functionality with CUDA.jl, but I've encountered several roadblocks:\n\n1. CUDA.jl uses the \"CUDA Driver API\" and the texture object setup is different enough that there is no distinct equivalent to  `readMode=cudaReadModeNormalizedFloat`.  The CUDA docs are not too clear on this, but it seems like maybe just leaving out the `CU_TRSF_READ_AS_INTEGER` flag might suffice?  Currently that flag is always set if an integer type is backing the texture object, but that could be made selectable with a new keyword argument (with backward compatible default value) to the `CuTexture` constructor.\n2. Even if that does enable the equivalent behavior in the texture object, it seems that CUDA.jl texture fetches always returns integer values if the data type backing the texture object is of an integer type.  This precludes any use of the texture memory for this free int-to-float conversion, but it's not clear to me how to make it possible to selectively enable/disable this aspect of CUDA.jl's texture fetch functionality.\n3. The `cufftXtSetCallback()` function is not exposed by CUDA.jl.  This would be easy enough to add, but it's not clear how one could create the callback functions and get pointers to them.  Maybe via `CUDA.dynamic_cufunction`?\n4. Given the above items, I'm contemplating taking the memory hit and expanding the input data to 32 (or 16?) bit floats.  Has anyone used the (not yet wrapped) NPP functions?  They seem fairly straightforward to use via `ccall()`, but I wonder whether they offer enough added performance over CUDA.jl conversion functions to be worth the extra calling effort.\nThanks for any feedback!","user":"U01FKQQ7J0J","ts":"1609316596.124800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aXQ5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a C program that uses CuFFT to perform long FFts on 8 bit (signed integer) data samples.  CuFFT doesn't support 8 bit integers natively, but to conserve GPU memory the program uses CuFFT callbacks to feed it normalized floats that are read though a texture memory object backed by an input buffer containing the 8-bit samples.  This texture memory object is setup using the \"CUDA Runtime API\" "},{"type":"text","text":"cudaTextureDesc","style":{"code":true}},{"type":"text","text":" structure, which has a "},{"type":"text","text":"readMode","style":{"code":true}},{"type":"text","text":" field that can be set to "},{"type":"text","text":"cudaReadModeNormalizedFloat","style":{"code":true}},{"type":"text","text":" to get a \"free\" on-the-fly conversion from 8 bit signed integer to normalized float, "},{"type":"text","text":"[-1, +1]","style":{"code":true}},{"type":"text","text":".\n\nI'd like to replicate this functionality with CUDA.jl, but I've encountered several roadblocks:\n\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"CUDA.jl uses the \"CUDA Driver API\" and the texture object setup is different enough that there is no distinct equivalent to  "},{"type":"text","text":"readMode=cudaReadModeNormalizedFloat","style":{"code":true}},{"type":"text","text":".  The CUDA docs are not too clear on this, but it seems like maybe just leaving out the "},{"type":"text","text":"CU_TRSF_READ_AS_INTEGER","style":{"code":true}},{"type":"text","text":" flag might suffice?  Currently that flag is always set if an integer type is backing the texture object, but that could be made selectable with a new keyword argument (with backward compatible default value) to the "},{"type":"text","text":"CuTexture","style":{"code":true}},{"type":"text","text":" constructor."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Even if that does enable the equivalent behavior in the texture object, it seems that CUDA.jl texture fetches always returns integer values if the data type backing the texture object is of an integer type.  This precludes any use of the texture memory for this free int-to-float conversion, but it's not clear to me how to make it possible to selectively enable/disable this aspect of CUDA.jl's texture fetch functionality."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"The "},{"type":"text","text":"cufftXtSetCallback()","style":{"code":true}},{"type":"text","text":" function is not exposed by CUDA.jl.  This would be easy enough to add, but it's not clear how one could create the callback functions and get pointers to them.  Maybe via "},{"type":"text","text":"CUDA.dynamic_cufunction","style":{"code":true}},{"type":"text","text":"?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Given the above items, I'm contemplating taking the memory hit and expanding the input data to 32 (or 16?) bit floats.  Has anyone used the (not yet wrapped) NPP functions?  They seem fairly straightforward to use via "},{"type":"text","text":"ccall()","style":{"code":true}},{"type":"text","text":", but I wonder whether they offer enough added performance over CUDA.jl conversion functions to be worth the extra calling effort."}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"\nThanks for any feedback!"}]}]}],"thread_ts":"1609316596.124800","reply_count":21,"reply_users_count":2,"latest_reply":"1609360626.130900","reply_users":["U67BJLYCS","U01FKQQ7J0J"],"subscribed":false},{"client_msg_id":"271514f8-8de9-4412-9519-da10a6348424","type":"message","text":"Hi Dave,\n\nTim is on Vacation right now, and he is the best one at answering your questions.","user":"U67BJLYCS","ts":"1609343653.126100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lupN6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi Dave,\n\nTim is on Vacation right now, and he is the best one at answering your questions."}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"8e6b5b85-0bd3-460e-a657-62fb1f44ae33","type":"message","text":"Reading the CUDA docs it seems to me that you don't want to set that flag","user":"U67BJLYCS","ts":"1609343861.126300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ryq87","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Reading the CUDA docs it seems to me that you don't want to set that flag"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"2f52d131-220d-4621-a609-9220d8243544","type":"message","text":"&gt; CU_TRSF_READ_AS_INTEGER, which suppresses the default behavior of having the texture promote integer data to floating point data in the range [0, 1];","user":"U67BJLYCS","ts":"1609343867.126500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=Xl1+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"> CU_TRSF_READ_AS_INTEGER, which suppresses the default behavior of having the texture promote integer data to floating point data in the range [0, 1];"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"ebae629c-644f-4250-b656-4d7d20892236","type":"message","text":"Looking at <http://pixel.ecn.purdue.edu:8080/purpl/WSJ/projects/DirectionalStippling/include/texture_fetch_functions.h|http://pixel.ecn.purdue.edu:8080/purpl/WSJ/projects/DirectionalStippling/include/texture_fetch_functions.h>","user":"U67BJLYCS","ts":"1609344283.126700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hLPx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Looking at "},{"type":"link","url":"http://pixel.ecn.purdue.edu:8080/purpl/WSJ/projects/DirectionalStippling/include/texture_fetch_functions.h","text":"http://pixel.ecn.purdue.edu:8080/purpl/WSJ/projects/DirectionalStippling/include/texture_fetch_functions.h"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"3fa5253a-2679-45cc-9e0d-94f7e618a848","type":"message","text":"It seems like cudaReadModeAsNormalizedFloat is not a hardware feature, but done in software","user":"U67BJLYCS","ts":"1609344316.126900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zY1+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It seems like cudaReadModeAsNormalizedFloat is not a hardware feature, but done in software"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"5518a7a7-9ca4-4019-9dea-2a63aca62784","type":"message","text":"Haven't found the definition of _`_int_as_float`_","user":"U67BJLYCS","ts":"1609344399.127100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ipO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Haven't found the definition of "},{"type":"text","text":"_int_as_float","style":{"italic":true,"code":true}}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"5db9558b-0e24-4a7f-8112-ab00edca8137","type":"message","text":"I am afk but I would look that up in the CUDA headers","user":"U67BJLYCS","ts":"1609344444.127300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cBa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am afk but I would look that up in the CUDA headers"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"87960161-70ed-4ab6-a712-d4cf0f342e5f","type":"message","text":"I hope that is sufficient to get you started in the right direction wrt to the texture conversion","user":"U67BJLYCS","ts":"1609344602.127500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7Pg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I hope that is sufficient to get you started in the right direction wrt to the texture conversion"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"68b6cd75-a6e1-4665-af9a-9f7b62fd0c87","type":"message","text":"The CuFFT function expect device pointers to raw device functions","user":"U67BJLYCS","ts":"1609344688.127700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2d3/S","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The CuFFT function expect device pointers to raw device functions"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"180f374e-4659-4ad4-92b0-891507591068","type":"message","text":"That should be feasible but also isn't trivial","user":"U67BJLYCS","ts":"1609344760.127900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lUm","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That should be feasible but also isn't trivial"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"c9abf20b-4c45-4fb2-bd3e-a51de8c54369","type":"message","text":"Maybe best to open an issue on CUDA.jl and let me think about how to best achieve that","user":"U67BJLYCS","ts":"1609344800.128100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WtlH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe best to open an issue on CUDA.jl and let me think about how to best achieve that"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"d1c624e6-7302-43e5-a4cd-e5befe9bf7e6","type":"message","text":"Never heard of NPP before today :)","user":"U67BJLYCS","ts":"1609344865.128300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vZuYK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Never heard of NPP before today :)"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"d44fb8ba-c684-4b6e-87fd-828c10c4a519","type":"message","text":"Thanks for the thoughtful replies","user":"U01FKQQ7J0J","ts":"1609359462.129100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BOAtW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for the thoughtful replies"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"de68fafd-15d0-4b29-8e84-f1008897f9bb","type":"message","text":"The `__int_as_float()` device function is declared in `crt/device_functions.h`:\n```/**\n * \\ingroup CUDA_MATH_INTRINSIC_CAST\n * \\brief Reinterpret bits in an integer as a float.\n *\n * Reinterpret the bits in the signed integer value \\p x as a single-precision\n * floating point value.\n * \\return Returns reinterpreted value.\n */\n__DEVICE_FUNCTIONS_DECL__ __device_builtin__ float                  __int_as_float(int x);```\nso I think the int-to-normlized-float conversion has already happened as an internal part of the texture fetch and this is just used to reinterpret the returned bits as a float rather than an int.","user":"U01FKQQ7J0J","ts":"1609359556.129300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RqdzA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The "},{"type":"text","text":"__int_as_float()","style":{"code":true}},{"type":"text","text":" device function is declared in "},{"type":"text","text":"crt/device_functions.h","style":{"code":true}},{"type":"text","text":":\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"/**\n * \\ingroup CUDA_MATH_INTRINSIC_CAST\n * \\brief Reinterpret bits in an integer as a float.\n *\n * Reinterpret the bits in the signed integer value \\p x as a single-precision\n * floating point value.\n * \\return Returns reinterpreted value.\n */\n__DEVICE_FUNCTIONS_DECL__ __device_builtin__ float                  __int_as_float(int x);"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"so I think the int-to-normlized-float conversion has already happened as an internal part of the texture fetch and this is just used to reinterpret the returned bits as a float rather than an int."}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"8656a731-ad0c-4c4f-b20f-eebeb9f67d50","type":"message","text":"I'll open in issue about the CuFFT callback support feature request","user":"U01FKQQ7J0J","ts":"1609359717.129700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WjwVU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'll open in issue about the CuFFT callback support feature request"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"2cea1444-e5c7-4469-8a87-e57518b2be5c","type":"message","text":"The NPP has a ton of functions, but I'm only interested (at present) in the bulk conversion from Int8 to Float32.  It's been included as part of CUDA for a while now.  It's easy to `ccall` it so I'll try doing some comparison benchmarks.  Does `dst .= src` parallelize automatically if `dst` and `src` are both CuArrays or would I have to write a kernel for maximum grid/block control?  I guess this is covered in the CUDA.jl tutorial that I need to re-read...","user":"U01FKQQ7J0J","ts":"1609360230.129900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oQ5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The NPP has a ton of functions, but I'm only interested (at present) in the bulk conversion from Int8 to Float32.  It's been included as part of CUDA for a while now.  It's easy to "},{"type":"text","text":"ccall","style":{"code":true}},{"type":"text","text":" it so I'll try doing some comparison benchmarks.  Does "},{"type":"text","text":"dst .= src","style":{"code":true}},{"type":"text","text":" parallelize automatically if "},{"type":"text","text":"dst","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"src","style":{"code":true}},{"type":"text","text":" are both CuArrays or would I have to write a kernel for maximum grid/block control?  I guess this is covered in the CUDA.jl tutorial that I need to re-read..."}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"3f7d8271-baaf-476b-ba0b-2cb9a4c49630","type":"message","text":"&gt; Does dst .= src parallelize automatically ... are both CuArrays\nyes","user":"U67BJLYCS","ts":"1609360271.130100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UmqIq","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"Does dst .= src parallelize automatically ... are both CuArrays"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nyes"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"a81864b4-9795-4615-9493-f0c1d53aba7d","type":"message","text":"&gt; The __int_as_float() device function is declared in crt/device_functions.h:","user":"U67BJLYCS","ts":"1609360346.130300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hhn","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"The __int_as_float() device function is declared in crt/device_functions.h:"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"25bbfe1c-08a4-450d-9ff7-6079ed8dcedd","type":"message","text":"looks like it is a libdevice functions","user":"U67BJLYCS","ts":"1609360354.130500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uz/o","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"looks like it is a libdevice functions"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"9c5a40d0-ffa8-4365-b5e1-d13a274c22a0","type":"message","text":"```vchuravy@odin /o/c/n/libdevice [0|1]&gt; opt libdevice.10.bc -S | grep int_as_float\ndefine float @__nv_int_as_float(i32 %x) #0 {\ndefine float @__nv_uint_as_float(i32 %x) #0 {```","user":"U67BJLYCS","ts":"1609360547.130700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Kjx89","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"vchuravy@odin /o/c/n/libdevice [0|1]> opt libdevice.10.bc -S | grep int_as_float\ndefine float @__nv_int_as_float(i32 %x) #0 {\ndefine float @__nv_uint_as_float(i32 %x) #0 {"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"},{"client_msg_id":"da3f0572-21be-4482-83ea-7b8bcfe6a26d","type":"message","text":"```define float @__nv_int_as_float(i32 %x) #0 {\n  %1 = bitcast i32 %x to float\n  ret float %1\n}```","user":"U67BJLYCS","ts":"1609360626.130900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4fXs","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"define float @__nv_int_as_float(i32 %x) #0 {\n  %1 = bitcast i32 %x to float\n  ret float %1\n}"}]}]}],"thread_ts":"1609316596.124800","parent_user_id":"U01FKQQ7J0J"}]