[{"client_msg_id":"292232c5-e34a-4c5e-a688-55d86f234233","type":"message","text":"I'm getting a cuDNN error when I try to differentiate softmax twice, known error ?\n\n```ERROR: LoadError: CUDNNError: CUDNN_STATUS_BAD_PARAM (code 3) \nStacktrace: \n [1] throw_api_error(res::CUDA.CUDNN.cudnnStatus_t) \n   @ CUDA.CUDNN ~/.julia/packages/CUDA/qEV3Y/lib/cudnn/error.jl:19 \n [2] macro expansion \n   @ ~/.julia/packages/CUDA/qEV3Y/lib/cudnn/error.jl:30 [inlined] \n [3] cudnnSoftmaxForward(handle::Ptr{Nothing}, algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t, mode::CUDA.CUDNN.cudn\nnSoftmaxMode_t, alpha::Base.RefValue{Float32}, xDesc::CUDA.CUDNN.TensorDesc, x::CuArray{Float32, 4}, beta::Base\n.RefValue{Float32}, yDesc::CUDA.CUDNN.TensorDesc, y::CuArray{Float32, 4}) \n   @ CUDA.CUDNN ~/.julia/packages/CUDA/qEV3Y/lib/utils/call.jl:26 \n [4] cudnnSoftmaxForward(x::CuArray{Float32, 4}, y::CuArray{Float32, 4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorith\nm_t, mode::CUDA.CUDNN.cudnnSoftmaxMode_t, alpha::Float64, beta::Float64)```\n","user":"UKJSNT1QR","ts":"1617785878.145200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"A4nre","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm getting a cuDNN error when I try to differentiate softmax twice, known error ?\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ERROR: LoadError: CUDNNError: CUDNN_STATUS_BAD_PARAM (code 3) \nStacktrace: \n [1] throw_api_error(res::CUDA.CUDNN.cudnnStatus_t) \n   @ CUDA.CUDNN ~/.julia/packages/CUDA/qEV3Y/lib/cudnn/error.jl:19 \n [2] macro expansion \n   @ ~/.julia/packages/CUDA/qEV3Y/lib/cudnn/error.jl:30 [inlined] \n [3] cudnnSoftmaxForward(handle::Ptr{Nothing}, algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t, mode::CUDA.CUDNN.cudn\nnSoftmaxMode_t, alpha::Base.RefValue{Float32}, xDesc::CUDA.CUDNN.TensorDesc, x::CuArray{Float32, 4}, beta::Base\n.RefValue{Float32}, yDesc::CUDA.CUDNN.TensorDesc, y::CuArray{Float32, 4}) \n   @ CUDA.CUDNN ~/.julia/packages/CUDA/qEV3Y/lib/utils/call.jl:26 \n [4] cudnnSoftmaxForward(x::CuArray{Float32, 4}, y::CuArray{Float32, 4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorith\nm_t, mode::CUDA.CUDNN.cudnnSoftmaxMode_t, alpha::Float64, beta::Float64)"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1617785878.145200","reply_count":1,"reply_users_count":1,"latest_reply":"1617786929.145300","reply_users":["UKJSNT1QR"],"is_locked":false,"subscribed":false},{"client_msg_id":"e29857b1-27a2-4e10-a443-d8ab59b6543a","type":"message","text":"Actually even in the CPU softmax isn't twice differentiable. Sigh. I'll dig into it\n\n```x = rand(1,2,2)\n\nfunction ftest(p)\n    test,back = Zygote.pullback(x -&gt; softmax(x; dims=3), x)\n    back(test)[1]\nend\n\ntest,back = Zygote.pullback(ftest, rand(2))\nback(test)```\n","user":"UKJSNT1QR","ts":"1617786929.145300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BJZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Actually even in the CPU softmax isn't twice differentiable. Sigh. I'll dig into it\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"x = rand(1,2,2)\n\nfunction ftest(p)\n    test,back = Zygote.pullback(x -> softmax(x; dims=3), x)\n    back(test)[1]\nend\n\ntest,back = Zygote.pullback(ftest, rand(2))\nback(test)"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1617785878.145200","parent_user_id":"UKJSNT1QR"}]