[{"client_msg_id":"d955b51e-d091-4855-80bf-75cb9c8dcac3","type":"message","text":"From what I understand, in KernelAbstractions, one can just pass an `ndrange` of indices, and KernelAbstractions will take care of splitting that range among threads. Is there a way to know how indices are split (or to impose manually how they are divided)? The use case are heterogeneous computations, where the kernel is more expensive on some indices than others, and one may want to make sure that \"easy\" and \"hard\" indices are more or less equally distributed among threads","user":"U6BJ9E351","ts":"1613319178.177900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"151v","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"From what I understand, in KernelAbstractions, one can just pass an "},{"type":"text","text":"ndrange","style":{"code":true}},{"type":"text","text":" of indices, and KernelAbstractions will take care of splitting that range among threads. Is there a way to know how indices are split (or to impose manually how they are divided)? The use case are heterogeneous computations, where the kernel is more expensive on some indices than others, and one may want to make sure that \"easy\" and \"hard\" indices are more or less equally distributed among threads"}]}]}],"thread_ts":"1613319178.177900","reply_count":10,"reply_users_count":3,"latest_reply":"1613323231.179900","reply_users":["UM30MT6RF","U67BJLYCS","U6BJ9E351"],"subscribed":false},{"client_msg_id":"f4bfeca9-c56b-4088-8658-f358d50ab5f8","type":"message","text":"You can specify a `workgroupsize` manually, either upon kernel creation for static sizes or dynamically upon actually running the kernel. On the latest release, KA will actually use CUDA's occupancy API to automatically tune the workgroupsize, if you don't explicitly specify it","user":"UM30MT6RF","ts":"1613320237.178000","team":"T68168MUP","edited":{"user":"UM30MT6RF","ts":"1613320261.000000"},"blocks":[{"type":"rich_text","block_id":"QloJX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can specify a "},{"type":"text","text":"workgroupsize","style":{"code":true}},{"type":"text","text":" manually, either upon kernel creation for static sizes or dynamically upon actually running the kernel. On the latest release, KA will actually use CUDA's occupancy API to automatically tune the workgroupsize, if you don't explicitly specify it"}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"af1ec612-42ea-46db-b393-5407e0c54705","type":"message","text":"KA inherits a lot from the GPU world so dynamic splitting isn't really a thing.","user":"U67BJLYCS","ts":"1613320601.178300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"e8g","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"KA inherits a lot from the GPU world so dynamic splitting isn't really a thing."}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"3a2568b0-5596-477e-b5a9-007a49bae103","type":"message","text":"You can map from the KA index space to your own index space if you want","user":"U67BJLYCS","ts":"1613320622.178500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7yz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can map from the KA index space to your own index space if you want"}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"4e4ff0e9-8150-4dd1-8441-024a65a13aee","type":"message","text":"That can make sense sometimes","user":"U67BJLYCS","ts":"1613320635.178700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"O4d","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That can make sense sometimes"}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"8b9102b5-28be-4f21-bcd5-a48077026f95","type":"message","text":"(Ah, sorry, I read over the heterogenous part in your question)","user":"UM30MT6RF","ts":"1613320684.178900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tww8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(Ah, sorry, I read over the heterogenous part in your question)"}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"4ade4f70-00b3-40a5-b252-7d112d22e033","type":"message","text":"&gt;  You can map from the KA index space to your own index space if you want\nAh, maybe I understand. \"Customizable static splitting\" would already be useful for me, so are you suggesting I could just take whatever splitting comes out of KA (maybe even just on a 1D range of the correct length) and apply manually a smart index transformation that's good for my usecase?","user":"U6BJ9E351","ts":"1613320888.179100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bWX","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":" You can map from the KA index space to your own index space if you want"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Ah, maybe I understand. \"Customizable static splitting\" would already be useful for me, so are you suggesting I could just take whatever splitting comes out of KA (maybe even just on a 1D range of the correct length) and apply manually a smart index transformation that's good for my usecase?"}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"703d620a-f3f0-4530-9e3c-d56e176964d6","type":"message","text":"I imagine by default I get the one computed with the `partition` internal function?","user":"U6BJ9E351","ts":"1613320930.179300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"i3pho","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I imagine by default I get the one computed with the "},{"type":"text","text":"partition","style":{"code":true}},{"type":"text","text":" internal function?"}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"fb4ac3a4-75a3-439d-b3e5-21c761203f20","type":"message","text":"Yeah pretty much","user":"U67BJLYCS","ts":"1613323133.179500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=umj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah pretty much"}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"f9f5ae5f-5e56-4424-bfb6-76ca77433207","type":"message","text":"I have been considered reverting back to workgroupsize+blocks instead of workgroupsize+ndrange","user":"U67BJLYCS","ts":"1613323184.179700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"O8NsK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have been considered reverting back to workgroupsize+blocks instead of workgroupsize+ndrange"}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"b99fd048-10e0-4841-9e8c-e76afb66704a","type":"message","text":"Actually I would be happy with a pr that adds blocks and short-circuit partition","user":"U67BJLYCS","ts":"1613323231.179900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6qHq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Actually I would be happy with a pr that adds blocks and short-circuit partition"}]}]}],"thread_ts":"1613319178.177900","parent_user_id":"U6BJ9E351"}]