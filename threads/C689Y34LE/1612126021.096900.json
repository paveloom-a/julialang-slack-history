[{"client_msg_id":"29629506-d933-48cf-998d-498b4dc5eb6a","type":"message","text":"I'm playing around with KernelAbstractions,and am liking it a lot so far. I have a basic doubt as to whether something is possible. I understand that in a kernel, the function is run asynchronously and in parallel on all the indices in the `ndrange`.\n\nImagine that the result is not completely independent from the order, but to compute the kernel on a given index, I necessarily need to have computed some other indices before (the overall dependency structure will be some directed acyclic graph). Is there a way to tell KernelAbstractions to follow this order (which still allows for a lot of parallelism) or should one do a manual layering, do a kernel on a chunk, wait on the result, do another kernel, and so on?","user":"U6BJ9E351","ts":"1612126021.096900","team":"T68168MUP","edited":{"user":"U6BJ9E351","ts":"1612126290.000000"},"blocks":[{"type":"rich_text","block_id":"L19Tj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm playing around with KernelAbstractions,and am liking it a lot so far. I have a basic doubt as to whether something is possible. I understand that in a kernel, the function is run asynchronously and in parallel on all the indices in the "},{"type":"text","text":"ndrange","style":{"code":true}},{"type":"text","text":".\n\nImagine that the result is not completely independent from the order, but to compute the kernel on a given index, I necessarily need to have computed some other indices before (the overall dependency structure will be some directed acyclic graph). Is there a way to tell KernelAbstractions to follow this order (which still allows for a lot of parallelism) or should one do a manual layering, do a kernel on a chunk, wait on the result, do another kernel, and so on?"}]}]}],"thread_ts":"1612126021.096900","reply_count":5,"reply_users_count":2,"latest_reply":"1612173224.103700","reply_users":["UC7AF7NSU","U6BJ9E351"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"Not sure what kind of DAGs you are talking about but is it possible to express it as a single kernel (even with some indexing tricks)? If so, maybe that's possible to formalize them as iterator combinators (like `zip`/`product`) and define a fold on it.","user":"UC7AF7NSU","ts":"1612145604.101600","thread_ts":"1612126021.096900","root":{"client_msg_id":"29629506-d933-48cf-998d-498b4dc5eb6a","type":"message","text":"I'm playing around with KernelAbstractions,and am liking it a lot so far. I have a basic doubt as to whether something is possible. I understand that in a kernel, the function is run asynchronously and in parallel on all the indices in the `ndrange`.\n\nImagine that the result is not completely independent from the order, but to compute the kernel on a given index, I necessarily need to have computed some other indices before (the overall dependency structure will be some directed acyclic graph). Is there a way to tell KernelAbstractions to follow this order (which still allows for a lot of parallelism) or should one do a manual layering, do a kernel on a chunk, wait on the result, do another kernel, and so on?","user":"U6BJ9E351","ts":"1612126021.096900","team":"T68168MUP","edited":{"user":"U6BJ9E351","ts":"1612126290.000000"},"blocks":[{"type":"rich_text","block_id":"L19Tj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm playing around with KernelAbstractions,and am liking it a lot so far. I have a basic doubt as to whether something is possible. I understand that in a kernel, the function is run asynchronously and in parallel on all the indices in the "},{"type":"text","text":"ndrange","style":{"code":true}},{"type":"text","text":".\n\nImagine that the result is not completely independent from the order, but to compute the kernel on a given index, I necessarily need to have computed some other indices before (the overall dependency structure will be some directed acyclic graph). Is there a way to tell KernelAbstractions to follow this order (which still allows for a lot of parallelism) or should one do a manual layering, do a kernel on a chunk, wait on the result, do another kernel, and so on?"}]}]}],"thread_ts":"1612126021.096900","reply_count":5,"reply_users_count":2,"latest_reply":"1612173224.103700","reply_users":["UC7AF7NSU","U6BJ9E351"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"U4TB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not sure what kind of DAGs you are talking about but is it possible to express it as a single kernel (even with some indexing tricks)? If so, maybe that's possible to formalize them as iterator combinators (like "},{"type":"text","text":"zip","style":{"code":true}},{"type":"text","text":"/"},{"type":"text","text":"product","style":{"code":true}},{"type":"text","text":") and define a fold on it."}]}]}],"client_msg_id":"eb905366-e52f-4d0f-923c-a9c307238570"},{"client_msg_id":"f1aa3ead-0c23-4825-8d76-75a61bbdfbc9","type":"message","text":"I'll need to think harder about that perspective, but I'm not sure that's possible. CUDA folds require that the combinator is associative, right?","user":"U6BJ9E351","ts":"1612165755.102100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XWd3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'll need to think harder about that perspective, but I'm not sure that's possible. CUDA folds require that the combinator is associative, right?"}]}]}],"thread_ts":"1612126021.096900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"94721e64-a55a-4059-be41-1b729da5a840","type":"message","text":"yeah, but I was thinking more about defining a clever `reduce` than defining a clever a monoid `op` passed to `reduce(op, ...)` (which mirrors that `zip` and `product` are much more efficient/straightforward to implement as `reduce` than transducers)\n\nfor generic problems that are easier to express as DAGs, it's probably not a great approach. but since you were mentioning indexing trick, I thought defining `reduce` could make sense.","user":"UC7AF7NSU","ts":"1612167592.102500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qZM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, but I was thinking more about defining a clever "},{"type":"text","text":"reduce","style":{"code":true}},{"type":"text","text":" than defining a clever a monoid "},{"type":"text","text":"op","style":{"code":true}},{"type":"text","text":" passed to "},{"type":"text","text":"reduce(op, ...)","style":{"code":true}},{"type":"text","text":" (which mirrors that "},{"type":"text","text":"zip","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"product","style":{"code":true}},{"type":"text","text":" are much more efficient/straightforward to implement as "},{"type":"text","text":"reduce","style":{"code":true}},{"type":"text","text":" than transducers)\n\nfor generic problems that are easier to express as DAGs, it's probably not a great approach. but since you were mentioning indexing trick, I thought defining "},{"type":"text","text":"reduce","style":{"code":true}},{"type":"text","text":" could make sense."}]}]}],"thread_ts":"1612126021.096900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"d00a338d-c9c0-4ae0-94dd-8e3bd7d47c8e","type":"message","text":"ah, I see, that's an interesting idea, but I'm doing more of a `scan` than a `fold` (input has same dimensionality as output) without associativity guarantees, so the `@spawn` approach in the other thread seems more promising","user":"U6BJ9E351","ts":"1612171465.103100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aV1M","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ah, I see, that's an interesting idea, but I'm doing more of a "},{"type":"text","text":"scan","style":{"code":true}},{"type":"text","text":" than a "},{"type":"text","text":"fold","style":{"code":true}},{"type":"text","text":" (input has same dimensionality as output) without associativity guarantees, so the "},{"type":"text","text":"@spawn","style":{"code":true}},{"type":"text","text":" approach in the other thread seems more promising"}]}]}],"thread_ts":"1612126021.096900","parent_user_id":"U6BJ9E351"},{"client_msg_id":"a8889d11-3471-45dc-b7a9-71ec93951d10","type":"message","text":"yeah, scan is not really fusable with pre- or post-computations (so only monoid combinators make sense), AFAIK, unless you have a very specific algebraic property","user":"UC7AF7NSU","ts":"1612173224.103700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OJ5fz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, scan is not really fusable with pre- or post-computations (so only monoid combinators make sense), AFAIK, unless you have a very specific algebraic property"}]}]}],"thread_ts":"1612126021.096900","parent_user_id":"U6BJ9E351"}]