[{"client_msg_id":"e8db1518-5a59-4900-a896-733a6d88cdbc","type":"message","text":"Hi I'm try the `ExpDecay` of Flux and seems it doesn't work.\n`opt = Flux.Optimiser(ExpDecay(0.001, 0.1, 1, 1e-4), Descent())`\n`for i=1:10`\n    `println(opt.os[2].eta)`\n    `Flux.train!(loss,θ,trainData,opt)`     \n`end`\nHere's my toy example. I thought the learning rate should decrease by 0.1 after each training following the document, but the toy return me same learning rate for 10 training. Am I missing anything here?","user":"U01977X150R","ts":"1613872391.004000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dxd3z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi I'm try the "},{"type":"text","text":"ExpDecay","style":{"code":true}},{"type":"text","text":" of Flux and seems it doesn't work.\n"},{"type":"text","text":"opt = Flux.Optimiser(ExpDecay(0.001, 0.1, 1, 1e-4), Descent())","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"for i=1:10","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    println(opt.os[2].eta)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    Flux.train!(loss,θ,trainData,opt)     ","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"end","style":{"code":true}},{"type":"text","text":"\nHere's my toy example. I thought the learning rate should decrease by 0.1 after each training following the document, but the toy return me same learning rate for 10 training. Am I missing anything here?"}]}]}],"thread_ts":"1613872391.004000","reply_count":3,"reply_users_count":2,"latest_reply":"1613874113.005400","reply_users":["UH9KWTTD3","UMY1LV01G"],"subscribed":false},{"client_msg_id":"4A81C961-9B85-425D-9BC9-AD5213DDC11B","type":"message","text":"It should just be `ExpDecay(0.1)`. But that will decay every iteration of training. Not every epoch like you are trying to do here.","user":"UH9KWTTD3","ts":"1613873524.004700","team":"T68168MUP","edited":{"user":"UH9KWTTD3","ts":"1613873687.000000"},"blocks":[{"type":"rich_text","block_id":"G5g","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It should just be "},{"type":"text","text":"ExpDecay(0.1)","style":{"code":true}},{"type":"text","text":". But that will decay every iteration of training. Not every epoch like you are trying to do here."}]}]}],"thread_ts":"1613872391.004000","parent_user_id":"U01977X150R"},{"client_msg_id":"2CFAF90D-1F92-4F56-99B9-EF0A7C2AB094","type":"message","text":"Shameless plug: <https://darsnack.github.io/ParameterSchedulers.jl/dev/docs/tutorials/basic-schedules.html|https://darsnack.github.io/ParameterSchedulers.jl/dev/docs/tutorials/basic-schedules.html>","user":"UH9KWTTD3","ts":"1613873584.005100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AvHJc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Shameless plug: "},{"type":"link","url":"https://darsnack.github.io/ParameterSchedulers.jl/dev/docs/tutorials/basic-schedules.html","text":"https://darsnack.github.io/ParameterSchedulers.jl/dev/docs/tutorials/basic-schedules.html"}]}]}],"thread_ts":"1613872391.004000","parent_user_id":"U01977X150R"},{"client_msg_id":"6a35253e-f96a-40dd-88d9-f3b2ba8f4833","type":"message","text":"ExpDecay does not change Descent's eta","user":"UMY1LV01G","ts":"1613874113.005400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/m+p","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ExpDecay does not change Descent's eta"}]}]}],"thread_ts":"1613872391.004000","parent_user_id":"U01977X150R"}]