[{"client_msg_id":"ccd5fdf1-c45a-4b77-a86f-8bd2caa2cb0b","type":"message","text":"Hi I'm trying to train a LSTM to predict a value based upon last 5 records for obs`i`.  I just use the sum of mse as my loss function and `trX`  is my records, `trY` is my labels in training sets.\n```function LSTMTest()\nlt = Chain(LSTM(5,1),Dense(1,1)) |&gt;gpu\n    function trial(i)\n        pre = lt(trX[i])\n        return pre\n    end  \nend\n\ntx = ty =  [i for i=1:10];\ntrainData = Flux.Data.DataLoader(tx,ty,shuffle=true,batchsize=10)\nm = LSTMTest()\nloss(x,y) = sum(mse.(m.(x),trY[y]))```\nHowever, when training this very simple LSTM, I got this warning which confuse me a lot. I was wondering whether I missed anything? Many thanks.\n```┌ Warning: calls to Base intrinsics might be GPU incompatible\n│   exception = (GPUCompiler.MethodSubstitutionWarning(log(x::Float64) in Base.Math at special/log.jl:253, log(x::Float64) in CUDA at /home/zq/.julia/packages/CUDA/wTQsK/src/device/intrinsics/math.jl:72), Base.StackTraces.StackFrame[log at log.jl:253, broadcast_kernel at broadcast.jl:59])\n└ @ GPUCompiler /home/zq/.julia/packages/GPUCompiler/uTpNx/src/irgen.jl:68\nGPU compilation of kernel broadcast_kernel(CUDA.CuKernelContext, CuDeviceArray{ForwardDiff.Dual{Nothing,Float32,2},1,1}, Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},Zygote.var\"#1079#1082\"{typeof(mse)},Tuple{Base.Broadcast.Extruded{Array{CuArray{Float32,1},1},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,1},Tuple{Bool},Tuple{Int64}}}}, Int64) failed\nKernelError: passing and using non-bitstype argument\n\nArgument 4 to your kernel function is of type Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},Zygote.var\"#1079#1082\"{typeof(mse)},Tuple{Base.Broadcast.Extruded{Array{CuArray{Float32,1},1},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,1},Tuple{Bool},Tuple{Int64}}}}, which is not isbits:\n  .args is of type Tuple{Base.Broadcast.Extruded{Array{CuArray{Float32,1},1},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,1},Tuple{Bool},Tuple{Int64}}} which is not isbits.\n    .1 is of type Base.Broadcast.Extruded{Array{CuArray{Float32,1},1},Tuple{Bool},Tuple{Int64}} which is not isbits.\n      .x is of type Array{CuArray{Float32,1},1} which is not isbits.```","user":"U01977X150R","ts":"1616734521.056300","team":"T68168MUP","edited":{"user":"U01977X150R","ts":"1616735188.000000"},"blocks":[{"type":"rich_text","block_id":"mK2R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi I'm trying to train a LSTM to predict a value based upon last 5 records for obs"},{"type":"text","text":"i","style":{"code":true}},{"type":"text","text":".  I just use the sum of mse as my loss function and "},{"type":"text","text":"trX","style":{"code":true}},{"type":"text","text":"  is my records, "},{"type":"text","text":"trY","style":{"code":true}},{"type":"text","text":" is my labels in training sets.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function LSTMTest()\nlt = Chain(LSTM(5,1),Dense(1,1)) |>gpu\n    function trial(i)\n        pre = lt(trX[i])\n        return pre\n    end  \nend\n\ntx = ty =  [i for i=1:10];\ntrainData = Flux.Data.DataLoader(tx,ty,shuffle=true,batchsize=10)\nm = LSTMTest()\nloss(x,y) = sum(mse.(m.(x),trY[y]))"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"However, when training this very simple LSTM, I got this warning which confuse me a lot. I was wondering whether I missed anything? Many thanks.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"┌ Warning: calls to Base intrinsics might be GPU incompatible\n│   exception = (GPUCompiler.MethodSubstitutionWarning(log(x::Float64) in Base.Math at special/log.jl:253, log(x::Float64) in CUDA at /home/zq/.julia/packages/CUDA/wTQsK/src/device/intrinsics/math.jl:72), Base.StackTraces.StackFrame[log at log.jl:253, broadcast_kernel at broadcast.jl:59])\n└ @ GPUCompiler /home/zq/.julia/packages/GPUCompiler/uTpNx/src/irgen.jl:68\nGPU compilation of kernel broadcast_kernel(CUDA.CuKernelContext, CuDeviceArray{ForwardDiff.Dual{Nothing,Float32,2},1,1}, Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},Zygote.var\"#1079#1082\"{typeof(mse)},Tuple{Base.Broadcast.Extruded{Array{CuArray{Float32,1},1},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,1},Tuple{Bool},Tuple{Int64}}}}, Int64) failed\nKernelError: passing and using non-bitstype argument\n\nArgument 4 to your kernel function is of type Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64}},Zygote.var\"#1079#1082\"{typeof(mse)},Tuple{Base.Broadcast.Extruded{Array{CuArray{Float32,1},1},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,1},Tuple{Bool},Tuple{Int64}}}}, which is not isbits:\n  .args is of type Tuple{Base.Broadcast.Extruded{Array{CuArray{Float32,1},1},Tuple{Bool},Tuple{Int64}},Base.Broadcast.Extruded{CuDeviceArray{Float32,1,1},Tuple{Bool},Tuple{Int64}}} which is not isbits.\n    .1 is of type Base.Broadcast.Extruded{Array{CuArray{Float32,1},1},Tuple{Bool},Tuple{Int64}} which is not isbits.\n      .x is of type Array{CuArray{Float32,1},1} which is not isbits."}]}]}],"thread_ts":"1616734521.056300","reply_count":1,"reply_users_count":1,"latest_reply":"1616735982.056500","reply_users":["UMY1LV01G"],"is_locked":false,"subscribed":false},{"client_msg_id":"d3d250af-4b68-47f7-a3ea-15917e59c076","type":"message","text":"Can you provide an MWE that actually has the code that triggers the error, as well as a full stack trace? This isn't enough to go on.","user":"UMY1LV01G","ts":"1616735982.056500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"R8Gu2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can you provide an MWE that actually has the code that triggers the error, as well as a full stack trace? This isn't enough to go on."}]}]}],"thread_ts":"1616734521.056300","parent_user_id":"U01977X150R"}]