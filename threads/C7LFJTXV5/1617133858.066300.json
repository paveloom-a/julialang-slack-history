[{"client_msg_id":"5861fc06-7ad8-4fb9-8948-317047190b23","type":"message","text":"I’m thinking of playing with the Vision Transformer for a class project. It probably isn’t going to be very practical to try to do it in Julia, right?\nEdit: it looks like there are pretrained ViT pytorch models, so maybe I can just use pytorch.jl to load them?","user":"US8V7JSKB","ts":"1617133858.066300","team":"T68168MUP","edited":{"user":"US8V7JSKB","ts":"1617135262.000000"},"blocks":[{"type":"rich_text","block_id":"ov=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m thinking of playing with the Vision Transformer for a class project. It probably isn’t going to be very practical to try to do it in Julia, right?\nEdit: it looks like there are pretrained ViT pytorch models, so maybe I can just use pytorch.jl to load them?"}]}]}],"thread_ts":"1617133858.066300","reply_count":19,"reply_users_count":4,"latest_reply":"1617405418.094100","reply_users":["UH9KWTTD3","US8V7JSKB","U6YRZ18GZ","U69F2VCFJ"],"is_locked":false,"subscribed":false},{"client_msg_id":"51a9fff9-3c46-4d56-97b3-8f69a6d5886d","type":"message","text":"What is PyTorch.jl? If you mean Torch.jl, the purpose of that package is not to run models written in PyTorch from Julia. It is to run models written in Flux with libtorch which is the C++ library underlying PyTorch operations.","user":"UH9KWTTD3","ts":"1617135499.066500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nwBP8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is PyTorch.jl? If you mean Torch.jl, the purpose of that package is not to run models written in PyTorch from Julia. It is to run models written in Flux with libtorch which is the C++ library underlying PyTorch operations."}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"6369981d-1505-47d1-825f-c62ecc7adbef","type":"message","text":"oops I meant torch.jl. thanks for explaining that --- you just saved me some work!","user":"US8V7JSKB","ts":"1617138205.066700","team":"T68168MUP","edited":{"user":"US8V7JSKB","ts":"1617138273.000000"},"blocks":[{"type":"rich_text","block_id":"A+na","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oops I meant torch.jl. thanks for explaining that --- you just saved me some work!"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"c7d5ec01-0ad4-4a1a-a142-0f939bb1527c","type":"message","text":"I saw a thread on the discourse that suggested that <@U69F2VCFJ>’s packages might be helpful; i’m going to look into that","user":"US8V7JSKB","ts":"1617138235.066900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"N8Lu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I saw a thread on the discourse that suggested that "},{"type":"user","user_id":"U69F2VCFJ"},{"type":"text","text":"’s packages might be helpful; i’m going to look into that"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"b530fd5b-ba62-486d-a474-cb848cefdcf6","type":"message","text":"(unless you already know that that won’t work for this :P)","user":"US8V7JSKB","ts":"1617138246.067100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"M=AzI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(unless you already know that that won’t work for this :P)"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"71e5db04-179a-45c6-a8b3-310895ca3b7d","type":"message","text":"Never worked with vision transformers so I am not sure. Would probably be a good reference of what you might need to implement if nothing else.","user":"UH9KWTTD3","ts":"1617138666.067400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"h27","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Never worked with vision transformers so I am not sure. Would probably be a good reference of what you might need to implement if nothing else."}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB","reactions":[{"name":"+1","users":["US8V7JSKB"],"count":1}]},{"client_msg_id":"5dd3ee30-0320-46f2-a86d-70e9f30c1689","type":"message","text":"Thanks Kyle! :slightly_smiling_face: :heart:","user":"US8V7JSKB","ts":"1617149656.067700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VA2z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks Kyle! "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" "},{"type":"emoji","name":"heart"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB","reactions":[{"name":"+1::skin-tone-5","users":["UH9KWTTD3"],"count":1}]},{"client_msg_id":"14b54bab-e7a6-4570-a6ff-a5a68ddbcacd","type":"message","text":"Having impementation in Julia would be great.","user":"U6YRZ18GZ","ts":"1617186193.069600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"e6+8L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Having impementation in Julia would be great."}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB","reactions":[{"name":"point_up::skin-tone-5","users":["UH9KWTTD3"],"count":1}]},{"client_msg_id":"0D46DA26-F4A0-4D21-97B3-B6777F582DFD","type":"message","text":"Would need to reimplementing the model in Julia with Flux. Currently we don’t have any stable ways  that can automatic convert the model definition from python to Julia. Though the weights can be loaded directly from Julia, reimplementing the model is almost unavoidable. ","user":"U69F2VCFJ","ts":"1617334644.077600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QZG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Would need to reimplementing the model in Julia with Flux. Currently we don’t have any stable ways  that can automatic convert the model definition from python to Julia. Though the weights can be loaded directly from Julia, reimplementing the model is almost unavoidable. "}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB","reactions":[{"name":"+1","users":["US8V7JSKB"],"count":1}]},{"type":"message","subtype":"thread_broadcast","text":"on a somewhat different, though related, topic: I was just looking at <https://thinc.ai/docs> and was very taken by how it’s apparently possible to “switch between PyTorch, TensorFlow and MXNet models without changing your application, or even create mutant hybrids using zero-copy array interchange.” I know this isn’t currently possible in Julia, but is _theoretically_ possible?","user":"US8V7JSKB","ts":"1617351365.077900","thread_ts":"1617133858.066300","root":{"client_msg_id":"5861fc06-7ad8-4fb9-8948-317047190b23","type":"message","text":"I’m thinking of playing with the Vision Transformer for a class project. It probably isn’t going to be very practical to try to do it in Julia, right?\nEdit: it looks like there are pretrained ViT pytorch models, so maybe I can just use pytorch.jl to load them?","user":"US8V7JSKB","ts":"1617133858.066300","team":"T68168MUP","edited":{"user":"US8V7JSKB","ts":"1617135262.000000"},"blocks":[{"type":"rich_text","block_id":"ov=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m thinking of playing with the Vision Transformer for a class project. It probably isn’t going to be very practical to try to do it in Julia, right?\nEdit: it looks like there are pretrained ViT pytorch models, so maybe I can just use pytorch.jl to load them?"}]}]}],"thread_ts":"1617133858.066300","reply_count":19,"reply_users_count":4,"latest_reply":"1617405418.094100","reply_users":["UH9KWTTD3","US8V7JSKB","U6YRZ18GZ","U69F2VCFJ"],"is_locked":false,"subscribed":false},"attachments":[{"service_name":"Thinc","title":"Introduction · Thinc  · A refreshing functional take on deep learning","title_link":"https://thinc.ai/docs","text":"Thinc is a lightweight type-checked deep learning library for composing models, with support for layers defined in frameworks like PyTorch and TensorFlow.","fallback":"Thinc: Introduction · Thinc  · A refreshing functional take on deep learning","image_url":"https://thinc.ai/static/social-ae90868b0b884a7e9c7f0be4ae73342d.jpg","from_url":"https://thinc.ai/docs","image_width":476,"image_height":250,"image_bytes":224483,"service_icon":"https://thinc.ai/icons/icon-48x48.png?v=955d2b4f3777d59a83a3c1b75d52903f","id":1,"original_url":"https://thinc.ai/docs"}],"blocks":[{"type":"rich_text","block_id":"F7=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"on a somewhat different, though related, topic: I was just looking at "},{"type":"link","url":"https://thinc.ai/docs"},{"type":"text","text":" and was very taken by how it’s apparently possible to “switch between PyTorch, TensorFlow and MXNet models without changing your application, or even create mutant hybrids using zero-copy array interchange.” I know this isn’t currently possible in Julia, but is "},{"type":"text","text":"theoretically","style":{"italic":true}},{"type":"text","text":" possible?"}]}]}],"client_msg_id":"f90c1bfa-bffc-4ea5-b329-213d1d70cc5b"},{"client_msg_id":"AF2AD6C7-5052-4719-89A3-681B4EC30232","type":"message","text":"In theory, yes. You can call code written in PyTorch from Julia with PyCall.jl. It works pretty well as far as I am told. And Flux doesn’t care that a particular layer(s) in a model are not Flux layers. They can be any function, including functions that actually call PyTorch models via PyCall. Thinc is clearly designed to minimize the overhead of this, and I don’t know what the current overhead of invoking PyCall is.","user":"UH9KWTTD3","ts":"1617371755.084600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qB8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In theory, yes. You can call code written in PyTorch from Julia with PyCall.jl. It works pretty well as far as I am told. And Flux doesn’t care that a particular layer(s) in a model are not Flux layers. They can be any function, including functions that actually call PyTorch models via PyCall. Thinc is clearly designed to minimize the overhead of this, and I don’t know what the current overhead of invoking PyCall is."}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"0895EDBD-D133-4417-83DA-8170C6CE7958","type":"message","text":"Also there is no package to make this seamless, so maybe there’s more boilerplate involved. I haven’t really looked into it.","user":"UH9KWTTD3","ts":"1617371795.085800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BMeYj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also there is no package to make this seamless, so maybe there’s more boilerplate involved. I haven’t really looked into it."}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"CEC25359-6845-4186-AC08-10676701EFB3","type":"message","text":"The more difficult part is training cause you’ll probably need to write a custom adjoint since Zygote can’t differentiate through PyCall.","user":"UH9KWTTD3","ts":"1617371917.087400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"blmpA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The more difficult part is training cause you’ll probably need to write a custom adjoint since Zygote can’t differentiate through PyCall."}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"351b1591-7edc-4341-b24e-57398aa03442","type":"message","text":"Out of curiosity, has anyone tried the opposite? To expose models written in Flux to PyTorch?","user":"U6YRZ18GZ","ts":"1617373304.089700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HJt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Out of curiosity, has anyone tried the opposite? To expose models written in Flux to PyTorch?"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"958E366D-DF64-4B06-8E13-B879FC95ECDC","type":"message","text":"Like call Julia from Python?","user":"UH9KWTTD3","ts":"1617374021.090100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ply+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Like call Julia from Python?"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"12519f44-7e42-49ef-8d0a-528f3029ffa5","type":"message","text":"Kyle: I was thinking not just of calling python PyTorch code, but also being able to import and use pre-trained python models as black boxes --- i.e., to use them without even writing the architecture up (sorta like a souped-up version of <@U69F2VCFJ>’s stuff). That would imo be very useful","user":"US8V7JSKB","ts":"1617381794.093200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"a0Pn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Kyle: I was thinking not just of calling python PyTorch code, but also being able to import and use pre-trained python models as black boxes --- i.e., to use them without even writing the architecture up (sorta like a souped-up version of "},{"type":"user","user_id":"U69F2VCFJ"},{"type":"text","text":"’s stuff). That would imo be very useful"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"3a14dfd1-cbb7-417f-ac3b-3af90c20aa3b","type":"message","text":"One way to think about it is that the “black box” model is still some code that has to run *somewhere*. If it were truly a black box, then that model would be some code written in PyTorch or something. But I think what you want is the ability to write something like `m = load(&lt;path to pretrained model saved from other framework&gt;)` then be able to directly run `m(x)` in Julia without needing to write out the architecture of `m`. I think the most immediate effort to support something like this is some recent work on reviving ONNX.jl. On top of this, we can build a translation package that takes ONNX graphs and translates them into Flux models and loads the pretrained weights in. The translation part would be a “souped up” version of what’s going on in Transformers.jl.","user":"UH9KWTTD3","ts":"1617394684.093400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=pF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One way to think about it is that the “black box” model is still some code that has to run "},{"type":"text","text":"somewhere","style":{"bold":true}},{"type":"text","text":". If it were truly a black box, then that model would be some code written in PyTorch or something. But I think what you want is the ability to write something like "},{"type":"text","text":"m = load(<path to pretrained model saved from other framework>)","style":{"code":true}},{"type":"text","text":" then be able to directly run "},{"type":"text","text":"m(x)","style":{"code":true}},{"type":"text","text":" in Julia without needing to write out the architecture of "},{"type":"text","text":"m","style":{"code":true}},{"type":"text","text":". I think the most immediate effort to support something like this is some recent work on reviving ONNX.jl. On top of this, we can build a translation package that takes ONNX graphs and translates them into Flux models and loads the pretrained weights in. The translation part would be a “souped up” version of what’s going on in Transformers.jl."}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"f8894d4e-fe2d-49ea-8a96-605d337e4fef","type":"message","text":"This is not the only way to get the end result you’re asking for, but just the one I’ve seen the most progress on so far","user":"UH9KWTTD3","ts":"1617394907.093600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AuA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This is not the only way to get the end result you’re asking for, but just the one I’ve seen the most progress on so far"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"04ec628d-254a-428c-9d2a-fc37c0cabdd2","type":"message","text":"yes Kyle that is exactly what I wanted --- that’s how I should have described it. Thanks for pointing me to the ONNX revival effort; I’ll try to catch myself up on how things have been going with that","user":"US8V7JSKB","ts":"1617405156.093800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dpu2B","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yes Kyle that is exactly what I wanted --- that’s how I should have described it. Thanks for pointing me to the ONNX revival effort; I’ll try to catch myself up on how things have been going with that"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"},{"client_msg_id":"c51a5f2f-d94f-456b-9516-6fbf3c8c1668","type":"message","text":"<https://github.com/FluxML/ML-Coordination-Tracker/discussions/24>","user":"UH9KWTTD3","ts":"1617405418.094100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NVq","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/FluxML/ML-Coordination-Tracker/discussions/24"}]}]}],"thread_ts":"1617133858.066300","parent_user_id":"US8V7JSKB"}]