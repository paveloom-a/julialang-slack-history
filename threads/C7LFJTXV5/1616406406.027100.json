[{"client_msg_id":"76bca2ac-30d7-4e95-b8e8-733c20054300","type":"message","text":"Morning! I'm trying to prune my NN removing (freezing) the smallest weights with the delete! function. But I noticed that after the pruning step the network accuracy doesn't increase it seems like all the parameters are frozen and the network is not able to learn anymore.\n\n`function one_shot_pruning(model,epochs::Tuple{Int64,Int64},loss::Function,accuracy::Function,data,opt,threshold::Real,X,Y, is_percentage::Bool = false)`\n    `evalcb = () -&gt; println(\"removed edges : \",compute_zero_entries(model), \"\\n  accuracy : \",accuracy(X,Y,model))  #exit training loop`    \n    `@Flux.epochs epochs[1] Flux.train!(loss, Flux.params(model), data, opt,cb = throttle(evalcb, 10))`    \n    `println(\"\\nPRUNING \",'='^40,\"\\n\")`\n    `model = cpu(model)`\n    `if(is_percentage)`\n      `threshold = compute_percentile_threshold(model,threshold)`\n    `end`\n    `ps =prune(model,threshold)  #PRUNING STEP`\n    `model = gpu(model)`\n    `@Flux.epochs epochs[2] Flux.train!(loss, ps, data, opt,cb = throttle(evalcb, 10))`    \n    `#@Flux.epochs epochs[2] my_custom_train!(loss,ps,data,opt,X,Y)`\n    `return model`\n  `end`\n\n\n\n  `function prune(model,threshold::Real)`\n    `for current_layer ∈ model[1:end-1]  #assume last layer softams, we skip this`\n      `current_weights = Flux.params(current_layer)[1]  #current weights is a matrix`\n      `mask = broadcast(abs,current_weights).&lt;= threshold`\n      `current_weights = current_weights[mask] .= 0`\n      `for p in current_weights`\n        `if p == 0`\n          `delete!(Flux.params(model), p)`\n        `end` \n      `end`\n    `end`\n    `return Flux.params(model)`   \n  `end`","user":"U01FTFACYJ0","ts":"1616406406.027100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yGy34","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Morning! I'm trying to prune my NN removing (freezing) the smallest weights with the delete! function. But I noticed that after the pruning step the network accuracy doesn't increase it seems like all the parameters are frozen and the network is not able to learn anymore.\n\n"},{"type":"text","text":"function one_shot_pruning(model,epochs::Tuple{Int64,Int64},loss::Function,accuracy::Function,data,opt,threshold::Real,X,Y, is_percentage::Bool = false)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    evalcb = () -> println(\"removed edges : \",compute_zero_entries(model), \"\\n  accuracy : \",accuracy(X,Y,model))  #exit training loop    ","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    @Flux.epochs epochs[1] Flux.train!(loss, Flux.params(model), data, opt,cb = throttle(evalcb, 10))    ","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    println(\"\\nPRUNING \",'='^40,\"\\n\")","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    model = cpu(model)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    if(is_percentage)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"      threshold = compute_percentile_threshold(model,threshold)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    end","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    ps =prune(model,threshold)  #PRUNING STEP","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    model = gpu(model)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    @Flux.epochs epochs[2] Flux.train!(loss, ps, data, opt,cb = throttle(evalcb, 10))    ","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    #@Flux.epochs epochs[2] my_custom_train!(loss,ps,data,opt,X,Y)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    return model","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"  end","style":{"code":true}},{"type":"text","text":"\n\n\n\n"},{"type":"text","text":"  function prune(model,threshold::Real)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    for current_layer ∈ model[1:end-1]  #assume last layer softams, we skip this","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"      current_weights = Flux.params(current_layer)[1]  #current weights is a matrix","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"      mask = broadcast(abs,current_weights).<= threshold","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"      current_weights = current_weights[mask] .= 0","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"      for p in current_weights","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"        if p == 0","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"          delete!(Flux.params(model), p)","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"        end ","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"      end","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    end","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"    return Flux.params(model)   ","style":{"code":true}},{"type":"text","text":"\n"},{"type":"text","text":"  end","style":{"code":true}}]}]}],"thread_ts":"1616406406.027100","reply_count":1,"reply_users_count":1,"latest_reply":"1616414850.027700","reply_users":["UC4QQPG4A"],"subscribed":false},{"client_msg_id":"8da0f088-a15b-4c33-8dc0-a6d6ad00f9cb","type":"message","text":"Seems like you return the original params at the end?\n\nI would also suggest trying to construct the params object anew rather than deleting to see if that gets in the way","user":"UC4QQPG4A","ts":"1616414850.027700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"K6K","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Seems like you return the original params at the end?\n\nI would also suggest trying to construct the params object anew rather than deleting to see if that gets in the way"}]}]}],"thread_ts":"1616406406.027100","parent_user_id":"U01FTFACYJ0"}]