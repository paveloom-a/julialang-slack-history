[{"client_msg_id":"ce5ecd7d-fd01-4747-a23e-e68f804fb76a","type":"message","text":"<https://mitmath.github.io/18337/lecture3/sciml.html>","user":"U69BL50BF","ts":"1614881405.376100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+Fs1","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://mitmath.github.io/18337/lecture3/sciml.html"}]}]}],"thread_ts":"1614881405.376100","reply_count":5,"reply_users_count":2,"latest_reply":"1615315482.010500","reply_users":["UKHLCGXH6","U69BL50BF"],"subscribed":false},{"client_msg_id":"d0dc687f-58c4-4b55-80ea-915176d875a9","type":"message","text":"Ok, I've taken a look, but  I notice there is a requirement of derivatives in the loss function. Are these realised by autodiff rather than finite differences then?","user":"UKHLCGXH6","ts":"1615301763.001000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dA/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok, I've taken a look, but  I notice there is a requirement of derivatives in the loss function. Are these realised by autodiff rather than finite differences then?"}]}]}],"thread_ts":"1614881405.376100","parent_user_id":"U69BL50BF"},{"client_msg_id":"78c2ec52-039e-4eaf-822d-67d55040e272","type":"message","text":"yes","user":"U69BL50BF","ts":"1615302001.001200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jXJiF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yes"}]}]}],"thread_ts":"1614881405.376100","parent_user_id":"U69BL50BF"},{"client_msg_id":"895b9d88-ed63-4136-9edb-8f524769ac27","type":"message","text":"Is the performance of such models state of the art for PDEs? If not what are the use cases for which they excel?","user":"UKHLCGXH6","ts":"1615310354.009800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gs9Ub","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is the performance of such models state of the art for PDEs? If not what are the use cases for which they excel?"}]}]}],"thread_ts":"1614881405.376100","parent_user_id":"U69BL50BF"},{"client_msg_id":"b11abfbb-8169-46e8-8e63-2672ba0edcb7","type":"message","text":"Ok I think I just now understood how powerful and general SciML is, any function that you can write no matter the complexity can be used as the loss and a fast model can be found by nature of neural nets being universal approximators - extremely useful and cool","user":"UKHLCGXH6","ts":"1615315396.010300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1Vd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ok I think I just now understood how powerful and general SciML is, any function that you can write no matter the complexity can be used as the loss and a fast model can be found by nature of neural nets being universal approximators - extremely useful and cool"}]}]}],"thread_ts":"1614881405.376100","parent_user_id":"U69BL50BF"},{"client_msg_id":"76b70d10-5737-4c37-acbf-eff8cc4ef7b5","type":"message","text":"of course more suited to some problems rather than others but still","user":"UKHLCGXH6","ts":"1615315482.010500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MAxy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"of course more suited to some problems rather than others but still"}]}]}],"thread_ts":"1614881405.376100","parent_user_id":"U69BL50BF"}]