[{"client_msg_id":"bab55009-e22e-4177-9afa-0b3b01da4f0c","type":"message","text":"Answering myself in this thread.","user":"U85JBUGGP","ts":"1617450689.086000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0Zpx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Answering myself in this thread."}]}]}],"thread_ts":"1617450689.086000","reply_count":1,"reply_users_count":1,"latest_reply":"1617451339.086100","reply_users":["U85JBUGGP"],"is_locked":false,"subscribed":false},{"client_msg_id":"e43c6408-0fae-47b0-86ef-b659fdc8e2f6","type":"message","text":"So as <@U85R3JJ8L> replied and then deleted his reply not to spoil the puzzle: “not every matrix is diagonalisable”. In particular, an eigenvalue decomposition of the form `A = Q * D * Q^-1` doesn’t always exist for every matrix `A`. The decomposition does not exist when the eigenspace associated with 1 or more of the eigenvalues is degenerate. In other words, the algebraic multiplicity (from the characteristic polynomial `det(A - λ I) = 0`) of an eigenvalue can be greater than 1 but the eigenspace associated with it can still be a vector, not a plane or a higher dimensional subspace. More generally, if the algebraic multiplicity is greater than the geometric multiplicity for any eigenvalue, the decomposition above doesn’t exist. So you can think of `Q` in this case as a non-square matrix but a rectangular one, hence it is not invertible. In Julia, you always get a square matrix but with dependent columns so it is still not invertible.\n```julia&gt; A = [1 1 1;\n            0 1 1;\n            0 0 1];\n\njulia&gt; eigen(A).vectors\n3×3 Matrix{Float64}:\n 1.0  -1.0           1.0\n 0.0   2.22045e-16  -2.22045e-16\n 0.0   0.0           4.93038e-32```\nIn this particular case, the algebraic multiplicity of the eigenvalue `λ = 1` is 3 but the geometric multiplicity (i.e. dimension of the eigenspace associated) is only 1 as can be seen above. The eigenspace is simply the x-axis. Interestingly, the SVD doesn’t have this issue and the left and right singular vectors are always independent and orthonormal as to be expected. This video shows a concrete example <https://www.youtube.com/watch?v=1lxjQhpIQ5E>.","user":"U85JBUGGP","ts":"1617451339.086100","team":"T68168MUP","edited":{"user":"U85JBUGGP","ts":"1617451684.000000"},"attachments":[{"service_name":"YouTube","service_url":"https://www.youtube.com/","title":"Matrix Diagonalization Examples: 2x2 Non Diagonalizable, 3x3 Diagonalizable with Repeated Eigenvalue","title_link":"https://www.youtube.com/watch?v=1lxjQhpIQ5E","author_name":"Bill Kinney","author_link":"https://www.youtube.com/user/billkinneymath","thumb_url":"https://i.ytimg.com/vi/1lxjQhpIQ5E/hqdefault.jpg","thumb_width":480,"thumb_height":360,"fallback":"YouTube Video: Matrix Diagonalization Examples: 2x2 Non Diagonalizable, 3x3 Diagonalizable with Repeated Eigenvalue","video_html":"<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/1lxjQhpIQ5E?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","video_html_width":400,"video_html_height":225,"from_url":"https://www.youtube.com/watch?v=1lxjQhpIQ5E","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png","id":1,"original_url":"https://www.youtube.com/watch?v=1lxjQhpIQ5E"}],"blocks":[{"type":"rich_text","block_id":"n5w","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So as "},{"type":"user","user_id":"U85R3JJ8L"},{"type":"text","text":" replied and then deleted his reply not to spoil the puzzle: “not every matrix is diagonalisable”. In particular, an eigenvalue decomposition of the form "},{"type":"text","text":"A = Q * D * Q^-1","style":{"code":true}},{"type":"text","text":" doesn’t always exist for every matrix "},{"type":"text","text":"A","style":{"code":true}},{"type":"text","text":". The decomposition does not exist when the eigenspace associated with 1 or more of the eigenvalues is degenerate. In other words, the algebraic multiplicity (from the characteristic polynomial "},{"type":"text","text":"det(A - λ I) = 0","style":{"code":true}},{"type":"text","text":") of an eigenvalue can be greater than 1 but the eigenspace associated with it can still be a vector, not a plane or a higher dimensional subspace. More generally, if the algebraic multiplicity is greater than the geometric multiplicity for any eigenvalue, the decomposition above doesn’t exist. So you can think of "},{"type":"text","text":"Q","style":{"code":true}},{"type":"text","text":" in this case as a non-square matrix but a rectangular one, hence it is not invertible. In Julia, you always get a square matrix but with dependent columns so it is still not invertible.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> A = [1 1 1;\n            0 1 1;\n            0 0 1];\n\njulia> eigen(A).vectors\n3×3 Matrix{Float64}:\n 1.0  -1.0           1.0\n 0.0   2.22045e-16  -2.22045e-16\n 0.0   0.0           4.93038e-32"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"In this particular case, the algebraic multiplicity of the eigenvalue "},{"type":"text","text":"λ = 1","style":{"code":true}},{"type":"text","text":" is 3 but the geometric multiplicity (i.e. dimension of the eigenspace associated) is only 1 as can be seen above. The eigenspace is simply the x-axis. Interestingly, the SVD doesn’t have this issue and the left and right singular vectors are always independent and orthonormal as to be expected. This video shows a concrete example "},{"type":"link","url":"https://www.youtube.com/watch?v=1lxjQhpIQ5E"},{"type":"text","text":"."}]}]}],"thread_ts":"1617450689.086000","parent_user_id":"U85JBUGGP"}]