[{"client_msg_id":"ab57a5c4-1d19-4ece-96e1-439a04360df6","type":"message","text":"Is there anyone familiar with approximated low-rank SVD algorithms such as <https://www.cs.cornell.edu/selman/local/notes-new/pdf/2005_02_26_fast_monte_carlo.pdf|FKV and similar>?\nIt is my understanding that they heavily rely on you being able to select (sample) rows of the matrix according to their norm, and then elements inside the rows.\nBut computing the norm of a row of the matrix is usually a very expensive operation...\nAre there similar algorithms where you only need to sample random elements in the matrix (not rows/columns)?","user":"UAJH2818E","ts":"1612779828.107400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NzenP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is there anyone familiar with approximated low-rank SVD algorithms such as "},{"type":"link","url":"https://www.cs.cornell.edu/selman/local/notes-new/pdf/2005_02_26_fast_monte_carlo.pdf","text":"FKV and similar"},{"type":"text","text":"?\nIt is my understanding that they heavily rely on you being able to select (sample) rows of the matrix according to their norm, and then elements inside the rows.\nBut computing the norm of a row of the matrix is usually a very expensive operation...\nAre there similar algorithms where you only need to sample random elements in the matrix (not rows/columns)?"}]}]}],"thread_ts":"1612779828.107400","reply_count":1,"reply_users_count":1,"latest_reply":"1613250256.137700","reply_users":["U01L0RJC6FM"],"subscribed":false},{"client_msg_id":"512a7ca3-ba73-468d-9ed2-bfa4a227f6ac","type":"message","text":"Hi Filippo, I am not sure what exactly you want, but I might be able to help. You are right in that you want to be able to somehow get a good estimate on which columns/rows are a good choice. But in general, you want to have the column information sooner or later or you need some more information.\n\nMost algorithms such as adaptive cross approximation or interpolative decomposition rely on having the column information. One way to overcome this is by random sampling, assuming that you can compute matrix-vector products x -&gt; Ax efficiently. You can then select rows cheaply on the sampled matrix which will be good rows in your big matrix, so that would be one way of avoiding that.\n\nGoing from just random entries in you matrix is _very_ hard and falls into the category of matrix-completion problems, which I wouldn't look into as they are of a completely different (and more expensive) complexity class.","user":"U01L0RJC6FM","ts":"1613250256.137700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gjO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi Filippo, I am not sure what exactly you want, but I might be able to help. You are right in that you want to be able to somehow get a good estimate on which columns/rows are a good choice. But in general, you want to have the column information sooner or later or you need some more information.\n\nMost algorithms such as adaptive cross approximation or interpolative decomposition rely on having the column information. One way to overcome this is by random sampling, assuming that you can compute matrix-vector products x -> Ax efficiently. You can then select rows cheaply on the sampled matrix which will be good rows in your big matrix, so that would be one way of avoiding that.\n\nGoing from just random entries in you matrix is "},{"type":"text","text":"very","style":{"italic":true}},{"type":"text","text":" hard and falls into the category of matrix-completion problems, which I wouldn't look into as they are of a completely different (and more expensive) complexity class."}]}]}],"thread_ts":"1612779828.107400","parent_user_id":"UAJH2818E"}]