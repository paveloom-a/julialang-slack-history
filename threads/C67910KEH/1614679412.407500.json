[{"client_msg_id":"916b3f9d-acb6-46b0-8a1e-c85b5a7d0ad1","type":"message","text":"<#C7120PCUQ|flux> when I use the train! function, It works well minimizing the loss funzion ecc..., but when I then display the params, they are the same as before the training step.","user":"U01FTFACYJ0","ts":"1614679412.407500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wlM","elements":[{"type":"rich_text_section","elements":[{"type":"channel","channel_id":"C7120PCUQ"},{"type":"text","text":" when I use the train! function, It works well minimizing the loss funzion ecc..., but when I then display the params, they are the same as before the training step."}]}]}],"thread_ts":"1614679412.407500","reply_count":14,"reply_users_count":3,"latest_reply":"1614785524.434100","reply_users":["UC4QQPG4A","U01FTFACYJ0","UH9KWTTD3"],"subscribed":false},{"client_msg_id":"4ae60dac-276a-42b5-bff0-c15ce8b24913","type":"message","text":"You might find people in <#C7LFJTXV5|flux-bridged> and <#C690QRAA3|machine-learning> \n\n\nBut could you elaborate on what you're doing? If the loss is getting optimised, surely the params are changing.","user":"UC4QQPG4A","ts":"1614680992.407600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fZg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You might find people in "},{"type":"channel","channel_id":"C7LFJTXV5"},{"type":"text","text":" and "},{"type":"channel","channel_id":"C690QRAA3"},{"type":"text","text":" \n\n\nBut could you elaborate on what you're doing? If the loss is getting optimised, surely the params are changing."}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"3bc5d8be-8cdc-45cf-b195-b54f50e28e91","type":"message","text":"yes I agree with you, but when I print Flux.params(model) I find the same weights of the initial model","user":"U01FTFACYJ0","ts":"1614682534.407800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xLwB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yes I agree with you, but when I print Flux.params(model) I find the same weights of the initial model"}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"8057d74b-1333-409d-bef5-f5673176e5b0","type":"message","text":"Is it the same `model` in terms of is it pointing to the same model that was trained on and not a copy of the initialised version for example?","user":"UC4QQPG4A","ts":"1614682616.408000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Qqk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Is it the same "},{"type":"text","text":"model","style":{"code":true}},{"type":"text","text":" in terms of is it pointing to the same model that was trained on and not a copy of the initialised version for example?"}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"type":"message","text":"","files":[{"id":"F01PMQ4F6P8","created":1614682859,"timestamp":1614682859,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01FTFACYJ0","editable":false,"size":81275,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01PMQ4F6P8/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01PMQ4F6P8/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ4F6P8-ee92a48da1/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ4F6P8-ee92a48da1/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ4F6P8-ee92a48da1/image_360.png","thumb_360_w":360,"thumb_360_h":182,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ4F6P8-ee92a48da1/image_480.png","thumb_480_w":480,"thumb_480_h":243,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ4F6P8-ee92a48da1/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ4F6P8-ee92a48da1/image_720.png","thumb_720_w":720,"thumb_720_h":364,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ4F6P8-ee92a48da1/image_800.png","thumb_800_w":800,"thumb_800_h":405,"original_w":903,"original_h":457,"thumb_tiny":"AwAYADDROe1Lg0hJzigE5NADqKQHINJu4NADqKaW4Bp1ADSPmBpADk0+igBqggGk2nBp9FADSpwBTqKKAP/Z","permalink":"https://julialang.slack.com/files/U01FTFACYJ0/F01PMQ4F6P8/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01PMQ4F6P8-88d196ecba","is_starred":false,"has_rich_preview":false},{"id":"F01PMQ6K27Q","created":1614682892,"timestamp":1614682892,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01FTFACYJ0","editable":false,"size":49750,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01PMQ6K27Q/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01PMQ6K27Q/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ6K27Q-1490935f67/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ6K27Q-1490935f67/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ6K27Q-1490935f67/image_360.png","thumb_360_w":360,"thumb_360_h":123,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ6K27Q-1490935f67/image_480.png","thumb_480_w":480,"thumb_480_h":164,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ6K27Q-1490935f67/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ6K27Q-1490935f67/image_720.png","thumb_720_w":720,"thumb_720_h":247,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01PMQ6K27Q-1490935f67/image_800.png","thumb_800_w":800,"thumb_800_h":274,"original_w":838,"original_h":287,"thumb_tiny":"AwAQADDRNHPrS0Y9qBhz60c+1GPb9aMe1Ag5paTHtS0Af//Z","permalink":"https://julialang.slack.com/files/U01FTFACYJ0/F01PMQ6K27Q/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01PMQ6K27Q-6d58ba1161","is_starred":false,"has_rich_preview":false},{"id":"F01Q0NJSKD2","created":1614682909,"timestamp":1614682909,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01FTFACYJ0","editable":false,"size":58993,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01Q0NJSKD2/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01Q0NJSKD2/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01Q0NJSKD2-b93abac99f/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01Q0NJSKD2-b93abac99f/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01Q0NJSKD2-b93abac99f/image_360.png","thumb_360_w":360,"thumb_360_h":102,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01Q0NJSKD2-b93abac99f/image_480.png","thumb_480_w":480,"thumb_480_h":136,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01Q0NJSKD2-b93abac99f/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01Q0NJSKD2-b93abac99f/image_720.png","thumb_720_w":720,"thumb_720_h":204,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01Q0NJSKD2-b93abac99f/image_800.png","thumb_800_w":800,"thumb_800_h":227,"original_w":896,"original_h":254,"thumb_tiny":"AwANADDQP3hQOppSOc0nSgBVPBpMnB5pwGB9aTaKAEJO0c08dKbtGMU6gD//2Q==","permalink":"https://julialang.slack.com/files/U01FTFACYJ0/F01Q0NJSKD2/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01Q0NJSKD2-58ede12db2","is_starred":false,"has_rich_preview":false}],"upload":false,"user":"U01FTFACYJ0","ts":"1614682912.408200","thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"44abcd89-ea88-43c5-a166-a2c316933f00","type":"message","text":"Yes its the same, these are the params before and after the training step","user":"U01FTFACYJ0","ts":"1614682930.408400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u79L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes its the same, these are the params before and after the training step"}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"3F58E44B-6E0A-4AB8-881D-649DFDA1E64A","type":"message","text":"How are `loss` and `ps` defined?","user":"UH9KWTTD3","ts":"1614696353.409600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uKl30","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How are "},{"type":"text","text":"loss","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"ps","style":{"code":true}},{"type":"text","text":" defined?"}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"type":"message","text":"this is the loss","files":[{"id":"F01QM2HDB96","created":1614716145,"timestamp":1614716145,"name":"image.png","title":"image.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01FTFACYJ0","editable":false,"size":67362,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01QM2HDB96/image.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01QM2HDB96/download/image.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01QM2HDB96-a507aac6a5/image_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01QM2HDB96-a507aac6a5/image_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01QM2HDB96-a507aac6a5/image_360.png","thumb_360_w":360,"thumb_360_h":179,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01QM2HDB96-a507aac6a5/image_480.png","thumb_480_w":480,"thumb_480_h":239,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01QM2HDB96-a507aac6a5/image_160.png","thumb_720":"https://files.slack.com/files-tmb/T68168MUP-F01QM2HDB96-a507aac6a5/image_720.png","thumb_720_w":720,"thumb_720_h":358,"thumb_800":"https://files.slack.com/files-tmb/T68168MUP-F01QM2HDB96-a507aac6a5/image_800.png","thumb_800_w":800,"thumb_800_h":398,"original_w":892,"original_h":444,"thumb_tiny":"AwAXADDRI9qBn0xS80fN7UAHNHNGG9aMN60AHNLTcN60oz3oAQDgUuD7UDpRSAKOfWiimAc+tGfeik70Af/Z","permalink":"https://julialang.slack.com/files/U01FTFACYJ0/F01QM2HDB96/image.png","permalink_public":"https://slack-files.com/T68168MUP-F01QM2HDB96-18bb98fde7","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"9LWE/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this is the loss"}]}]}],"user":"U01FTFACYJ0","display_as_bot":false,"ts":"1614716149.410600","thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"3b0f28cc-db7c-45d0-a34b-dfab50605063","type":"message","text":"and\nps = Flux.params(mnist_model);","user":"U01FTFACYJ0","ts":"1614716168.410800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7pB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and\nps = Flux.params(mnist_model);"}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"5c159ce1-0fa7-44d0-9058-3fa4cc7589cd","type":"message","text":"but I have to I correct myself, after the training step the biases are update while the weights remain the same","user":"U01FTFACYJ0","ts":"1614716237.411000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"knS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but I have to I correct myself, after the training step the biases are update while the weights remain the same"}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"e4b1d000-df34-4f86-9f5e-93ffbe7eb177","type":"message","text":"I guess I’m confused how the code ends up running in a Pluto notebook. Training a neural network seems like an inherently stateful program. Expressing it in a feedforward style execution flow like Pluto appears really tricky.","user":"UH9KWTTD3","ts":"1614724101.416800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"97P","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I guess I’m confused how the code ends up running in a Pluto notebook. Training a neural network seems like an inherently stateful program. Expressing it in a feedforward style execution flow like Pluto appears really tricky."}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"4bc0c55b-0b66-47ab-8714-85f6020f8bbc","type":"message","text":"Can you double check your code running the jl file?","user":"UH9KWTTD3","ts":"1614724120.417000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"x/2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can you double check your code running the jl file?"}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"e8cff7fe-65de-4da7-a514-6d7368b9148b","type":"message","text":"Or better would be upload your jl file","user":"UH9KWTTD3","ts":"1614724133.417200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"x8Yiu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Or better would be upload your jl file"}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"type":"message","text":"","files":[{"id":"F01PL4JP5LP","created":1614784167,"timestamp":1614784167,"name":"mnist_test.jl","title":"mnist_test.jl","mimetype":"application/octet-stream","filetype":"binary","pretty_type":"Binary","user":"U01FTFACYJ0","editable":false,"size":11235,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01PL4JP5LP/mnist_test.jl","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01PL4JP5LP/download/mnist_test.jl","permalink":"https://julialang.slack.com/files/U01FTFACYJ0/F01PL4JP5LP/mnist_test.jl","permalink_public":"https://slack-files.com/T68168MUP-F01PL4JP5LP-bb45be8e7f","is_starred":false,"has_rich_preview":false}],"upload":false,"user":"U01FTFACYJ0","display_as_bot":false,"ts":"1614784170.433800","thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"},{"client_msg_id":"092f7df0-5e9e-43ab-a116-242f0a5ac3f5","type":"message","text":"Okay a couple notes. First, everything is working from Flux’s perspective. Second, your regularization term is currently a constant. If you want it to recompute every time you call the loss, you should add parentheses:\n```regularization_term() = (λ * sum(sqnorm, Flux.params(mnist_model)))\n# later\nloss(x,y) = Flux.crossentropy(mnist_model(x),y) + regularization_term()```\nLast, your weights are all updating, it’s just that the gradient for the weights of the first layer are very small because of your model architecture. So they are changing, but the changes are &lt; 10^-5 compared to the other parameters which are 10^-2. If you print ps[3] (weights for the second dense layer), you’ll see they are changing more dramatically. You can inspect the gradients with:\n```gs = gradient(() -&gt; loss(X, Y), ps)\n# check gradients\ngs[ps[1]]```","user":"UH9KWTTD3","ts":"1614785524.434100","team":"T68168MUP","edited":{"user":"UH9KWTTD3","ts":"1614785802.000000"},"blocks":[{"type":"rich_text","block_id":"+px","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Okay a couple notes. First, everything is working from Flux’s perspective. Second, your regularization term is currently a constant. If you want it to recompute every time you call the loss, you should add parentheses:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"regularization_term() = (λ * sum(sqnorm, Flux.params(mnist_model)))\n# later\nloss(x,y) = Flux.crossentropy(mnist_model(x),y) + regularization_term()"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Last, your weights are all updating, it’s just that the gradient for the weights of the first layer are very small because of your model architecture. So they are changing, but the changes are < 10^-5 compared to the other parameters which are 10^-2. If you print ps[3] (weights for the second dense layer), you’ll see they are changing more dramatically. You can inspect the gradients with:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"gs = gradient(() -> loss(X, Y), ps)\n# check gradients\ngs[ps[1]]"}]}]}],"thread_ts":"1614679412.407500","parent_user_id":"U01FTFACYJ0"}]