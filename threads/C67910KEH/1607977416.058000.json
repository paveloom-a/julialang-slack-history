[{"client_msg_id":"fae3795c-03c8-426e-8a9c-835195bbda63","type":"message","text":"Hi, I wanted to know if Julia uses intel’s MKL and is therefore any difference in Julia’s performance between AMD and intel? Thank you","user":"U01GH8MFGM9","ts":"1607977416.058000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Psq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi, I wanted to know if Julia uses intel’s MKL and is therefore any difference in Julia’s performance between AMD and intel? Thank you"}]}]}],"thread_ts":"1607977416.058000","reply_count":35,"reply_users_count":6,"latest_reply":"1608044950.089700","reply_users":["UH8A351DJ","U67D54KS8","U013V2CFZAN","U01GH8MFGM9","U67461GUB","UMDEUKM29"],"subscribed":false},{"client_msg_id":"7ba8b628-596b-4b20-97c5-1ea90ffb7766","type":"message","text":"not by default. there's MKL.jl you can use. The reason is that Intel's license for MKL is ****","user":"UH8A351DJ","ts":"1607977429.058100","team":"T68168MUP","edited":{"user":"UH8A351DJ","ts":"1607977443.000000"},"blocks":[{"type":"rich_text","block_id":"QM8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"not by default. there's MKL.jl you can use. The reason is that Intel's license for MKL is ****"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9","reactions":[{"name":"laughing","users":["U9VG1AYSG","U01GH8MFGM9","U6QGE7S86"],"count":3}]},{"client_msg_id":"5e140d94-ca85-44e2-8d48-8ced82184d6a","type":"message","text":"&gt; The reason is that Intel's license for MKL is ****\nI don't think that is true? From what I know, it is that Julia ships with some GPL license libraries (like UMFPack) and it is the license of those that prohibit it","user":"U67D54KS8","ts":"1607978024.059800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XGE4D","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"The reason is that Intel's license for MKL is ****"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nI don't think that is true? From what I know, it is that Julia ships with some GPL license libraries (like UMFPack) and it is the license of those that prohibit it"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"40028514-7f8a-4542-ae1e-bfa33daa5205","type":"message","text":"The MKL license is really permissive from my understanding and e.g. numpy ships with it.","user":"U67D54KS8","ts":"1607978038.060000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oDlp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The MKL license is really permissive from my understanding and e.g. numpy ships with it."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"15fa88c3-73ec-4393-b781-4e52237219ab","type":"message","text":"<https://software.intel.com/content/www/us/en/develop/articles/build-numpy-with-mkl-and-icc.html>","user":"UH8A351DJ","ts":"1607978064.060200","team":"T68168MUP","edited":{"user":"UH8A351DJ","ts":"1607978069.000000"},"blocks":[{"type":"rich_text","block_id":"HKlWL","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://software.intel.com/content/www/us/en/develop/articles/build-numpy-with-mkl-and-icc.html"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"add63335-b0f2-451f-8223-51c01403d7b1","type":"message","text":"I don't think so?","user":"UH8A351DJ","ts":"1607978066.060500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"q08u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't think so?"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"da0467d1-fb67-4fe8-9a45-41704913ea23","type":"message","text":"I guess it is anaconda that provides it (<https://docs.anaconda.com/mkl-optimizations/>). Anyway, there is nothing within the MKL license that prohibits Julia to ship with it. It is the GPL that is blocking.","user":"U67D54KS8","ts":"1607978302.061100","team":"T68168MUP","edited":{"user":"U67D54KS8","ts":"1607978310.000000"},"blocks":[{"type":"rich_text","block_id":"0Q7u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I guess it is anaconda that provides it ("},{"type":"link","url":"https://docs.anaconda.com/mkl-optimizations/"},{"type":"text","text":"). Anyway, there is nothing within the MKL license that prohibits Julia to ship with it. It is the GPL that is blocking."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9","reactions":[{"name":"point_up","users":["U6740K1SP"],"count":1}]},{"client_msg_id":"9532d0c0-0597-48ca-b3d7-96cb9f831de9","type":"message","text":"I'd argue that's the problem on Intel not open sourcing it, especially valid considering MKL used to throttle you when running on non-intel CPU","user":"UH8A351DJ","ts":"1607978627.062100","team":"T68168MUP","edited":{"user":"UH8A351DJ","ts":"1607978664.000000"},"blocks":[{"type":"rich_text","block_id":"dcwt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd argue that's the problem on Intel not open sourcing it, especially valid considering MKL used to throttle you when running on non-intel CPU"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"9f07a913-64a8-4622-befe-55049451dde2","type":"message","text":"core scientific language/library simply cannot rely on \"free software\" like this","user":"UH8A351DJ","ts":"1607978685.062500","team":"T68168MUP","edited":{"user":"UH8A351DJ","ts":"1607978690.000000"},"blocks":[{"type":"rich_text","block_id":"QUUZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"core scientific language/library simply cannot rely on \"free software\" like this"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9","reactions":[{"name":"100","users":["U01GH8MFGM9"],"count":1},{"name":"+1","users":["U01GH8MFGM9"],"count":1}]},{"client_msg_id":"c64b7972-8923-4e89-858a-85b05fd48b42","type":"message","text":"yeah since anaconda is also a commercial software, unlike numpy","user":"UH8A351DJ","ts":"1607978749.062800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iz0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah since anaconda is also a commercial software, unlike numpy"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"803c846d-488d-405c-b2f0-3dde1afc3a24","type":"message","text":"MKL has a very permissive license <https://software.intel.com/content/www/us/en/develop/articles/intel-math-kernel-library-license-faq.html>. Indeed it's not open source, but for most applications it's fine.\n\nIt is also very true that Intel throttles down non-Intel CPUs. However, there are ways around that. If you set this flag MKL_DEBUG_CPU_TYPE=5 MKL always thinks that it's running on an Intel CPU","user":"U013V2CFZAN","ts":"1607980254.067500","team":"T68168MUP","attachments":[{"service_name":"Intel","title":"Intel® Math Kernel Library License FAQ","title_link":"https://software.intel.com/content/www/us/en/develop/articles/intel-math-kernel-library-license-faq.html","text":"Get answers to common licensing and distribution questions for Intel® Math Kernel Library.","fallback":"Intel: Intel® Math Kernel Library License FAQ","image_url":"https://www.intel.com/content/dam/develop/public/us/en/images/thumbnails/fallback-icons-articles.png","from_url":"https://software.intel.com/content/www/us/en/develop/articles/intel-math-kernel-library-license-faq.html","image_width":444,"image_height":250,"image_bytes":91132,"service_icon":"https://software.intel.com/etc.clientlibs/settings/wcm/designs/intel/default/resources/favicon.ico","id":1,"original_url":"https://software.intel.com/content/www/us/en/develop/articles/intel-math-kernel-library-license-faq.html"}],"blocks":[{"type":"rich_text","block_id":"9jFIJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"MKL has a very permissive license "},{"type":"link","url":"https://software.intel.com/content/www/us/en/develop/articles/intel-math-kernel-library-license-faq.html"},{"type":"text","text":". Indeed it's not open source, but for most applications it's fine.\n\nIt is also very true that Intel throttles down non-Intel CPUs. However, there are ways around that. If you set this flag MKL_DEBUG_CPU_TYPE=5 MKL always thinks that it's running on an Intel CPU"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9","reactions":[{"name":"+1","users":["UH8A351DJ"],"count":1}]},{"client_msg_id":"c9ae4f7f-6292-40a4-996b-3ce11d0b2594","type":"message","text":"in my experience OpenBLAS is roughly the same as MKL, sometimes is faster and sometimes is slower ... I would say that on average OpenBLAS is 95% the speed of MKL","user":"U013V2CFZAN","ts":"1607980367.068000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"B4REa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"in my experience OpenBLAS is roughly the same as MKL, sometimes is faster and sometimes is slower ... I would say that on average OpenBLAS is 95% the speed of MKL"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9","reactions":[{"name":"+1","users":["UH8A351DJ"],"count":1},{"name":"pray","users":["U01GH8MFGM9"],"count":1}]},{"client_msg_id":"47be9d8f-10c2-437e-95c6-8528fe508ad0","type":"message","text":"I have :arrow_up_down: feeling about MKL, one end, hand tuned for their CPU Arch, impressive work, on the other hand, you never know what they're doing under the hood","user":"UH8A351DJ","ts":"1607980389.068200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1xaC0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have "},{"type":"emoji","name":"arrow_up_down"},{"type":"text","text":" feeling about MKL, one end, hand tuned for their CPU Arch, impressive work, on the other hand, you never know what they're doing under the hood"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"af4bbfef-c66a-4081-8dc6-6dd0851863e3","type":"message","text":"<@U013V2CFZAN> since 2020-1 update, setting the environment variable `MKL_DEBUG_CPU_TYPE=5` is no longer working:\n<https://en.wikipedia.org/wiki/Math_Kernel_Library#Performance_and_vendor_lock-in>","user":"U01GH8MFGM9","ts":"1607983169.069900","team":"T68168MUP","attachments":[{"title":"Math Kernel Library","title_link":"https://en.wikipedia.org/wiki/Math_Kernel_Library#Performance_and_vendor_lock-in","from_url":"https://en.wikipedia.org/wiki/Math_Kernel_Library#Performance_and_vendor_lock-in","author_name":"Wikipedia","author_link":"https://en.wikipedia.org/","text":"Intel Math Kernel Library (Intel MKL) is a library of optimized math routines for science, engineering, and financial applications. Core math functions include BLAS, LAPACK, ScaLAPACK, sparse solvers, fast Fourier transforms, and vector math.The library supports Intel processors and is available for Windows, Linux and macOS operating systems.","fallback":"wikipedia: Math Kernel Library","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/wikipedia.png","id":1,"original_url":"https://en.wikipedia.org/wiki/Math_Kernel_Library#Performance_and_vendor_lock-in"}],"blocks":[{"type":"rich_text","block_id":"pZtc","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U013V2CFZAN"},{"type":"text","text":" since 2020-1 update, setting the environment variable "},{"type":"text","text":"MKL_DEBUG_CPU_TYPE=5","style":{"code":true}},{"type":"text","text":" is no longer working:\n"},{"type":"link","url":"https://en.wikipedia.org/wiki/Math_Kernel_Library#Performance_and_vendor_lock-in"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9","reactions":[{"name":"joy","users":["UH8A351DJ"],"count":1}]},{"client_msg_id":"868fcb67-6dfd-40fd-a898-3192122c498a","type":"message","text":"well, ****","user":"UH8A351DJ","ts":"1607983714.070300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0pBpA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"well, ****"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"56ce1b12-12bc-4835-af48-1aab9bcc5012","type":"message","text":"<@U01GH8MFGM9> and that's why I don't upgrade that often :sweat_smile:","user":"U013V2CFZAN","ts":"1607985700.070900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SQ0","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U01GH8MFGM9"},{"type":"text","text":" and that's why I don't upgrade that often "},{"type":"emoji","name":"sweat_smile"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"5a762d02-8824-47ab-aa14-b4fa928657bf","type":"message","text":"openblas has some serious performance issues with high thread counts, and problematic when used with suitesparse for sparse cases.","user":"U67461GUB","ts":"1607988298.071700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1rk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"openblas has some serious performance issues with high thread counts, and problematic when used with suitesparse for sparse cases."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"c9b04829-17d9-4b5e-b483-ab036ff655a3","type":"message","text":"hmm... that' interesting ... I mostly use OpenBLAS in combination with SuiteSparse and I have never had an issue. However, I don't use it threaded by itself, I always force num threads to 1. Do you have references (an article or link)? I would like to know in which situations this happens","user":"U013V2CFZAN","ts":"1608016983.080800","team":"T68168MUP","edited":{"user":"U013V2CFZAN","ts":"1608017403.000000"},"blocks":[{"type":"rich_text","block_id":"OM6ya","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hmm... that' interesting ... I mostly use OpenBLAS in combination with SuiteSparse and I have never had an issue. However, I don't use it threaded by itself, I always force num threads to 1. Do you have references (an article or link)? I would like to know in which situations this happens"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"f1ed3ff8-1947-454f-bf9f-fa543eb6053f","type":"message","text":"openblas threading is pretty bad in my experience","user":"UMDEUKM29","ts":"1608022521.083500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=+e","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"openblas threading is pretty bad in my experience"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"5c5899b2-6e48-4fc9-ab58-deb3fe4a17a4","type":"message","text":"on my 4cores 8threads intel laptop, it starts with 8 threads by default and has extremely bad performance","user":"UMDEUKM29","ts":"1608022583.083700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Eq7Ye","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"on my 4cores 8threads intel laptop, it starts with 8 threads by default and has extremely bad performance"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"2b43bb17-5b42-4b19-9f23-778a7464f781","type":"message","text":"I don't understand why is that the default (also for MKL). I don't think that BLAS computations are easy to parallelize in the first place. Except perhaps BLAS1 operations","user":"U013V2CFZAN","ts":"1608022738.083900","team":"T68168MUP","edited":{"user":"U013V2CFZAN","ts":"1608022834.000000"},"blocks":[{"type":"rich_text","block_id":"fU9zJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't understand why is that the default (also for MKL). I don't think that BLAS computations are easy to parallelize in the first place. Except perhaps BLAS1 operations"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"a26826ed-b373-4457-ad3c-17f9714df47d","type":"message","text":"what? I'm not an HPC expert but BLAS1 is memory bound so harder to parallelize than BLAS3, no?","user":"UMDEUKM29","ts":"1608023316.084200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+ay","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"what? I'm not an HPC expert but BLAS1 is memory bound so harder to parallelize than BLAS3, no?"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"6c3f9a0d-722d-4ab7-acd4-bb8f87abf69a","type":"message","text":"BLAS1 are vector-vector operations like dot products and norms. Why would they be harder to parallelize? Although you are right, for small sizes memory speed is the limiting factor hence the \"perhaps\" in my previous statement","user":"U013V2CFZAN","ts":"1608023653.084400","team":"T68168MUP","edited":{"user":"U013V2CFZAN","ts":"1608027944.000000"},"blocks":[{"type":"rich_text","block_id":"8FCW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"BLAS1 are vector-vector operations like dot products and norms. Why would they be harder to parallelize? Although you are right, for small sizes memory speed is the limiting factor hence the \"perhaps\" in my previous statement"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"b5ff4bad-ad83-44e6-bb6f-ae2ddf20eb51","type":"message","text":"BLAS 1 is restricted by the speed of memory - not by compute - at scale.","user":"U67461GUB","ts":"1608035994.085200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u4+KE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"BLAS 1 is restricted by the speed of memory - not by compute - at scale."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"1e23549d-040d-4d0a-8a51-ca9fc7917110","type":"message","text":"I did some significant benchmarking with suitesparse+openblas recently. Obviously you have to set blas threads to 1. But when calling multiple suitesparse cholesky solves from different julia threads, I got a slowdown beyond 4 cores. When linked against MKL, we got quite a bit of scaling. Did some benchmarking with pardiso too, which gave worse performance than cholmod single core, but scaled well.","user":"U67461GUB","ts":"1608036105.085400","team":"T68168MUP","edited":{"user":"U67461GUB","ts":"1608036291.000000"},"blocks":[{"type":"rich_text","block_id":"KcT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I did some significant benchmarking with suitesparse+openblas recently. Obviously you have to set blas threads to 1. But when calling multiple suitesparse cholesky solves from different julia threads, I got a slowdown beyond 4 cores. When linked against MKL, we got quite a bit of scaling. Did some benchmarking with pardiso too, which gave worse performance than cholmod single core, but scaled well."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"270ae752-a6b8-4bb6-8f31-94968cd5bfa6","type":"message","text":"BLAS 3 has lots of parallelism, but getting it all right across different numbers of cores, matrix sizes, aspect ratios across different range of problems is not easy.","user":"U67461GUB","ts":"1608036175.085600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bE=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"BLAS 3 has lots of parallelism, but getting it all right across different numbers of cores, matrix sizes, aspect ratios across different range of problems is not easy."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"88d1a5fb-202a-4caa-bb6d-5d09a3ef164e","type":"message","text":"Sure about BLAS1, and matrix operations are not easy to parellize in general (depends on your matrix structure , computer topology and other factors), but it's not the point. In general I don't know why either OpenBLAS and MKL are threaded by default.","user":"U013V2CFZAN","ts":"1608036289.085800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u/i2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sure about BLAS1, and matrix operations are not easy to parellize in general (depends on your matrix structure , computer topology and other factors), but it's not the point. In general I don't know why either OpenBLAS and MKL are threaded by default."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"24acd1f2-b259-4a1f-84de-c76d4349b8a0","type":"message","text":"PARDISO is quite bad in general ... in my opinion. I read somewhere in an article that Intel's implementation is also kind of broken (if I remember correctly)","user":"U013V2CFZAN","ts":"1608036356.086100","team":"T68168MUP","edited":{"user":"U013V2CFZAN","ts":"1608036374.000000"},"blocks":[{"type":"rich_text","block_id":"wJ7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"PARDISO is quite bad in general ... in my opinion. I read somewhere in an article that Intel's implementation is also kind of broken (if I remember correctly)"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"d0fd47c2-ae5a-499c-8176-d332a4100058","type":"message","text":"So that users writing single threaded programs can automatically benefit from parallelism.","user":"U67461GUB","ts":"1608036360.086300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"aQ9L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"So that users writing single threaded programs can automatically benefit from parallelism."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"eea3f9be-0014-4f24-b358-6ae80786290d","type":"message","text":"If you have the article on intel’s pardiso being broken, I’d love to see it.","user":"U67461GUB","ts":"1608036403.086600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XQq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you have the article on intel’s pardiso being broken, I’d love to see it."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"f8eb8c6d-acb1-43eb-af30-4a8ea37efbea","type":"message","text":"hmmm... let me look for it, chances are it's in my workstation at my office ... which I haven't touched for 9 months or so :sweat_smile:","user":"U013V2CFZAN","ts":"1608036463.086800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rG3rA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"hmmm... let me look for it, chances are it's in my workstation at my office ... which I haven't touched for 9 months or so "},{"type":"emoji","name":"sweat_smile"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"590fc6f6-e226-4940-829f-1b9d94bd9771","type":"message","text":"Re suitesparse, openblas and mkl: <https://github.com/DrTimothyAldenDavis/SuiteSparse/issues/1>","user":"U67461GUB","ts":"1608036463.087000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hmgz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Re suitesparse, openblas and mkl: "},{"type":"link","url":"https://github.com/DrTimothyAldenDavis/SuiteSparse/issues/1"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9","reactions":[{"name":"+1","users":["U013V2CFZAN","U6QGE7S86"],"count":2}]},{"client_msg_id":"c4052772-a8dd-40eb-8caf-97f4f30839ff","type":"message","text":"I can't find the article ... it was relatively recent from (2017 or so) and it was a survey of several direct sparse solvers and the best one was Supernodal Cholesky (from SuiteSparse) for symmetric matrices, can't remember which was the fastest for unsymmetric ones. There I found that there were multiple implementations of PARDISO and the one from MKL was substantially slower than the one from <https://www.pardiso-project.org/> (good to see that Julia is already refenced there :slightly_smiling_face: ) . On the website there is a comparison by them, but the article that I had it was a 3rd party comparison.","user":"U013V2CFZAN","ts":"1608041340.088100","team":"T68168MUP","edited":{"user":"U013V2CFZAN","ts":"1608041772.000000"},"blocks":[{"type":"rich_text","block_id":"/LVe","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can't find the article ... it was relatively recent from (2017 or so) and it was a survey of several direct sparse solvers and the best one was Supernodal Cholesky (from SuiteSparse) for symmetric matrices, can't remember which was the fastest for unsymmetric ones. There I found that there were multiple implementations of PARDISO and the one from MKL was substantially slower than the one from "},{"type":"link","url":"https://www.pardiso-project.org/"},{"type":"text","text":" (good to see that Julia is already refenced there "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" ) . On the website there is a comparison by them, but the article that I had it was a 3rd party comparison."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"fafcc665-94bc-42e3-a8d3-f880709f4622","type":"message","text":"if I find the article, I will send it to you","user":"U013V2CFZAN","ts":"1608041604.088300","team":"T68168MUP","edited":{"user":"U013V2CFZAN","ts":"1608041615.000000"},"blocks":[{"type":"rich_text","block_id":"5Ho","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"if I find the article, I will send it to you"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"50d584d2-8e97-4686-8a34-76aab93981e5","type":"message","text":"thank you. I am aware of tim davis papers on the topic, but these things keep changing.","user":"U67461GUB","ts":"1608044820.089100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cHhD9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"thank you. I am aware of tim davis papers on the topic, but these things keep changing."}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"},{"client_msg_id":"1a8307b3-03c8-4aec-81ea-b049528471ac","type":"message","text":"was another one not by Tim Davis, that's why I can't find it ... because it can't remember the author","user":"U013V2CFZAN","ts":"1608044950.089700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qk1wz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"was another one not by Tim Davis, that's why I can't find it ... because it can't remember the author"}]}]}],"thread_ts":"1607977416.058000","parent_user_id":"U01GH8MFGM9"}]