[{"client_msg_id":"483879fe-c71b-49cc-a2df-0e0015a71151","type":"message","text":"Just out of curiosity, and somewhat out of topic: the channel dimension for images is the first, whereas the channel dimension (not counting the batch dimension) for deep neural network stuff is the last. Why is that? Just unfortunate convention incompatibilities, or there is a performance reason?","user":"ULDCM1P9P","ts":"1616604731.310100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cr15J","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just out of curiosity, and somewhat out of topic: the channel dimension for images is the first, whereas the channel dimension (not counting the batch dimension) for deep neural network stuff is the last. Why is that? Just unfortunate convention incompatibilities, or there is a performance reason?"}]}]}],"thread_ts":"1616604731.310100","reply_count":6,"reply_users_count":2,"latest_reply":"1616604958.311200","reply_users":["ULDCM1P9P","U67BJLYCS"],"is_locked":false,"subscribed":false},{"client_msg_id":"aa46bea6-0675-48af-a449-59a768f09751","type":"message","text":"sorry, that was meant for helpdesk :confused:","user":"ULDCM1P9P","ts":"1616604810.310200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Oaq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"sorry, that was meant for helpdesk "},{"type":"emoji","name":"confused"}]}]}],"thread_ts":"1616604731.310100","parent_user_id":"ULDCM1P9P"},{"client_msg_id":"960b42f8-5c28-4a46-ba1a-c772009049ce","type":"message","text":"there are actual performance reasons.","user":"U67BJLYCS","ts":"1616604831.310400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4nEeZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"there are actual performance reasons."}]}]}],"thread_ts":"1616604731.310100","parent_user_id":"ULDCM1P9P"},{"client_msg_id":"2eb122e4-9ea0-417b-9bd3-a883e77fa16d","type":"message","text":"In deep learning you often do convolution over each channel seperatly","user":"U67BJLYCS","ts":"1616604865.310600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"97c","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In deep learning you often do convolution over each channel seperatly"}]}]}],"thread_ts":"1616604731.310100","parent_user_id":"ULDCM1P9P"},{"client_msg_id":"f644510f-7827-4496-8e98-8c7006942865","type":"message","text":"so you want your spatial dimensions to be the fastest","user":"U67BJLYCS","ts":"1616604875.310800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"K21O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so you want your spatial dimensions to be the fastest"}]}]}],"thread_ts":"1616604731.310100","parent_user_id":"ULDCM1P9P"},{"client_msg_id":"bbc7195e-b92c-4c4a-b2bd-f43fb71e7f56","type":"message","text":"for images we often store the pixel values next to each other (and the pixel values can be stored compressed)","user":"U67BJLYCS","ts":"1616604934.311000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"atEoV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"for images we often store the pixel values next to each other (and the pixel values can be stored compressed)"}]}]}],"thread_ts":"1616604731.310100","parent_user_id":"ULDCM1P9P"},{"client_msg_id":"a04e98b4-ed56-4d8f-8545-e09c63f0fa20","type":"message","text":"I see, that's pretty clear, thanks!","user":"ULDCM1P9P","ts":"1616604958.311200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JWE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I see, that's pretty clear, thanks!"}]}]}],"thread_ts":"1616604731.310100","parent_user_id":"ULDCM1P9P"}]