[{"client_msg_id":"e4462ac7-c5db-4828-870a-a8e085005fda","type":"message","text":"Has anyone used Julia’s excellent multi threading capabilities to transform blob data (S3)? It seems like it would be a good use case based on Julia’s speed but I’d like input from some others.","user":"USSNH7BGT","ts":"1616100239.085500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LFT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Has anyone used Julia’s excellent multi threading capabilities to transform blob data (S3)? It seems like it would be a good use case based on Julia’s speed but I’d like input from some others."}]}]}],"thread_ts":"1616100239.085500","reply_count":10,"reply_users_count":5,"latest_reply":"1616104779.088900","reply_users":["USU9FRPEU","UGU761DU2","U6740K1SP","U01FAHWCMFF","UBG5JAHS7"],"is_locked":false,"subscribed":false},{"client_msg_id":"68287ccc-d8f6-4400-b96a-3634b5086ca2","type":"message","text":"I started using SIMD via Julia. It was so efficient that it made my multithreading obsolete. It was faster just to stick with single threaded SIMD.","user":"USU9FRPEU","ts":"1616100555.085600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZNHFy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I started using SIMD via Julia. It was so efficient that it made my multithreading obsolete. It was faster just to stick with single threaded SIMD."}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT"},{"client_msg_id":"259f959b-49ec-48b2-97be-a858d45f0578","type":"message","text":"Have never done stuff with S3 in particular, but that general sentiment resonates so much with me as well <@USU9FRPEU>.\n\nAnd if you really need more than what you can get with SIMD / `@avx` on one thread alone, my next step tends to be going straight to MPI; in principle you could multithread too, but it just hasn’t been necessary for me (one thread per MPI task FTW, IMO)  — that way you never need to worry about stuff like how GC is only ever single threaded, etc..","user":"UGU761DU2","ts":"1616101638.085900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2sj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Have never done stuff with S3 in particular, but that general sentiment resonates so much with me as well "},{"type":"user","user_id":"USU9FRPEU"},{"type":"text","text":".\n\nAnd if you really need more than what you can get with SIMD / "},{"type":"text","text":"@avx","style":{"code":true}},{"type":"text","text":" on one thread alone, my next step tends to be going straight to MPI; in principle you could multithread too, but it just hasn’t been necessary for me (one thread per MPI task FTW, IMO)  — that way you never need to worry about stuff like how GC is only ever single threaded, etc.."}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT"},{"client_msg_id":"ae58bfd6-690a-44d3-862a-cb39a19c5d6c","type":"message","text":"Over at :juliacomputing: we’re working on getting DataSets.jl working nicely with S3 and distributed compute on JuliaHub","user":"U6740K1SP","ts":"1616101676.086100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Z+m","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Over at "},{"type":"emoji","name":"juliacomputing"},{"type":"text","text":" we’re working on getting DataSets.jl working nicely with S3 and distributed compute on JuliaHub"}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT","reactions":[{"name":"+1","users":["UGU761DU2","USSNH7BGT","UKG4WF8PJ"],"count":3}]},{"client_msg_id":"61ec46df-c77f-47bf-8891-ad4c479c123e","type":"message","text":"Sorry if this is slightly unrelated. In my experience transforming biological data from buckets, it always seemed to me that the bottleneck was IO as opposed to proccessing speed. Is that the case for anyone else here?","user":"U01FAHWCMFF","ts":"1616101860.086400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8aF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sorry if this is slightly unrelated. In my experience transforming biological data from buckets, it always seemed to me that the bottleneck was IO as opposed to proccessing speed. Is that the case for anyone else here?"}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT"},{"client_msg_id":"3347b42e-602e-4dde-a6a0-4e61530ba3ec","type":"message","text":"I definitely have I/O problems. I have 30 GB/sec of image data to deal with from a microscope. I'm only saved by the fact that the local hard drives fill up in an about an hour.","user":"USU9FRPEU","ts":"1616102009.086600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xZxIB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I definitely have I/O problems. I have 30 GB/sec of image data to deal with from a microscope. I'm only saved by the fact that the local hard drives fill up in an about an hour."}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT","reactions":[{"name":"100","users":["UGU761DU2","UKG4WF8PJ"],"count":2}]},{"client_msg_id":"f209d2e3-61ad-47fd-ad64-2af27c1a5f81","type":"message","text":"For some reason, I'm trying to make my life harder by introducing real time compression and some streaming capability to downstream storage.","user":"USU9FRPEU","ts":"1616102054.086900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pNW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For some reason, I'm trying to make my life harder by introducing real time compression and some streaming capability to downstream storage."}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT","reactions":[{"name":"laughing","users":["UGU761DU2","USSNH7BGT"],"count":2}]},{"client_msg_id":"7c5ea910-3dfd-429c-992e-381bc88fe973","type":"message","text":"Right now I'm producing HDF5 files, but I've been really interested in this blog post where one can serve HDF5 chunks over S3: <https://medium.com/pangeo/cloud-performant-netcdf4-hdf5-with-zarr-fsspec-and-intake-3d3a3e7cb935>","user":"USU9FRPEU","ts":"1616102391.087100","team":"T68168MUP","attachments":[{"service_name":"Medium","title":"Cloud-Performant NetCDF4/HDF5 with Zarr, Fsspec and Intake","title_link":"https://medium.com/pangeo/cloud-performant-netcdf4-hdf5-with-zarr-fsspec-and-intake-3d3a3e7cb935","text":"By Rich Signell (USGS), Martin Durant (Anaconda) and Aleksandar Jelenak (HDF Group)","fallback":"Medium: Cloud-Performant NetCDF4/HDF5 with Zarr, Fsspec and Intake","image_url":"https://miro.medium.com/max/1200/1*1jqgZt_YkMHiOAfvoOsYIg.png","fields":[{"title":"Reading time","value":"6 min read","short":true}],"ts":1608291287,"from_url":"https://medium.com/pangeo/cloud-performant-netcdf4-hdf5-with-zarr-fsspec-and-intake-3d3a3e7cb935","image_width":611,"image_height":250,"image_bytes":291340,"service_icon":"https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png","id":1,"original_url":"https://medium.com/pangeo/cloud-performant-netcdf4-hdf5-with-zarr-fsspec-and-intake-3d3a3e7cb935"}],"blocks":[{"type":"rich_text","block_id":"q7RK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Right now I'm producing HDF5 files, but I've been really interested in this blog post where one can serve HDF5 chunks over S3: "},{"type":"link","url":"https://medium.com/pangeo/cloud-performant-netcdf4-hdf5-with-zarr-fsspec-and-intake-3d3a3e7cb935"}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT","reactions":[{"name":"hdf","users":["UGU761DU2"],"count":1}]},{"client_msg_id":"a8bfc49a-ed81-4b6b-b64e-602ecedec1b5","type":"message","text":"That seems like a very interesting problem Mark!\nI know there are new SSDs that can do 50Gb/s (bits).\nIf IO is a big killer, you can probably ask your supervisor for one.","user":"U01FAHWCMFF","ts":"1616102404.087400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qbJjO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That seems like a very interesting problem Mark!\nI know there are new SSDs that can do 50Gb/s (bits).\nIf IO is a big killer, you can probably ask your supervisor for one."}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT"},{"client_msg_id":"bf941f0c-ec00-43fd-93a4-9b7c1f944d5f","type":"message","text":"Well initially it is distributed over 10 nodes. They're starting to work the problem on where to send all the data to.","user":"USU9FRPEU","ts":"1616103032.088100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"xkp/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Well initially it is distributed over 10 nodes. They're starting to work the problem on where to send all the data to."}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT"},{"client_msg_id":"39bc2f31-a07f-42cd-9f72-58f67ec12bae","type":"message","text":"You might be interested in <https://github.com/meggart/YAXArrays.jl|YAXArrays.jl> which uses zarr or netcdf in the background to do computations along an axis in chunks.","user":"UBG5JAHS7","ts":"1616104779.088900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ag3E","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You might be interested in "},{"type":"link","url":"https://github.com/meggart/YAXArrays.jl","text":"YAXArrays.jl"},{"type":"text","text":" which uses zarr or netcdf in the background to do computations along an axis in chunks."}]}]}],"thread_ts":"1616100239.085500","parent_user_id":"USSNH7BGT"}]