[{"client_msg_id":"d8087d16-4624-487a-96ed-61a47dddc312","type":"message","text":"Theoretically, is it possible to fill Dict/Set in such a way that the worst-case scenario for time complexity is filled (all entries are inserted into the same bucket)? Let's say I want to make a set with 10 carefully chosen integers such a way that checking the existence of some value v is done in O(n) time?","user":"UAGBT2X1A","ts":"1615292750.013900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"v=iv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Theoretically, is it possible to fill Dict/Set in such a way that the worst-case scenario for time complexity is filled (all entries are inserted into the same bucket)? Let's say I want to make a set with 10 carefully chosen integers such a way that checking the existence of some value v is done in O(n) time?"}]}]}],"thread_ts":"1615292750.013900","reply_count":20,"reply_users_count":5,"latest_reply":"1615320441.032300","reply_users":["U7HAYKY9X","U6A936746","UAGBT2X1A","UDHCV0BHD","U01M655G9AR"],"subscribed":false},{"client_msg_id":"03ad13e4-dc3d-4312-9b91-5b399372541a","type":"message","text":"That's hard to do, I think. It's easy to find a sequence of intergers with O(n) insert time, but once you've put in a few of those, the dict will re-hash, and then there are no more slots with O(n) insert time.\nIf you have a very large dict, it can take long before it re-hashes, though","user":"U7HAYKY9X","ts":"1615293807.014300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GZKZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's hard to do, I think. It's easy to find a sequence of intergers with O(n) insert time, but once you've put in a few of those, the dict will re-hash, and then there are no more slots with O(n) insert time.\nIf you have a very large dict, it can take long before it re-hashes, though"}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"0c344060-d53e-48c6-a319-1906396f299d","type":"message","text":"If you are allowed to use your own type it is easy.\n```Base.hash(::MyType, seed::UInt) = seed```\n","user":"U6A936746","ts":"1615298649.014700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"e5t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you are allowed to use your own type it is easy.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Base.hash(::MyType, seed::UInt) = seed"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A","reactions":[{"name":"+1","users":["U7HAYKY9X"],"count":1}]},{"client_msg_id":"eb05a111-2f52-4e27-8661-97efeb1b05fd","type":"message","text":"For any type that has 10x more possible values than an `UInt` , e.g. `NTuple{10, UInt}`  it is certain to be possible to find 10 collisions that apply no matter the size of the Dict.\nand in general it is probably possible much earlier, because many `hash` functions are not perfect.\n*and nor should they be*, it is cheaper to have them be fast and then add a few `isequal` checks when collisions occur, than to make them slow but perfect.\n`OrderedCollections.LittleDict`  is in effect a dictionary with 1 bucket (i.e. that always collides) and it is faster for a lot of types than a `Dict` if you don’t have more than a few dozen elements, because `hash` is expensive","user":"U6A936746","ts":"1615299073.015100","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1615299098.000000"},"blocks":[{"type":"rich_text","block_id":"KVvaa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For any type that has 10x more possible values than an "},{"type":"text","text":"UInt","style":{"code":true}},{"type":"text","text":" , e.g. "},{"type":"text","text":"NTuple{10, UInt}","style":{"code":true}},{"type":"text","text":"  it is certain to be possible to find 10 collisions that apply no matter the size of the Dict.\nand in general it is probably possible much earlier, because many "},{"type":"text","text":"hash","style":{"code":true}},{"type":"text","text":" functions are not perfect.\n"},{"type":"text","text":"and nor should they be","style":{"bold":true}},{"type":"text","text":", it is cheaper to have them be fast and then add a few "},{"type":"text","text":"isequal","style":{"code":true}},{"type":"text","text":" checks when collisions occur, than to make them slow but perfect.\n"},{"type":"text","text":"OrderedCollections.LittleDict","style":{"code":true}},{"type":"text","text":"  is in effect a dictionary with 1 bucket (i.e. that always collides) and it is faster for a lot of types than a "},{"type":"text","text":"Dict","style":{"code":true}},{"type":"text","text":" if you don’t have more than a few dozen elements, because "},{"type":"text","text":"hash","style":{"code":true}},{"type":"text","text":" is expensive"}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"6a8bb082-2eb0-43f5-8459-c155504ed029","type":"message","text":"The reason why I'm wondering is that I was asked an algorithm with no worse complexity than O(n log n) of finding a number from a list that also has its double in that same list. So if there's e.g. list `[3, 22, 7, 5, 11, 5]`, the correct number is 11 because there's also 22. My initial solution is using a set:\n\n```function ratk5(T)\n    V = Set(T)\n    for t ∈ V\n        2*t ∈ V &amp;&amp; return t\n    end\n    return -1\nend```\nBut the initial comments was that checking if `2t in V` can be O(n) in the worst case, making this O(n^2) in the worst-case scenario. Yes, it's true that if all numbers are in one bucket due to some clever choice of numbers in T, it could be O(n^2) but I still think could this be possible if Set is implemented in the right way.","user":"UAGBT2X1A","ts":"1615308403.020100","team":"T68168MUP","edited":{"user":"UAGBT2X1A","ts":"1615308435.000000"},"blocks":[{"type":"rich_text","block_id":"BXh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The reason why I'm wondering is that I was asked an algorithm with no worse complexity than O(n log n) of finding a number from a list that also has its double in that same list. So if there's e.g. list "},{"type":"text","text":"[3, 22, 7, 5, 11, 5]","style":{"code":true}},{"type":"text","text":", the correct number is 11 because there's also 22. My initial solution is using a set:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function ratk5(T)\n    V = Set(T)\n    for t ∈ V\n        2*t ∈ V && return t\n    end\n    return -1\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"But the initial comments was that checking if "},{"type":"text","text":"2t in V","style":{"code":true}},{"type":"text","text":" can be O(n) in the worst case, making this O(n^2) in the worst-case scenario. Yes, it's true that if all numbers are in one bucket due to some clever choice of numbers in T, it could be O(n^2) but I still think could this be possible if Set is implemented in the right way."}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"982d5a83-a47c-4d01-9871-909cb54c4c0c","type":"message","text":"In general people often lie and say that big O for dictionaries is `O(1)`","user":"U6A936746","ts":"1615309063.020400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"h95xS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In general people often lie and say that big O for dictionaries is "},{"type":"text","text":"O(1)","style":{"code":true}}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"033c72e6-565b-45d2-bcf2-58de7ecc4460","type":"message","text":"Yes, but do they equally lie when telling that the worst case is O(n) if there's no theoretical proof that when properly implemented, it's impossible to make is O(n)?","user":"UAGBT2X1A","ts":"1615309137.020600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nL6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, but do they equally lie when telling that the worst case is O(n) if there's no theoretical proof that when properly implemented, it's impossible to make is O(n)?"}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"fff3e62f-98b8-41de-adbf-9a34abb8dd67","type":"message","text":"If you know bounds on the range of values that can occur in the list. then from a theoretical perspective you can just have a bit set.\nWhich is O(1) check and set for certain.","user":"U6A936746","ts":"1615309211.020800","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1615309223.000000"},"blocks":[{"type":"rich_text","block_id":"0Ow","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you know bounds on the range of values that can occur in the list. then from a theoretical perspective you can just have a bit set.\nWhich is O(1) check and set for certain."}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"6ecafbbd-e794-41a0-adc5-d0eab8bda4bd","type":"message","text":"If you take a binary tree for `V` your code should do. See for example <https://juliacollections.github.io/DataStructures.jl/latest/red_black_tree/>","user":"UDHCV0BHD","ts":"1615312330.021700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mqi8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you take a binary tree for "},{"type":"text","text":"V","style":{"code":true}},{"type":"text","text":" your code should do. See for example "},{"type":"link","url":"https://juliacollections.github.io/DataStructures.jl/latest/red_black_tree/"}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"3c45aa62-8b67-44bb-b706-db5c911c1bb0","type":"message","text":"Yes, binary trees are indeed the right solution (and there's one more based on merge sort). Theoretical judgment would be easier. But in reality, I'm quite confident that my solution is in real life faster as checking existence from a set is by average O(1). I'm talking about practice. I think my solution is the fastest one. Could we find a counterexample where it's actually slower?","user":"UAGBT2X1A","ts":"1615313518.022000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"T8s","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, binary trees are indeed the right solution (and there's one more based on merge sort). Theoretical judgment would be easier. But in reality, I'm quite confident that my solution is in real life faster as checking existence from a set is by average O(1). I'm talking about practice. I think my solution is the fastest one. Could we find a counterexample where it's actually slower?"}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"c8cc2de9-d83d-4d71-aa9c-cfc1d3eda0dc","type":"message","text":"you could just sort all elements and scan the list with two pointers. Could probably be written more elegantly, but you get the idea.:\n```function finddouble(x)\n   x = sort(x)\n   j = 1\n   n = length(x)\n   for i=1:n\n       while x[j] &lt; 2x[i] &amp;&amp; j &lt; n\n           j += 1\n       end\n       if x[j] == 2x[i]\n           return x[i],x[j]\n       end\n   end\nend```\n","user":"U01M655G9AR","ts":"1615314116.022300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G57","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"you could just sort all elements and scan the list with two pointers. Could probably be written more elegantly, but you get the idea.:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function finddouble(x)\n   x = sort(x)\n   j = 1\n   n = length(x)\n   for i=1:n\n       while x[j] < 2x[i] && j < n\n           j += 1\n       end\n       if x[j] == 2x[i]\n           return x[i],x[j]\n       end\n   end\nend"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"d5eeb5ec-2e7d-4b9f-b93f-b8c4350647a6","type":"message","text":"Because of that sort, it's definitely O(n log n). What is left is to make experiments with bigger data.","user":"UAGBT2X1A","ts":"1615314279.022500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fkZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Because of that sort, it's definitely O(n log n). What is left is to make experiments with bigger data."}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"d646e59b-1521-47ca-8b25-9fcbbb6e4036","type":"message","text":"```function test()\n    T = Random.shuffle(1:10000)\n    @btime ratk5($T)\n    @btime finddouble($T)\nend\n\n  144.767 μs (7 allocations: 144.66 KiB)\n  371.294 μs (2 allocations: 78.20 KiB)```\n","user":"UAGBT2X1A","ts":"1615314523.022700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5lw","elements":[{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function test()\n    T = Random.shuffle(1:10000)\n    @btime ratk5($T)\n    @btime finddouble($T)\nend\n\n  144.767 μs (7 allocations: 144.66 KiB)\n  371.294 μs (2 allocations: 78.20 KiB)"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"65c9fd1c-13a2-4ea4-881d-d71f42225347","type":"message","text":"dang! :slightly_smiling_face: probably you can get some gain by using inplace sorting (i.e. `sort!(x)`  instead of `x=sort(x)` .","user":"U01M655G9AR","ts":"1615315425.023100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vtgg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"dang! "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" probably you can get some gain by using inplace sorting (i.e. "},{"type":"text","text":"sort!(x)","style":{"code":true}},{"type":"text","text":"  instead of "},{"type":"text","text":"x=sort(x)","style":{"code":true}},{"type":"text","text":" ."}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"d492ffd7-fe1b-4f4f-8177-b860c9e31265","type":"message","text":"My solution _should_ be O(n) when data is somehow \"normal\", but it's unclear for me how to manipulate data such a way that things turn around","user":"UAGBT2X1A","ts":"1615315646.023300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RSszQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My solution "},{"type":"text","text":"should","style":{"italic":true}},{"type":"text","text":" be O(n) when data is somehow \"normal\", but it's unclear for me how to manipulate data such a way that things turn around"}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"e2f0e3dd-92d6-456e-93f2-79c6c5acaaa9","type":"message","text":"But your solution _cannot_ be faster than O(n log n) because of that sort","user":"UAGBT2X1A","ts":"1615316008.023500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lzM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But your solution "},{"type":"text","text":"cannot","style":{"italic":true}},{"type":"text","text":" be faster than O(n log n) because of that sort"}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"41a3bb7b-f943-4bc5-a6ee-fdf17661b19b","type":"message","text":"In a worst-case, my solution _could_ be O(n^2) if T is chosen such a way that Set(T) is not working at all, but I'm quite suspicious of that kind of T, even if we harmfully try to figure out some T that is trying to maximize hash collisions.","user":"UAGBT2X1A","ts":"1615316128.023700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vFdq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In a worst-case, my solution "},{"type":"text","text":"could","style":{"italic":true}},{"type":"text","text":" be O(n^2) if T is chosen such a way that Set(T) is not working at all, but I'm quite suspicious of that kind of T, even if we harmfully try to figure out some T that is trying to maximize hash collisions."}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"d1e628fc-88f2-4300-aaa5-66505d81f3b6","type":"message","text":"Your solution is O(n log n) as well. But the difference here is just a small constant, and is probably dominated by allocation/copy time...","user":"U01M655G9AR","ts":"1615319506.028100","team":"T68168MUP","edited":{"user":"U01M655G9AR","ts":"1615319518.000000"},"blocks":[{"type":"rich_text","block_id":"PEg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Your solution is O(n log n) as well. But the difference here is just a small constant, and is probably dominated by allocation/copy time..."}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"31e3327a-40ac-4c0e-a216-ff60aa1bca33","type":"message","text":"How's that?","user":"UAGBT2X1A","ts":"1615319579.030200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"P6NY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How's that?"}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"37957bbb-af45-4bbd-81e9-de48be359bfd","type":"message","text":"Oh, extrema is in `O(n)`\nThus the bitset solution is always available and `O(n)`.\nCos 1 pass to get get `extrema`\nAnd then `sizehint!`\nNow your search needs 2 more passed through the array 1 to fill and one to check.\nThis `O(n)`\n\nAlthough the memory used will be potentially large.\n\nIt's also amortized `O(n)` if you skip the size hint. And just stick things straight in. (As to be fair us `Set)`","user":"U6A936746","ts":"1615320158.032000","team":"T68168MUP","edited":{"user":"U6A936746","ts":"1615320182.000000"},"blocks":[{"type":"rich_text","block_id":"OCV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh, extrema is in "},{"type":"text","text":"O(n)","style":{"code":true}},{"type":"text","text":"\nThus the bitset solution is always available and "},{"type":"text","text":"O(n)","style":{"code":true}},{"type":"text","text":".\nCos 1 pass to get get `extrema`\nAnd then "},{"type":"text","text":"sizehint!\n","style":{"code":true}},{"type":"text","text":"Now your search needs 2 more passed through the array 1 to fill and one to check.\nThis `O(n)`\n\nAlthough the memory used will be potentially large.\n\nIt's also amortized "},{"type":"text","text":"O(n)","style":{"code":true}},{"type":"text","text":" if you skip the size hint. And just stick things straight in. (As to be fair us "},{"type":"text","text":"Set)","style":{"code":true}}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"},{"client_msg_id":"f9732ec4-020a-4b51-aaa9-06e9958f9936","type":"message","text":"DataStructures.jl's SparseIntSet is also O(1) check and insert (though probably 3-10 times slower that BitSet's, still very fast though).\nAnd it doesn't use arbitrarily large amounts of memory.\nAnd still gives amortized O(n)","user":"U6A936746","ts":"1615320441.032300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BPYMw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"DataStructures.jl's SparseIntSet is also O(1) check and insert (though probably 3-10 times slower that BitSet's, still very fast though).\nAnd it doesn't use arbitrarily large amounts of memory.\nAnd still gives amortized O(n)"}]}]}],"thread_ts":"1615292750.013900","parent_user_id":"UAGBT2X1A"}]