[{"client_msg_id":"d91f2aa8-79fd-4074-9648-9745a4b0e47c","type":"message","text":"Curious if anyone has thoughts on the Scalable Vector Extension 2 (SVE2) added to the new ARMv9. Will this be beneficial to Julia scientific computing, machine learning etc on ARM?","user":"UTJT285RN","ts":"1617202231.083100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MkOH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Curious if anyone has thoughts on the Scalable Vector Extension 2 (SVE2) added to the new ARMv9. Will this be beneficial to Julia scientific computing, machine learning etc on ARM?"}]}]}],"thread_ts":"1617202231.083100","reply_count":33,"reply_users_count":5,"latest_reply":"1617204488.090800","reply_users":["U0179G7FG4F","UTJT285RN","UH24GRBLL","U6N6VQE30","UAUPJLBQX"],"is_locked":false,"subscribed":false},{"client_msg_id":"0d970a0a-b640-404a-ba8e-535d905e9a26","type":"message","text":"SVE2 is awesome.","user":"U0179G7FG4F","ts":"1617202588.083300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m83","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"SVE2 is awesome."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"a5f64889-57a6-4e30-8c04-cbabe27063bc","type":"message","text":"What do you think is awesome about them? I have look at RISC-V vector extensions in the past but don't know that much about SVE2. I have the impression they are quite similar.","user":"UTJT285RN","ts":"1617202685.083500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BBw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What do you think is awesome about them? I have look at RISC-V vector extensions in the past but don't know that much about SVE2. I have the impression they are quite similar."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"479a5265-fef8-46b1-8be2-a2c4d3614bc5","type":"message","text":"It's basically the same thing conceptually like SSE and AVX on x86","user":"UH24GRBLL","ts":"1617202760.083800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ofxK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's basically the same thing conceptually like SSE and AVX on x86"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"65434cda-10ab-4357-b009-d1c47a3d24cd","type":"message","text":"One thing that makes AVX instructions really annoying to work with is that they are very tightly tied to the chip architecture. The SVE2, (and RISC-V vector) instructions have the length as a parameter, so there (hopefully) won't be a new set every couple years when the processor gets a little bigger","user":"U0179G7FG4F","ts":"1617202808.084000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SpkZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One thing that makes AVX instructions really annoying to work with is that they are very tightly tied to the chip architecture. The SVE2, (and RISC-V vector) instructions have the length as a parameter, so there (hopefully) won't be a new set every couple years when the processor gets a little bigger"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"87b840b2-0ae3-4ff5-8b5f-592cf5f9af4b","type":"message","text":"SSE and AVX are more like NEON as far as I understand <@UH24GRBLL>. Meaning they are fixed length SIMD instructions. While with SVE2 and RVV you specify length of vector in register. The vector instructions themselves are basically polymorphic. They work on any length up to the max.","user":"UTJT285RN","ts":"1617202905.084300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ei/q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"SSE and AVX are more like NEON as far as I understand "},{"type":"user","user_id":"UH24GRBLL"},{"type":"text","text":". Meaning they are fixed length SIMD instructions. While with SVE2 and RVV you specify length of vector in register. The vector instructions themselves are basically polymorphic. They work on any length up to the max."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN","reactions":[{"name":"thumbsup_all","users":["U0179G7FG4F","UKG4WF8PJ"],"count":2}]},{"client_msg_id":"e4b0dac9-2776-44f0-af5c-93c596f7bb19","type":"message","text":"<@U0179G7FG4F> when I tried following this debate before it seems very contentious. Many opinion that variable length vectors are of no use for general computing. That you only need small vectors and if you need long vectors you should just use the GPU instead. Hard to make head or tails of this debate. Especially when you don't do this type of coding yourself (like me)","user":"UTJT285RN","ts":"1617203016.084600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=Tzp9","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U0179G7FG4F"},{"type":"text","text":" when I tried following this debate before it seems very contentious. Many opinion that variable length vectors are of no use for general computing. That you only need small vectors and if you need long vectors you should just use the GPU instead. Hard to make head or tails of this debate. Especially when you don't do this type of coding yourself (like me)"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"902a9117-7d2f-4623-8309-6626cbb64f6b","type":"message","text":"I mean, julia did not have any issues with SSE/AVX/AVX512 since it compiles on the target architecture anyways","user":"U6N6VQE30","ts":"1617203124.084800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YhKE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I mean, julia did not have any issues with SSE/AVX/AVX512 since it compiles on the target architecture anyways"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN","reactions":[{"name":"100","users":["UAUPJLBQX","UKG4WF8PJ","U6QGE7S86"],"count":3}]},{"client_msg_id":"3ed6ad4c-641c-464a-9167-e0b76b2f6453","type":"message","text":"It's basically boiling down to whether LLVM emits those instructions","user":"UH24GRBLL","ts":"1617203156.085000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"W8D","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's basically boiling down to whether LLVM emits those instructions"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"3a80ff55-a2b0-435d-ba4e-cc57806b7c83","type":"message","text":"from the julia side not much is going to change explicitly","user":"UH24GRBLL","ts":"1617203165.085200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YYRk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"from the julia side not much is going to change explicitly"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"f313f115-b302-44fe-98ba-468fbd5ca429","type":"message","text":"at most something like LoopVectorization would have to change some internals","user":"UH24GRBLL","ts":"1617203209.085400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6wj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"at most something like LoopVectorization would have to change some internals"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"d5ab99dd-0f2f-44bd-9aeb-a3bacafa8c49","type":"message","text":"What I mean is: SVE is interesting for languages that do static compilation, because you can compile once and run on different micro-archs without sacrificing performance. In julia you recompile all the time, so what's the point (except maybe generic sysimages...)?","user":"U6N6VQE30","ts":"1617203447.085600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Itl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What I mean is: SVE is interesting for languages that do static compilation, because you can compile once and run on different micro-archs without sacrificing performance. In julia you recompile all the time, so what's the point (except maybe generic sysimages...)?"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN","reactions":[{"name":"+1","users":["UTJT285RN"],"count":1}]},{"client_msg_id":"1f2496f9-6d29-4eda-8dd9-0c1dacf52f2e","type":"message","text":"recompile all the time...? I mean, across different executions maybe, but not during the same execution","user":"UH24GRBLL","ts":"1617203505.085800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TqM+q","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"recompile all the time...? I mean, across different executions maybe, but not during the same execution"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"0aece148-9fe9-49eb-a5e7-e6806c7aaf86","type":"message","text":"<@U6N6VQE30> One advantage is that it makes <@UAUPJLBQX>'s job much easier.","user":"U0179G7FG4F","ts":"1617203518.086000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"VQg","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U6N6VQE30"},{"type":"text","text":" One advantage is that it makes "},{"type":"user","user_id":"UAUPJLBQX"},{"type":"text","text":"'s job much easier."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"8ac8501c-7d71-4652-bfd4-c83cd10219ef","type":"message","text":"One problem with AVX512 is the market segmentation that results. People like Linus Torvalds will gripe about every bit of SIMD and floating point math they have to \"waste\" silicon on","user":"UAUPJLBQX","ts":"1617203914.086500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cWkzQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One problem with AVX512 is the market segmentation that results. People like Linus Torvalds will gripe about every bit of SIMD and floating point math they have to \"waste\" silicon on"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"c5417239-89ac-4dad-b0e9-7e0bbc8ced9a","type":"message","text":"while others (such as myself) like big vectors.","user":"UAUPJLBQX","ts":"1617203968.086700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ErDGB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"while others (such as myself) like big vectors."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"1a3c3b2e-f210-43ea-a332-1aaf0c7e9a0c","type":"message","text":"<@U0179G7FG4F> VectorizationBase is mapping to LLVM IR at the lowest level, and LLVM IR's vector types do not map 1-to-1 to hardware vectors, so you can work with \"dynamic\" vector sizes already","user":"U6N6VQE30","ts":"1617203969.086900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Vya","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U0179G7FG4F"},{"type":"text","text":" VectorizationBase is mapping to LLVM IR at the lowest level, and LLVM IR's vector types do not map 1-to-1 to hardware vectors, so you can work with \"dynamic\" vector sizes already"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"18f23451-a627-4158-983d-ba8cf84de35d","type":"message","text":"as in, you can run fma's and shuffle instructions on vectors of 1000 doubles :smile:","user":"U6N6VQE30","ts":"1617204030.087100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wx8z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"as in, you can run fma's and shuffle instructions on vectors of 1000 doubles "},{"type":"emoji","name":"smile"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"4b52ed2f-8fde-4a85-a003-8d99649a7b3a","type":"message","text":"llvm will just break it up into whatever the target arch supports","user":"U6N6VQE30","ts":"1617204051.087300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MnfC+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"llvm will just break it up into whatever the target arch supports"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"f89fe6a8-8cfd-4195-bb88-c8c947d80db3","type":"message","text":"If Intel wants to appeal to both audiences, they need to make chips with and without AVX512.\nDistributing lots of chips without AVX512 hinders its adoption, and reduces the amount of people who want to put effort into supporting it or optimizing for it.","user":"UAUPJLBQX","ts":"1617204052.087500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nkvCV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If Intel wants to appeal to both audiences, they need to make chips with and without AVX512.\nDistributing lots of chips without AVX512 hinders its adoption, and reduces the amount of people who want to put effort into supporting it or optimizing for it."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"da98356c-2d7a-4e4a-b707-40bbdeb46e15","type":"message","text":"In VectorizationBase, I do normally try to keep it to hardware supported vector lengths","user":"UAUPJLBQX","ts":"1617204100.087700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u1J","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In VectorizationBase, I do normally try to keep it to hardware supported vector lengths"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN","reactions":[{"name":"slightly_smiling_face","users":["UTJT285RN"],"count":1}]},{"client_msg_id":"8005e709-3fea-4e6c-867d-c67e6f93cd01","type":"message","text":"and it will normally automatically split vectors if you try to create something larger.","user":"UAUPJLBQX","ts":"1617204115.087900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cMABh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and it will normally automatically split vectors if you try to create something larger."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"89cb4c37-f7e0-45ea-adc5-bd1056a9213a","type":"message","text":"But that size is still `N` in the code, right?","user":"U6N6VQE30","ts":"1617204117.088200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"90xq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But that size is still "},{"type":"text","text":"N","style":{"code":true}},{"type":"text","text":" in the code, right?"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"b38614cc-3612-4c5a-a5fa-65eb955349d2","type":"message","text":"Oh, you mean VecUnroll :smile:","user":"U6N6VQE30","ts":"1617204145.088400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"KEVv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh, you mean VecUnroll "},{"type":"emoji","name":"smile"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN","reactions":[{"name":"heavy_check_mark","users":["UAUPJLBQX"],"count":1}]},{"client_msg_id":"6cb4435e-d233-4144-b24d-03300262a3cc","type":"message","text":"You mean `N` is a parameter instead of hardcoded? Yeah. Have to support 128-bit/256-bit/512-bit.","user":"UAUPJLBQX","ts":"1617204182.088700","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1617204280.000000"},"blocks":[{"type":"rich_text","block_id":"WCyl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You mean "},{"type":"text","text":"N","style":{"code":true}},{"type":"text","text":" is a parameter instead of hardcoded? Yeah. Have to support 128-bit/256-bit/512-bit."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"46dd8bf4-0f42-40c5-acd7-23e31e2dd332","type":"message","text":"The main use case for creating giant vectors is shuffles like you noted. In many cases, LLVM does a really good job generating efficient shuffle sequences from that.","user":"UAUPJLBQX","ts":"1617204239.088900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"q62","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The main use case for creating giant vectors is shuffles like you noted. In many cases, LLVM does a really good job generating efficient shuffle sequences from that."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"fd731e58-9d0d-4aa7-b343-9605dbbac166","type":"message","text":"(I don't suppose you've come up with a generic algorithm that beats LLVM yet?)","user":"UAUPJLBQX","ts":"1617204253.089100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"9DqJ5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(I don't suppose you've come up with a generic algorithm that beats LLVM yet?)"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"7f4cd546-440e-4c5a-9bd7-d61ba5898a00","type":"message","text":"(I didn't have a lot of time for my side projects :sob:)","user":"U6N6VQE30","ts":"1617204295.089400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cszwH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(I didn't have a lot of time for my side projects "},{"type":"emoji","name":"sob"},{"type":"text","text":")"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"e3e10b13-1c9f-4b27-96f9-44f12a4ac345","type":"message","text":"The main thing I still need to figure out about SVE(2) is how to get the actual hardware vector width","user":"UAUPJLBQX","ts":"1617204299.089600","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1617204305.000000"},"blocks":[{"type":"rich_text","block_id":"OLTHW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The main thing I still need to figure out about SVE(2) is how to get the actual hardware vector width"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"4ea13233-7b2a-4c69-b655-dfb835bec9a7","type":"message","text":"e.g., 128/256/512 bits for Neoverse N2/Neoverse V1/A64FX","user":"UAUPJLBQX","ts":"1617204325.089900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UPwZ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"e.g., 128/256/512 bits for Neoverse N2/Neoverse V1/A64FX"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"b9a70f5f-97ba-4e1e-9b53-0e9e50530218","type":"message","text":"I'm curious what\n```vscale() = ccall(\"llvm.vscale.i64\", llvmcall, Int64, ())```\nreturns","user":"UAUPJLBQX","ts":"1617204349.090100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QKx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm curious what\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"vscale() = ccall(\"llvm.vscale.i64\", llvmcall, Int64, ())"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"returns"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"e1fa8280-b2ac-4b87-b916-40ec037c876d","type":"message","text":"But if you want to support both AVX* and SVE, it's unlikely VectorizationBase will change at all, right? Except for extracting hardware features","user":"U6N6VQE30","ts":"1617204408.090300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Q3OIj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But if you want to support both AVX* and SVE, it's unlikely VectorizationBase will change at all, right? Except for extracting hardware features"}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN","reactions":[{"name":"heavy_check_mark","users":["UAUPJLBQX"],"count":1}]},{"client_msg_id":"dae966ba-1cd5-4343-a44f-beca177894d0","type":"message","text":"The reason it'd be really useful to know this and directly use the vector size instead of emitting agnostic `vscale x n x type` code is because sometimes we have short statically sized loops.","user":"UAUPJLBQX","ts":"1617204411.090500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"DGsM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The reason it'd be really useful to know this and directly use the vector size instead of emitting agnostic "},{"type":"text","text":"vscale x n x type","style":{"code":true}},{"type":"text","text":" code is because sometimes we have short statically sized loops."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"},{"client_msg_id":"5d925404-f8f9-44e0-8c6d-d3172b1bd323","type":"message","text":"Yeah, extracting hardware features is the only thing. And as you noted, we recompile for specific host machines anyway, so there is no cost to doing this instead of the `vscale` approach, only upside for continuing to do things how it is already done.","user":"UAUPJLBQX","ts":"1617204488.090800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"utN0C","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, extracting hardware features is the only thing. And as you noted, we recompile for specific host machines anyway, so there is no cost to doing this instead of the "},{"type":"text","text":"vscale","style":{"code":true}},{"type":"text","text":" approach, only upside for continuing to do things how it is already done."}]}]}],"thread_ts":"1617202231.083100","parent_user_id":"UTJT285RN"}]