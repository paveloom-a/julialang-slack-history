[{"client_msg_id":"11e341ab-e04f-4e63-9ad2-becea15e1834","type":"message","text":"Hi,\n\nI'm just wondering if I have Group A (N=20) and group B (N=1), does it valid to do a statistical test, such as (independent) Wilcoxon rank sums or independent t-test?\n\nGiven that these tests works on class distribution, it seems that it wouldn't be correct to draw class distribution from only 1 sample. Any thoughts?\n\nThanks","user":"UUT4VGTE2","ts":"1612747178.066200","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1612747676.000000"},"blocks":[{"type":"rich_text","block_id":"Tj0AC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi,\n\nI'm just wondering if I have Group A (N=20) and group B (N=1), does it valid to do a statistical test, such as (independent) Wilcoxon rank sums or independent t-test?\n\nGiven that these tests works on class distribution, it seems that it wouldn't be correct to draw class distribution from only 1 sample. Any thoughts?\n\nThanks"}]}]}],"thread_ts":"1612747178.066200","reply_count":15,"reply_users_count":3,"latest_reply":"1612937813.077900","reply_users":["U017JTQFNEQ","UKLKS1WC8","UUT4VGTE2"],"subscribed":false},{"client_msg_id":"1d55a576-6973-4d19-b91d-8993c8db804c","type":"message","text":"With that little data, you will need to make some assumption about A. if you believe A is normally distributed you can do\n```HypothesisTests.OneSampleTTest(A,B)```","user":"U017JTQFNEQ","ts":"1612793685.068200","team":"T68168MUP","edited":{"user":"U017JTQFNEQ","ts":"1612793730.000000"},"blocks":[{"type":"rich_text","block_id":"ACtS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"With that little data, you will need to make some assumption about A. if you believe A is normally distributed you can do\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"HypothesisTests.OneSampleTTest(A,B)"}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"6c68a315-47e1-4973-be1c-385d6499dc48","type":"message","text":"If you think A comes from another distribution, like Poisson you could do:\n```HypothesisTests.ExactOneSampleKSTest([B], Distributions.Poisson(mean(A)))```","user":"U017JTQFNEQ","ts":"1612793776.068500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"O8r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you think A comes from another distribution, like Poisson you could do:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"HypothesisTests.ExactOneSampleKSTest([B], Distributions.Poisson(mean(A)))"}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"107edf65-6d35-46e4-8e35-57343d7d433e","type":"message","text":"Exact Wilcoxon-rank sum test (Mann-Whitney) would be OK here under its standard assumptions. It just would not have any power to detect anything. In fact, even if the one sample from B is strictly smaller than all 20 samples from A, you would get a p-value of 0.1.","user":"UKLKS1WC8","ts":"1612820575.069500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iKqh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Exact Wilcoxon-rank sum test (Mann-Whitney) would be OK here under its standard assumptions. It just would not have any power to detect anything. In fact, even if the one sample from B is strictly smaller than all 20 samples from A, you would get a p-value of 0.1."}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"870cdddc-9a64-4e60-9020-1eebe7c7fb78","type":"message","text":"Please don't use a t-test here! As Jeff wrote, it will have to rely too strongly on assumptions as Normality. In fact to even do a t-test here you will need to assume that the single sample from B has the same variance as samples from A. Jeff's suggestions have some issues too (the first one  treats the value of B as deterministic, the second one treats the mean of A as deterministic , these are random and inference should account for that randomness!).","user":"UKLKS1WC8","ts":"1612820675.069700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NLo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Please don't use a t-test here! As Jeff wrote, it will have to rely too strongly on assumptions as Normality. In fact to even do a t-test here you will need to assume that the single sample from B has the same variance as samples from A. Jeff's suggestions have some issues too (the first one  treats the value of B as deterministic, the second one treats the mean of A as deterministic , these are random and inference should account for that randomness!)."}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"e5354cf2-652b-45e1-9a4c-baa102a9a85e","type":"message","text":"<@UKLKS1WC8> although i agree with you, i have seen many papers that do use a t-test in this kind of situation! I guess i should have been more clean when i said that he would need to make some assumptions. I meant that without some assumptions and that little data he would not be able to do any inference - basically what you said. Depending on what A is, some assumptions about Normality might be OK. Like if A is something that is known to be Normally distributed because of the generative process or past literature.","user":"U017JTQFNEQ","ts":"1612841870.071300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"G6O2","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UKLKS1WC8"},{"type":"text","text":" although i agree with you, i have seen many papers that do use a t-test in this kind of situation! I guess i should have been more clean when i said that he would need to make some assumptions. I meant that without some assumptions and that little data he would not be able to do any inference - basically what you said. Depending on what A is, some assumptions about Normality might be OK. Like if A is something that is known to be Normally distributed because of the generative process or past literature."}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"c7566f24-b6b8-4836-ba67-57dfd95685e7","type":"message","text":"<@U017JTQFNEQ>  `OneSampleTTest(A,B)` is problematic even if `A,B` really are normal! It tests the (random) hypothesis that the (mean of A) = B (instead of the standard null hypothesis that mean of A = mean of B). See the simulation below where the samples of A and B have exactly the same Standard Normal distribution, but `OneSampleTTest(A,B)`  overrejects if we use the random B!\n\n```using HypothesisTests\nusing Statistics\n\nfunction generate_pvalue(; mean_B = false)\n    As = randn(20)\n    B = mean_B ? 0.0 : randn()\n    pvalue(OneSampleTTest(As,B))\nend\n\nfalse_pvals = [generate_pvalue(; mean_B = false) for _ in 1:10000]\ncorrect_pvals = [generate_pvalue(; mean_B = true) for _ in 1:10000]\nmean(false_pvals .&lt;= 0.05) #0.66\nmean(correct_pvals .&lt;= 0.05) #0.053```","user":"UKLKS1WC8","ts":"1612843385.071700","team":"T68168MUP","edited":{"user":"UKLKS1WC8","ts":"1612843569.000000"},"blocks":[{"type":"rich_text","block_id":"fitTb","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U017JTQFNEQ"},{"type":"text","text":"  "},{"type":"text","text":"OneSampleTTest(A,B)","style":{"code":true}},{"type":"text","text":" is problematic even if "},{"type":"text","text":"A,B","style":{"code":true}},{"type":"text","text":" really are normal! It tests the (random) hypothesis that the (mean of A) = B (instead of the standard null hypothesis that mean of A = mean of B). See the simulation below where the samples of A and B have exactly the same Standard Normal distribution, but "},{"type":"text","text":"OneSampleTTest(A,B)","style":{"code":true}},{"type":"text","text":"  overrejects if we use the random B!\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using HypothesisTests\nusing Statistics\n\nfunction generate_pvalue(; mean_B = false)\n    As = randn(20)\n    B = mean_B ? 0.0 : randn()\n    pvalue(OneSampleTTest(As,B))\nend\n\nfalse_pvals = [generate_pvalue(; mean_B = false) for _ in 1:10000]\ncorrect_pvals = [generate_pvalue(; mean_B = true) for _ in 1:10000]\nmean(false_pvals .<= 0.05) #0.66\nmean(correct_pvals .<= 0.05) #0.053"}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2","reactions":[{"name":"+1","users":["UUT4VGTE2"],"count":1}]},{"client_msg_id":"9d4e486a-dba3-4d9c-b0ba-26d8526415c0","type":"message","text":"The same is true for the Kolmogorov-Smirnov test. It is valid when the distribution is deterministic, say `Distributions.Poisson(2.0)`, once you use a random distribution that is learned from fitting the data, such as `Distributions.Poisson(mean(A))` , all statistical guarantees of the test are gone.","user":"UKLKS1WC8","ts":"1612843464.071900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"te10","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The same is true for the Kolmogorov-Smirnov test. It is valid when the distribution is deterministic, say "},{"type":"text","text":"Distributions.Poisson(2.0)","style":{"code":true}},{"type":"text","text":", once you use a random distribution that is learned from fitting the data, such as "},{"type":"text","text":"Distributions.Poisson(mean(A))","style":{"code":true}},{"type":"text","text":" , all statistical guarantees of the test are gone."}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"e220b606-f58f-454f-846b-5ab80e4fa594","type":"message","text":"Good point. I assumed he wanted to test that mean(A) = B","user":"U017JTQFNEQ","ts":"1612847222.072300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qU+=5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Good point. I assumed he wanted to test that mean(A) = B"}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"9372bfbe-7f57-48b2-a639-f97d127a8e7f","type":"message","text":"since if length(B)=1 he doesn’t know anything about the distribution of B!","user":"U017JTQFNEQ","ts":"1612847256.072500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ZLOp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"since if length(B)=1 he doesn’t know anything about the distribution of B!"}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2","reactions":[{"name":"+1","users":["UUT4VGTE2","UKLKS1WC8"],"count":2}]},{"client_msg_id":"cb5e7de9-f82a-4d50-8294-85b5602f2fcc","type":"message","text":"<@U017JTQFNEQ> <@UKLKS1WC8> Thanks a lot guys for the thoughts! I am planning to use this test to filter significant features (looking into p-value). I can confirm that some of the features have outliers, so I would need to use non-parametric. I agreed that `length(B)=1` is the issue of running this test, though.\n\nIn the end, I decided to scale those with modified z-score (using median and median abs deviation) and put the group B (n=1) in that z-score. This way I can get the idea how much does the sample B deviate from the A's median. Then, I'm looking into the `mod_z_score` and consider the feature significant if `mod_z_score` &gt; 1.95 as it's &gt;95% confidence.\n\nAny thoughts on this approach?","user":"UUT4VGTE2","ts":"1612873369.074100","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1612873380.000000"},"blocks":[{"type":"rich_text","block_id":"/IJ","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U017JTQFNEQ"},{"type":"text","text":" "},{"type":"user","user_id":"UKLKS1WC8"},{"type":"text","text":" Thanks a lot guys for the thoughts! I am planning to use this test to filter significant features (looking into p-value). I can confirm that some of the features have outliers, so I would need to use non-parametric. I agreed that "},{"type":"text","text":"length(B)=1","style":{"code":true}},{"type":"text","text":" is the issue of running this test, though.\n\nIn the end, I decided to scale those with modified z-score (using median and median abs deviation) and put the group B (n=1) in that z-score. This way I can get the idea how much does the sample B deviate from the A's median. Then, I'm looking into the "},{"type":"text","text":"mod_z_score","style":{"code":true}},{"type":"text","text":" and consider the feature significant if "},{"type":"text","text":"mod_z_score","style":{"code":true}},{"type":"text","text":" > 1.95 as it's >95% confidence.\n\nAny thoughts on this approach?"}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"f6bdfc10-e6c4-43d5-a5c0-a1ae11a1ebb7","type":"message","text":"What is the setting in which you want to use this? If I understand your approach correctly, it has the same issue as what we discussed with Jeff (i.e. it treats B as constant, but B is presumably random too). See the code snippet I posted above for the potential complication (and whether that interpretation of the test is OK for you). For most setting I would rather assume that B also has the same variance as the samples from A, rather than assuming it has 0 variance (or conditioning on it).","user":"UKLKS1WC8","ts":"1612890266.075700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"mFXo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What is the setting in which you want to use this? If I understand your approach correctly, it has the same issue as what we discussed with Jeff (i.e. it treats B as constant, but B is presumably random too). See the code snippet I posted above for the potential complication (and whether that interpretation of the test is OK for you). For most setting I would rather assume that B also has the same variance as the samples from A, rather than assuming it has 0 variance (or conditioning on it)."}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"4e1b3f04-1a40-48d7-93f9-8d0270c1df4f","type":"message","text":"<@UKLKS1WC8> So, this will be more of a case study in health sector - we have this 1 participant's data from a new group (Group B) and we want to compare this to Group A. We'd like to see what is the distinguishing factor of this sample compared to Group A. In other words, as stated above, filtering important features (or univariate feature selection, if you'd like to call).\n\nClearly, as you mentioned, hypothesis testing is not suitable here. Even wilcoxon's is unreliable due to this number of sample in Group B.\n\nFor this reason, I think fitting the 1 sample into Group A's distribution works (as explained above, with modified z-score). Then, I can filter the important features based on where that sample sits compared to the group A (based on modified z-score, translated to confidence). WDYT?","user":"UUT4VGTE2","ts":"1612917163.077000","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1612917248.000000"},"blocks":[{"type":"rich_text","block_id":"t3W0T","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UKLKS1WC8"},{"type":"text","text":" So, this will be more of a case study in health sector - we have this 1 participant's data from a new group (Group B) and we want to compare this to Group A. We'd like to see what is the distinguishing factor of this sample compared to Group A. In other words, as stated above, filtering important features (or univariate feature selection, if you'd like to call).\n\nClearly, as you mentioned, hypothesis testing is not suitable here. Even wilcoxon's is unreliable due to this number of sample in Group B.\n\nFor this reason, I think fitting the 1 sample into Group A's distribution works (as explained above, with modified z-score). Then, I can filter the important features based on where that sample sits compared to the group A (based on modified z-score, translated to confidence). WDYT?"}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"7287ab9f-f52e-43b0-8d42-859e2c21fea7","type":"message","text":"i think what you are doing is fine as long as your claims are aligned with your methods. In anomaly detection it is very common to take a set of data points to compute a mean/std (or median/dev) and then zscore new data as such and threshold  the zscore. What you are effective asking is the likelihood of observing sample B being drawn from A. If you want a “sanity” check, just put all the subjects together (A U B) and for each subject put them as a “test” and generate your median zscore. Then you can more reasonably say if B is special.\n\n But it sounds to me like you have many features for each subject in A and for the subject B? In that case you might want to consider all the features at the same time: using PCA or something to combine features into a few components and look at the zscore in each component. If there is one PC that distinguishes B from A you can inspect which features load heavily onto that PC.","user":"U017JTQFNEQ","ts":"1612924641.077500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fM00t","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"i think what you are doing is fine as long as your claims are aligned with your methods. In anomaly detection it is very common to take a set of data points to compute a mean/std (or median/dev) and then zscore new data as such and threshold  the zscore. What you are effective asking is the likelihood of observing sample B being drawn from A. If you want a “sanity” check, just put all the subjects together (A U B) and for each subject put them as a “test” and generate your median zscore. Then you can more reasonably say if B is special.\n\n But it sounds to me like you have many features for each subject in A and for the subject B? In that case you might want to consider all the features at the same time: using PCA or something to combine features into a few components and look at the zscore in each component. If there is one PC that distinguishes B from A you can inspect which features load heavily onto that PC."}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"f63dcc7f-1ff8-4866-a2a8-5426e097cbc9","type":"message","text":"<@U017JTQFNEQ> PCA makes sense! Is there any recommendation as to how many components I should start with?","user":"UUT4VGTE2","ts":"1612929528.077700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bdp6b","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U017JTQFNEQ"},{"type":"text","text":" PCA makes sense! Is there any recommendation as to how many components I should start with?"}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"e141a67f-5046-4580-87a4-2d75192e583c","type":"message","text":"Make a plot of cumulative variance explained vs # of components. Take as many as you need to cover 90 or 95% of variance. [like in this python tutorial](<https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html#Choosing-the-number-of-components>)","user":"U017JTQFNEQ","ts":"1612937813.077900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Dqbq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Make a plot of cumulative variance explained vs # of components. Take as many as you need to cover 90 or 95% of variance. [like in this python tutorial]("},{"type":"link","url":"https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html#Choosing-the-number-of-components"},{"type":"text","text":")"}]}]}],"thread_ts":"1612747178.066200","parent_user_id":"UUT4VGTE2","reactions":[{"name":"+1","users":["UUT4VGTE2"],"count":1}]}]