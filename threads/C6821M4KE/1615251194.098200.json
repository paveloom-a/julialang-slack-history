[{"client_msg_id":"647db3a2-1f95-4afc-b28b-35bd8f7fdfc5","type":"message","text":"Hi guys, suppose I have this p-values taken from multiple binary tests.\n```Compared Groups | Variable | p-value\nG1vsG2          | var1     | 0.5\n                | var2     | 0.03\n                | var3     | 0.01\nG2vsG3          | var1     | 0.2\n                | var2     | 0.0232\n                | var3     | 0.0.15\nG1vsG3          | var1     | 0.005\n                | var2     | 0.06\n                | var3     | 0.8```\nI am just wondering how should I approach multiple tests correction here? Options:\n1. For each compared group, e.g. in G1vsG2 correction([p_val_var1_g1g2, p_val_var2_g1g2, p_val_var3_g1g2)\n2. For each variable, e.g. in var1 correction([p_val_var1_g1g2, p_val_var1_g2g3, p_val_var1_g1g3)\n3. Combine all those p-values and correct correction(all_p_values_list). I think this doesn't make sense since each variable will have multiple p-values and the correction can't distinguish which comes from the same variable but different tests, but I could be wrong.\nAny thoughts?","user":"UUT4VGTE2","ts":"1615251194.098200","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1615251275.000000"},"blocks":[{"type":"rich_text","block_id":"8Up","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys, suppose I have this p-values taken from multiple binary tests.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Compared Groups | Variable | p-value\nG1vsG2          | var1     | 0.5\n                | var2     | 0.03\n                | var3     | 0.01\nG2vsG3          | var1     | 0.2\n                | var2     | 0.0232\n                | var3     | 0.0.15\nG1vsG3          | var1     | 0.005\n                | var2     | 0.06\n                | var3     | 0.8"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I am just wondering how should I approach multiple tests correction here? Options:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For each compared group, e.g. in G1vsG2 correction([p_val_var1_g1g2, p_val_var2_g1g2, p_val_var3_g1g2)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"For each variable, e.g. in var1 correction([p_val_var1_g1g2, p_val_var1_g2g3, p_val_var1_g1g3)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Combine all those p-values and correct correction(all_p_values_list). I think this doesn't make sense since each variable will have multiple p-values and the correction can't distinguish which comes from the same variable but different tests, but I could be wrong."}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"Any thoughts?"}]}]}],"thread_ts":"1615251194.098200","reply_count":52,"reply_users_count":6,"latest_reply":"1615270178.110900","reply_users":["UBF9YRB6H","U01EF0QVAB0","UUT4VGTE2","U017JTQFNEQ","UKLKS1WC8","U7JQGPGCQ"],"subscribed":false},{"client_msg_id":"02cb9a14-15a5-4c6f-9ee8-939d1732414d","type":"message","text":"My intuition is that you need to do them all together, since none of them are independent hypotheses.\n\nBecause they are not independent, you also probably have to use simulation methods like westfall-young.","user":"UBF9YRB6H","ts":"1615251372.098600","team":"T68168MUP","edited":{"user":"UBF9YRB6H","ts":"1615251719.000000"},"blocks":[{"type":"rich_text","block_id":"FZ0c5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My intuition is that you need to do them all together, since none of them are independent hypotheses.\n\nBecause they are not independent, you also probably have to use simulation methods like westfall-young."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"07aba3a8-31f4-4c27-9306-a7ebacb2ba21","type":"message","text":"I think one can correct within an outcome too and do it separately for all the outcomes. But there really isn't an accepted standard for multiple testing. Researchers I have worked with hate correcting for all and I can understand because it destroys power and I guess there is a balance between the rigor and resources at some point","user":"U01EF0QVAB0","ts":"1615251566.098800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nBJA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think one can correct within an outcome too and do it separately for all the outcomes. But there really isn't an accepted standard for multiple testing. Researchers I have worked with hate correcting for all and I can understand because it destroys power and I guess there is a balance between the rigor and resources at some point"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"c2f16462-7648-4fbe-add2-73e838134ea3","type":"message","text":"<@U01EF0QVAB0> Thanks for replying! I'm really confused about this. With no accepted standard for the correction, how does this work when people publishing their work and stating 'I did Bonferroni correction...', which approach will they usually do?\n\nIt seems to be a huge issue if there is no accepted standard, but those 3 approaches could yield  different results.\n\nWhat I want to do here is basically getting which of those variables are significant in those 3 comparison.","user":"UUT4VGTE2","ts":"1615252121.099100","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1615252198.000000"},"blocks":[{"type":"rich_text","block_id":"65X","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U01EF0QVAB0"},{"type":"text","text":" Thanks for replying! I'm really confused about this. With no accepted standard for the correction, how does this work when people publishing their work and stating 'I did Bonferroni correction...', which approach will they usually do?\n\nIt seems to be a huge issue if there is no accepted standard, but those 3 approaches could yield  different results.\n\nWhat I want to do here is basically getting which of those variables are significant in those 3 comparison."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"644bd733-07db-47b3-a450-b57c7c8be494","type":"message","text":"What field are you in, might I ask?","user":"UBF9YRB6H","ts":"1615252177.099300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+q6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What field are you in, might I ask?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"433a9103-c0df-462c-9d6b-292e55f9548e","type":"message","text":"<@UBF9YRB6H> I work in health field, but my background is in CS/DS (I'm not stats expert by any means!)","user":"UUT4VGTE2","ts":"1615252264.099600","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1615252283.000000"},"blocks":[{"type":"rich_text","block_id":"/Yau","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UBF9YRB6H"},{"type":"text","text":" I work in health field, but my background is in CS/DS (I'm not stats expert by any means!)"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"157cafd7-f267-4b47-b0ed-02398d273186","type":"message","text":"Ah okay. In economics, specifically RCTs that I am familiar with, there is no agreed upon standard. basically, if you your p-values survive Bonferroni, use Bonferroni. If they don't, use Hochberg. If they don't survive Hochberg, use simulation methods.\n\nYou should group together all tests you think are correlated, like the same outcome with different groups.","user":"UBF9YRB6H","ts":"1615252435.099900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2C/O","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah okay. In economics, specifically RCTs that I am familiar with, there is no agreed upon standard. basically, if you your p-values survive Bonferroni, use Bonferroni. If they don't, use Hochberg. If they don't survive Hochberg, use simulation methods.\n\nYou should group together all tests you think are correlated, like the same outcome with different groups."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"deeabb77-d2fe-421d-9e1a-e19344fa5b85","type":"message","text":"<@UBF9YRB6H> But that 'survive Bonferroni', so it would be approach 1, i.e. comparing it across variables in each binary tests?","user":"UUT4VGTE2","ts":"1615252833.100100","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1615252883.000000"},"blocks":[{"type":"rich_text","block_id":"XXX","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UBF9YRB6H"},{"type":"text","text":" But that 'survive Bonferroni', so it would be approach 1, i.e. comparing it across variables in each binary tests?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"55482b48-8c6e-45b5-9c10-72ac87e5d638","type":"message","text":"I'm being a big facetious, just being cynical about the inconsistent use of p-value corrections in the literature. I think its fine to start there, but a more disciplined approach would be to use a simulation method like westfall-young directly","user":"UBF9YRB6H","ts":"1615252904.100400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"sahv","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm being a big facetious, just being cynical about the inconsistent use of p-value corrections in the literature. I think its fine to start there, but a more disciplined approach would be to use a simulation method like westfall-young directly"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"a0e7b289-ded7-4de2-9100-b698f035a5c9","type":"message","text":"Right! Is there any library that helps me with westfall-young?","user":"UUT4VGTE2","ts":"1615253127.100600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"W7nqr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Right! Is there any library that helps me with westfall-young?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"8ada92bd-4c90-4f49-9be6-4d12c813672d","type":"message","text":"Here is a quantecon post from 2014 about it? <https://juliaeconomics.com/2014/06/17/stepdown-p-values-for-multiple-hypothesis-testing-in-julia/>\n\nThe syntax will obviously be broken but it will serve as a useful example","user":"UBF9YRB6H","ts":"1615253291.100800","team":"T68168MUP","attachments":[{"service_name":"Julia/Economics","service_url":"http://juliaeconomics.com","title":"Stepdown p-values for Multiple Hypothesis Testing in Julia","title_link":"https://juliaeconomics.com/2014/06/17/stepdown-p-values-for-multiple-hypothesis-testing-in-julia/","author_name":"bradleysetzler","author_link":"https://juliaeconomics.com/author/bradleysetzler/","text":"* The script to reproduce the results of this tutorial in Julia is located here.\nTo finish yesterday&rsquo;s tutorial on hypothesis testing with non-parametric p-values in Julia, I show how to perform the bootstrap stepdown correction to p-values for multiple testing, which many economists find intimidating (including me) but is actually not so difficult.\nFirst, I will show the simple case of&nbsp;Holm&rsquo;s (1979)&nbsp;stepdown procedure. Then, I will build on the bootstrap example to apply&nbsp;one of the most exciting advances in econometric theory from the past decade, the bootstrap step-down procedure, developed by&nbsp;Romano and Wolf (2004)&nbsp;and extended by Chicago professor&nbsp;Azeem Shaikh. These methods allow one to bound&nbsp;the family-wise error rate, which is the probability of making at least one false discovery (i.e., rejecting a null hypothesis when the null hypothesis was true).\nMotivation\nThe standard example to motivate this discussion is to suppose you compute p-values for, say, 10 parameters with independent estimators. If all 10 have p-value equal to 0.05 corresponding to the null hypothesis of each, then we reject the null hypothesis for any one of them with 95% confidence. However, the probability that all of them reject the null hypothesis is  (by independence, the joint probability is the product of marginal probabilities), so we only have 60% confidence in rejecting all of them jointly. If we wish to test for all of the hypotheses jointly, we need some way to adjust the p-values to give us greater confidence in jointly rejecting them. Holm&rsquo;s solution to this problem is to iteratively inflate the individual p-values, so that the smallest p-value is inflated the most, and the largest p-value is not inflated at all (unless one of the smaller p-values is inflated above the largest p-value, then the largest p-value will be inflated to preserve the order of p-values). The specifics of the procedure are below.\nThe Romano-Wolf-Shaikh approach is to account for&nbsp;the dependence among the estimators, and penalize estimators more as they become more independent.&nbsp;Here&rsquo;s&nbsp;how I motivate their approach: First, consider the extreme case of two estimators that are identical. Then, if we reject the null hypothesis for the first, there is no reason to penalize the second; it would be very strange to reject the null hypothesis for the first but not the second when they are identical. Second, suppose&nbsp;they are almost perfectly dependent. Then, rejecting the null for one strongly suggests that we should also reject the null for the second, so we do not want to penalize&nbsp;one very strongly for the rejection of the other. But as they become increasingly independent, the rejection of one provides less and less affirmative information about the other, and we approach the case of perfect independence shown above, which receives the greatest penalty. The specifics of the procedure are below.\nHolm&rsquo;s Correction to the&nbsp;p-values\nSuppose you have a vector of p-values, , of length , and a desired maximum family-wise error rate,  (the most common choice is . These are all of the needed ingredients. Holm&rsquo;s stepdown procedure is as follows:\nIf the&nbsp;smallest element of &nbsp;is greater than , reject no null hypotheses and exit&nbsp;(do not continue to step 2). Else, reject the null hypothesis corresponding to the smallest element of  (continue to step 2).\nIf the second-smallest element of  is greater than , reject no remaining null hypotheses and exit (do not continue to step 3). Else, reject the null hypothesis corresponding to the second-smallest element of  (continue to step 3).\nIf the third-smallest element of  is greater than , reject no remaining null hypotheses and exit (do not continue to step 4). Else, reject the null hypothesis corresponding to the third-smallest element of  (continue to step 4).\nAnd so on.\nWe could program this directly as a loop-based function that takes  as parameters, but a simpler approach is to compute the p-values equivalent&nbsp;to this procedure for any , which are,\n,\nwhere  means the  smallest element. This expression is equivalent&nbsp;to the algorithm above in the sense that, for any family-wise error rate , &nbsp;if and only if the corresponding hypothesis is rejected by the algorithm above.\nThe following code computes these p-values. Julia (apparently) lacks a command that would tell me the index of the rank of the p-values, so my loop below does this, including the handling of ties (when some of the p-values are the same):\n\nfunction Holm(p)\n    K = length(p)\n    sort_index = -ones(K)\n    sorted_p = sort(p)\n    sorted_p_adj = sorted_p.*[K+1-i for i=1:K]\n    for j=1:K\n        num_ties = length(sort_index[(p.==sorted_p[j]) &amp; (sort_index.\nThis is straight-forward except for sort_index, which I constructed such that, e.g., if the first element of sort_index&nbsp;is 3, then the first element of pvalues is the third smallest.&nbsp;Unfortunately, it&nbsp;arbitrarily breaks ties in favor of the parameter that appears first in the MLE array, so the second entry of sort_index&nbsp;is 1 and the third entry is 2, even though the two corresponding p-values are equal. \nPlease email me or leave a comment if you know of a better way to handle ties.\nBootstrap Stepdown p-values\nGiven our work yesterday, it is relatively easy to replace bootstrap marginal p-values with bootstrap stepdown p-values. We begin with&nbsp;samples, as created yesterday. The following code creates tNullDistribution, which is the same as nullDistribution from yesterday except as t-statistics (i.e., divided by standard error).\n\nfunction stepdown(MLE,bootSamples)\n    K = length(MLE)\n    tMLE = MLE\n    bootstrapSE = std(bootSamples,1)\n    tNullDistribution = bootSamples\n    p = -ones(K)\n    for i=1:K\n        tMLE[i] = abs(tMLE[i]/bootstrapSE[i])\n        tNullDistribution[:,i] = abs((tNullDistribution[:,i]-mean(tNullDistribution[:,i]))/bootstrapSE[i])\n        p[i] = mean(tMLE[i].=k]\n        stepdown_p[sort_index[k]] = mean(maximum(tNullDistribution[:,sort_index.&gt;=k],2).&gt;tMLE[sort_index[k]])\n    end\n    return [\"single_pvalues\"=&gt;p,\"stepdown_pvalues\"=&gt;stepdown_p,\"Holm_pvalues\"=&gt;Holm(p)]\nend\n\nThe only difference between the single p-values and the stepdown p-values is the use of the maximum t-statistic in the comparison to the null distribution, and the maximum is taken over only the parameter estimates whose p-values have not yet been computed. Notice that I&nbsp;used a dictionary in the return&nbsp;so that I could output&nbsp;single, stepdown, and Holm p-values from the&nbsp;stepdown function.\nResults\nTo test out the above corrected p-values, we return to MLE and samples&nbsp;from yesterday. Suppose we want to perform the two-sided tests simultaneously for the null hypotheses . The results from the above code are,\n\njulia&gt;&nbsp;stepdown(MLE[1:4],samples[:,1:4])\nDict{ASCIIString,Any} with 3 entries:\n  \"Holm_pvalues\"     =&gt; {0.766,0.766,0.18,0.036}\n  \"stepdown_pvalues\" =&gt; [0.486,0.649,0.169,0.034]\n  \"single_pvalues\"   =&gt; [0.486,0.383,0.06,0.009]\n\nWe see that the p-value corresponding to the null hypothesis  is inflated by both the bootstrap stepdown and Holm procedures, and is no longer significant at the 0.10 level.\nBradley J. Setzler\n&nbsp;","fallback":"Julia/Economics Link: Stepdown p-values for Multiple Hypothesis Testing in&nbsp;Julia","from_url":"https://juliaeconomics.com/2014/06/17/stepdown-p-values-for-multiple-hypothesis-testing-in-julia/","service_icon":"https://s2.wp.com/i/webclip.png","id":1,"original_url":"https://juliaeconomics.com/2014/06/17/stepdown-p-values-for-multiple-hypothesis-testing-in-julia/"}],"blocks":[{"type":"rich_text","block_id":"bsN","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Here is a quantecon post from 2014 about it? "},{"type":"link","url":"https://juliaeconomics.com/2014/06/17/stepdown-p-values-for-multiple-hypothesis-testing-in-julia/"},{"type":"text","text":"\n\nThe syntax will obviously be broken but it will serve as a useful example"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"fac5d510-44a6-486a-b6de-c26f0c6a7198","type":"message","text":"Generally the method is supposed to be pre-specified, but the fact you are even doing a multiple comparison correction is good. Many don't even bother with that a lot of times. I'm also in the health (well, biotech) field. Holm is also an option, it is uniformly more powerful than Bonferroni while keeping the type I error at 5%. I actually haven't heard of these simulation methods myself. Usually I do p.adjust() in R and I think there is something similar in HypothesisTests.jl. Imo saying \"We did Bonferroni correction\" isn't really enough if they have multiple outcomes I agree its ambiguous if they meant they did it on the whole thing vs. separately.","user":"U01EF0QVAB0","ts":"1615253502.101100","team":"T68168MUP","edited":{"user":"U01EF0QVAB0","ts":"1615253647.000000"},"blocks":[{"type":"rich_text","block_id":"dR9T","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Generally the method is supposed to be pre-specified, but the fact you are even doing a multiple comparison correction is good. Many don't even bother with that a lot of times. I'm also in the health (well, biotech) field. Holm is also an option, it is uniformly more powerful than Bonferroni while keeping the type I error at 5%. I actually haven't heard of these simulation methods myself. Usually I do p.adjust() in R and I think there is something similar in HypothesisTests.jl. Imo saying \"We did Bonferroni correction\" isn't really enough if they have multiple outcomes I agree its ambiguous if they meant they did it on the whole thing vs. separately."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"4f01e6c3-afd1-472e-b4e6-d8facf8760c3","type":"message","text":"I like bonferonni-holm","user":"U017JTQFNEQ","ts":"1615255733.101400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jyWf","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I like bonferonni-holm"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"f78c0eab-40c8-4c08-9c14-bb1be8a2bb9c","type":"message","text":"<@U01EF0QVAB0> In statistical point of view, which one is correct, i.e. on whole thing or separately? if separately, which one? People can use wrong implementation of this, but I believe that stats is a exact science, so there should be a correct way of doing this, right?\n\nIf not, do you think it would be fine to increasing the threshold (e.g. 99% significance/0.01 p-value) and do some post-hoc analysis on those combined/union significant variables (e.g. PCA-based multi-colinearity removal)?","user":"UUT4VGTE2","ts":"1615256185.101600","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1615256201.000000"},"blocks":[{"type":"rich_text","block_id":"A2Cp","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U01EF0QVAB0"},{"type":"text","text":" In statistical point of view, which one is correct, i.e. on whole thing or separately? if separately, which one? People can use wrong implementation of this, but I believe that stats is a exact science, so there should be a correct way of doing this, right?\n\nIf not, do you think it would be fine to increasing the threshold (e.g. 99% significance/0.01 p-value) and do some post-hoc analysis on those combined/union significant variables (e.g. PCA-based multi-colinearity removal)?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"7b9f8da0-c675-4ddc-91d6-ea33a98bb55c","type":"message","text":"<@UUT4VGTE2> Stats sometimes can be more of an art than a science, imo. Its not pure mathematics. In that sense both methods are \"correct\", but the interpretation is different (correcting for Type I error rate in your entire study vs per outcome). If I do False Discovery Rate based corrections though I generally correct the whole thing at once (but FDR for this few tests I wouldn't do anyways) because FDR is less conservative as it is than Bonf/Bonf-Holm. It sounds like this is exploratory analysis anyways? In which case, yea going for the more modern regularization or PCA based methods is also an option. I am a statistician and I like the newer stat learning methods personally but a lot of researchers often want p values","user":"U01EF0QVAB0","ts":"1615257626.101900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4aLX","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UUT4VGTE2"},{"type":"text","text":" Stats sometimes can be more of an art than a science, imo. Its not pure mathematics. In that sense both methods are \"correct\", but the interpretation is different (correcting for Type I error rate in your entire study vs per outcome). If I do False Discovery Rate based corrections though I generally correct the whole thing at once (but FDR for this few tests I wouldn't do anyways) because FDR is less conservative as it is than Bonf/Bonf-Holm. It sounds like this is exploratory analysis anyways? In which case, yea going for the more modern regularization or PCA based methods is also an option. I am a statistician and I like the newer stat learning methods personally but a lot of researchers often want p values"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2","reactions":[{"name":"+1","users":["UUT4VGTE2","UKLKS1WC8"],"count":2}]},{"client_msg_id":"2107cbbe-6210-4185-8126-edbc7188bd47","type":"message","text":"Unfortunately indeed there is no consensus.\nIndeed, should all p-values across all domains and scientists be subject to global,\nonline (as in OnlineStats.jl) multiple testing :D?","user":"UKLKS1WC8","ts":"1615258440.102100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pNLBH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Unfortunately indeed there is no consensus.\nIndeed, should all p-values across all domains and scientists be subject to global,\nonline (as in OnlineStats.jl) multiple testing :D?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"024cae6d-525c-435c-8b04-61f06a9e3a23","type":"message","text":"As statisticians we often develop methods that assume the researcher provides\n(data, inferential assumptions, inferential goals)\nand then conduct inference based on these (unfortunately, the assumptions\nand goals are often only implicitly defined).\nThus also here what approach you choose depends on what you want to achieve.\nDo you want to protect against making any false discovery (say with probability 95%)?\nThen use your option 3 (with a method controlling family-wise error at 0.05).\nDo you want to have this protection for all groups separately?\nThen do option 1; this means that say, if you had lots of groups and assuming(!)\nindependent p-values (across groups), then you would make no false discoveries for 95% of the groups)\nand so forth.","user":"UKLKS1WC8","ts":"1615258466.102300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hZUNu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"As statisticians we often develop methods that assume the researcher provides\n(data, inferential assumptions, inferential goals)\nand then conduct inference based on these (unfortunately, the assumptions\nand goals are often only implicitly defined).\nThus also here what approach you choose depends on what you want to achieve.\nDo you want to protect against making any false discovery (say with probability 95%)?\nThen use your option 3 (with a method controlling family-wise error at 0.05).\nDo you want to have this protection for all groups separately?\nThen do option 1; this means that say, if you had lots of groups and assuming(!)\nindependent p-values (across groups), then you would make no false discoveries for 95% of the groups)\nand so forth."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2","reactions":[{"name":"+1","users":["UUT4VGTE2"],"count":1}]},{"client_msg_id":"306c3166-1558-428a-8f6e-d18254adf096","type":"message","text":"Btw I also recommend the following package: <https://github.com/juliangehring/MultipleTesting.jl>","user":"UKLKS1WC8","ts":"1615258489.102500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1U1x","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Btw I also recommend the following package: "},{"type":"link","url":"https://github.com/juliangehring/MultipleTesting.jl"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"95c81282-d8b5-4c33-957c-4539ac64bc41","type":"message","text":"<@U01EF0QVAB0> <@UKLKS1WC8> Thanks for your thoughts! Nikos' explanation makes sense on the purpose of all those approaches.\n\nNikos, do you also agree that I can swap this out with the PCA-based multicolinearity removal (by looking into scree plot and first components)?","user":"UUT4VGTE2","ts":"1615261868.102900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hyg3","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U01EF0QVAB0"},{"type":"text","text":" "},{"type":"user","user_id":"UKLKS1WC8"},{"type":"text","text":" Thanks for your thoughts! Nikos' explanation makes sense on the purpose of all those approaches.\n\nNikos, do you also agree that I can swap this out with the PCA-based multicolinearity removal (by looking into scree plot and first components)?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"b539533f-0677-4213-9b2c-0b5fae1ca4d3","type":"message","text":"I don't quite see how PCA will let you remove features totally, sounds like you want something like elastic net regularization? (Don't use pure L1 with multicollinear features)","user":"U01EF0QVAB0","ts":"1615262089.103100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ckgwu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't quite see how PCA will let you remove features totally, sounds like you want something like elastic net regularization? (Don't use pure L1 with multicollinear features)"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"5d56ef0d-f41e-40c7-84cb-c1d2ad274c8c","type":"message","text":"It's by looking into covariance matrices, and because PCA tries to put most of information in the first components, looking at it we'll see which feature that's best explain the variance of the data mostly.\n\nSimilar like this basically: <https://towardsdatascience.com/how-to-remove-multicollinearity-in-dataset-using-pca-4b4561c28d0b>","user":"UUT4VGTE2","ts":"1615262454.103300","team":"T68168MUP","attachments":[{"service_name":"Medium","title":"How to remove Multicollinearity in dataset using PCA?","title_link":"https://towardsdatascience.com/how-to-remove-multicollinearity-in-dataset-using-pca-4b4561c28d0b","text":"Address Multicollinearity using Principal Component Analysis","fallback":"Medium: How to remove Multicollinearity in dataset using PCA?","image_url":"https://miro.medium.com/max/1200/0*Ha4U528VbaMxNiZ1","fields":[{"title":"Reading time","value":"5 min read","short":true}],"ts":1608405804,"from_url":"https://towardsdatascience.com/how-to-remove-multicollinearity-in-dataset-using-pca-4b4561c28d0b","image_width":375,"image_height":250,"image_bytes":97013,"service_icon":"https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png","id":1,"original_url":"https://towardsdatascience.com/how-to-remove-multicollinearity-in-dataset-using-pca-4b4561c28d0b"}],"blocks":[{"type":"rich_text","block_id":"4geb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's by looking into covariance matrices, and because PCA tries to put most of information in the first components, looking at it we'll see which feature that's best explain the variance of the data mostly.\n\nSimilar like this basically: "},{"type":"link","url":"https://towardsdatascience.com/how-to-remove-multicollinearity-in-dataset-using-pca-4b4561c28d0b"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"cf89e4a3-ef6e-419a-957e-93532ba221b9","type":"message","text":"<@U01EF0QVAB0> most implementations of PCA will return a reduced rank matrix (e.g. if your full data is 10 dimensional but rank 4, you will just get a projection from your original data down to 4D which will not have collinearity). If you take the further step of discarding some low variance components you can denoise as well","user":"U017JTQFNEQ","ts":"1615262854.103600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"O7Fop","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U01EF0QVAB0"},{"type":"text","text":" most implementations of PCA will return a reduced rank matrix (e.g. if your full data is 10 dimensional but rank 4, you will just get a projection from your original data down to 4D which will not have collinearity). If you take the further step of discarding some low variance components you can denoise as well"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2","reactions":[{"name":"+1","users":["UUT4VGTE2"],"count":1}]},{"client_msg_id":"7258c03e-e475-44d2-8044-443ae8821e1b","type":"message","text":"Yea but each PC uses all the features (unless its like sparse PCA), I guess what you mean is discarding the later PCs and then backtransforming or something? I don't see what the advantage of PC over just using l1+l2 regularization is. I think I recall in a grad stat class they mentioned that regularization actually ends up shrinking the directions with less variance anyways","user":"U01EF0QVAB0","ts":"1615263056.103900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Jklx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yea but each PC uses all the features (unless its like sparse PCA), I guess what you mean is discarding the later PCs and then backtransforming or something? I don't see what the advantage of PC over just using l1+l2 regularization is. I think I recall in a grad stat class they mentioned that regularization actually ends up shrinking the directions with less variance anyways"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"071ed50e-6190-42ed-8b31-eecd5b899038","type":"message","text":"I agree with everything <@U01EF0QVAB0> has said. I don't think PCA is the best method to choose which features to look at.  I think using LASSO for exploratory (!) feature selection makes sense (though we could help more with more details about your dataset). A note of caution: If you use the LASSO for feature selection, be very careful in computing p-values (there are so called conditional post-selective inference methods to compute p-values in this case). If you choose a feature by LASSO and then compute the p-values as you showed in the table, then you cannot trust the p-values! (you cannot circumvent the need for multiple testing like this)","user":"UKLKS1WC8","ts":"1615263614.104200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CKqZd","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I agree with everything "},{"type":"user","user_id":"U01EF0QVAB0"},{"type":"text","text":" has said. I don't think PCA is the best method to choose which features to look at.  I think using LASSO for exploratory (!) feature selection makes sense (though we could help more with more details about your dataset). A note of caution: If you use the LASSO for feature selection, be very careful in computing p-values (there are so called conditional post-selective inference methods to compute p-values in this case). If you choose a feature by LASSO and then compute the p-values as you showed in the table, then you cannot trust the p-values! (you cannot circumvent the need for multiple testing like this)"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"29a7428b-31de-4f2e-adde-7be994b634b1","type":"message","text":"(LASSO -&gt; elastic net for the multicollinearity Rohan mentioned)","user":"UKLKS1WC8","ts":"1615263658.104400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8u+P7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(LASSO -> elastic net for the multicollinearity Rohan mentioned)"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"22edd868-2edd-4143-b94f-cf97ff85d161","type":"message","text":"Re-reading this whole thread, I’m pretty confused how we got from correcting for multiple-comparisons to feature selection. <@UUT4VGTE2> i think we could advise you a lot better if you gave a clearer description of what your goal is with this analysis.","user":"U017JTQFNEQ","ts":"1615264187.104600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pRT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Re-reading this whole thread, I’m pretty confused how we got from correcting for multiple-comparisons to feature selection. "},{"type":"user","user_id":"UUT4VGTE2"},{"type":"text","text":" i think we could advise you a lot better if you gave a clearer description of what your goal is with this analysis."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2","reactions":[{"name":"+1","users":["UKLKS1WC8"],"count":1}]},{"client_msg_id":"494d1438-42da-4217-aaec-11b4b006ccf1","type":"message","text":"My goal is basically an explanatory analysis.\n\nI would need to find a set of significant distinguishing variables between those 3 groups.","user":"UUT4VGTE2","ts":"1615264260.104800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"luQz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"My goal is basically an explanatory analysis.\n\nI would need to find a set of significant distinguishing variables between those 3 groups."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"712b2ba2-f468-4beb-aebc-44806e6a4444","type":"message","text":"On further thought maybe your goal  <@UUT4VGTE2> is to do unsupervised feature reduction? I think something  like the following by would work better compared to PCA (though not sure how often people use such approaches in the wild...) <https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0210571>","user":"UKLKS1WC8","ts":"1615264313.105000","team":"T68168MUP","attachments":[{"title":"Deterministic column subset selection for single-cell RNA-Seq","title_link":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0210571","text":"Analysis of single-cell RNA sequencing (scRNA-Seq) data often involves filtering out uninteresting or poorly measured genes and dimensionality reduction to reduce noise and simplify data visualization. However, techniques such as principal components analysis (PCA) fail to preserve non-negativity and sparsity structures present in the original matrices, and the coordinates of projected cells are not easily interpretable. Commonly used thresholding methods to filter genes avoid those pitfalls, but ignore collinearity and covariance in the original matrix. We show that a deterministic column subset selection (DCSS) method possesses many of the favorable properties of common thresholding methods and PCA, while avoiding pitfalls from both. We derive new spectral bounds for DCSS. We apply DCSS to two measures of gene expression from two scRNA-Seq experiments with different clustering workflows, and compare to three thresholding methods. In each case study, the clusters based on the small subset of the complete gene expression profile selected by DCSS are similar to clusters produced from the full set. The resulting clusters are informative for cell type.","fallback":"Deterministic column subset selection for single-cell RNA-Seq","thumb_url":"https://journals.plos.org/plosone/article/figure/image?id=10.1371/journal.pone.0210571.g012&size=inline","from_url":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0210571","thumb_width":320,"thumb_height":193,"service_icon":"https://journals.plos.org/plosone/resource/img/favicon.ico","service_name":"journals.plos.org","id":1,"original_url":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0210571"}],"blocks":[{"type":"rich_text","block_id":"d=iJL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"On further thought maybe your goal  "},{"type":"user","user_id":"UUT4VGTE2"},{"type":"text","text":" is to do unsupervised feature reduction? I think something  like the following by would work better compared to PCA (though not sure how often people use such approaches in the wild...) "},{"type":"link","url":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0210571"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"b3064869-1c2e-4c29-884e-8a641e1945d2","type":"message","text":"Anyway, really appreciate for taking your time to read the whole thread and your assistance guys! <@U01EF0QVAB0> <@UKLKS1WC8> <@U017JTQFNEQ> <@UBF9YRB6H>","user":"UUT4VGTE2","ts":"1615264333.105300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=5V4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyway, really appreciate for taking your time to read the whole thread and your assistance guys! "},{"type":"user","user_id":"U01EF0QVAB0"},{"type":"text","text":" "},{"type":"user","user_id":"UKLKS1WC8"},{"type":"text","text":" "},{"type":"user","user_id":"U017JTQFNEQ"},{"type":"text","text":" "},{"type":"user","user_id":"UBF9YRB6H"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"0611173f-152c-4508-a3a8-b427b924bc4e","type":"message","text":"How many features are there in your dataset? (3 as in the example or a lot more?)","user":"UKLKS1WC8","ts":"1615264365.105500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oTltj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"How many features are there in your dataset? (3 as in the example or a lot more?)"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"398cc49a-c6a9-41f4-8cd0-6fa13806bf16","type":"message","text":"I got 69 features in total, and 3 groups..","user":"UUT4VGTE2","ts":"1615264384.105800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"F9w","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I got 69 features in total, and 3 groups.."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"4aa66aaf-7172-4349-a0d4-56893be5f5af","type":"message","text":"and the p-values are OLS p-values?","user":"UKLKS1WC8","ts":"1615264415.106000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4Decu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and the p-values are OLS p-values?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"8b32c158-bb3f-46fb-9756-8de5704f1423","type":"message","text":"no, it's simple hypothesis test. I used Wilcoxon test.","user":"UUT4VGTE2","ts":"1615264477.106200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=qsO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"no, it's simple hypothesis test. I used Wilcoxon test."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"4755476a-9a88-4a03-bee0-a19a345cd09f","type":"message","text":"sorry for beating a dead horse <@UUT4VGTE2>, but *why* do you want to find a set of distinguishing variables? Are you trying to develop a diagnostic to see if future samples belong to one of the groups? Are you trying to posthoc understand some biological mechanism? are you just trying to add a figure to your paper (which is fine). in other words, if your goal is prediction that would be different than if your goal was understanding (or trying to come up with some parsimonious mechanisms).","user":"U017JTQFNEQ","ts":"1615264755.106400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eWQY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"sorry for beating a dead horse "},{"type":"user","user_id":"UUT4VGTE2"},{"type":"text","text":", but "},{"type":"text","text":"why","style":{"bold":true}},{"type":"text","text":" do you want to find a set of distinguishing variables? Are you trying to develop a diagnostic to see if future samples belong to one of the groups? Are you trying to posthoc understand some biological mechanism? are you just trying to add a figure to your paper (which is fine). in other words, if your goal is prediction that would be different than if your goal was understanding (or trying to come up with some parsimonious mechanisms)."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"6294a4dd-5f35-4a5d-bb41-e1d71173885a","type":"message","text":"<@UUT4VGTE2> is this interpretation correct regarding your goal? You are doing 207 Wilcoxon tests, nothing comes up significant, say, after Bonferroni correction with 207 tests, and you want to find ways to improve power and still make some discoveries?","user":"UKLKS1WC8","ts":"1615264901.106600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gz3QL","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UUT4VGTE2"},{"type":"text","text":" is this interpretation correct regarding your goal? You are doing 207 Wilcoxon tests, nothing comes up significant, say, after Bonferroni correction with 207 tests, and you want to find ways to improve power and still make some discoveries?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"f9a9c46c-dc84-42ad-8345-e16f5d57e3f2","type":"message","text":"It's more like understanding (hence I mentioned explanatory) and not developing any predictive model out of it.\n\nWe would like to see which bio-chemical is statistically significant, then pass to our neurologist team to makes sense of it.","user":"UUT4VGTE2","ts":"1615264927.106800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7D4w","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's more like understanding (hence I mentioned explanatory) and not developing any predictive model out of it.\n\nWe would like to see which bio-chemical is statistically significant, then pass to our neurologist team to makes sense of it."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"8d5c1f96-14af-44b3-808b-a8062bb79049","type":"message","text":"I mean Discoveries that would be considered \"significant\" by reviewers or so","user":"UKLKS1WC8","ts":"1615264944.107000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"r9R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I mean Discoveries that would be considered \"significant\" by reviewers or so"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"90c97b5e-ef37-4132-913d-614031d1b0af","type":"message","text":"Oops, sorry I was replying to Jeff above haha.","user":"UUT4VGTE2","ts":"1615264968.107200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QYuj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oops, sorry I was replying to Jeff above haha."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"50e169f7-b31e-4a84-972c-9907213692e0","type":"message","text":"Yes, on the 207 tests. I'm just trying to make sense of that correction strategy before. And yeah, when I did like my option 1, say, in G1vsG2, nothing comes up significant even on 5% threshold..","user":"UUT4VGTE2","ts":"1615265091.107400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"i/g","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes, on the 207 tests. I'm just trying to make sense of that correction strategy before. And yeah, when I did like my option 1, say, in G1vsG2, nothing comes up significant even on 5% threshold.."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"fab0ae52-0d66-4911-b410-3948c58516a9","type":"message","text":"I would try to see if this could be done through a different model and not just multiple Wilcoxon tests, like the OLS/GLM p value approach (ANOVA is actually just a standard GLM). Those would have more power anyways than wilcoxon since they are parametric and tthey use information from all groups to estimate SEs. And actually, the normality assumptions isn't very important-- but the variance of residual one is, and often times biochemicals are heteroscedastic with constant coef of variation so I would consider like a Gamma GLM regression or log transformed OLS","user":"U01EF0QVAB0","ts":"1615265131.107600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IvI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I would try to see if this could be done through a different model and not just multiple Wilcoxon tests, like the OLS/GLM p value approach (ANOVA is actually just a standard GLM). Those would have more power anyways than wilcoxon since they are parametric and tthey use information from all groups to estimate SEs. And actually, the normality assumptions isn't very important-- but the variance of residual one is, and often times biochemicals are heteroscedastic with constant coef of variation so I would consider like a Gamma GLM regression or log transformed OLS"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"71d4a2bd-b68b-4904-839b-3f5e17720736","type":"message","text":"The reason I'm doing this multiple tests as opposed to something like Kruskal-Walis is that 2 of my group, e.g. G1 and G2 are related (i.e. before and after activity).","user":"UUT4VGTE2","ts":"1615265159.107800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CT1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The reason I'm doing this multiple tests as opposed to something like Kruskal-Walis is that 2 of my group, e.g. G1 and G2 are related (i.e. before and after activity)."}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"1dee3ba1-370e-4d04-8f35-cd44e771bc4a","type":"message","text":"Oh in that case LMMs/GLMMs would be the corresponding equivalent","user":"U01EF0QVAB0","ts":"1615265185.108000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"YOhqE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh in that case LMMs/GLMMs would be the corresponding equivalent"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2","reactions":[{"name":"thumbsup_all","users":["U017JTQFNEQ"],"count":1}]},{"client_msg_id":"b176a9d5-084b-41e6-9e45-2eafff2c83ec","type":"message","text":"Ah ok. What's the smallest p-value you have (without multiplicity correction)? A possibility here (if that smallest p-value still is reasonably small) if you want to stay with the Wilcoxon p-values is the following: You can do Independent Filtering :smile:, that is a general set of techniques which first subsets your hypotheses and then applies the multiple testing method to the remaining ones. You need to be careful in general to do this (to not lose guarantees of statistical validity but sometimes it is possible). This is the canonical paper for this kind of technique <https://www.pnas.org/content/107/21/9546> and I think it discusses Wilcoxon too. [In fact, I have spent a lot of time doing research to extend this idea from filtering to hypothesis weighting, so just ask me if that is a path you want to pursue]","user":"UKLKS1WC8","ts":"1615265377.108200","team":"T68168MUP","attachments":[{"service_name":"PNAS","title":"Independent filtering increases detection power for high-throughput experiments","title_link":"https://www.pnas.org/content/107/21/9546","text":"With high-dimensional data, variable-by-variable statistical testing is often used to select variables whose behavior differs across conditions. Such an approach requires adjustment for multiple testing, which can result in low statistical power. A two-stage approach that first filters variables by a criterion independent of the test statistic, and then only tests variables which pass the filter, can provide higher power. We show that use of some filter/test statistics pairs presented in the literature may, however, lead to loss of type I error control. We describe other pairs which avoid this problem. In an application to microarray data, we found that gene-by-gene filtering by overall variance followed by a t -test increased the number of discoveries by 50%. We also show that this particular statistic pair induces a lower bound on fold-change among the set of discoveries. Independent filtering—using filter/test pairs that are independent under the null hypothesis but correlated under the alternative—is a general approach that can substantially increase the efficiency of experiments.","fallback":"PNAS: Independent filtering increases detection power for high-throughput experiments","ts":1274770800,"from_url":"https://www.pnas.org/content/107/21/9546","service_icon":"https://www.pnas.org/sites/default/files/images/favicon.ico","id":1,"original_url":"https://www.pnas.org/content/107/21/9546"}],"blocks":[{"type":"rich_text","block_id":"Z2O0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah ok. What's the smallest p-value you have (without multiplicity correction)? A possibility here (if that smallest p-value still is reasonably small) if you want to stay with the Wilcoxon p-values is the following: You can do Independent Filtering "},{"type":"emoji","name":"smile"},{"type":"text","text":", that is a general set of techniques which first subsets your hypotheses and then applies the multiple testing method to the remaining ones. You need to be careful in general to do this (to not lose guarantees of statistical validity but sometimes it is possible). This is the canonical paper for this kind of technique "},{"type":"link","url":"https://www.pnas.org/content/107/21/9546"},{"type":"text","text":" and I think it discusses Wilcoxon too. [In fact, I have spent a lot of time doing research to extend this idea from filtering to hypothesis weighting, so just ask me if that is a path you want to pursue]"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"671c24f6-0c88-4d5d-96b5-c8e59eca97f4","type":"message","text":"<@UKLKS1WC8> So let me try to sum up that method:\n1. Filter my variables by some stats measures, e.g. remove variable with high variance.\n2. Do Wilcoxon tests -&gt; results in uncorrected p-values\n3. Perform correction (on those combined p-values, i.e. option 3 in my question) and get significant variables based on these corrected p-values\nIs that correct?","user":"UUT4VGTE2","ts":"1615266088.108500","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1615266129.000000"},"blocks":[{"type":"rich_text","block_id":"A+7ek","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UKLKS1WC8"},{"type":"text","text":" So let me try to sum up that method:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Filter my variables by some stats measures, e.g. remove variable with high variance."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Do Wilcoxon tests -> results in uncorrected p-values"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Perform correction (on those combined p-values, i.e. option 3 in my question) and get significant variables based on these corrected p-values"}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"Is that correct?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"a54ef303-f173-41c3-b53e-0245beb5f26a","type":"message","text":"<@U01EF0QVAB0> Thanks for that suggestion. I will look at that. With that approach, what is the measurement of significance for each variable?","user":"UUT4VGTE2","ts":"1615267449.108900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"HZuq5","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U01EF0QVAB0"},{"type":"text","text":" Thanks for that suggestion. I will look at that. With that approach, what is the measurement of significance for each variable?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"bcac1562-233a-441c-a493-6372e22a9aca","type":"message","text":"Yes that is correct. The main subtlety is in step 1: You need a measure that is independent of the p-value under the null hypothesis (the paper I referenced gives example of how to do this in the case of Wilcoxon, e.g. you can use the sample variance where however you pool all samples together. So e.g. compute the sample variance of variable 1 after creating a joint vector of the samples in group 1 and group 2 -- the measure definitely is not allowed to know the group identities in this case.)","user":"UKLKS1WC8","ts":"1615267596.109100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UOIa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes that is correct. The main subtlety is in step 1: You need a measure that is independent of the p-value under the null hypothesis (the paper I referenced gives example of how to do this in the case of Wilcoxon, e.g. you can use the sample variance where however you pool all samples together. So e.g. compute the sample variance of variable 1 after creating a joint vector of the samples in group 1 and group 2 -- the measure definitely is not allowed to know the group identities in this case.)"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"c524ec5e-92dd-41bf-aff1-a79b4df5a07f","type":"message","text":"[At least for high-throughput genomics datasets, for this type of filtering  you typically want to keep the high variance ones though. You basically are hoping that a decent component of the variance can be explained by the inter-group differences and this is what your filter is picking up.]","user":"UKLKS1WC8","ts":"1615267717.109300","team":"T68168MUP","edited":{"user":"UKLKS1WC8","ts":"1615267741.000000"},"blocks":[{"type":"rich_text","block_id":"3GXtl","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"[At least for high-throughput genomics datasets, for this type of filtering  you typically want to keep the high variance ones though. You basically are hoping that a decent component of the variance can be explained by the inter-group differences and this is what your filter is picking up.]"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"32d3a838-be02-41c0-8301-e39608ee585f","type":"message","text":"<@UKLKS1WC8> Thanks! I will try this..\n\nDo you mind if I share what I did to see if that is sufficient for my goal?","user":"UUT4VGTE2","ts":"1615268101.109600","team":"T68168MUP","edited":{"user":"UUT4VGTE2","ts":"1615268108.000000"},"blocks":[{"type":"rich_text","block_id":"pJLcu","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UKLKS1WC8"},{"type":"text","text":" Thanks! I will try this..\n\nDo you mind if I share what I did to see if that is sufficient for my goal?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"2a2de43b-4bbc-4cb4-a9f1-79c59b666f92","type":"message","text":"Yes of course, feel free to ping/pm me","user":"UKLKS1WC8","ts":"1615269012.110000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/uGX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yes of course, feel free to ping/pm me"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"30b1c0ee-fdfb-4460-b2c6-58175edc7b50","type":"message","text":"Don't want to be the guy who just jumps in to say \"you should read this paper\" without offering practical suggestions, but I think this is a helpful perspective: <http://www.stat.columbia.edu/~gelman/research/published/multiple2f.pdf|http://www.stat.columbia.edu/~gelman/research/published/multiple2f.pdf>","user":"U7JQGPGCQ","ts":"1615269620.110200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7++e","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Don't want to be the guy who just jumps in to say \"you should read this paper\" without offering practical suggestions, but I think this is a helpful perspective: "},{"type":"link","url":"http://www.stat.columbia.edu/~gelman/research/published/multiple2f.pdf","text":"http://www.stat.columbia.edu/~gelman/research/published/multiple2f.pdf"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"0c788488-715c-436d-8e0b-297a503ff7e8","type":"message","text":"<@UUT4VGTE2> For LMMs/GLMMs it is just p values from contrasts of the regression coefficients. The random effects can mostly be treated as a nuisance parameter so the inference is similar to that of OLS/GLM","user":"U01EF0QVAB0","ts":"1615269956.110400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FK=0","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UUT4VGTE2"},{"type":"text","text":" For LMMs/GLMMs it is just p values from contrasts of the regression coefficients. The random effects can mostly be treated as a nuisance parameter so the inference is similar to that of OLS/GLM"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"09118d23-be6c-4c34-9acb-2674d8ec4de4","type":"message","text":"I unfortunately don't know any Julia packages (nor Python) that have contrasts but the emmeans library in R is good, you can use emmeans(model,pairwise~Group) on a model to get the pairwise comparisons between groups","user":"U01EF0QVAB0","ts":"1615270046.110600","team":"T68168MUP","edited":{"user":"U01EF0QVAB0","ts":"1615270066.000000"},"blocks":[{"type":"rich_text","block_id":"0Iu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I unfortunately don't know any Julia packages (nor Python) that have contrasts but the emmeans library in R is good, you can use emmeans(model,pairwise~Group) on a model to get the pairwise comparisons between groups"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"70f52e61-34bc-44ff-9e6b-df2723b71ea7","type":"message","text":"Statsmodel's formula will just apply contrasts coding to a categorical variable, no?","user":"U7JQGPGCQ","ts":"1615270178.110900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fvCJT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Statsmodel's formula will just apply contrasts coding to a categorical variable, no?"}]}]}],"thread_ts":"1615251194.098200","parent_user_id":"UUT4VGTE2"}]