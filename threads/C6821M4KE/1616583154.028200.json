[{"client_msg_id":"2550201f-9348-4bea-998c-0609040c2d8d","type":"message","text":"I have a bit of an audit sampling conundrum, which isn't really my area of expertise, but one of those problems where I think I should definitely be a Bayesian so maybe someone here has ideas or pointers. I have a population of (let's say) 100,000 invoices, and want to answer the standard audit question \"which fraction of these invoices is incorrect\", for which a sample has to be audited. Now the standard approach would (probably) be to just specify some prior Beta distribution with \"success\" denoting an error found, and then work out how many samples I need (assuming a certain chance of drawing a success on each draw) to get to a posterior that gives the required confidence interval.\n\nNow the twist is that I have a small (let's say 5%) subpopulation for which I know that the error rate is higher, and I wonder how (if at all) I should incorporate this knowledge:\n\n* Just ignore it, the higher expected error rate in the subpopulation changes my expected whole population error rate and so the info is already in the sample calculation above;\n* Treat them as two separate populations, which would likely lead to a higher overall sample size (as the whole population error rate is close to zero, removing the subpopulation will not really decrease the required sample size there, but a relatively large sample size will be required for the more volatile subpopulation)\n* Something in between (I hear a lot about \"pooling\" estimators in Bayesian analysis, but it's one of these things I've never really got my traditional-econometrics-trained head around\n\nI could imagine amending point (2) above in some way to basically calculate the sample size with reference to the whole population posterior, i.e. taking into account that the posterior for the subpopulation will be much less important when estimating the population posterior (which I guess would be a mixture of the two posteriors, weighted by the whole population share of both subpopulations?)\n\nIf anyone has any ideas on how to conceptually best approach this I'd be most grateful!","user":"U7JQGPGCQ","ts":"1616583154.028200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5T3/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I have a bit of an audit sampling conundrum, which isn't really my area of expertise, but one of those problems where I think I should definitely be a Bayesian so maybe someone here has ideas or pointers. I have a population of (let's say) 100,000 invoices, and want to answer the standard audit question \"which fraction of these invoices is incorrect\", for which a sample has to be audited. Now the standard approach would (probably) be to just specify some prior Beta distribution with \"success\" denoting an error found, and then work out how many samples I need (assuming a certain chance of drawing a success on each draw) to get to a posterior that gives the required confidence interval.\n\nNow the twist is that I have a small (let's say 5%) subpopulation for which I know that the error rate is higher, and I wonder how (if at all) I should incorporate this knowledge:\n\n* Just ignore it, the higher expected error rate in the subpopulation changes my expected whole population error rate and so the info is already in the sample calculation above;\n* Treat them as two separate populations, which would likely lead to a higher overall sample size (as the whole population error rate is close to zero, removing the subpopulation will not really decrease the required sample size there, but a relatively large sample size will be required for the more volatile subpopulation)\n* Something in between (I hear a lot about \"pooling\" estimators in Bayesian analysis, but it's one of these things I've never really got my traditional-econometrics-trained head around\n\nI could imagine amending point (2) above in some way to basically calculate the sample size with reference to the whole population posterior, i.e. taking into account that the posterior for the subpopulation will be much less important when estimating the population posterior (which I guess would be a mixture of the two posteriors, weighted by the whole population share of both subpopulations?)\n\nIf anyone has any ideas on how to conceptually best approach this I'd be most grateful!"}]}]}],"thread_ts":"1616583154.028200","reply_count":3,"reply_users_count":1,"latest_reply":"1616584262.028900","reply_users":["U6C937ENB"],"is_locked":false,"subscribed":false},{"client_msg_id":"859c46d0-de50-4ebd-a3ef-7e30e5175d38","type":"message","text":"If you have to subpopulations with different error rates, the model which assumes one error rate for everybody is not correct* and the uncertainty in the error rate of the subpopulation is real.","user":"U6C937ENB","ts":"1616583758.028300","team":"T68168MUP","edited":{"user":"U6C937ENB","ts":"1616583825.000000"},"blocks":[{"type":"rich_text","block_id":"uQf8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If you have to subpopulations with different error rates, the model which assumes one error rate for everybody is not correct* and the uncertainty in the error rate of the subpopulation is real."}]}]}],"thread_ts":"1616583154.028200","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"11d95abe-0739-47b9-9f1a-35ce8a7a448f","type":"message","text":"* mildy, because it is difficult to tell a mixture of Bernoullis apart from homogeneous Bernoullis based on  data without observing the labels. Might be impossible","user":"U6C937ENB","ts":"1616583920.028600","team":"T68168MUP","edited":{"user":"U6C937ENB","ts":"1616583972.000000"},"blocks":[{"type":"rich_text","block_id":"UcV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"* mildy, because it is difficult to tell a mixture of Bernoullis apart from homogeneous Bernoullis based on  data without observing the labels. Might be impossible"}]}]}],"thread_ts":"1616583154.028200","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"94979625-cf09-4690-86c3-8a555646c60d","type":"message","text":"I think now you can take option “just ignore it” if this is good news","user":"U6C937ENB","ts":"1616584262.028900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"X0F","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think now you can take option “just ignore it” if this is good news"}]}]}],"thread_ts":"1616583154.028200","parent_user_id":"U7JQGPGCQ"}]