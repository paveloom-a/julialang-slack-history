[{"client_msg_id":"1cce40ae-f293-4d76-827c-ca3a9a462c43","type":"message","text":"Hi guys, quick question on basic sequential forward selection. Does that algorithm stops when performance starts to drop? For instance, if I specify _k=5_ (5 features to look for) and by adding the 4th feature the performance (e.g. some metrics such as accuracy) drops, will it stop or move forward?","user":"UUT4VGTE2","ts":"1615866051.001500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"H9H","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi guys, quick question on basic sequential forward selection. Does that algorithm stops when performance starts to drop? For instance, if I specify "},{"type":"text","text":"k=5","style":{"italic":true}},{"type":"text","text":" (5 features to look for) and by adding the 4th feature the performance (e.g. some metrics such as accuracy) drops, will it stop or move forward?"}]}]}],"thread_ts":"1615866051.001500","reply_count":4,"reply_users_count":3,"latest_reply":"1616037660.000800","reply_users":["UPFC1UFJM","UUT4VGTE2","U01EF0QVAB0"],"subscribed":false},{"client_msg_id":"6e1ef576-14f3-4341-96e9-bd1954a044a9","type":"message","text":"Typically the model wouldn’t move forward if no additional variable improved performance","user":"UPFC1UFJM","ts":"1615904641.001800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=4/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Typically the model wouldn’t move forward if no additional variable improved performance"}]}]}],"thread_ts":"1615866051.001500","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"cf25f717-7dbd-4951-8eb5-454811b2c8df","type":"message","text":"<@UPFC1UFJM> Thanks for replying. Is there any paper I could reference this to? <http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/|This Mlxtend> description doesn't seem to mention on stopping when the performance doesn't improve.","user":"UUT4VGTE2","ts":"1615943930.000100","team":"T68168MUP","attachments":[{"title":"Sequential Feature Selector - mlxtend","title_link":"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/","text":"A library consisting of useful tools and extensions for the day-to-day data science tasks.","fallback":"Sequential Feature Selector - mlxtend","from_url":"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/","service_icon":"http://rasbt.github.io/mlxtend/img/favicon.ico","service_name":"rasbt.github.io","id":1,"original_url":"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/"}],"blocks":[{"type":"rich_text","block_id":"gskFS","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UPFC1UFJM"},{"type":"text","text":" Thanks for replying. Is there any paper I could reference this to? "},{"type":"link","url":"http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/","text":"This Mlxtend"},{"type":"text","text":" description doesn't seem to mention on stopping when the performance doesn't improve."}]}]}],"thread_ts":"1615866051.001500","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"5986361c-5fa2-4d3a-b624-0546206cbaf2","type":"message","text":"I learned about the technique in school and through textbooks, so I haven’t read any papers going through the stepwise selection.","user":"UPFC1UFJM","ts":"1615994866.000400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ANEH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I learned about the technique in school and through textbooks, so I haven’t read any papers going through the stepwise selection."}]}]}],"thread_ts":"1615866051.001500","parent_user_id":"UUT4VGTE2"},{"client_msg_id":"823f79db-9273-4631-9131-add84a1a7c6d","type":"message","text":"I would honestly avoid stepwise feature selection in 2021, a lot of statisticians consider it dubious. Better to use regularization (L1/L2) or Bayesian methods (which indirectly regularize anyways). From an inferential perspective, assessing pvalues after stepwise is wrong whereas from a predictive perspective, regularization performs and generalizes much better","user":"U01EF0QVAB0","ts":"1616037660.000800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nfG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I would honestly avoid stepwise feature selection in 2021, a lot of statisticians consider it dubious. Better to use regularization (L1/L2) or Bayesian methods (which indirectly regularize anyways). From an inferential perspective, assessing pvalues after stepwise is wrong whereas from a predictive perspective, regularization performs and generalizes much better"}]}]}],"thread_ts":"1615866051.001500","parent_user_id":"UUT4VGTE2","reactions":[{"name":"+1","users":["UPFC1UFJM"],"count":1}]}]