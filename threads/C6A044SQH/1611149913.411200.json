[{"client_msg_id":"d8665440-5410-465e-ac88-7c928ab781e3","type":"message","text":"Hi everyone, I have a large (non-sparse) array of data in julia of dimension (5,000,000 x 33). Is there an efficient way to save this as a compressed data file such that I can quickly import it into R?","user":"ULVNP0ZFW","ts":"1611149913.411200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"420","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi everyone, I have a large (non-sparse) array of data in julia of dimension (5,000,000 x 33). Is there an efficient way to save this as a compressed data file such that I can quickly import it into R?"}]}]}],"thread_ts":"1611149913.411200","reply_count":2,"reply_users_count":2,"latest_reply":"1611153533.415600","reply_users":["U012C82M8T0","U01FAHWCMFF"],"subscribed":false},{"client_msg_id":"4ffce320-f155-4272-bae3-6810215927a0","type":"message","text":"It depends on what you are trying to achieve. You could build a DataFrames.DataFrame and write this as a csv-File. Afterwards you could zip this ore something else. But the matrix is relativ huge. I tried this and ended up with a csv-Fiel about 2,98 GB (storing floats).\nit works like this:\nusing DataFrames\nusing CSV\ndf = DataFrames.DatatFrame(array)\nCSV.write(yourCSVFile.csv, df)\n\nHTH\nFrank","user":"U012C82M8T0","ts":"1611152353.414500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"kstV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It depends on what you are trying to achieve. You could build a DataFrames.DataFrame and write this as a csv-File. Afterwards you could zip this ore something else. But the matrix is relativ huge. I tried this and ended up with a csv-Fiel about 2,98 GB (storing floats).\nit works like this:\nusing DataFrames\nusing CSV\ndf = DataFrames.DatatFrame(array)\nCSV.write(yourCSVFile.csv, df)\n\nHTH\nFrank"}]}]}],"thread_ts":"1611149913.411200","parent_user_id":"ULVNP0ZFW"},{"client_msg_id":"c8db2021-346c-4fa2-a462-411628d1f339","type":"message","text":"<https://github.com/JuliaData/Arrow.jl> for fast file read speeds\n<https://github.com/JuliaIO/Parquet.jl> for fast file read speeds + compressed file","user":"U01FAHWCMFF","ts":"1611153533.415600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/l7","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/JuliaData/Arrow.jl"},{"type":"text","text":" for fast file read speeds\n"},{"type":"link","url":"https://github.com/JuliaIO/Parquet.jl"},{"type":"text","text":" for fast file read speeds + compressed file"}]}]}],"thread_ts":"1611149913.411200","parent_user_id":"ULVNP0ZFW"}]