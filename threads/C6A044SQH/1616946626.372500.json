[{"client_msg_id":"d55a58e0-38d5-41c7-89a3-0b91141feee5","type":"message","text":"Any Flux.jl experts? For some reason I'm finding it really hard to debug gradient based errors.\n\nThe loss is computed but the gradient is never taken.\n```        gs = gradient(ps) do\n            training_loss = loss(a, b)\n            println(\"Loss = \", training_loss)\n            training_loss\n        end\n        print(\"CHECK\")```\n```┌ Info: Epoch 1\n└ @ Main /root/.julia/packages/Flux/fIQzT/src/optimise/train.jl:136\n\nLoss = 5595.0067610553515\n\nMethodError: no method matching getindex(::Dict{Any, Any})\nClosest candidates are:\n  getindex(::Dict{K, V}, ::Any) where {K, V} at dict.jl:480\n  getindex(::AbstractDict, ::Any) at abstractdict.jl:494\n  getindex(::AbstractDict, ::Any, ::Any, ::Any...) at abstractdict.jl:504```","user":"U01FAHWCMFF","ts":"1616946626.372500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"PiSI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Any Flux.jl experts? For some reason I'm finding it really hard to debug gradient based errors.\n\nThe loss is computed but the gradient is never taken.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"        gs = gradient(ps) do\n            training_loss = loss(a, b)\n            println(\"Loss = \", training_loss)\n            training_loss\n        end\n        print(\"CHECK\")"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"┌ Info: Epoch 1\n└ @ Main /root/.julia/packages/Flux/fIQzT/src/optimise/train.jl:136\n\nLoss = 5595.0067610553515\n\nMethodError: no method matching getindex(::Dict{Any, Any})\nClosest candidates are:\n  getindex(::Dict{K, V}, ::Any) where {K, V} at dict.jl:480\n  getindex(::AbstractDict, ::Any) at abstractdict.jl:494\n  getindex(::AbstractDict, ::Any, ::Any, ::Any...) at abstractdict.jl:504"}]}]}],"thread_ts":"1616946626.372500","reply_count":16,"reply_users_count":2,"latest_reply":"1616954642.377900","reply_users":["UC4QQPG4A","U01FAHWCMFF"],"is_locked":false,"subscribed":false},{"client_msg_id":"e8afb2f4-9eec-4daf-a222-260623b62825","type":"message","text":"Hi! What's the loss function doing here? It seems to be calling getindex without an index?","user":"UC4QQPG4A","ts":"1616946951.372700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jsoPQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi! What's the loss function doing here? It seems to be calling getindex without an index?"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"bebb7f35-2472-49c7-9af9-cd1d89f60669","type":"message","text":"Ya it was just a typo that did this. Been banging my head for 30 min trying to solve it :cry: Thanks","user":"U01FAHWCMFF","ts":"1616947664.374300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0ERVa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ya it was just a typo that did this. Been banging my head for 30 min trying to solve it "},{"type":"emoji","name":"cry"},{"type":"text","text":" Thanks"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"1e13aae6-36e3-4da6-bf94-810ce142db3f","type":"message","text":"Oof, glad you got it sorted!","user":"UC4QQPG4A","ts":"1616948128.374800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Zbw","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oof, glad you got it sorted!"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"ad924916-1db4-4759-8ee1-5f4c3c649db7","type":"message","text":"Thanks, btw are you familiar with negative sampling loss?","user":"U01FAHWCMFF","ts":"1616948149.375000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"eKz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks, btw are you familiar with negative sampling loss?"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"d5b2836b-a703-432b-89b8-1d0bf613df59","type":"message","text":"Sure","user":"UC4QQPG4A","ts":"1616948166.375200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1blj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Sure"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"b3e1fafd-8dbe-4a16-8f5b-ee37c9f4ff4a","type":"message","text":"I just need another pair of eyes but can you see if Im calculating it correctly?\n\n\n```function negative_sampling_loss(model, vocab_idx, doc_idx)\n    y = Int(round(length(vocab_idx) / 2))\n    ŷs = model(vocab_idx, doc_idx)\n    ŷ = argmax(ŷs)\n    target_id = ŷ\n    context_idx = vocab_idx[vocab_idx .!= y]\n    sample_idx = 1:length(ŷs)\n    sample_idx = setdiff(sample_idx, [target_id, context_idx...])\n    loss_1 = -sum(log.(sigmoid.((context_idx' * target_id))))\n    loss_2 = -sum(log.(sigmoid.(-(sample_idx' * target_id))))\n    loss_1 + loss_2\nend```\n","user":"U01FAHWCMFF","ts":"1616948198.375600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JnU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I just need another pair of eyes but can you see if Im calculating it correctly?\n\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function negative_sampling_loss(model, vocab_idx, doc_idx)\n    y = Int(round(length(vocab_idx) / 2))\n    ŷs = model(vocab_idx, doc_idx)\n    ŷ = argmax(ŷs)\n    target_id = ŷ\n    context_idx = vocab_idx[vocab_idx .!= y]\n    sample_idx = 1:length(ŷs)\n    sample_idx = setdiff(sample_idx, [target_id, context_idx...])\n    loss_1 = -sum(log.(sigmoid.((context_idx' * target_id))))\n    loss_2 = -sum(log.(sigmoid.(-(sample_idx' * target_id))))\n    loss_1 + loss_2\nend"}]},{"type":"rich_text_section","elements":[]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"3f129196-390b-4d81-b608-a86380fa5655","type":"message","text":"I should clarify Im trying to get some basic NLP libraries made","user":"U01FAHWCMFF","ts":"1616948233.375800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GGQL9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I should clarify Im trying to get some basic NLP libraries made"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"d2ceefb0-8b00-4557-9a7d-f116b5ae7cb4","type":"message","text":"Seems to be decent, but I'm just able to do a cursory look on the phone. Do you have a link to these libraries?","user":"UC4QQPG4A","ts":"1616948355.376000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zIVy","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Seems to be decent, but I'm just able to do a cursory look on the phone. Do you have a link to these libraries?"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"5b1622f6-799c-4919-b347-03c17acf3050","type":"message","text":"Everything is local atm but I will soon post to github, as soon as my NN actually runs once.","user":"U01FAHWCMFF","ts":"1616948389.376200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2o9f","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Everything is local atm but I will soon post to github, as soon as my NN actually runs once."}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"d3e8c815-1a16-4bc3-9c99-bbfb1fdc120a","type":"message","text":"Im finding the stacktrace for flux/gradient stuff really hard to debug","user":"U01FAHWCMFF","ts":"1616948407.376400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Kzmg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Im finding the stacktrace for flux/gradient stuff really hard to debug"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"63528dcd-5310-4379-b7ba-6256cf5ea2ed","type":"message","text":"Why is it outputing the loss even though the code is breaking in the loss function","user":"U01FAHWCMFF","ts":"1616948449.376600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GSi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Why is it outputing the loss even though the code is breaking in the loss function"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"ddc74e8f-06aa-463c-ac5e-28e7dc57ef56","type":"message","text":"There's two stages essentially. The first where we follow the \"forward pass\" which is the regular function call and use it to construct the \"backwards pass\". The printing just happens to happen in the forward pass. We need to do it this way so that any expressions that need to be tracked to calculate the gradients correctly are caught.","user":"UC4QQPG4A","ts":"1616948869.376800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"94t9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's two stages essentially. The first where we follow the \"forward pass\" which is the regular function call and use it to construct the \"backwards pass\". The printing just happens to happen in the forward pass. We need to do it this way so that any expressions that need to be tracked to calculate the gradients correctly are caught."}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"e343db43-9c52-4839-bbcd-4eb642bbf3fa","type":"message","text":"Ah I see, its breaking in the backpropagation stage. Ok now I get why that happens. Is there a way to debug during this propogation with print statements. Currently trying to debug the following. Note this bugs in backpropogation not foreward.\n\nThe error\n```DimensionMismatch(\"cannot broadcast array to have fewer dimensions\")```\nThe code\n```function negative_sampling_loss(model, vocab_idx, doc_idx)\n    y = Int(round(length(vocab_idx) / 2))\n    ŷs = model(vocab_idx, doc_idx)\n    ŷ = argmax(ŷs)\n    target_id = ŷ\n    context_idx = vocab_idx[vocab_idx .!= y]\n    sample_idx = 1:length(ŷs)\n    sample_idx = setdiff(sample_idx, [target_id, context_idx...])\n    loss_1 = -sum(log.(sigmoid.((context_idx' * target_id))))\n    loss_2 = -sum(log.(sigmoid.(-(sample_idx' * target_id))))\n    loss_1 + loss_2\nend```\nWhere its breaking\n```    sample_idx = setdiff(sample_idx, [target_id, context_idx...])```","user":"U01FAHWCMFF","ts":"1616949128.377000","team":"T68168MUP","edited":{"user":"U01FAHWCMFF","ts":"1616949162.000000"},"blocks":[{"type":"rich_text","block_id":"3wA","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah I see, its breaking in the backpropagation stage. Ok now I get why that happens. Is there a way to debug during this propogation with print statements. Currently trying to debug the following. Note this bugs in backpropogation not foreward.\n\nThe error\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"DimensionMismatch(\"cannot broadcast array to have fewer dimensions\")"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nThe code\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function negative_sampling_loss(model, vocab_idx, doc_idx)\n    y = Int(round(length(vocab_idx) / 2))\n    ŷs = model(vocab_idx, doc_idx)\n    ŷ = argmax(ŷs)\n    target_id = ŷ\n    context_idx = vocab_idx[vocab_idx .!= y]\n    sample_idx = 1:length(ŷs)\n    sample_idx = setdiff(sample_idx, [target_id, context_idx...])\n    loss_1 = -sum(log.(sigmoid.((context_idx' * target_id))))\n    loss_2 = -sum(log.(sigmoid.(-(sample_idx' * target_id))))\n    loss_1 + loss_2\nend"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nWhere its breaking\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"    sample_idx = setdiff(sample_idx, [target_id, context_idx...])"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"a86736a6-a0ee-4833-bfe8-4781241531ad","type":"message","text":"Could you try to come up with an MWE with just that line?","user":"UC4QQPG4A","ts":"1616954186.377500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"medM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Could you try to come up with an MWE with just that line?"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"2cc70fb8-b1e1-43c7-a2bd-6d0478c05133","type":"message","text":"What i ended up doing to fix this was simply make the loss function the calculation part, and moving all the sampling stuff outside into the training loop. No idea why some functions don't work in the gradient step.\n\nAnyways I finally got everything to run, so thanks :slightly_smiling_face:","user":"U01FAHWCMFF","ts":"1616954347.377700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WvP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What i ended up doing to fix this was simply make the loss function the calculation part, and moving all the sampling stuff outside into the training loop. No idea why some functions don't work in the gradient step.\n\nAnyways I finally got everything to run, so thanks "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF"},{"client_msg_id":"a18fd1b8-43a7-40db-9600-262928c1d7eb","type":"message","text":"You could just use Zygote.ignore there.","user":"UC4QQPG4A","ts":"1616954642.377900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"M38Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You could just use Zygote.ignore there."}]}]}],"thread_ts":"1616946626.372500","parent_user_id":"U01FAHWCMFF","reactions":[{"name":"thumbsup_all","users":["U01FAHWCMFF"],"count":1}]}]