[{"client_msg_id":"d00bd9ba-e7ad-4bdf-9315-9552d381e103","type":"message","text":"I am trying to run a script in parallel and using something like this `julia --project -p 4 mpi_shallow_water_turbulence.jl` , which I hope means it's going to run on 4 cores.  Unfortunately, this doesn't run and it seems to be running with 5 cores.  Am I using the wrong syntax to run the script on 4 cores?\n\n```ERROR: LoadError: ProcessExitedException(3)\n\n...and 2 more exception(s).\n\nStacktrace:\n [1] sync_end(::Channel{Any}) at ./task.jl:314\n [2] macro expansion at ./task.jl:333 [inlined]\n [3] _require_callback(::Base.PkgId) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/Distributed.jl:75\n [4] #invokelatest#1 at ./essentials.jl:710 [inlined]\n [5] invokelatest at ./essentials.jl:709 [inlined]\n [6] require(::Base.PkgId) at ./loading.jl:931\n [7] require(::Module, ::Symbol) at ./loading.jl:923\n [8] include(::Function, ::Module, ::String) at ./Base.jl:380\n [9] include(::Module, ::String) at ./Base.jl:368\n [10] exec_options(::Base.JLOptions) at ./client.jl:296\n [11] _start() at ./client.jl:506\nin expression starting at /home/fpoulin/software/Oceananigans.jl/examples/mpi_shallow_water_turbulence.jl:6```","user":"U01FBLBCP7S","ts":"1615315704.225500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tnCY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am trying to run a script in parallel and using something like this "},{"type":"text","text":"julia --project -p 4 mpi_shallow_water_turbulence.jl","style":{"code":true}},{"type":"text","text":" , which I hope means it's going to run on 4 cores.  Unfortunately, this doesn't run and it seems to be running with 5 cores.  Am I using the wrong syntax to run the script on 4 cores?\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"ERROR: LoadError: ProcessExitedException(3)\n\n...and 2 more exception(s).\n\nStacktrace:\n [1] sync_end(::Channel{Any}) at ./task.jl:314\n [2] macro expansion at ./task.jl:333 [inlined]\n [3] _require_callback(::Base.PkgId) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/Distributed.jl:75\n [4] #invokelatest#1 at ./essentials.jl:710 [inlined]\n [5] invokelatest at ./essentials.jl:709 [inlined]\n [6] require(::Base.PkgId) at ./loading.jl:931\n [7] require(::Module, ::Symbol) at ./loading.jl:923\n [8] include(::Function, ::Module, ::String) at ./Base.jl:380\n [9] include(::Module, ::String) at ./Base.jl:368\n [10] exec_options(::Base.JLOptions) at ./client.jl:296\n [11] _start() at ./client.jl:506\nin expression starting at /home/fpoulin/software/Oceananigans.jl/examples/mpi_shallow_water_turbulence.jl:6"}]}]}],"thread_ts":"1615315704.225500","reply_count":6,"reply_users_count":3,"latest_reply":"1615316748.231200","reply_users":["B01J9QZ4SP8","UEGRU91B2","U01FBLBCP7S"],"subscribed":false},{"type":"message","subtype":"bot_message","text":"Can we cross post this publicly to <https://discourse.julialang.org|Discourse> for further visibility? React with :bridge: on the message above to approve. <https://github.com/JuliaCommunity/SlackBridge/blob/main/README.md#faq|More info here>","ts":"1615315706.225600","username":"HelpDeskBot","bot_id":"B01J9QZ4SP8","thread_ts":"1615315704.225500","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"aa7ffd46-ef30-42e0-8d03-fd4c4f0c2213","type":"message","text":"The `-p n` flag launches n additional processes, so in your case you have the master process plus 5 more see what pops up when running `julia -h`:\n``` -p, --procs {N|auto}      Integer value N launches N additional local worker processes\n                           \"auto\" launches as many workers as the number of local CPU threads (logical cores)```","user":"UEGRU91B2","ts":"1615315793.225800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"uy3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The "},{"type":"text","text":"-p n","style":{"code":true}},{"type":"text","text":" flag launches n additional processes, so in your case you have the master process plus 5 more see what pops up when running "},{"type":"text","text":"julia -h","style":{"code":true}},{"type":"text","text":":\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":" -p, --procs {N|auto}      Integer value N launches N additional local worker processes\n                           \"auto\" launches as many workers as the number of local CPU threads (logical cores)"}]}]}],"thread_ts":"1615315704.225500","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"b076c4b6-2e84-436c-a011-da08da9c5758","type":"message","text":"Ah, so if I only want 4 then I should start using `julia -p 3`   Thanks <@UEGRU91B2>!","user":"U01FBLBCP7S","ts":"1615315938.226500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pkWL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah, so if I only want 4 then I should start using "},{"type":"text","text":"julia -p 3","style":{"code":true}},{"type":"text","text":"   Thanks "},{"type":"user","user_id":"UEGRU91B2"},{"type":"text","text":"!"}]}]}],"thread_ts":"1615315704.225500","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"39ff8e04-54c8-4038-b617-70a74268e7e7","type":"message","text":"Although I am not sure you can use `-p 3` if you want MPI-based parallelism, I think not, you would be using Julia’s own distributed computing implementation. If you want to get MPI tasks you probably want something like `mpiexec -n 4 julia --project mpi_shallow…` people at <#C6E78Q2NT|distributed> for sure will be able to answer better","user":"UEGRU91B2","ts":"1615316166.227600","team":"T68168MUP","edited":{"user":"UEGRU91B2","ts":"1615316189.000000"},"blocks":[{"type":"rich_text","block_id":"ZI/","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Although I am not sure you can use "},{"type":"text","text":"-p 3","style":{"code":true}},{"type":"text","text":" if you want MPI-based parallelism, I think not, you would be using Julia’s own distributed computing implementation. If you want to get MPI tasks you probably want something like "},{"type":"text","text":"mpiexec -n 4 julia --project mpi_shallow…","style":{"code":true}},{"type":"text","text":" people at "},{"type":"channel","channel_id":"C6E78Q2NT"},{"type":"text","text":" for sure will be able to answer better"}]}]}],"thread_ts":"1615315704.225500","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"08ca9a1a-f964-4688-a393-47597bee5142","type":"message","text":"Ah, that is probably what I am doing wrong.  I will give that a try","user":"U01FBLBCP7S","ts":"1615316264.228100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"0x3a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ah, that is probably what I am doing wrong.  I will give that a try"}]}]}],"thread_ts":"1615315704.225500","parent_user_id":"U01FBLBCP7S"},{"client_msg_id":"a82341b2-29e0-4e94-8537-68652d246c26","type":"message","text":"that did work, thanks <@UEGRU91B2>!","user":"U01FBLBCP7S","ts":"1615316748.231200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hqp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that did work, thanks "},{"type":"user","user_id":"UEGRU91B2"},{"type":"text","text":"!"}]}]}],"thread_ts":"1615315704.225500","parent_user_id":"U01FBLBCP7S"}]