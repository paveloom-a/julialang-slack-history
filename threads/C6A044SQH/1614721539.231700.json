[{"client_msg_id":"205bf469-265d-4207-8abf-1db4bd4c3ff9","type":"message","text":"Can someone tell me why `Float32` is (much) slower than `Float64` here?\n```julia&gt; function f(x::AbstractVector{T}) where T\n           m = length(x)\n           V = Matrix{T}(undef, m, m)\n           for j = 1:m\n               V[j,1] = one(T)\n           end\n           for i= 2:m\n               for j = 1:m\n                   V[j,i] = x[j] * V[j,i-1]\n               end\n           end\n           return V\n       end\nf (generic function with 1 method)\n\njulia&gt; using BenchmarkTools\n\njulia&gt; x = rand(Float64, 100);\n\njulia&gt; y = rand(Float32, 100);\n\njulia&gt; @btime f($x);\n  5.656 μs (2 allocations: 78.20 KiB)\n\njulia&gt; @btime f($y);\n  21.023 μs (2 allocations: 39.14 KiB)```","user":"U881D0W2C","ts":"1614721539.231700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hdwn3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can someone tell me why "},{"type":"text","text":"Float32","style":{"code":true}},{"type":"text","text":" is (much) slower than "},{"type":"text","text":"Float64","style":{"code":true}},{"type":"text","text":" here?\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> function f(x::AbstractVector{T}) where T\n           m = length(x)\n           V = Matrix{T}(undef, m, m)\n           for j = 1:m\n               V[j,1] = one(T)\n           end\n           for i= 2:m\n               for j = 1:m\n                   V[j,i] = x[j] * V[j,i-1]\n               end\n           end\n           return V\n       end\nf (generic function with 1 method)\n\njulia> using BenchmarkTools\n\njulia> x = rand(Float64, 100);\n\njulia> y = rand(Float32, 100);\n\njulia> @btime f($x);\n  5.656 μs (2 allocations: 78.20 KiB)\n\njulia> @btime f($y);\n  21.023 μs (2 allocations: 39.14 KiB)"}]}]}],"thread_ts":"1614721539.231700","reply_count":5,"reply_users_count":3,"latest_reply":"1614723133.236200","reply_users":["B01J9QZ4SP8","U7HAYKY9X","U881D0W2C"],"subscribed":false},{"type":"message","subtype":"bot_message","text":"Can we cross post this publicly to <https://discourse.julialang.org|Discourse> for further visibility? React with :bridge: on the message above to approve. <https://github.com/JuliaCommunity/SlackBridge/blob/main/README.md#faq|More info here>","ts":"1614721541.231800","username":"HelpDeskBot","bot_id":"B01J9QZ4SP8","thread_ts":"1614721539.231700","parent_user_id":"U881D0W2C"},{"client_msg_id":"24930d2b-8e67-429e-9b51-59c3b8381216","type":"message","text":"It's probably due to cache alignment effects - the CPU cache fetches memory most effectively from addresses that are aligned with the cache line boundraries.","user":"U7HAYKY9X","ts":"1614722022.232000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jFTfb","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It's probably due to cache alignment effects - the CPU cache fetches memory most effectively from addresses that are aligned with the cache line boundraries."}]}]}],"thread_ts":"1614721539.231700","parent_user_id":"U881D0W2C"},{"client_msg_id":"f2912632-e8fd-452b-a03d-e9de12bea476","type":"message","text":"What I also noted is that on a different machine, adding `@inbounds` annotations makes the `Float32` part faster than `Float64`. On my machine it doesn’t. (Without `@inbounds` the `Float32` case is slower on both machines).","user":"U881D0W2C","ts":"1614722874.235800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"QQs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What I also noted is that on a different machine, adding "},{"type":"text","text":"@inbounds","style":{"code":true}},{"type":"text","text":" annotations makes the "},{"type":"text","text":"Float32","style":{"code":true}},{"type":"text","text":" part faster than "},{"type":"text","text":"Float64","style":{"code":true}},{"type":"text","text":". On my machine it doesn’t. (Without "},{"type":"text","text":"@inbounds","style":{"code":true}},{"type":"text","text":" the "},{"type":"text","text":"Float32","style":{"code":true}},{"type":"text","text":" case is slower on both machines)."}]}]}],"thread_ts":"1614721539.231700","parent_user_id":"U881D0W2C"},{"client_msg_id":"82a77110-dcfb-4caa-82c5-bb20608e2f87","type":"message","text":"Yeah, SIMD interacts interestingly with cache alignment, because of the larger loads (and the unrolling)","user":"U7HAYKY9X","ts":"1614722968.236000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pap","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, SIMD interacts interestingly with cache alignment, because of the larger loads (and the unrolling)"}]}]}],"thread_ts":"1614721539.231700","parent_user_id":"U881D0W2C"},{"client_msg_id":"65f463dd-464e-4606-9c41-50c603c3af62","type":"message","text":"Check the benchmarks here - how large a difference the precise vector lengths make: <https://chriselrod.github.io/LoopVectorization.jl/latest/examples/matrix_vector_ops/#Matrix-Vector-Operations>","user":"U7HAYKY9X","ts":"1614723133.236200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"TYh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Check the benchmarks here - how large a difference the precise vector lengths make: "},{"type":"link","url":"https://chriselrod.github.io/LoopVectorization.jl/latest/examples/matrix_vector_ops/#Matrix-Vector-Operations"}]}]}],"thread_ts":"1614721539.231700","parent_user_id":"U881D0W2C","reactions":[{"name":"+1","users":["U881D0W2C"],"count":1}]}]