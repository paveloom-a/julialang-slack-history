[{"client_msg_id":"6d20a49e-fc09-457a-9c82-f4c13544dddf","type":"message","text":"Hello everyone! I have a question regarding parallelization of a combinatorial operation, let me know if my question is better suited for another channel.\n\nI am using the `Combinatorics.jl` package. I have to perform an operation on two matrices for each `permutations(1:N, 4)` where `N` should go up to 100.  For now I wrote it like this,\n\n```function Δfe(M::Matrix, i, j, k, l)\n    first = M[i, j] - M[i, k]\n    second = M[l, j] - M[l, k]\n\n    return first - second\nend\n\nfunction computeU(X, U, tetrads)\n    u = 0.\n\n    for t in tetrads\n        u += Δfe(X, t...) * Δfe(U, t...)\n    end\n\n    return u / length(tetrads)\n\nend\n\nN = 100\n\nX, U = # NxN matrices\ntetrads = permutations(1:N, 4)\ncomputeU(X, U, tetrads)```\nThis is currently very slow. I would like to know if there is any way to parallelize the `for t in tetrads` or a way of restructuring this to make it faster.","user":"U01FPHR7WKB","ts":"1616060236.007800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"pVK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hello everyone! I have a question regarding parallelization of a combinatorial operation, let me know if my question is better suited for another channel.\n\nI am using the "},{"type":"text","text":"Combinatorics.jl","style":{"code":true}},{"type":"text","text":" package. I have to perform an operation on two matrices for each "},{"type":"text","text":"permutations(1:N, 4)","style":{"code":true}},{"type":"text","text":" where "},{"type":"text","text":"N","style":{"code":true}},{"type":"text","text":" should go up to 100.  For now I wrote it like this,\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"function Δfe(M::Matrix, i, j, k, l)\n    first = M[i, j] - M[i, k]\n    second = M[l, j] - M[l, k]\n\n    return first - second\nend\n\nfunction computeU(X, U, tetrads)\n    u = 0.\n\n    for t in tetrads\n        u += Δfe(X, t...) * Δfe(U, t...)\n    end\n\n    return u / length(tetrads)\n\nend\n\nN = 100\n\nX, U = # NxN matrices\ntetrads = permutations(1:N, 4)\ncomputeU(X, U, tetrads)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nThis is currently very slow. I would like to know if there is any way to parallelize the "},{"type":"text","text":"for t in tetrads","style":{"code":true}},{"type":"text","text":" or a way of restructuring this to make it faster."}]}]}],"thread_ts":"1616060236.007800","reply_count":9,"reply_users_count":5,"latest_reply":"1616080972.009700","reply_users":["U01FPHR7WKB","U01MG0TN079","U01GMP3HF9C","U67G3QRJM","UDD5Z7FLZ"],"subscribed":false},{"client_msg_id":"73efaeb7-2aed-4587-adde-8655ba672ccd","type":"message","text":"Btw, I also tried to use,\n\n```Δfe(M::Matrix) = t -&gt; Δfe(M, t...)\n\n(Δfe(X).(tetrads)' Δfe(U).(tetrads) )/ length(tetrads) ```\nwhich was of slower.","user":"U01FPHR7WKB","ts":"1616060371.007900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"izoM+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Btw, I also tried to use,\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Δfe(M::Matrix) = t -> Δfe(M, t...)\n\n(Δfe(X).(tetrads)' Δfe(U).(tetrads) )/ length(tetrads) "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nwhich was of slower."}]}]}],"thread_ts":"1616060236.007800","parent_user_id":"U01FPHR7WKB"},{"client_msg_id":"f053d5de-f0eb-40fd-bf27-06c1ca02a698","type":"message","text":"look here maybe ? <https://docs.julialang.org/en/v1.5/manual/distributed-computing/>","user":"U01MG0TN079","ts":"1616061600.008100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FbR/I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"look here maybe ? "},{"type":"link","url":"https://docs.julialang.org/en/v1.5/manual/distributed-computing/"}]}]}],"thread_ts":"1616060236.007800","parent_user_id":"U01FPHR7WKB"},{"client_msg_id":"b8d49b50-120b-46e0-91a7-47d270703ced","type":"message","text":"I think you'd use `@distributed`  here","user":"U01MG0TN079","ts":"1616061714.008300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"f+4a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think you'd use "},{"type":"text","text":"@distributed","style":{"code":true}},{"type":"text","text":"  here"}]}]}],"thread_ts":"1616060236.007800","parent_user_id":"U01FPHR7WKB"},{"client_msg_id":"44df1d84-1189-4704-bea7-898761954048","type":"message","text":"I cannot use `@distributed` because the permutations are a generator hence there is no `getindex` and I cannot collect them, it would be to big.","user":"U01FPHR7WKB","ts":"1616064967.008500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"z/lY8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I cannot use "},{"type":"text","text":"@distributed","style":{"code":true}},{"type":"text","text":" because the permutations are a generator hence there is no "},{"type":"text","text":"getindex","style":{"code":true}},{"type":"text","text":" and I cannot collect them, it would be to big."}]}]}],"thread_ts":"1616060236.007800","parent_user_id":"U01FPHR7WKB"},{"client_msg_id":"197bf1fe-5242-4bea-b8d3-029fea80bfac","type":"message","text":"Then multithreading ?","user":"U01GMP3HF9C","ts":"1616069984.008700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Anvh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Then multithreading ?"}]}]}],"thread_ts":"1616060236.007800","parent_user_id":"U01FPHR7WKB"},{"client_msg_id":"c4b18c16-89ad-43ed-aaf9-ff0cf370e283","type":"message","text":"You can \"manually\" separate out the permutations by generating separate ones in different processors presumably","user":"U67G3QRJM","ts":"1616073700.008900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"839V3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can \"manually\" separate out the permutations by generating separate ones in different processors presumably"}]}]}],"thread_ts":"1616060236.007800","parent_user_id":"U01FPHR7WKB","reactions":[{"name":"thumbsup_all","users":["U01FPHR7WKB","U01GMP3HF9C"],"count":2}]},{"client_msg_id":"0c4aa160-6ec6-420c-b5ad-07634f91abc4","type":"message","text":"Can try `@inline` the function and `@inbounds` the for loop for a decent speedup","user":"UDD5Z7FLZ","ts":"1616075940.009200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"+RTt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can try "},{"type":"text","text":"@inline","style":{"code":true}},{"type":"text","text":" the function and "},{"type":"text","text":"@inbounds","style":{"code":true}},{"type":"text","text":" the for loop for a decent speedup"}]}]}],"thread_ts":"1616060236.007800","parent_user_id":"U01FPHR7WKB","reactions":[{"name":"+1","users":["UEN48T0BT"],"count":1}]},{"client_msg_id":"b55f97e9-78ba-4c62-9ac4-8d24897190d4","type":"message","text":"Thanks everyone. i will try both approaches now.","user":"U01FPHR7WKB","ts":"1616080178.009500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oXn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks everyone. i will try both approaches now."}]}]}],"thread_ts":"1616060236.007800","parent_user_id":"U01FPHR7WKB"},{"client_msg_id":"73bd1e0b-fe7f-4962-8b3e-19940502ea88","type":"message","text":"Anyway, this should run in ~5-10 seconds for N = 100","user":"UDD5Z7FLZ","ts":"1616080972.009700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"XGPK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyway, this should run in ~5-10 seconds for N = 100"}]}]}],"thread_ts":"1616060236.007800","parent_user_id":"U01FPHR7WKB"}]