[{"client_msg_id":"5a341186-f7f0-4094-968c-009329994979","type":"message","text":"I'm mostly interested in escaping local minima","user":"UGTUKUHLN","ts":"1614554826.037700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hry2i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm mostly interested in escaping local minima"}]}]}],"thread_ts":"1614554826.037700","reply_count":19,"reply_users_count":2,"latest_reply":"1614558294.043800","reply_users":["U9MD78Z9N","UGTUKUHLN"],"subscribed":false},{"type":"message","text":"Momentum or Restarts might be intersting for you.","user":"U9MD78Z9N","ts":"1614555083.038700","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"f15cdf0f-aed8-409e-b5d4-4387d6578398","type":"message","text":"In a sense, restarts are what I currently do - just run bfgs from a few thousands random initializations","user":"UGTUKUHLN","ts":"1614555518.040000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tXfz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In a sense, restarts are what I currently do - just run bfgs from a few thousands random initializations"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"e51d54d1-2bdf-4df9-8877-8c2fc7880ebc","type":"message","text":"But generally interested in these stochastic gradient methods - basically impossible to find information about them that is not on neural nets","user":"UGTUKUHLN","ts":"1614555555.040200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=awU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But generally interested in these stochastic gradient methods - basically impossible to find information about them that is not on neural nets"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"I see that, i thought you were interested in neural nets too.","user":"U9MD78Z9N","ts":"1614555613.040400","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"I would not look into SGD unless you have thousands of parameters.","user":"U9MD78Z9N","ts":"1614555777.040600","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"You might also want to look in having a global search algorithm (genetic stuff, simulated annealing, ...) and switch to local optimization for the k-best","user":"U9MD78Z9N","ts":"1614556084.040800","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"8afc890f-71ba-412a-9ec5-cfb4fc11f590","type":"message","text":"Hm... it just seems weird to ignore easily available derivatives to guide the global search","user":"UGTUKUHLN","ts":"1614556212.041000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ihOJY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hm... it just seems weird to ignore easily available derivatives to guide the global search"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"Genetic algorithms can make use of gradients. But think of it that way, if the calculation of the gradient takes as long as a function call you can visit twice as many points with the same computational budget, in addition you have no sequential dependencies in your algorithm so it will scale better when parrallelized.","user":"U9MD78Z9N","ts":"1614556387.041200","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"gradient informarmatin tells you nothing* about global structure.\n*if it does you should use a specialized algorithm for your very structured problem.","user":"U9MD78Z9N","ts":"1614556467.041400","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"9d20dee1-fd69-462a-8704-cc04bdb60233","type":"message","text":"Gradients give far better information on the behaviour around the point than the function value by itself\nAlso functions are often lipshitz-continuous in reality","user":"UGTUKUHLN","ts":"1614556608.041600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"W+IiM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Gradients give far better information on the behaviour around the point than the function value by itself\nAlso functions are often lipshitz-continuous in reality"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"Ok, it depends, i had good experience with combining a global and then a local search on a variety of problems.\nEscaping local minimas is a hard problem, since all gradient information is effectively useless when you are still in the attractor of the local optima.\nDepending on your problem you might want to fit a model to the local minima of your problem if your solution space is uniformly noisy and might have a nice structure otherwise (think Rastrigin function).","user":"U9MD78Z9N","ts":"1614556934.042200","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"67af3c23-4826-4a5b-9e34-54274c61e77a","type":"message","text":"What do you mean \"fit a model to the local minima\"? Like, describe them all in a systematic manner?","user":"UGTUKUHLN","ts":"1614557203.042400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hSk3k","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What do you mean \"fit a model to the local minima\"? Like, describe them all in a systematic manner?"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"Fit a quadratic model for example.","user":"U9MD78Z9N","ts":"1614557262.042600","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"You can decide to only use minimas in some trust region and varry that to trade exploitation and exploration. Note this is in operation you should only perform a few times, not every time you found a new minima.","user":"U9MD78Z9N","ts":"1614557438.042800","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"ca7db2b1-7191-4817-a8af-279389d4d304","type":"message","text":"Interesting... So, first I find a few local minima eg using many random local optimization runs, and then fit some function to their values and hope that its minimum is closer to the global one?","user":"UGTUKUHLN","ts":"1614557866.043000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yTIS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Interesting... So, first I find a few local minima eg using many random local optimization runs, and then fit some function to their values and hope that its minimum is closer to the global one?"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"This optimization approach basically assumes that the trere is underlying, mybe convex structure and some high frequency noise that is sort of bounded and doesn't vary much. Depending on your problem (in particular if you have some idea what the noiseless function behaves like, it could produce excelent results.","user":"U9MD78Z9N","ts":"1614558055.043200","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"Trying to get local optimizers to find a global optima is dark art.","user":"U9MD78Z9N","ts":"1614558090.043400","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"1091572a-edfe-476e-b193-32b6d53b818a","type":"message","text":"I see, sounds reasonable and may help in my case","user":"UGTUKUHLN","ts":"1614558261.043600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LKt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I see, sounds reasonable and may help in my case"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"One thing i want to try at some point is this <https://arxiv.org/abs/2011.06505> but i'm not aware of any Julia implementation","user":"U9MD78Z9N","ts":"1614558294.043800","team":"T68168MUP","edited":{"user":"U9MD78Z9N","ts":"1614558324.000000"},"attachments":[{"service_name":"arXiv.org","title":"Ridge Rider: Finding Diverse Solutions by Following Eigenvectors...","title_link":"https://arxiv.org/abs/2011.06505","text":"Over the last decade, a single algorithm has changed many facets of our lives - Stochastic Gradient Descent (SGD). In the era of ever decreasing loss functions, SGD and its various offspring have...","fallback":"arXiv.org: Ridge Rider: Finding Diverse Solutions by Following Eigenvectors...","from_url":"https://arxiv.org/abs/2011.06505","service_icon":"https://static.arxiv.org/static/browse/0.3.2.6/images/icons/favicon.ico","id":1,"original_url":"https://arxiv.org/abs/2011.06505"}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"}]