[{"client_msg_id":"5a341186-f7f0-4094-968c-009329994979","type":"message","text":"I'm mostly interested in escaping local minima","user":"UGTUKUHLN","ts":"1614554826.037700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Hry2i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm mostly interested in escaping local minima"}]}]}],"thread_ts":"1614554826.037700","reply_count":23,"reply_users_count":3,"latest_reply":"1614622196.046000","reply_users":["U9MD78Z9N","UGTUKUHLN","U013B3NSZGB"],"subscribed":false},{"type":"message","text":"Momentum or Restarts might be intersting for you.","user":"U9MD78Z9N","ts":"1614555083.038700","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"f15cdf0f-aed8-409e-b5d4-4387d6578398","type":"message","text":"In a sense, restarts are what I currently do - just run bfgs from a few thousands random initializations","user":"UGTUKUHLN","ts":"1614555518.040000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tXfz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In a sense, restarts are what I currently do - just run bfgs from a few thousands random initializations"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"e51d54d1-2bdf-4df9-8877-8c2fc7880ebc","type":"message","text":"But generally interested in these stochastic gradient methods - basically impossible to find information about them that is not on neural nets","user":"UGTUKUHLN","ts":"1614555555.040200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"=awU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But generally interested in these stochastic gradient methods - basically impossible to find information about them that is not on neural nets"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"I see that, i thought you were interested in neural nets too.","user":"U9MD78Z9N","ts":"1614555613.040400","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"I would not look into SGD unless you have thousands of parameters.","user":"U9MD78Z9N","ts":"1614555777.040600","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"You might also want to look in having a global search algorithm (genetic stuff, simulated annealing, ...) and switch to local optimization for the k-best","user":"U9MD78Z9N","ts":"1614556084.040800","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"8afc890f-71ba-412a-9ec5-cfb4fc11f590","type":"message","text":"Hm... it just seems weird to ignore easily available derivatives to guide the global search","user":"UGTUKUHLN","ts":"1614556212.041000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ihOJY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hm... it just seems weird to ignore easily available derivatives to guide the global search"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"Genetic algorithms can make use of gradients. But think of it that way, if the calculation of the gradient takes as long as a function call you can visit twice as many points with the same computational budget, in addition you have no sequential dependencies in your algorithm so it will scale better when parrallelized.","user":"U9MD78Z9N","ts":"1614556387.041200","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"gradient informarmatin tells you nothing* about global structure.\n*if it does you should use a specialized algorithm for your very structured problem.","user":"U9MD78Z9N","ts":"1614556467.041400","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN","reactions":[{"name":"+1","users":["U6CJRSR63","UGD4K0Z25"],"count":2}]},{"client_msg_id":"9d20dee1-fd69-462a-8704-cc04bdb60233","type":"message","text":"Gradients give far better information on the behaviour around the point than the function value by itself\nAlso functions are often lipshitz-continuous in reality","user":"UGTUKUHLN","ts":"1614556608.041600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"W+IiM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Gradients give far better information on the behaviour around the point than the function value by itself\nAlso functions are often lipshitz-continuous in reality"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"Ok, it depends, i had good experience with combining a global and then a local search on a variety of problems.\nEscaping local minimas is a hard problem, since all gradient information is effectively useless when you are still in the attractor of the local optima.\nDepending on your problem you might want to fit a model to the local minima of your problem if your solution space is uniformly noisy and might have a nice structure otherwise (think Rastrigin function).","user":"U9MD78Z9N","ts":"1614556934.042200","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"67af3c23-4826-4a5b-9e34-54274c61e77a","type":"message","text":"What do you mean \"fit a model to the local minima\"? Like, describe them all in a systematic manner?","user":"UGTUKUHLN","ts":"1614557203.042400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hSk3k","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What do you mean \"fit a model to the local minima\"? Like, describe them all in a systematic manner?"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"Fit a quadratic model for example.","user":"U9MD78Z9N","ts":"1614557262.042600","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"You can decide to only use minimas in some trust region and varry that to trade exploitation and exploration. Note this is in operation you should only perform a few times, not every time you found a new minima.","user":"U9MD78Z9N","ts":"1614557438.042800","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"ca7db2b1-7191-4817-a8af-279389d4d304","type":"message","text":"Interesting... So, first I find a few local minima eg using many random local optimization runs, and then fit some function to their values and hope that its minimum is closer to the global one?","user":"UGTUKUHLN","ts":"1614557866.043000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yTIS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Interesting... So, first I find a few local minima eg using many random local optimization runs, and then fit some function to their values and hope that its minimum is closer to the global one?"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"This optimization approach basically assumes that the trere is underlying, mybe convex structure and some high frequency noise that is sort of bounded and doesn't vary much. Depending on your problem (in particular if you have some idea what the noiseless function behaves like, it could produce excelent results.","user":"U9MD78Z9N","ts":"1614558055.043200","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"Trying to get local optimizers to find a global optima is dark art.","user":"U9MD78Z9N","ts":"1614558090.043400","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"1091572a-edfe-476e-b193-32b6d53b818a","type":"message","text":"I see, sounds reasonable and may help in my case","user":"UGTUKUHLN","ts":"1614558261.043600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LKt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I see, sounds reasonable and may help in my case"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"One thing i want to try at some point is this <https://arxiv.org/abs/2011.06505> but i'm not aware of any Julia implementation","user":"U9MD78Z9N","ts":"1614558294.043800","team":"T68168MUP","edited":{"user":"U9MD78Z9N","ts":"1614558324.000000"},"attachments":[{"service_name":"arXiv.org","title":"Ridge Rider: Finding Diverse Solutions by Following Eigenvectors...","title_link":"https://arxiv.org/abs/2011.06505","text":"Over the last decade, a single algorithm has changed many facets of our lives - Stochastic Gradient Descent (SGD). In the era of ever decreasing loss functions, SGD and its various offspring have...","fallback":"arXiv.org: Ridge Rider: Finding Diverse Solutions by Following Eigenvectors...","from_url":"https://arxiv.org/abs/2011.06505","service_icon":"https://static.arxiv.org/static/browse/0.3.2.6/images/icons/favicon.ico","id":1,"original_url":"https://arxiv.org/abs/2011.06505"}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN","reactions":[{"name":"+1","users":["U013B3NSZGB"],"count":1}]},{"client_msg_id":"ba2b5710-084f-48a0-b1f6-5c008dd41473","type":"message","text":"This Ridge Rider technique actually looks very promising.","user":"U013B3NSZGB","ts":"1614621310.045300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6yX1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This Ridge Rider technique actually looks very promising."}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"I'm not sure that EV of the hessian is the right way to go, as there might be more valleys you want to explore that there could be eigenvectors.\n<https://en.wikipedia.org/wiki/Monkey_saddle> is a |R^2 -&gt; |R function but it has 3 different seperated minima directions.","user":"U9MD78Z9N","ts":"1614621975.045500","team":"T68168MUP","attachments":[{"image_url":"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Monkey_Saddle_Surface_%28Shaded%29.png/1200px-Monkey_Saddle_Surface_%28Shaded%29.png","image_width":1200,"image_height":900,"image_bytes":709533,"title":"Monkey saddle","title_link":"https://en.wikipedia.org/wiki/Monkey_saddle","from_url":"https://en.wikipedia.org/wiki/Monkey_saddle","author_name":"Wikipedia","author_link":"https://en.wikipedia.org/","text":"In mathematics, the monkey saddle is the surface defined by the equation \n\n  \n    \n      \n        z\n        =\n        \n          x\n          \n            3\n          \n        \n        −\n        3\n        x\n        \n          y\n          \n            2\n          \n        \n        ,\n        \n      \n    \n    {\\displaystyle z=x^{3}-3xy^{2},\\,}\n  \nor in cylindrical coordinates\n  \n    \n      \n        z\n        =\n        \n          ρ\n          \n            3\n          \n        \n        cos\n        ⁡\n        (\n        3\n        φ\n        )\n        .\n      \n    \n    {\\displaystyle z=\\rho ^{3}\\cos(3\\varphi ).}\n  It belongs to the class of saddle surfaces, and its name derives from the observation that a saddle for a monkey would require two depressions for the legs and one for the tail. The point (0,0,0) on the monkey saddle corresponds to a degenerate critical point of the function z(x,y) at (0, 0). The monkey saddle has an isolated umbilical point with zero Gaussian curvature at the origin, while the curvature is strictly negative at all other points.\nOne can relate the rectangular and cylindrical equations using complex numbers \n  \n    \n      \n        x\n        +\n        i\n        y\n        =\n        r\n        \n          e\n          \n            i\n            φ\n          \n        \n      \n    \n    {\\displaystyle x+iy=re^{i\\varphi }}\n  :\n\n  \n    \n      \n        z\n        =\n        \n          x\n          \n            3\n          \n        \n        −\n        3\n        x\n        \n          y\n          \n            2\n          \n        \n        =\n        Re\n        ⁡\n        [\n        (\n        x\n        +\n        i\n        y\n        \n          )\n          \n            3\n          \n        \n        ]\n        =\n        Re\n        ⁡\n        [\n        \n          r\n          \n            3\n          \n        \n        \n          e\n          \n            3\n            i\n            φ\n          \n        \n        ]\n        =\n        \n          r\n          \n            3\n          \n        \n        cos\n        ⁡\n        (\n        3\n        φ\n        )\n        .\n      \n    \n    {\\displaystyle z=x^{3}-3xy^{2}=\\operatorname {Re} [(x+iy)^{3}]=\\operatorname {Re} [r^{3}e^{3i\\varphi }]=r^{3}\\cos(3\\varphi ).}\n  By replacing 3 in the cylindrical equation with any integer k ≥ 1, one can create a saddle with k depressions.Another orientation of the monkey saddle is the Smelt petal defined by \n  \n    \n      \n        x\n        +\n        y\n        +\n        z\n        +\n        x\n        y\n        z\n        =\n        0\n      \n    \n    {\\displaystyle x+y+z+xyz=0}\n  , so that the z-axis of the monkey saddle corresponds to the direction (1,1,1) in the Smelt petal.","fallback":"wikipedia: Monkey saddle","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/wikipedia.png","id":1,"original_url":"https://en.wikipedia.org/wiki/Monkey_saddle"}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"type":"message","text":"I haven't studied how ridge rider haves on this function but it doesn't seem to be a final solution","user":"U9MD78Z9N","ts":"1614622027.045800","team":"T68168MUP","thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"},{"client_msg_id":"2b225b46-eba6-430c-be06-0829deab5811","type":"message","text":"I'd be curious to know where these eigenvalues would take us in this situation. I'm not an expert at all but I think the key point is to exploit properties of higher derivatives than just the gradient and incorporate a discrete search recognizing that you may want to explore in multiple directions","user":"U013B3NSZGB","ts":"1614622196.046000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"id6LH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd be curious to know where these eigenvalues would take us in this situation. I'm not an expert at all but I think the key point is to exploit properties of higher derivatives than just the gradient and incorporate a discrete search recognizing that you may want to explore in multiple directions"}]}]}],"thread_ts":"1614554826.037700","parent_user_id":"UGTUKUHLN"}]