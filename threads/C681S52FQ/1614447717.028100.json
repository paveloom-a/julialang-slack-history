[{"client_msg_id":"fd7b9339-2b1f-4a24-8914-b6b784ffdc61","type":"message","text":"L-BFGS is prone to getting stuck on saddle-points (like all Newton-like second-order methods). Are there alternative methods in Optim / NLopt that one can use that avoid this problem?","user":"U7YD3DKL2","ts":"1614447717.028100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jUh8","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"L-BFGS is prone to getting stuck on saddle-points (like all Newton-like second-order methods). Are there alternative methods in Optim / NLopt that one can use that avoid this problem?"}]}]}],"thread_ts":"1614447717.028100","reply_count":5,"reply_users_count":3,"latest_reply":"1614457702.029900","reply_users":["U67G3QRJM","U9MD78Z9N","UMDEUKM29"],"subscribed":false},{"client_msg_id":"d6cf6871-21c2-4e97-8952-f4a496ce5e45","type":"message","text":"Maybe <https://arxiv.org/abs/2006.00719>","user":"U67G3QRJM","ts":"1614448855.028200","team":"T68168MUP","attachments":[{"service_name":"arXiv.org","title":"ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning","title_link":"https://arxiv.org/abs/2006.00719","text":"We introduce ADAHESSIAN, a second order stochastic optimization algorithm which dynamically incorporates the curvature of the loss function via ADAptive estimates of the HESSIAN. Second order...","fallback":"arXiv.org: ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning","from_url":"https://arxiv.org/abs/2006.00719","service_icon":"https://static.arxiv.org/static/browse/0.3.2.6/images/icons/favicon.ico","id":1,"original_url":"https://arxiv.org/abs/2006.00719"}],"blocks":[{"type":"rich_text","block_id":"YaxdW","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Maybe "},{"type":"link","url":"https://arxiv.org/abs/2006.00719"}]}]}],"thread_ts":"1614447717.028100","parent_user_id":"U7YD3DKL2"},{"client_msg_id":"5aa2f2ba-a1d8-4905-8b9a-bad16b14fa0a","type":"message","text":"<https://github.com/amirgholami/adahessian>","user":"U67G3QRJM","ts":"1614448885.028500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lEFI","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/amirgholami/adahessian"}]}]}],"thread_ts":"1614447717.028100","parent_user_id":"U7YD3DKL2"},{"type":"message","text":"Momentum based algorithms could also help.","user":"U9MD78Z9N","ts":"1614449448.028700","team":"T68168MUP","thread_ts":"1614447717.028100","parent_user_id":"U7YD3DKL2","reactions":[{"name":"+1","users":["U67G3QRJM","U7YD3DKL2","UKG4WF8PJ"],"count":3}]},{"type":"message","text":"Because a short region with 0 gradient doesn't slow the ball enough.","user":"U9MD78Z9N","ts":"1614450417.029500","team":"T68168MUP","thread_ts":"1614447717.028100","parent_user_id":"U7YD3DKL2","reactions":[{"name":"+1","users":["U67G3QRJM"],"count":1}]},{"client_msg_id":"2b0d9e69-7953-4d14-a164-972da3c9acbc","type":"message","text":"What do you mean getting stuck in saddle points? Why should it be? It's still an optimization method","user":"UMDEUKM29","ts":"1614457702.029900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/I3i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What do you mean getting stuck in saddle points? Why should it be? It's still an optimization method"}]}]}],"thread_ts":"1614447717.028100","parent_user_id":"U7YD3DKL2","reactions":[{"name":"-1","users":["U9MD78Z9N"],"count":1}]}]