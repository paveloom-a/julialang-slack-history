[{"client_msg_id":"0cacdfb3-f079-4244-93ae-55162efcec46","type":"message","text":"What do we think the quickest way to find roots of bessel functions of first kind zero order that would satisfy `J₀(A*sₙ) = 0` where A is some varying positive constant? I see there is FunctionZeros.jl that will find the roots of bessels functions but unfortunately I am using this as an inverse model and calculating sₙ for each iteration is very slow (as the constant A depends on the fitting parameters in the fitting model)....","user":"U01FSUY7YES","ts":"1612198572.024700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"M23I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What do we think the quickest way to find roots of bessel functions of first kind zero order that would satisfy `J₀(A*sₙ) = 0` where A is some varying positive constant? I see there is FunctionZeros.jl that will find the roots of bessels functions but unfortunately I am using this as an inverse model and calculating sₙ for each iteration is very slow (as the constant A depends on the fitting parameters in the fitting model)...."}]}]}],"thread_ts":"1612198572.024700","reply_count":15,"reply_users_count":4,"latest_reply":"1612548851.036200","reply_users":["U01FSUY7YES","U67G3QRJM","UHDQQ4GN6","U9MD78Z9N"],"subscribed":false},{"client_msg_id":"59b15160-cc50-42c7-9d47-91baf5236853","type":"message","text":"Ideally I would be able to precompute the roots and store them prior to the inverse fit and modify it based on the factor A but the number of roots over a fixed region changes rapidly as A increases...","user":"U01FSUY7YES","ts":"1612198954.024800","team":"T68168MUP","edited":{"user":"U01FSUY7YES","ts":"1612199321.000000"},"blocks":[{"type":"rich_text","block_id":"hLVfs","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Ideally I would be able to precompute the roots and store them prior to the inverse fit and modify it based on the factor A but the number of roots over a fixed region changes rapidly as A increases..."}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES"},{"client_msg_id":"541ae5de-3198-4b57-9fbf-168cde69fcff","type":"message","text":"I made some modifications to the FunctionZeros.jl code that appear to give the desired results for sn but unfortunately still have to recompute sn each iteration in the inverse solver.....\n```using SpecialFunctions, Roots\nbesselj_zero_asymptotic(n, A) = π*(4*n + 3) / (4*A) # with factor A and 0 order\nbesselj_zero(n, A; order=2) = Roots.fzero((x) -&gt; SpecialFunctions.besselj0(A*x), besselj_zero_asymptotic(n, A); order=order)\nsn = map(s -&gt; besselj_zero(s, 1; order = 2), 1:1000)```","user":"U01FSUY7YES","ts":"1612206624.025100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"rAw7r","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I made some modifications to the FunctionZeros.jl code that appear to give the desired results for sn but unfortunately still have to recompute sn each iteration in the inverse solver.....\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using SpecialFunctions, Roots\nbesselj_zero_asymptotic(n, A) = π*(4*n + 3) / (4*A) # with factor A and 0 order\nbesselj_zero(n, A; order=2) = Roots.fzero((x) -> SpecialFunctions.besselj0(A*x), besselj_zero_asymptotic(n, A); order=order)\nsn = map(s -> besselj_zero(s, 1; order = 2), 1:1000)"}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES"},{"client_msg_id":"0f726dd4-1d56-49d4-ae83-31246fcb29de","type":"message","text":"If `z_n` are the roots of J_0 then `s_n = z_n / A` as far as I understand. So precompute a big table of all the zeros of J_0 and then just use that relation?","user":"U67G3QRJM","ts":"1612220561.025400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3Qzs9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"If "},{"type":"text","text":"z_n","style":{"code":true}},{"type":"text","text":" are the roots of J_0 then "},{"type":"text","text":"s_n = z_n / A","style":{"code":true}},{"type":"text","text":" as far as I understand. So precompute a big table of all the zeros of J_0 and then just use that relation?"}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES","reactions":[{"name":"white_check_mark","users":["U01FSUY7YES"],"count":1}]},{"client_msg_id":"87db34b2-dd62-4f94-9e1b-5a4d97a1c0dc","type":"message","text":"You can do it adaptively where you check if you are outside the range you already computed; if so then add some more to the table","user":"U67G3QRJM","ts":"1612220607.025600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6QI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You can do it adaptively where you check if you are outside the range you already computed; if so then add some more to the table"}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES","reactions":[{"name":"+1","users":["U01FSUY7YES"],"count":1}]},{"client_msg_id":"CD531815-923A-4542-9BF6-B6EF2B51D902","type":"message","text":"Haha yes wow they are directly related just like that! Super helpful thank you! But yes I’ll try to integrate something adaptive as it’s an infinite summation that I have to truncate somewhere. ","user":"U01FSUY7YES","ts":"1612222002.029700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"klRal","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Haha yes wow they are directly related just like that! Super helpful thank you! But yes I’ll try to integrate something adaptive as it’s an infinite summation that I have to truncate somewhere. "}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES","reactions":[{"name":"+1","users":["U67G3QRJM"],"count":1}]},{"client_msg_id":"c70841ea-8f60-465d-aa1a-46ab24788377","type":"message","text":"There's also `GSL.sf_bessel_zero_J0`, which is I believe faster than the approach with Roots, if you're comfortable limiting to Float32 and Float64 and adding GSL.jl as a dependency. We use it in Hankel.jl to initialize the Roots approach, which is inaccurate for large order with the initialization FunctionZeros uses: <https://github.com/chrisbrahms/Hankel.jl/blob/v0.5.4/src/utils.jl#L166-L186>","user":"UHDQQ4GN6","ts":"1612302793.032400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"nyiNu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's also "},{"type":"text","text":"GSL.sf_bessel_zero_J0","style":{"code":true}},{"type":"text","text":", which is I believe faster than the approach with Roots, if you're comfortable limiting to Float32 and Float64 and adding GSL.jl as a dependency. We use it in Hankel.jl to initialize the Roots approach, which is inaccurate for large order with the initialization FunctionZeros uses: "},{"type":"link","url":"https://github.com/chrisbrahms/Hankel.jl/blob/v0.5.4/src/utils.jl#L166-L186"}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES","reactions":[{"name":"bulb","users":["U01FSUY7YES"],"count":1}]},{"client_msg_id":"a2827346-b046-4964-8e3d-d217db4841e6","type":"message","text":"Also, I found `Roots.find_zero` to be substantially faster than `Roots.fzero` for this task.","user":"UHDQQ4GN6","ts":"1612302855.032600","team":"T68168MUP","edited":{"user":"UHDQQ4GN6","ts":"1612302865.000000"},"blocks":[{"type":"rich_text","block_id":"q7Xww","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Also, I found "},{"type":"text","text":"Roots.find_zero","style":{"code":true}},{"type":"text","text":" to be substantially faster than "},{"type":"text","text":"Roots.fzero","style":{"code":true}},{"type":"text","text":" for this task."}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES","reactions":[{"name":"+1","users":["U01FSUY7YES"],"count":1}]},{"client_msg_id":"a52b840e-4e80-4c8a-9f28-6b8a3d227809","type":"message","text":"Thank you <@UHDQQ4GN6> I will definitely check that out! So far it looks like precomputing the zeros once and storing them on the repo is going to work ok. Thanks for introducing me to those packages!!\n\n I was dealing with a model that had a hankel transform a couple of weeks ago so looking at your package would've been helpful! This model actually takes the form f(sn, ω)*J₀(sₙ*r)/J₁(A*sₙ)^2 that can usually be truncated for 600-800 zeros.. the crux is now the transform from the frequency domain to time domain. The current implementation is a DFT that has to compute about 1200 frequencies to get a good time domain signal but is incredibly slow.\n\nIs the recommended package for laplace transforms InverseLaplace.jl? This looks like a much more efficient way to compute the TD signal from the spatial or frequency domain but have never implemented it... Thanks for the suggestions!","user":"U01FSUY7YES","ts":"1612313960.032900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"BLUj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thank you "},{"type":"user","user_id":"UHDQQ4GN6"},{"type":"text","text":" I will definitely check that out! So far it looks like precomputing the zeros once and storing them on the repo is going to work ok. Thanks for introducing me to those packages!!\n\n I was dealing with a model that had a hankel transform a couple of weeks ago so looking at your package would've been helpful! This model actually takes the form f(sn, ω)*J₀(sₙ*r)/J₁(A*sₙ)^2 that can usually be truncated for 600-800 zeros.. the crux is now the transform from the frequency domain to time domain. The current implementation is a DFT that has to compute about 1200 frequencies to get a good time domain signal but is incredibly slow.\n\nIs the recommended package for laplace transforms InverseLaplace.jl? This looks like a much more efficient way to compute the TD signal from the spatial or frequency domain but have never implemented it... Thanks for the suggestions!"}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES"},{"client_msg_id":"2c4dd507-df36-4777-bc29-248313d4d757","type":"message","text":"&gt; This model actually takes the form f(sn, ω)*J₀(sₙ*r)/J₁(A*sₙ)^2 that can usually be truncated for 600-800 zeros\nYeah, that looks pretty similar to the quasi-discrete Hankel transform we use. Currently our implementation would require recomputing zeros whenever  `A` (maps to our `R` or `K` I believe) changes, but that could be refactored.","user":"UHDQQ4GN6","ts":"1612324646.033300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"W79YF","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"This model actually takes the form f(sn, ω)*J₀(sₙ*r)/J₁(A*sₙ)^2 that can usually be truncated for 600-800 zeros"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, that looks pretty similar to the quasi-discrete Hankel transform we use. Currently our implementation would require recomputing zeros whenever  "},{"type":"text","text":"A","style":{"code":true}},{"type":"text","text":" (maps to our "},{"type":"text","text":"R","style":{"code":true}},{"type":"text","text":" or "},{"type":"text","text":"K","style":{"code":true}},{"type":"text","text":" I believe) changes, but that could be refactored."}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES","reactions":[{"name":"+1","users":["U01FSUY7YES"],"count":1}]},{"type":"message","subtype":"thread_broadcast","text":"Just to follow up on numerically evaluating the inverse Laplace transform. It didn't look like InverseLaplace.jl had implemented the Post-Widder formula as described <https://arxiv.org/abs/1204.4754|here>. I implemented it below if anyone is interested. It's actually really impressive how many less evaluations in the frequency domain you need to reconstruct the time domain signal (compared to FT). If anyone has any optimization tips for the algorithm (PWcoeffs can be precomputed, LT_postwid is very performance critical) let me know.\n```# Compute Post-Widder coefficients Vk\nfunction _PWcoeffs(N)\n    v = zeros(N)\n    aux = 0.0\n    for k in 1:N\n        for j in floor(Int, (k + 1)/2):minimum(Int, [k, N/2])\n            aux = big(j)^(N/2)*factorial(big(2*j))\n            aux /= factorial(big(N/2 - j))*factorial(big(j))*factorial(big(j-1))\n            aux /= factorial(big(k - j))*factorial(big(2*j - k))\n            v[k] += aux\n        end\n        v[k] *= (-1)^(k + N/2) \n    end\n    return v\nend\n\n# compute LT for an array of t using multithreading\nfunction LT_postwid(f::Function, v, t::AbstractArray)\n    N = length(v)\n    a = zeros(length(t))\n    Threads.@threads for ind in eachindex(t)\n        for k in 1:N\n            a[ind] += v[k]*f(k*log(2)/t[ind])\n        end\n        a[ind] *= log(2)/t[ind]\n    end\n    return a\nend\n\n### example\nv = _PWcoeffs(18)\nlt2 = LT_postwid(s -&gt; exp(-sqrt(3 + s/3))/(4*pi*0.1),v, 0.01:0.01:4)```","user":"U01FSUY7YES","ts":"1612536580.034300","thread_ts":"1612198572.024700","root":{"client_msg_id":"0cacdfb3-f079-4244-93ae-55162efcec46","type":"message","text":"What do we think the quickest way to find roots of bessel functions of first kind zero order that would satisfy `J₀(A*sₙ) = 0` where A is some varying positive constant? I see there is FunctionZeros.jl that will find the roots of bessels functions but unfortunately I am using this as an inverse model and calculating sₙ for each iteration is very slow (as the constant A depends on the fitting parameters in the fitting model)....","user":"U01FSUY7YES","ts":"1612198572.024700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"M23I","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"What do we think the quickest way to find roots of bessel functions of first kind zero order that would satisfy `J₀(A*sₙ) = 0` where A is some varying positive constant? I see there is FunctionZeros.jl that will find the roots of bessels functions but unfortunately I am using this as an inverse model and calculating sₙ for each iteration is very slow (as the constant A depends on the fitting parameters in the fitting model)...."}]}]}],"thread_ts":"1612198572.024700","reply_count":15,"reply_users_count":4,"latest_reply":"1612548851.036200","reply_users":["U01FSUY7YES","U67G3QRJM","UHDQQ4GN6","U9MD78Z9N"],"subscribed":false},"attachments":[{"service_name":"arXiv.org","title":"Review of Inverse Laplace Transform Algorithms for Laplace-Space...","title_link":"https://arxiv.org/abs/1204.4754","text":"A boundary element method (BEM) simulation is used to compare the efficiency of numerical inverse Laplace transform strategies, considering general requirements of Laplace-space numerical...","fallback":"arXiv.org: Review of Inverse Laplace Transform Algorithms for Laplace-Space...","from_url":"https://arxiv.org/abs/1204.4754","service_icon":"https://static.arxiv.org/static/browse/0.3.2.6/images/icons/favicon.ico","id":1,"original_url":"https://arxiv.org/abs/1204.4754"}],"blocks":[{"type":"rich_text","block_id":"K42","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Just to follow up on numerically evaluating the inverse Laplace transform. It didn't look like InverseLaplace.jl had implemented the Post-Widder formula as described "},{"type":"link","url":"https://arxiv.org/abs/1204.4754","text":"here"},{"type":"text","text":". I implemented it below if anyone is interested. It's actually really impressive how many less evaluations in the frequency domain you need to reconstruct the time domain signal (compared to FT). If anyone has any optimization tips for the algorithm (PWcoeffs can be precomputed, LT_postwid is very performance critical) let me know.\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"# Compute Post-Widder coefficients Vk\nfunction _PWcoeffs(N)\n    v = zeros(N)\n    aux = 0.0\n    for k in 1:N\n        for j in floor(Int, (k + 1)/2):minimum(Int, [k, N/2])\n            aux = big(j)^(N/2)*factorial(big(2*j))\n            aux /= factorial(big(N/2 - j))*factorial(big(j))*factorial(big(j-1))\n            aux /= factorial(big(k - j))*factorial(big(2*j - k))\n            v[k] += aux\n        end\n        v[k] *= (-1)^(k + N/2) \n    end\n    return v\nend\n\n# compute LT for an array of t using multithreading\nfunction LT_postwid(f::Function, v, t::AbstractArray)\n    N = length(v)\n    a = zeros(length(t))\n    Threads.@threads for ind in eachindex(t)\n        for k in 1:N\n            a[ind] += v[k]*f(k*log(2)/t[ind])\n        end\n        a[ind] *= log(2)/t[ind]\n    end\n    return a\nend\n\n### example\nv = _PWcoeffs(18)\nlt2 = LT_postwid(s -> exp(-sqrt(3 + s/3))/(4*pi*0.1),v, 0.01:0.01:4)"}]}]}],"client_msg_id":"9842bd63-098d-4b72-b449-25c3ae7e99f3","edited":{"user":"U01FSUY7YES","ts":"1612536710.000000"}},{"type":"message","text":"Here is how it looks compared to the 'true' analytical solution in the time-domain. Some negative values still and gets noiser at longer time scales. It looks like I would have to compute higher N coefficients though that hasn't helped (the paper mentions you suffer from cancellation at large N). Very interesting nonetheless","files":[{"id":"F01LQEWSWHM","created":1612536916,"timestamp":1612536916,"name":"lt_vs_td.png","title":"lt_vs_td.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01FSUY7YES","editable":false,"size":24598,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01LQEWSWHM/lt_vs_td.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01LQEWSWHM/download/lt_vs_td.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01LQEWSWHM-cdd454a737/lt_vs_td_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01LQEWSWHM-cdd454a737/lt_vs_td_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01LQEWSWHM-cdd454a737/lt_vs_td_360.png","thumb_360_w":360,"thumb_360_h":239,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01LQEWSWHM-cdd454a737/lt_vs_td_480.png","thumb_480_w":480,"thumb_480_h":319,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01LQEWSWHM-cdd454a737/lt_vs_td_160.png","original_w":606,"original_h":403,"thumb_tiny":"AwAfADDQVRgcDp6U7aPQflSLjj6U6gBNq+g/KjaPQflS0UAMK+gH5UbeDkDp6U+kb7p+lACL2+lOpq5wPpTufSgAoo59KOfSgBPpSFsggjHFO59Kaeh4oA//2Q==","permalink":"https://julialang.slack.com/files/U01FSUY7YES/F01LQEWSWHM/lt_vs_td.png","permalink_public":"https://slack-files.com/T68168MUP-F01LQEWSWHM-9fce6325bb","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"BWRCV","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Here is how it looks compared to the 'true' analytical solution in the time-domain. Some negative values still and gets noiser at longer time scales. It looks like I would have to compute higher N coefficients though that hasn't helped (the paper mentions you suffer from cancellation at large N). Very interesting nonetheless"}]}]}],"user":"U01FSUY7YES","display_as_bot":false,"ts":"1612537111.034900","thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES"},{"client_msg_id":"64c07ab4-e918-46d0-89c0-58e53b6cabbb","type":"message","text":"This looks super neat","user":"U9MD78Z9N","ts":"1612546764.035300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"M04R","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This looks super neat"}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES","reactions":[{"name":"exclamation","users":["U01FSUY7YES"],"count":1}]},{"client_msg_id":"b5011e5b-9a5b-4de9-82ce-6006338ae6d6","type":"message","text":"Definitely agree!!! I went a different approach as well by integrating over a hyperbolic contour instead (though the constants need to be optimized) which is a much more exact way to solve the LT. Here is how the code looks:\n```\nfunction s(θ, N, t)\n    μ = 4.492075287*N/t\n    ϕ = 1.172104229 \n    return μ + im*μ*sinh(θ + im*ϕ)\nend\n\nfunction ds(θ, N, t)\n    μ = 4.492075287*N/t\n    ϕ = 1.172104229 \n    return im*μ*cosh(θ + im*ϕ)\nend\n\n# compute the laplace transform along a hyperbola contour\nfunction LT_hyperbola(f::Function, N, t::AbstractFloat)\n    a = 0.0 + 0.0*im\n    h = 1.081792140/N\n    for k in 0:N-1\n        sk = s((k + 1/2)*h, N, t)\n        dsk = ds((k + 1/2)*h, N, t)\n        a += f(sk)*exp(sk*t)*dsk\n    end\n    return imag(a)*h/pi\nend\n\nfunction LT_hyperbola(f::Function, N, t::AbstractArray)\n    out = similar(t)\n    Threads.@threads for ind in eachindex(t)\n        out[ind] = LT_hyperbola(f, N, t[ind])\n    end\n    return out   \nend```","user":"U01FSUY7YES","ts":"1612548455.035600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"CheD1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Definitely agree!!! I went a different approach as well by integrating over a hyperbolic contour instead (though the constants need to be optimized) which is a much more exact way to solve the LT. Here is how the code looks:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"\nfunction s(θ, N, t)\n    μ = 4.492075287*N/t\n    ϕ = 1.172104229 \n    return μ + im*μ*sinh(θ + im*ϕ)\nend\n\nfunction ds(θ, N, t)\n    μ = 4.492075287*N/t\n    ϕ = 1.172104229 \n    return im*μ*cosh(θ + im*ϕ)\nend\n\n# compute the laplace transform along a hyperbola contour\nfunction LT_hyperbola(f::Function, N, t::AbstractFloat)\n    a = 0.0 + 0.0*im\n    h = 1.081792140/N\n    for k in 0:N-1\n        sk = s((k + 1/2)*h, N, t)\n        dsk = ds((k + 1/2)*h, N, t)\n        a += f(sk)*exp(sk*t)*dsk\n    end\n    return imag(a)*h/pi\nend\n\nfunction LT_hyperbola(f::Function, N, t::AbstractArray)\n    out = similar(t)\n    Threads.@threads for ind in eachindex(t)\n        out[ind] = LT_hyperbola(f, N, t[ind])\n    end\n    return out   \nend"}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES"},{"type":"message","text":"And the results compared to the Post-Widder and true solutions. For reference the direct analytical solutions takes 10 us, LT-PostWidder = 100 us, and LT- hyperbolic contour = 120 us.","files":[{"id":"F01M688U13L","created":1612548480,"timestamp":1612548480,"name":"hypervpostw.png","title":"hypervpostw.png","mimetype":"image/png","filetype":"png","pretty_type":"PNG","user":"U01FSUY7YES","editable":false,"size":36653,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01M688U13L/hypervpostw.png","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01M688U13L/download/hypervpostw.png","thumb_64":"https://files.slack.com/files-tmb/T68168MUP-F01M688U13L-b3823f625e/hypervpostw_64.png","thumb_80":"https://files.slack.com/files-tmb/T68168MUP-F01M688U13L-b3823f625e/hypervpostw_80.png","thumb_360":"https://files.slack.com/files-tmb/T68168MUP-F01M688U13L-b3823f625e/hypervpostw_360.png","thumb_360_w":360,"thumb_360_h":241,"thumb_480":"https://files.slack.com/files-tmb/T68168MUP-F01M688U13L-b3823f625e/hypervpostw_480.png","thumb_480_w":480,"thumb_480_h":321,"thumb_160":"https://files.slack.com/files-tmb/T68168MUP-F01M688U13L-b3823f625e/hypervpostw_160.png","original_w":588,"original_h":393,"thumb_tiny":"AwAgADC9IDlFVtuT1x7UqtztcAN+h+lDf6yP8f5U9lDjDDIoAXA9KMD0qPLR/ey6+vcf408EMAVIIPpQA05xwP0oXJ6in0UARt/rY/x/lUlMYEyIccDNPzQAUxo+SyHa36H60/NGaAIftKqcSgow/I/Q04SgkAKxz3xSsob7wyKQIUPyH5f7p7fSnoB//9k=","permalink":"https://julialang.slack.com/files/U01FSUY7YES/F01M688U13L/hypervpostw.png","permalink_public":"https://slack-files.com/T68168MUP-F01M688U13L-72cf4e37b8","is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"G9g","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And the results compared to the Post-Widder and true solutions. For reference the direct analytical solutions takes 10 us, LT-PostWidder = 100 us, and LT- hyperbolic contour = 120 us."}]}]}],"user":"U01FSUY7YES","display_as_bot":false,"ts":"1612548534.035800","thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES"},{"client_msg_id":"0411d853-11b4-45a9-ab89-3beb48594503","type":"message","text":"Here the LT Hyperbola needed only 8 evaluations of the function for each time point compared to the Post-Widder 18 and is more accurate (though the contour needs to be highly optimized and the coefficients can't be precomputed as with Post-Widder, in practice these coefficients need to be known and optimized where Post-Widder has no such optimization). The real speed up could happen by assuming a fixed contour path that doesn't depend on time that you could then precompute.... this seems a little more challenging. Though because I'm actually trying to fit experimental data here my system only has a dynamic range of 3-4 orders of magnitude so those late time discrepancies may not matter....","user":"U01FSUY7YES","ts":"1612548851.036200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"dgK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Here the LT Hyperbola needed only 8 evaluations of the function for each time point compared to the Post-Widder 18 and is more accurate (though the contour needs to be highly optimized and the coefficients can't be precomputed as with Post-Widder, in practice these coefficients need to be known and optimized where Post-Widder has no such optimization). The real speed up could happen by assuming a fixed contour path that doesn't depend on time that you could then precompute.... this seems a little more challenging. Though because I'm actually trying to fit experimental data here my system only has a dynamic range of 3-4 orders of magnitude so those late time discrepancies may not matter...."}]}]}],"thread_ts":"1612198572.024700","parent_user_id":"U01FSUY7YES"}]