[{"type":"message","text":"Okay I think I have narrowed it down to the MWE below.\n\nFor context (feel free to skip), this occurs as part of my (still woefully incomplete) SynthControl package, which implements synthetic control estimation. The core of the method is to take a number of potential \"donor\" time series and weight them in such a way that they get as close as possible to a target time series. The full code is here: <https://github.com/nilshg/SynthControl.jl/blob/master/src/SynthControl.jl>, but I've extracted out the relevant bits below:\n\n```using Optim, DelimitedFiles, LinearAlgebra\n\nfunction get_weights(y, xs)\n\n    obj(w) = norm(y .- xs*w) + 1e6*abs(1.0 - sum(w))\n\n    # Initial condition and bounds\n    initial = [1e-5 for _ in 1:size(xs, 2)]\n    lower = zeros(size(xs, 2))\n    upper = ones(size(xs, 2))\n\n    # Get weights through optimization\n    res = optimize(obj, lower, upper, initial)\n\n    return res.minimizer\nend\n\nyᵂ = [100.9, 100.9, 100.9, 100.9, 100.9, 100.9, 100.9, 100.9, 100.7, 100.7, 100.7, 100.7, \n      100.2, 100.2, 100.2, 100.1, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.8, \n      99.4, 99.4, 99.4, 99.4, 99.3, 99.2, 99.2, 99.2, 99.2, 98.9, 98.9, 98.9, 98.9, 98.9, \n      98.9, 98.9, 98.9, 98.9, 98.9, 98.8, 98.8, 98.8, 98.7, 98.7, 98.6, 98.6, 98.6, 98.3, \n      97.9, 97.9, 97.9, 97.9, 97.8, 97.7, 97.7, 97.7]\n\nxs = readdlm(\"xs.txt\")\n\nget_weights(yᵂ, xs) # Fails - some weights are NaN\nw₁ = get_weights(yᵂ, xs[:, [1:4; 6:end]])\n\nsum(w₁) # ≈ 1.00\nnorm(yᵂ .- xs[:, [1:4; 6:end]]*w₁) # ≈ 0.897```\n","files":[{"id":"F01JZDH0YP3","created":1610533648,"timestamp":1610533648,"name":"xs.txt","title":"xs.txt","mimetype":"text/plain","filetype":"text","pretty_type":"Plain Text","user":"U7JQGPGCQ","editable":true,"size":5899,"mode":"snippet","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https://files.slack.com/files-pri/T68168MUP-F01JZDH0YP3/xs.txt","url_private_download":"https://files.slack.com/files-pri/T68168MUP-F01JZDH0YP3/download/xs.txt","permalink":"https://julialang.slack.com/files/U7JQGPGCQ/F01JZDH0YP3/xs.txt","permalink_public":"https://slack-files.com/T68168MUP-F01JZDH0YP3-9eb35dde6d","edit_link":"https://julialang.slack.com/files/U7JQGPGCQ/F01JZDH0YP3/xs.txt/edit","preview":"100.0\t100.7\t101.7\t102.1\t96.2\t100.8\t100.3\t99.6\t97.6\t99.8\t99.5\t100.9\t99.0\t101.4\t101.2\t100.9\t102.5\t102.4\n100.0\t101.3\t101.7\t102.1\t95.7\t101.0\t100.3\t99.6\t97.4\t99.7\t99.5\t101.0\t98.2\t101.4\t101.2\t100.9\t102.5\t102.4\n99.9\t101.1\t101.7\t102.1\t97.1\t101.1\t100.3\t99.6\t97.4\t99.8\t99.5\t100.7\t97.9\t101.4\t101.2\t100.9\t102.5\t102.4\n100.0\t101.1\t101.7\t101.9\t97.4\t101.1\t100.7\t99.6\t97.6\t99.8\t99.6\t100.9\t98.0\t101.3\t101.2\t100.6\t102.5\t102.3\n100.0\t101.1\t101.7\t101.9\t97.6\t101.1\t100.7\t99.5\t97.7\t99.9\t99.6\t100.8\t97.9\t100.2\t101.3\t100.6\t102.5\t102.3","preview_highlight":"<div class=\"CodeMirror cm-s-default CodeMirrorServer\" oncopy=\"if(event.clipboardData){event.clipboardData.setData('text/plain',window.getSelection().toString().replace(/\\u200b/g,''));event.preventDefault();event.stopPropagation();}\">\n<div class=\"CodeMirror-code\">\n<div><pre>100.0   100.7   101.7   102.1   96.2    100.8   100.3   99.6    97.6    99.8    99.5    100.9   99.0    101.4   101.2   100.9   102.5   102.4</pre></div>\n<div><pre>100.0   101.3   101.7   102.1   95.7    101.0   100.3   99.6    97.4    99.7    99.5    101.0   98.2    101.4   101.2   100.9   102.5   102.4</pre></div>\n<div><pre>99.9    101.1   101.7   102.1   97.1    101.1   100.3   99.6    97.4    99.8    99.5    100.7   97.9    101.4   101.2   100.9   102.5   102.4</pre></div>\n<div><pre>100.0   101.1   101.7   101.9   97.4    101.1   100.7   99.6    97.6    99.8    99.6    100.9   98.0    101.3   101.2   100.6   102.5   102.3</pre></div>\n<div><pre>100.0   101.1   101.7   101.9   97.6    101.1   100.7   99.5    97.7    99.9    99.6    100.8   97.9    100.2   101.3   100.6   102.5   102.3</pre></div>\n</div>\n</div>\n","lines":61,"lines_more":56,"preview_is_truncated":true,"is_starred":false,"has_rich_preview":false}],"upload":false,"blocks":[{"type":"rich_text","block_id":"pMLF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Okay I think I have narrowed it down to the MWE below.\n\nFor context (feel free to skip), this occurs as part of my (still woefully incomplete) SynthControl package, which implements synthetic control estimation. The core of the method is to take a number of potential \"donor\" time series and weight them in such a way that they get as close as possible to a target time series. The full code is here: "},{"type":"link","url":"https://github.com/nilshg/SynthControl.jl/blob/master/src/SynthControl.jl"},{"type":"text","text":", but I've extracted out the relevant bits below:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using Optim, DelimitedFiles, LinearAlgebra\n\nfunction get_weights(y, xs)\n\n    obj(w) = norm(y .- xs*w) + 1e6*abs(1.0 - sum(w))\n\n    # Initial condition and bounds\n    initial = [1e-5 for _ in 1:size(xs, 2)]\n    lower = zeros(size(xs, 2))\n    upper = ones(size(xs, 2))\n\n    # Get weights through optimization\n    res = optimize(obj, lower, upper, initial)\n\n    return res.minimizer\nend\n\nyᵂ = [100.9, 100.9, 100.9, 100.9, 100.9, 100.9, 100.9, 100.9, 100.7, 100.7, 100.7, 100.7, \n      100.2, 100.2, 100.2, 100.1, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.8, \n      99.4, 99.4, 99.4, 99.4, 99.3, 99.2, 99.2, 99.2, 99.2, 98.9, 98.9, 98.9, 98.9, 98.9, \n      98.9, 98.9, 98.9, 98.9, 98.9, 98.8, 98.8, 98.8, 98.7, 98.7, 98.6, 98.6, 98.6, 98.3, \n      97.9, 97.9, 97.9, 97.9, 97.8, 97.7, 97.7, 97.7]\n\nxs = readdlm(\"xs.txt\")\n\nget_weights(yᵂ, xs) # Fails - some weights are NaN\nw₁ = get_weights(yᵂ, xs[:, [1:4; 6:end]])\n\nsum(w₁) # ≈ 1.00\nnorm(yᵂ .- xs[:, [1:4; 6:end]]*w₁) # ≈ 0.897"}]},{"type":"rich_text_section","elements":[]}]}],"user":"U7JQGPGCQ","display_as_bot":false,"ts":"1610533782.021300","thread_ts":"1610533782.021300","reply_count":9,"reply_users_count":2,"latest_reply":"1610558807.025400","reply_users":["UCT7E536E","U7JQGPGCQ"],"subscribed":false},{"client_msg_id":"5d925770-a154-423c-8a4f-6628ea60b92e","type":"message","text":"(don't know the inner workings of Optim, so I can only comment on the math part)\nYour objective is not differentiable everywhere: `norm` is not differentiable at `0`, nor is `abs` ---&gt; I'd bet this is why you're getting some NaN values.\nYou can square the objective &amp; penalty, which will make everything strongly convex:\n``` obj(w) = dot(y .- xs*w, y .- xs*w) + 1e6*(1.0 - sum(w))^2```\nPlus, it may make the optimizer's life easier if your initial point satisfies the `sum(w) == 1` constraint. I'd suggest starting with\n```n = size(xs, 2)\ninitial = [(1/n) for _ in 1:n]```","user":"UCT7E536E","ts":"1610547253.023800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"IN=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"(don't know the inner workings of Optim, so I can only comment on the math part)\nYour objective is not differentiable everywhere: "},{"type":"text","text":"norm","style":{"code":true}},{"type":"text","text":" is not differentiable at "},{"type":"text","text":"0","style":{"code":true}},{"type":"text","text":", nor is "},{"type":"text","text":"abs","style":{"code":true}},{"type":"text","text":" ---> I'd bet this is why you're getting some NaN values.\nYou can square the objective & penalty, which will make everything strongly convex:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":" obj(w) = dot(y .- xs*w, y .- xs*w) + 1e6*(1.0 - sum(w))^2"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Plus, it may make the optimizer's life easier if your initial point satisfies the "},{"type":"text","text":"sum(w) == 1","style":{"code":true}},{"type":"text","text":" constraint. I'd suggest starting with\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"n = size(xs, 2)\ninitial = [(1/n) for _ in 1:n]"}]}]}],"thread_ts":"1610533782.021300","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"04c1373d-e19d-42c7-b9b2-2b40a80f0a73","type":"message","text":"BTW, this problem is a simple quadratic optimization problem, for which you can also use a number of solvers through, e.g., JuMP.\nFor instance:\n```using JuMP, ECOS\n\nfunction get_weights(y, xs)\n    m, n = size(xs)\n    \n    model = Model(ECOS.Optimizer)\n    \n    @variable(model, w[1:n] &gt;= 0)  # your weights\n    \n    @constraint(model, sum(w) == 1)  # this automatically implies w &lt;= 1\n    \n    @variable(model, z[1:m])       # this will hold y - Xw\n    @constraint(model, z .== y .- xs * w)\n    @objective(model, Min, z'z)\n\n    optimize!(model)\n    return value.(w)\nend```","user":"UCT7E536E","ts":"1610547750.024000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hcG/f","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"BTW, this problem is a simple quadratic optimization problem, for which you can also use a number of solvers through, e.g., JuMP.\nFor instance:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"using JuMP, ECOS\n\nfunction get_weights(y, xs)\n    m, n = size(xs)\n    \n    model = Model(ECOS.Optimizer)\n    \n    @variable(model, w[1:n] >= 0)  # your weights\n    \n    @constraint(model, sum(w) == 1)  # this automatically implies w <= 1\n    \n    @variable(model, z[1:m])       # this will hold y - Xw\n    @constraint(model, z .== y .- xs * w)\n    @objective(model, Min, z'z)\n\n    optimize!(model)\n    return value.(w)\nend"}]}]}],"thread_ts":"1610533782.021300","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"1590f39c-66e6-4260-908d-5c3235318b1a","type":"message","text":"Thanks for the suggestions!","user":"U7JQGPGCQ","ts":"1610554320.024200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SAQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks for the suggestions!"}]}]}],"thread_ts":"1610533782.021300","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"09de1845-f949-4a67-80eb-5ed4ad176ae8","type":"message","text":"Okay so switching the objective to quadratic definitely helps, starting from 1/n as initial guess is not so clear cut. I'm getting:\n\n```Starting guess 0, 18 columns\n1.360420 seconds (4.88 M allocations: 2.421 GiB, 17.64% gc time)\nStarting guess 0, 17 columns\n  0.781552 seconds (2.63 M allocations: 1.294 GiB, 17.52% gc time)\nStarting guess 1/n, 18 columns\n┌ Warning: Failed to achieve finite new evaluation point, using alpha=0\n└ @ LineSearches C:\\Users\\ngudat\\.julia\\packages\\LineSearches\\Ki4c5\\src\\hagerzhang.jl:148\n┌ Warning: Failed to achieve finite new evaluation point, using alpha=0\n└ @ LineSearches C:\\Users\\ngudat\\.julia\\packages\\LineSearches\\Ki4c5\\src\\hagerzhang.jl:148\n  1.793122 seconds (6.33 M allocations: 3.154 GiB, 17.62% gc time)\nStarting guess 1/n, 17 columns\n  0.528031 seconds (1.96 M allocations: 981.625 MiB, 17.13% gc time)```\nSo in the \"nicer\" case (where I remove the column that seems to complicate the solution), it helps to speed up the solution if I start from 1/n, while in the pathological case I get warnings and (presumable because of that) the runtime goes up. The overall solution is unaffected though, i.e. both starting guesses yield the same final optimizer.","user":"U7JQGPGCQ","ts":"1610555366.024400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OO9a","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Okay so switching the objective to quadratic definitely helps, starting from 1/n as initial guess is not so clear cut. I'm getting:\n\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"Starting guess 0, 18 columns\n1.360420 seconds (4.88 M allocations: 2.421 GiB, 17.64% gc time)\nStarting guess 0, 17 columns\n  0.781552 seconds (2.63 M allocations: 1.294 GiB, 17.52% gc time)\nStarting guess 1/n, 18 columns\n┌ Warning: Failed to achieve finite new evaluation point, using alpha=0\n└ @ LineSearches C:\\Users\\ngudat\\.julia\\packages\\LineSearches\\Ki4c5\\src\\hagerzhang.jl:148\n┌ Warning: Failed to achieve finite new evaluation point, using alpha=0\n└ @ LineSearches C:\\Users\\ngudat\\.julia\\packages\\LineSearches\\Ki4c5\\src\\hagerzhang.jl:148\n  1.793122 seconds (6.33 M allocations: 3.154 GiB, 17.62% gc time)\nStarting guess 1/n, 17 columns\n  0.528031 seconds (1.96 M allocations: 981.625 MiB, 17.13% gc time)"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"\nSo in the \"nicer\" case (where I remove the column that seems to complicate the solution), it helps to speed up the solution if I start from 1/n, while in the pathological case I get warnings and (presumable because of that) the runtime goes up. The overall solution is unaffected though, i.e. both starting guesses yield the same final optimizer."}]}]}],"thread_ts":"1610533782.021300","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"a711e8fb-9377-4f34-945c-5ef2b63bae84","type":"message","text":"And my god why is the JuMP solution so fast? The runtime is on the order of 0.01 seconds, 50 times faster than going through Optim??","user":"U7JQGPGCQ","ts":"1610555690.024600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"WJh6H","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And my god why is the JuMP solution so fast? The runtime is on the order of 0.01 seconds, 50 times faster than going through Optim??"}]}]}],"thread_ts":"1610533782.021300","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"76fc21f6-259e-49aa-b0d3-53abbaffa0b5","type":"message","text":"In any case for now I've changed the obective, as that seems to be an easy win: <https://github.com/nilshg/SynthControl.jl/commit/1d631118ce5ad7c217b78ee75d4bb7de10963e61>","user":"U7JQGPGCQ","ts":"1610557458.024800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"3LCUJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"In any case for now I've changed the obective, as that seems to be an easy win: "},{"type":"link","url":"https://github.com/nilshg/SynthControl.jl/commit/1d631118ce5ad7c217b78ee75d4bb7de10963e61"}]}]}],"thread_ts":"1610533782.021300","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"e44bb4a6-70bc-46ec-91ba-c7fdfc910672","type":"message","text":"But I wonder whether JuMP is always that much faster for this kind of problem? The next step in my package will be to implement inference which relies on bootstrapping, so I'm going to have to fit this model quite a few times and that kind of speed boost would be welcome","user":"U7JQGPGCQ","ts":"1610557504.025000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"AhJ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"But I wonder whether JuMP is always that much faster for this kind of problem? The next step in my package will be to implement inference which relies on bootstrapping, so I'm going to have to fit this model quite a few times and that kind of speed boost would be welcome"}]}]}],"thread_ts":"1610533782.021300","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"344f99f4-eae3-4ab8-aae9-9289a7f70024","type":"message","text":"Again, I can only reliably comment on the JuMP (really ECOS, JuMP only does the modeling) part:\n• Your problem is convex, and interior-point solvers are among the fastest algorithms for solving those.\n• In addition, the linear constraints are handled explicitly, which removes the need for your original penalty `1e6*abs(1.0 - sum(w))` (especially since the `1e6` factor is likely to have a bad influence on numerics).\n• Finally, by introducing the additional variables `z` in the formulation, the objective becomes diagonal, whereas `dot(y .- xs*w, y .- xs*w)` has a nasty dense structure. That means fewer non-zeros and faster per-iteration operations. (there are still non-zeros in the `z == y - xs * w`, but they only appear once)\nIf you intend to fit the model repeatedly, and assuming only the target `y` changes, then switching to a solver that supports warmstart could give you further performance boost (if you need it). I think SCS, OSQP or COSMO might fit the bill.","user":"UCT7E536E","ts":"1610558409.025200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gLyHg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Again, I can only reliably comment on the JuMP (really ECOS, JuMP only does the modeling) part:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Your problem is convex, and interior-point solvers are among the fastest algorithms for solving those."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"In addition, the linear constraints are handled explicitly, which removes the need for your original penalty "},{"type":"text","text":"1e6*abs(1.0 - sum(w))","style":{"code":true}},{"type":"text","text":" (especially since the "},{"type":"text","text":"1e6","style":{"code":true}},{"type":"text","text":" factor is likely to have a bad influence on numerics)."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Finally, by introducing the additional variables "},{"type":"text","text":"z","style":{"code":true}},{"type":"text","text":" in the formulation, the objective becomes diagonal, whereas "},{"type":"text","text":"dot(y .- xs*w, y .- xs*w)","style":{"code":true}},{"type":"text","text":" has a nasty dense structure. That means fewer non-zeros and faster per-iteration operations. (there are still non-zeros in the "},{"type":"text","text":"z == y - xs * w","style":{"code":true}},{"type":"text","text":", but they only appear once)"}]}],"style":"bullet","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"If you intend to fit the model repeatedly, and assuming only the target "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":" changes, then switching to a solver that supports warmstart could give you further performance boost (if you need it). I think SCS, OSQP or COSMO might fit the bill."}]}]}],"thread_ts":"1610533782.021300","parent_user_id":"U7JQGPGCQ"},{"client_msg_id":"df05ecb0-f312-4d48-960b-dfd3a53f5746","type":"message","text":"Thanks, that's really helpful. For the repeated fit, both `y` and `xs` would change - essentially `y` would be replaced with one of the columns of `xs`, and `y` would instead move into `xs` (so basically a permutation of columns). Would this still be something that warmstart algorithms could deal with?","user":"U7JQGPGCQ","ts":"1610558807.025400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vAM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Thanks, that's really helpful. For the repeated fit, both "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":" and "},{"type":"text","text":"xs","style":{"code":true}},{"type":"text","text":" would change - essentially "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":" would be replaced with one of the columns of "},{"type":"text","text":"xs","style":{"code":true}},{"type":"text","text":", and "},{"type":"text","text":"y","style":{"code":true}},{"type":"text","text":" would instead move into "},{"type":"text","text":"xs","style":{"code":true}},{"type":"text","text":" (so basically a permutation of columns). Would this still be something that warmstart algorithms could deal with?"}]}]}],"thread_ts":"1610533782.021300","parent_user_id":"U7JQGPGCQ"}]