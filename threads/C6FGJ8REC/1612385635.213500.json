[{"client_msg_id":"8bbede20-214d-4113-94dc-92ccd2570dda","type":"message","text":"mad props to <@U681ELA87> and the Arrow.jl contributors for reviving/spearheading the effort to include a pure Julia implementation in the latest Apache Arrow release! <https://arrow.apache.org/blog/2021/01/25/3.0.0-release/> :slightly_smiling_face: happened a few days ago apparently but just saw the HN post today","user":"U674T0Y9Z","ts":"1612385635.213500","team":"T68168MUP","attachments":[{"service_name":"Apache Arrow","title":"Apache Arrow 3.0.0 Release","title_link":"https://arrow.apache.org/blog/2021/01/25/3.0.0-release/","text":"The Apache Arrow team is pleased to announce the 3.0.0 release. This covers over 3 months of development work and includes 666 resolved issues from 106 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Columnar Format Notes The Decimal256 data type, which was already supported by the Arrow columnar format specification, is now implemented in C++ and Java (ARROW-9747). Arrow Flight RPC notes Authentication in C++/Java/Python has been overhauled, allowing more flexible authentication methods and use of standard headers. Support for cookies has also been added. The C++/Java implementations are now more permissive when parsing messages in order to interoperate better with other Flight implementations. A basic Flight implementation for C#/.NET has been added. See the implementation status matrix for details. C++ notes The default memory pool can now be changed at runtime using the environment variable ARROW_DEFAULT_MEMORY_POOL (ARROW-11009). The environment variable is inspected at process startup. This is useful when trying to diagnose memory consumption issues with Arrow. STL-like iterators are now provided over concrete arrays. Those are useful for non-performance critical tasks, for example testing (ARROW-10776). It is now possible to concatenate dictionary arrays with unequal dictionaries. The dictionaries are unified when concatenating, for supported data types (ARROW-5336). Threads in a thread pool are now spawned lazily as needed for enqueued tasks, up to the configured capacity. They used to be spawned upfront on creation of the thread pool (ARROW-10038). Compute layer Comprehensive documentation for compute functions is now available: <https://arrow.apache.org/docs/cpp/compute.html> Compute functions for string processing have been added for: splitting on whitespace (ASCII and Unicode flavors) and splitting on a pattern (ARROW-9991); trimming characters (ARROW-9128). Behavior of the index_in and is_in compute functions with nulls has been changed for consistency (ARROW-10663). Multiple-column sort kernels are now available for tables and record batches (ARROW-8199, ARROW-10796, ARROW-10790). Performance of table filtering has been vastly improved (ARROW-10569). Scalar arguments are now accepted for more compute functions. Compute functions quantile (ARROW-10831) and is_nan (ARROW-11043) have been added for numeric data. Aggregation functions any (ARROW-1846) and all (ARROW-10301) have been added for boolean data. Dataset The Expression hierarchy has simplified to a wrapper around literals, field references, or calls to named functions. This enables usage of any compute function while filtering with no boilerplate. Parquet statistics are lazily parsed in ParquetDatasetFactory and ParquetFileFragment for shorter construction time. CSV Conversion of string columns is now faster thanks to faster UTF-8 validation of small strings (ARROW-10313). Conversion of floating-point columns is now faster thanks to optimized string-to-double conversion routines (ARROW-10328). Parsing of ISO8601 timestamps is now more liberal: trailing zeros can be omitted in the fractional part (ARROW-10337). Fixed a bug where null detection could give the wrong results on some platforms (ARROW-11067). Added type inference for Date32 columns for values in the form YYYY-MM-DD (ARROW-11247). Feather Fixed reading of compressed Feather files written with Arrow 0.17 (ARROW-11163). Filesystem layer S3 recursive tree walks now benefit from a parallel implementation, where reads of multiple child directories are now issued concurrently (ARROW-10788). Improved empty directory detection to be mindful of differences between Amazon and Minio S3 implementations (ARROW-10942). Flight RPC IPv6 host addresses are now supported (ARROW-10475). IPC It is now possible to emit dictionary deltas where possible using the IPC stream writer. This is governed by a new variable in the IpcWriteOptions class (ARROW-6883). It is now possible to read wider tables, which used to fail due to reaching a limit during Flatbuffers verification (ARROW-10056). Parquet Fixed reading of LZ4-compressed Parquet columns emitted by the Java Parquet implementation (ARROW-11301). Fixed a bug where writing multiple batches of nullable nested strings to Parquet would not write any data in batches after the first one (ARROW-10493) The Decimal256 data type can be read from and written to Parquet (ARROW-10607). LargeString and LargeBinary data can now be written to Parquet (ARROW-10426). C# notes The .NET package added initial support for Arrow Flight clients and servers. Support is enabled through two new NuGet packages Apache.Arrow.Flight (client) and Apache.Arrow.Flight.AspNetCore (server). Also fixed an issue where ArrowStreamWriter wasn’t writing schema metadata to Arrow streams. Julia notes This is the first release to officially include an implementation for the Julia language. The pure Julia implementation includes support for wide coverage of the format specification. Additional details can be found in the <http://julialang.org|julialang.org> blog post. Python notes Support for Python 3.9 was added (ARROW-10224), and support for Python 3.5 was removed (ARROW-5679). Support for building manylinux1 packages has been removed (ARROW-11212). PyArrow continues to be available as manylinux2010 and manylinux2014 wheels. The minimal required version for NumPy is now 1.16.6. Note that when upgrading NumPy to 1.20, you also need to upgrade pyarrow to 3.0.0 to ensure compatibility, as this pyarrow release fixed a compatibility issue with NumPy 1.20 (ARROW-10833). Compute functions are now automatically exported from C++ to the pyarrow.compute module, and they have docstrings matching their C++ definition. An iter_batches() method is now available for reading a Parquet file iteratively (ARROW-7800). Alternate memory pools (such as mimalloc, jemalloc or the C malloc-based memory pool) are now available from Python (ARROW-11049). Fixed a potential deadlock when importing pandas from several threads (ARROW-10519). See the C++ notes above for additional details. R notes This release contains new features for the Flight RPC wrapper, better support for saving R metadata (including sf spatial data) to Feather and Parquet files, several significant improvements to speed and memory management, and many other enhancements. For more on what’s in the 3.0.0 R package, see the R changelog. Ruby and C GLib notes Ruby In Ruby binding, 256-bit decimal support and Arrow::FixedBinaryArrayBuilder are added likewise C GLib below. C GLib In the version 3.0.0 of C GLib consists of many new features. A chunked array, a record batch, and a table support sort_indices function as well as an array. These functions including array’s support to specify sorting option. garrow_array_sort_to_indices has been renamed to garrow_array_sort_indices and the previous name has been deprecated. GArrowField supports functions to handle metadata. GArrowSchema supports garrow_schema_has_metadata() function. GArrowArrayBuilder supports to add single null, multiple nulls, single empty value, and multiple empty values. GArrowFixedSizedBinaryArrayBuilder is newly supported. 256-bit decimal and extension types are newly supported. Filesystem module supports Mock, HDFS, S3 file systems. Dataset module supports CSV, IPC, and Parquet file formats. Rust notes Core Arrow Crate The development of the arrow crate was focused on four main aspects: Make the crate usable in stable Rust Bug fixing and removal of unsafe code Extend functionality to keep up with the specification Increase performance of existing kernels Stable Rust Possibly the biggest news for this release is that all project crates, including arrow, parquet, and datafusion now build with sta…","fallback":"Apache Arrow: Apache Arrow 3.0.0 Release","ts":1611554400,"from_url":"https://arrow.apache.org/blog/2021/01/25/3.0.0-release/","service_icon":"https://arrow.apache.org/img/apple-touch-icon.png","id":1,"original_url":"https://arrow.apache.org/blog/2021/01/25/3.0.0-release/"}],"blocks":[{"type":"rich_text","block_id":"lSp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"mad props to "},{"type":"user","user_id":"U681ELA87"},{"type":"text","text":" and the Arrow.jl contributors for reviving/spearheading the effort to include a pure Julia implementation in the latest Apache Arrow release! "},{"type":"link","url":"https://arrow.apache.org/blog/2021/01/25/3.0.0-release/"},{"type":"text","text":" "},{"type":"emoji","name":"slightly_smiling_face"},{"type":"text","text":" happened a few days ago apparently but just saw the HN post today"}]}]}],"thread_ts":"1612385635.213500","reply_count":31,"reply_users_count":8,"latest_reply":"1612455827.228300","reply_users":["U681ELA87","U0179G7FG4F","U9VG1AYSG","U674T0Y9Z","USU9FRPEU","U679VPJ8L","UB7JS9CHF","U6A936746"],"subscribed":false,"reactions":[{"name":"+1","users":["U69CJGKEY","U0179G7FG4F","UGR3910CQ","UDXST8ARK","UC53031QU","U9VG1AYSG","U67G3QRJM","UM30MT6RF","U6795JH6H","U68907M46"],"count":10},{"name":"heart","users":["UGR3910CQ","UDXST8ARK","UC53031QU","U67G3QRJM","U6QGE7S86","US64J0NPQ","U66SGEWAC","UM30MT6RF","U6795JH6H","U68907M46"],"count":10},{"name":"dart","users":["U66M57AN4","U6QGE7S86","UM30MT6RF","U6795JH6H","U68907M46","ULUC3K6M6","U821PV38V","U82LX4ACB","U68QW0PUZ"],"count":9},{"name":"bow_and_arrow","users":["UDB26738Q","U6QGE7S86","US64J0NPQ","UM30MT6RF","U6795JH6H","U68907M46","ULUC3K6M6","U82LX4ACB","U68QW0PUZ"],"count":9},{"name":"point_up","users":["U6A936746","U6795JH6H","U68907M46"],"count":3}]},{"client_msg_id":"d1d38962-49d9-4d8c-887e-fa33c1afb1a6","type":"message","text":"yeah, they just merged in the official blogpost announcement, so that's the hype going on today. fun stuff!","user":"U681ELA87","ts":"1612385708.213800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gUUK","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, they just merged in the official blogpost announcement, so that's the hype going on today. fun stuff!"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"08e7ecd4-a9d5-4742-8881-9ba970cc7086","type":"message","text":"I'm interested to hear where people think we should take Arrow.jl next; options including:\n• wrap the C data interface, which sounds like it makes interopping w/ R/Python a little more straightforward? I haven't looked into all the details yet\n• Providing full Julia object serialization/deserialization abilities; pyarrow supports this, but it hasn't been super popular due to other languages not being able to interop super well. But we've had some requests on the Julia side to support tuples, sets, DataType, etc.\n• arrow flight/gRPC capabilities; again, I don't know all the details here, but I've just heard a few requests and know it's part of the \"implementation status\" for other languages.","user":"U681ELA87","ts":"1612385871.214100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4FXq","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm interested to hear where people think we should take Arrow.jl next; options including:\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"wrap the C data interface, which sounds like it makes interopping w/ R/Python a little more straightforward? I haven't looked into all the details yet"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Providing full Julia object serialization/deserialization abilities; pyarrow supports this, but it hasn't been super popular due to other languages not being able to interop super well. But we've had some requests on the Julia side to support tuples, sets, DataType, etc."}]},{"type":"rich_text_section","elements":[{"type":"text","text":"arrow flight/gRPC capabilities; again, I don't know all the details here, but I've just heard a few requests and know it's part of the \"implementation status\" for other languages."}]}],"style":"bullet","indent":0}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"280ec06b-e020-4ad9-8c0d-1770b950c1ee","type":"message","text":"2 sounds like a really good GSOC","user":"U0179G7FG4F","ts":"1612386417.215000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"EIo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"2 sounds like a really good GSOC"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z","reactions":[{"name":"+1","users":["U680THK2S","U6QGE7S86"],"count":2}]},{"client_msg_id":"ff44ca38-a6b0-4430-abe6-9b8e180a94e4","type":"message","text":"I think what's probably most needed is making it easy to emit arrow messages from objects that are not necessarily arrow formatted.  For example, not only do we desperately need a much more mature and robust Parquet package, but it would be nice to be able to generate arrow messages from it without copying.  This would be a major step toward gettign Julia on equal fotting with the JVM \"big data\" ecosystem i.e. spark","user":"U9VG1AYSG","ts":"1612386549.215300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qkC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think what's probably most needed is making it easy to emit arrow messages from objects that are not necessarily arrow formatted.  For example, not only do we desperately need a much more mature and robust Parquet package, but it would be nice to be able to generate arrow messages from it without copying.  This would be a major step toward gettign Julia on equal fotting with the JVM \"big data\" ecosystem i.e. spark"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z","reactions":[{"name":"thumbsup_all","users":["U0179G7FG4F","UDXST8ARK"],"count":2}]},{"client_msg_id":"8da3bbff-69f2-471d-a723-82e904da7717","type":"message","text":"granted, a lot of that work will not be directly related to arrow, so it may not be the kind of thing you're looking to get into","user":"U9VG1AYSG","ts":"1612386593.215700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tBM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"granted, a lot of that work will not be directly related to arrow, so it may not be the kind of thing you're looking to get into"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"fa5a2078-f5d5-4145-9bd0-ba8f10cc506d","type":"message","text":"Parquet is by a very wide margin my most wanted/needed thing to be better supported in the Julia data ecosystem right now.  I've been contemplating making a package for a very long time, but I learned a lesson about not taking on things that I might think are useful but really do not want to work on when I failed to follow through on arrow in the first place","user":"U9VG1AYSG","ts":"1612386721.215900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"cV39","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Parquet is by a very wide margin my most wanted/needed thing to be better supported in the Julia data ecosystem right now.  I've been contemplating making a package for a very long time, but I learned a lesson about not taking on things that I might think are useful but really do not want to work on when I failed to follow through on arrow in the first place"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z","reactions":[{"name":"thumbsup_all","users":["U0179G7FG4F","UDXST8ARK"],"count":2}]},{"client_msg_id":"2b853a05-b639-4629-a223-ed6faa1ce065","type":"message","text":"yeah, that's a good point on Parquet.jl integration. I've looked over Parquet.jl code and it's not too bad; there's just a lot of gaps in coverage, and some API \"conveniences\" that would make it a lot more useable.","user":"U681ELA87","ts":"1612386834.216400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"f2/7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, that's a good point on Parquet.jl integration. I've looked over Parquet.jl code and it's not too bad; there's just a lot of gaps in coverage, and some API \"conveniences\" that would make it a lot more useable."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"966076b3-8d3c-4c28-9056-a91a0230aeee","type":"message","text":"at least from my perspective:\n\n1. agnostic to this\n2. I think there'd be potentially sharp edge cases here depending on how generic/automagic the target functionality is. My preference would be to make the system for extending \"built-in\" conversions very nice/robust. The existing system is already pretty capable as-is, can imagine extra niceties like  an option for callsite overrides, e.g. \"I know the default for `T` is usually to serialize it as `X` but for this call please serialize any encountered `T` as `Y`\". \n3. IMO this could be a big/fun win if Flight gains more adoption in other tools/services. I'd like to see it supported just so I have an excuse to play with it :grin: \nhaving Parquet file -&gt; Arrow in-memory super nicely supported as mentioned would probably make a lot of folks more willing to use Julia vs. pyarrow. For this use case my current preferred fallback is to read in the file via pyarrow + PyCall and then I can map the memory with Julia lol. Though haven't had to interact with Parquet in a while","user":"U674T0Y9Z","ts":"1612386955.216700","team":"T68168MUP","edited":{"user":"U674T0Y9Z","ts":"1612386998.000000"},"blocks":[{"type":"rich_text","block_id":"Lyj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"at least from my perspective:\n\n"}]},{"type":"rich_text_list","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"agnostic to this"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"I think there'd be potentially sharp edge cases here depending on how generic/automagic the target functionality is. My preference would be to make the system for extending \"built-in\" conversions very nice/robust. The existing system is already pretty capable as-is, can imagine extra niceties like  an option for callsite overrides, e.g. \"I know the default for "},{"type":"text","text":"T","style":{"code":true}},{"type":"text","text":" is usually to serialize it as "},{"type":"text","text":"X","style":{"code":true}},{"type":"text","text":" but for this call please serialize any encountered "},{"type":"text","text":"T","style":{"code":true}},{"type":"text","text":" as "},{"type":"text","text":"Y","style":{"code":true}},{"type":"text","text":"\". "}]},{"type":"rich_text_section","elements":[{"type":"text","text":"IMO this could be a big/fun win if Flight gains more adoption in other tools/services. I'd like to see it supported just so I have an excuse to play with it "},{"type":"emoji","name":"grin"},{"type":"text","text":" "}]}],"style":"ordered","indent":0},{"type":"rich_text_section","elements":[{"type":"text","text":"\nhaving Parquet file -> Arrow in-memory super nicely supported as mentioned would probably make a lot of folks more willing to use Julia vs. pyarrow. For this use case my current preferred fallback is to read in the file via pyarrow + PyCall and then I can map the memory with Julia lol. Though haven't had to interact with Parquet in a while"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z","reactions":[{"name":"+1","users":["UDXST8ARK","U6A936746"],"count":2},{"name":"point_up","users":["U6A936746"],"count":1},{"name":"100","users":["U6A936746"],"count":1}]},{"client_msg_id":"b7f3bd04-fbf9-4305-abe2-3f27226e3755","type":"message","text":"One of the big problems with Parquet.jl was that it did not support writing.  I know somebody hacked in a temporary fix, but, last I checked, it didn't perform very well","user":"U9VG1AYSG","ts":"1612387089.217000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"4SX","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One of the big problems with Parquet.jl was that it did not support writing.  I know somebody hacked in a temporary fix, but, last I checked, it didn't perform very well"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"e03344a6-d282-4d5a-ac8b-9639d83a3081","type":"message","text":"Parquet is a very big deal because in many contexts it's really the *only* viable binary format.  One of the reasons is that it is the only binary format that AWS-athena/apache-presto can read out of the box.  Even though I think arrow is perfectly fine for an on-disk format and i'd be happy to use it, at work I am almost always stuck with csv's in practice because my colleagues simply can't use anything other than parquet","user":"U9VG1AYSG","ts":"1612387200.217200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"fKH","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Parquet is a very big deal because in many contexts it's really the "},{"type":"text","text":"only","style":{"bold":true}},{"type":"text","text":" viable binary format.  One of the reasons is that it is the only binary format that AWS-athena/apache-presto can read out of the box.  Even though I think arrow is perfectly fine for an on-disk format and i'd be happy to use it, at work I am almost always stuck with csv's in practice because my colleagues simply can't use anything other than parquet"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"be6c8c4f-a184-4267-81dd-3e9e4e4fe518","type":"message","text":"btw, on your other points: I think 2 will have so many annoying and hard to resolve edge cases that it's just not going to be worth your time.  and isn't 3 basically done?  what else would you need to do for that?","user":"U9VG1AYSG","ts":"1612387258.217600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"FNk","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"btw, on your other points: I think 2 will have so many annoying and hard to resolve edge cases that it's just not going to be worth your time.  and isn't 3 basically done?  what else would you need to do for that?"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"1c21b07e-5fb8-45d6-b554-87d036e2bd1d","type":"message","text":"Someone should add Julia to the Wikipedia page: <https://en.wikipedia.org/wiki/Apache_Arrow>","user":"USU9FRPEU","ts":"1612390325.220300","team":"T68168MUP","attachments":[{"title":"Apache Arrow","title_link":"https://en.wikipedia.org/wiki/Apache_Arrow","from_url":"https://en.wikipedia.org/wiki/Apache_Arrow","author_name":"Wikipedia","author_link":"https://en.wikipedia.org/","text":"Apache Arrow is a language-agnostic software framework for developing data analytics applications that process columnar data. It contains a standardized column-oriented memory format that is able to represent flat and hierarchical data for efficient analytic operations on modern CPU and GPU hardware. This reduces or eliminates factors that limit the feasibility of working with large sets of data, such as the cost, volatility, or physical constraints of dynamic random-access memory.","fallback":"wikipedia: Apache Arrow","service_icon":"https://a.slack-edge.com/80588/img/unfurl_icons/wikipedia.png","id":1,"original_url":"https://en.wikipedia.org/wiki/Apache_Arrow"}],"blocks":[{"type":"rich_text","block_id":"/=AAa","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Someone should add Julia to the Wikipedia page: "},{"type":"link","url":"https://en.wikipedia.org/wiki/Apache_Arrow"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z","reactions":[{"name":"thumbsup_all","users":["U0179G7FG4F"],"count":1}]},{"client_msg_id":"5a696896-fdf7-4300-8e84-e8fd82e6f9a3","type":"message","text":"<@U9VG1AYSG>, unfortunately I think #3 is still a lot of work because we need to first have a working gRPC implementation, which I've heard requires HTTP2. :grimacing: . I should look more into it though to get a better idea of what's actually required.","user":"U681ELA87","ts":"1612391112.220700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LN4","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U9VG1AYSG"},{"type":"text","text":", unfortunately I think #3 is still a lot of work because we need to first have a working gRPC implementation, which I've heard requires HTTP2. "},{"type":"emoji","name":"grimacing"},{"type":"text","text":" . I should look more into it though to get a better idea of what's actually required."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"b47846cc-bc0f-4a6a-978f-33c1997121b1","type":"message","text":"This may not be a good idea, but I should mention that base now comes with curl, and that is built with HTTP2 support. If that helps.","user":"U679VPJ8L","ts":"1612392160.220900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"p06f","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"This may not be a good idea, but I should mention that base now comes with curl, and that is built with HTTP2 support. If that helps."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"155c0390-530e-4b53-87d1-bf83fe2faa1c","type":"message","text":"doesn't HTTP.jl support HTTP2?  I thought it did.  If it doesn't, it needs to","user":"U9VG1AYSG","ts":"1612392293.221100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Tvfu","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"doesn't HTTP.jl support HTTP2?  I thought it did.  If it doesn't, it needs to"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"2df23691-589c-4770-a9a2-1eb524a54691","type":"message","text":"HTTP.jl  really needs some love","user":"U0179G7FG4F","ts":"1612392385.221300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"jisrt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"HTTP.jl  really needs some love"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"95d91cf3-ef6b-4052-af9e-5ce1d1364a02","type":"message","text":"Not, http.jl does not support HTTP2.","user":"U679VPJ8L","ts":"1612392461.221500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hIO1e","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Not, http.jl does not support HTTP2."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"4c4dfbd4-f768-47d5-95f3-f271b3cc4e38","type":"message","text":"Oh, it could certainly be interesting to look into using libcurl for the http2 part.","user":"U681ELA87","ts":"1612392638.221700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"45+i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Oh, it could certainly be interesting to look into using libcurl for the http2 part."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"a6933aea-9a3b-462b-b94c-abf8e1afbed5","type":"message","text":"I can't say I like that idea.  Shouldn't HTTP support it?  Would it even be that hard?","user":"U9VG1AYSG","ts":"1612393965.221900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JD2i","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I can't say I like that idea.  Shouldn't HTTP support it?  Would it even be that hard?"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"5978f23a-4731-4214-b848-b09e050675a2","type":"message","text":"I think the core parts of HTTP.jl are really good, but a lot of functionality has been crammed into it over the years and not all of it is so great.  For example, I was looking into using it as a REST API server, and I found [this](<https://github.com/JuliaWeb/HTTP.jl/issues/668>).  I think a lot of that stuff  which is pretty wonky should just be moved to other packages anyway","user":"U9VG1AYSG","ts":"1612394039.222100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ALo","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I think the core parts of HTTP.jl are really good, but a lot of functionality has been crammed into it over the years and not all of it is so great.  For example, I was looking into using it as a REST API server, and I found [this]("},{"type":"link","url":"https://github.com/JuliaWeb/HTTP.jl/issues/668"},{"type":"text","text":").  I think a lot of that stuff  which is pretty wonky should just be moved to other packages anyway"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"7e2ec615-3597-4bb9-a791-4a161d06a8de","type":"message","text":"but I think the core functionality is fine","user":"U9VG1AYSG","ts":"1612394057.222300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"V+c","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"but I think the core functionality is fine"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"ab0aa1b5-2b18-4f2a-9595-923ffe4bfa35","type":"message","text":"ok, I looked at it, and yeah, it's a lot more involved than I thought to do HTTP2.  It would be kind of depressing if we had to rely on a curl wrapper for it though","user":"U9VG1AYSG","ts":"1612394221.222500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Bx=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ok, I looked at it, and yeah, it's a lot more involved than I thought to do HTTP2.  It would be kind of depressing if we had to rely on a curl wrapper for it though"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"3ed262f1-73fe-4f54-add2-a26a121df443","type":"message","text":"HTTP/2 support and gRPC support are critical for a number of projects that I’ve been involved with.\nIf HTTP.jl needs love, then I think getting that revamped, cleaned up, along with adding HTTP/2 support, should be the #1 priority.","user":"UB7JS9CHF","ts":"1612441900.223700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JKF6u","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"HTTP/2 support and gRPC support are critical for a number of projects that I’ve been involved with.\nIf HTTP.jl needs love, then I think getting that revamped, cleaned up, along with adding HTTP/2 support, should be the #1 priority."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"37c34312-3ba0-4b9d-a00a-c1ce62feaafc","type":"message","text":"Followed by using that to have rock solid gRPC &amp; Arrow Flight support.","user":"UB7JS9CHF","ts":"1612441933.223900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"GCpCz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Followed by using that to have rock solid gRPC & Arrow Flight support."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"e3ab672c-deef-4c2c-9e1a-06fa137b8e60","type":"message","text":"re #2, how much overlap would it have with StructTypes?\nRIght now it seems storing a `Interval{ZonedDateTime}` in a Arrow comes back as a\n`NamedTuple{(:first, :last),Tuple{ZonedDateTime,ZonedDateTime}}`\n\nWhich is Pretty Good.","user":"U6A936746","ts":"1612443954.224100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"SHY","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"re #2, how much overlap would it have with StructTypes?\nRIght now it seems storing a "},{"type":"text","text":"Interval{ZonedDateTime}","style":{"code":true}},{"type":"text","text":" in a Arrow comes back as a\n"},{"type":"text","text":"NamedTuple{(:first, :last),Tuple{ZonedDateTime,ZonedDateTime}}","style":{"code":true}},{"type":"text","text":"\n\nWhich is Pretty Good."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"db76e510-f48d-4406-af67-b2c9de553194","type":"message","text":"Arbitary serialization and deserialization is hard, and tends to lead to eventually having to depend on the Julia serializer (as BSON.jl does) which gives up a lot of the benifits of stability.\n\nbut on things that are simply “record” types, i.e. that basically already work with JSON3\nthat seems doable","user":"U6A936746","ts":"1612444070.224300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"tIvT","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Arbitary serialization and deserialization is hard, and tends to lead to eventually having to depend on the Julia serializer (as BSON.jl does) which gives up a lot of the benifits of stability.\n\nbut on things that are simply “record” types, i.e. that basically already work with JSON3\nthat seems doable"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"11be74fd-9b2d-4dd9-8708-24335ab751c1","type":"message","text":"oh apparently this already works via <https://arrow.juliadata.org/dev/manual/#Custom-types>","user":"U6A936746","ts":"1612446335.224600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vR2d","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"oh apparently this already works via "},{"type":"link","url":"https://arrow.juliadata.org/dev/manual/#Custom-types"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"e33081fd-521a-483b-bb7a-5fa038f0a70d","type":"message","text":"Arbitrary serialization and deserialization might also run into issues with security, if you are deserializing methods.","user":"UB7JS9CHF","ts":"1612452420.224800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1HYV6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Arbitrary serialization and deserialization might also run into issues with security, if you are deserializing methods."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"27b01c7e-7914-403d-9624-f43839eef66f","type":"message","text":"I am largely convinced that you can’t have arbitrary serialisation that is secure (or for that matter language independent)\n\n<@UEE32C30F> made proof of concept arbitary code execution attacks for a bunch of our formats\ne.g. <https://github.com/JuliaIO/BSON.jl/issues/50>\n\nand I know these exist for Python’s pickles.","user":"U6A936746","ts":"1612452767.225600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ETjN4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I am largely convinced that you can’t have arbitrary serialisation that is secure (or for that matter language independent)\n\n"},{"type":"user","user_id":"UEE32C30F"},{"type":"text","text":" made proof of concept arbitary code execution attacks for a bunch of our formats\ne.g. "},{"type":"link","url":"https://github.com/JuliaIO/BSON.jl/issues/50"},{"type":"text","text":"\n\nand I know these exist for Python’s pickles."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z"},{"client_msg_id":"8d93c2f6-f57a-4b81-acd7-6956bde70c2b","type":"message","text":"usually arbitrarily serialization is only used in trusted contexts anyway, e.g. Julia's cluster manager.  It's not really a public internet thing","user":"U9VG1AYSG","ts":"1612454887.226900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"gpcQ1","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"usually arbitrarily serialization is only used in trusted contexts anyway, e.g. Julia's cluster manager.  It's not really a public internet thing"}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z","reactions":[{"name":"+1","users":["U6A936746"],"count":1}]},{"client_msg_id":"d1a995da-4611-435c-b023-446e9f1be7f7","type":"message","text":"You would hope that.\nBut sadly often people are not aware of this.\nand are just like:\n“BSON.jl? Seems legit lets share my pretrained models in BSON.jl”\nDoesn’t pretrained Flux models in TextAnalysis and MetalHead do that?\n\nMLJ serialized with JLSO (which has this flaw also), though I don’t think it has a libary of pretraining models\n\n\nPyTorch uses Pickles\n<https://pytorch.org/tutorials/beginner/saving_loading_models.html>\nI haven’t checked if they also use it in their `hub` submodule, which is used for their giant library of pretained models.\n\n\nIn general academic publish data in random formats all the time.\nThey shouldn’t but they do.","user":"U6A936746","ts":"1612455827.228300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Lds3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"You would hope that.\nBut sadly often people are not aware of this.\nand are just like:\n“BSON.jl? Seems legit lets share my pretrained models in BSON.jl”\nDoesn’t pretrained Flux models in TextAnalysis and MetalHead do that?\n\nMLJ serialized with JLSO (which has this flaw also), though I don’t think it has a libary of pretraining models\n\n\nPyTorch uses Pickles\n"},{"type":"link","url":"https://pytorch.org/tutorials/beginner/saving_loading_models.html"},{"type":"text","text":"\nI haven’t checked if they also use it in their "},{"type":"text","text":"hub","style":{"code":true}},{"type":"text","text":" submodule, which is used for their giant library of pretained models.\n\n\nIn general academic publish data in random formats all the time.\nThey shouldn’t but they do."}]}]}],"thread_ts":"1612385635.213500","parent_user_id":"U674T0Y9Z","reactions":[{"name":"thumbsup_all","users":["U0179G7FG4F"],"count":1}]}]