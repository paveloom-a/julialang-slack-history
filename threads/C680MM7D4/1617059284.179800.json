[{"client_msg_id":"25f2a8df-e89d-4119-921a-e86d8930b522","type":"message","text":"I had been wondering for a while why noone used the x86 instruction for sin.\n\n<https://randomascii.wordpress.com/2014/10/09/intel-underestimates-error-bounds-by-1-3-quintillion/|https://randomascii.wordpress.com/2014/10/09/intel-underestimates-error-bounds-by-1-3-quintillion/>","user":"U6A936746","ts":"1617059284.179800","team":"T68168MUP","attachments":[{"service_name":"Random ASCII - tech blog of Bruce Dawson","service_url":"http://randomascii.wordpress.com","title":"Intel Underestimates Error Bounds by 1.3 quintillion","title_link":"https://randomascii.wordpress.com/2014/10/09/intel-underestimates-error-bounds-by-1-3-quintillion/","author_name":"brucedawson","author_link":"https://randomascii.wordpress.com/author/brucedawson/","thumb_url":"http://randomascii.files.wordpress.com/2014/10/image_thumb.png?fit=200%2C150","text":"Intel&rsquo;s manuals for their x86/x64 processor clearly state that the fsin instruction (calculating the trigonometric sine) has a maximum error, in round-to-nearest mode, of one unit in the last place. This is not true. It&rsquo;s not even close.\nThe worst-case error for the fsin instruction for small inputs is actually about 1.37 quintillion units in the last place, leaving fewer than four bits correct. For huge inputs it can be much worse, but I&rsquo;m going to ignore that.\nI was shocked when I discovered this. Both the fsin instruction and Intel&rsquo;s documentation are hugely inaccurate, and the inaccurate documentation has led to poor decisions being made.\nThe great news is that when I shared an early version of this blog post with Intel they reacted quickly and the documentation is going to get fixed!\n\nI discovered this while playing around with my favorite mathematical identity. If you add a double-precision approximation for pi to the sin() of that same value then the sum of the two values (added by hand) gives you a quad-precision estimate (about 33 digits) for the value of pi. This works because the sine of a number very close to pi is almost equal to the error in the estimate of pi. This is just calculus 101, and a variant of Newton&rsquo;s method, but I still find it charming.\nThe sin() function in VC++ is accurate enough for this technique to work well. However this technique relies on printing the value of the double-precision approximation of pi to 33 digits, and up to VC++ 2013&nbsp; this doesn&rsquo;t work &ndash; the extra digits are all printed as zeroes. So, you either need custom printing code or you need to wait for Dev 14 which has improved printing code.\nSo, I tried g++ on 32-bit Linux (Ubuntu 12.04) because I knew that glibc handles the printing just fine. However the results weren&rsquo;t adding up correctly. I eventually realized that the sin() function in 32-bit versions of 2.15 glibc is just a thin wrappers around fsin and this instruction is painfully inaccurate when the input is near pi.\nCatastrophic cancellation, enshrined in silicon\nThe first step in calculating trigonometric functions like sin() is range reduction. The input number, which Intel says can be up into the quintillion range, needs to be reduced down to between +/- pi/2.\nRange reduction in general is a tricky problem, but range reduction around pi is actually very easy. You just have to subtract the input number from a sufficiently precise approximation of pi. The worst-case for range reduction near pi will be the value that is closest to pi. For double-precision this will be a 53-bit approximation to pi that is off by, at most, half a unit in the last place (0.5 ULP). If you want to have 53 bits of accuracy in the result then you need to subtract from an approximation to pi that is accurate to at least 106 bits &ndash; half the bits will cancel out but you&rsquo;ll still be left with enough.\nBut you actually need more than that. The x87 FPU has 80-bit registers which have a 64-bit mantissa. If you are doing long-double math and you want your range reduction of numbers near pi to be accurate then you need to subtract from at least a 128-bit approximation to pi.\nThis is still easy. If you know your input number is near pi then just extract the mantissa and do high-precision integer math to subtract from a hard-coded 128-bit approximation to pi. Round carefully and then convert back to floating-point. In case you want to give this a try I converted&nbsp;pi to 192-bits of hexadecimal:\nC90FDAA2 2168C234 C4C6628B 80DC1CD1 29024E08 8A67CC74\nBut Intel doesn&rsquo;t use a 128-bit approximation to pi. Their approximation has just 66 bits. Here it is, taken from their manuals:\nC90FDAA2 2168C234 C\nTherein lies the problem. When doing range reduction from double-precision (53-bit mantissa) pi the results will have about 13 bits of precision (66 minus 53), for an error of up to 2^40 ULPs (53 minus 13). The measured error is lower at approximately 164 billion ULPs (~37 bits), but that&rsquo;s still large. When doing range reduction from the 80-bit long-double format there will be almost complete cancellation and the worst-case error is 1.376 quintillion ULPs.\nOops.\nActually calculating sin\nAfter range reduction the next step is to calculate sin. For numbers that are sufficiently close to pi this is trivial &ndash; the range-reduced number is the answer. Therefore, for double(pi) the error in the range reduction is the error in fsin, and fsin is inaccurate near pi, contradicting Intel&rsquo;s documentation. QED.\nNote that sin(double(pi)) should not return zero. The sine of pi is, mathematically, zero, but since float/double/long-double can&rsquo;t represent pi it would actually be incorrect for sin() to return zero when passed an approximation to pi.\nFrustration\nIt is surprising that fsin is so inaccurate. I could perhaps forgive it for being inaccurate for extremely large inputs (which it is) but it is hard to forgive it for being so inaccurate on pi which is, ultimately, a very &lsquo;normal&rsquo; input to the sin() function. Ah, the age-old decisions that we&rsquo;re then stuck with for decades.\nI also find Intel&rsquo;s documentation frustrating. In their most recent Volume 2: Instruction Set Reference they say that the range for fsin is -2^63 to +2^63. Then, in Volume 3: System Programming Guide, section 22.18.8 (Transcendental Instructions) they say &ldquo;results will have a worst case error of less than 1 ulp when rounding to the nearest-even&rdquo;. They reiterate this in section 8.3.10 (Transcendental Instruction Accuracy) of Volume 1: Basic Architecture.\nSection 8.3.8 (Pi) of the most recent Volume 1: Basic Architecture documentation from Intel discusses the 66-bit approximation for pi that the x87 CPU uses, and says that it has been &ldquo;chosen to guarantee no loss of significance in a source operand&rdquo;, which is simply not true. This optimistic documentation has consequences. In 2001 an up-and-coming Linux kernel programmer believed this documentation and used it to argue against adding an fsin wrapper function to glibc.\nSimilar problems apply to fcos near pi/2. See this blog post for more details and pretty pictures.\nIntel has known for years that these instructions are not as accurate as promised. They are now making updates to their documentation. Updating the instruction is not a realistic option.\nI ran my tests on the 2.19 version of glibc (Ubuntu 14.04) and found that it no longer uses fsin. Clearly the glibc developers are aware of the problems with fsin and have stopped using it. That&rsquo;s good because g++ sometimes calculates sin at compile-time, and the compile-time version is far more accurate than fsin, which makes for some bizarre inconsistencies when using glibc 2.15, which can make floating-point determinism challenging.\nIs it a bug?\nWhen Intel&rsquo;s fdiv instruction was found to be flawed it was clearly a bug. The IEEE-754 spec says exactly how fdiv should be calculated (perfectly rounded) but imposes no restrictions on fsin. Intel&rsquo;s implementation of fsin is clearly weak, but for compatibility reasons it probably can&rsquo;t be changed so it can&rsquo;t really be considered a bug at this point.\nHowever the documentation is buggy. By claiming near-perfect accuracy across a huge domain and then only providing it in a tiny domain Intel has misled developers and caused them to make poor decisions. Scott Duplichan&rsquo;s research shows that at long-double precision the fsin fails to meet its guarantees at numbers as small as 3.01626.\nFor double-precision the guarantees are not met for numbers as small as about 3.14157. Another way of looking at this is that there are tens of billions of doubles near pi where the double-precision result from fsin fails to meet Intel&rsquo;s precision guarantees.\nThe absolute error in the range I was looking at was fairly constant at about 4e-21, which is quite small. For many purposes thi…","fallback":"Random ASCII - tech blog of Bruce Dawson Link: Intel Underestimates Error Bounds by 1.3&nbsp;quintillion","from_url":"https://randomascii.wordpress.com/2014/10/09/intel-underestimates-error-bounds-by-1-3-quintillion/","thumb_width":200,"thumb_height":104,"service_icon":"https://randomascii.files.wordpress.com/2017/07/cropped-uiforetwicon2.png?w=180","id":1,"original_url":"https://randomascii.wordpress.com/2014/10/09/intel-underestimates-error-bounds-by-1-3-quintillion/"}],"blocks":[{"type":"rich_text","block_id":"tUNk+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I had been wondering for a while why noone used the x86 instruction for sin.\n\n"},{"type":"link","url":"https://randomascii.wordpress.com/2014/10/09/intel-underestimates-error-bounds-by-1-3-quintillion/","text":"https://randomascii.wordpress.com/2014/10/09/intel-underestimates-error-bounds-by-1-3-quintillion/"}]}]}],"thread_ts":"1617059284.179800","reply_count":2,"reply_users_count":2,"latest_reply":"1617064826.182200","reply_users":["UM30MT6RF","U0179G7FG4F"],"is_locked":false,"subscribed":false,"reactions":[{"name":"sin","users":["UDB26738Q","UGU761DU2","UM30MT6RF","U9V8ZQVEY"],"count":4}]},{"client_msg_id":"df6d5537-38c3-4a44-acfa-bafc9029e088","type":"message","text":":grapes:: People who use quintillion instead of just 10^18. Who remembers how many zeros that is? Worst part is that in German, \"Quintillionen\" is actually 10^30 :sweat_smile:","user":"UM30MT6RF","ts":"1617060314.181000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Xr59m","elements":[{"type":"rich_text_section","elements":[{"type":"emoji","name":"grapes"},{"type":"text","text":": People who use quintillion instead of just 10^18. Who remembers how many zeros that is? Worst part is that in German, \"Quintillionen\" is actually 10^30 "},{"type":"emoji","name":"sweat_smile"}]}]}],"thread_ts":"1617059284.179800","parent_user_id":"U6A936746","reactions":[{"name":"+1","users":["U6A936746","UKG4WF8PJ"],"count":2}]},{"client_msg_id":"5b65c872-568e-4a2c-b723-fb70862e574b","type":"message","text":"that's shockingly bad. I'd forgive them if it was breaking for big numbers, but something is really bad if it doesn't give good results for 1 period","user":"U0179G7FG4F","ts":"1617064826.182200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"OJMzG","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that's shockingly bad. I'd forgive them if it was breaking for big numbers, but something is really bad if it doesn't give good results for 1 period"}]}]}],"thread_ts":"1617059284.179800","parent_user_id":"U6A936746"}]