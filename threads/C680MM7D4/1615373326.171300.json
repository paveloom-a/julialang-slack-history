[{"client_msg_id":"794d6404-70c5-4009-8c6b-27cf235adb8c","type":"message","text":"<https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron>","user":"UH24GRBLL","ts":"1615373326.171300","team":"T68168MUP","attachments":[{"service_name":"The Verge","title":"OpenAI’s state-of-the-art machine vision AI is fooled by handwritten notes","title_link":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron","text":"Reading is believing.","fallback":"The Verge: OpenAI’s state-of-the-art machine vision AI is fooled by handwritten notes","image_url":"https://cdn.vox-cdn.com/thumbor/SArfDFeVMgOfre78OYFqZX3MjmI=/0x146:1196x772/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/22353458/apple_ipod_test.jpg","image_width":478,"image_height":250,"ts":1615211398,"from_url":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron","image_bytes":65169,"service_icon":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/7395359/ios-icon.0.png","id":1,"original_url":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron"}],"blocks":[{"type":"rich_text","block_id":"n6Ti","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron"}]}]}],"thread_ts":"1615373326.171300","reply_count":13,"reply_users_count":6,"latest_reply":"1615381612.180700","reply_users":["UH24GRBLL","U7JQGPGCQ","U7HAYKY9X","UPUBAM63X","UC4QQPG4A","U017LQ3A59U"],"subscribed":false},{"type":"message","subtype":"thread_broadcast","text":"&gt; “We refer to these attacks as typographic attacks,” write OpenAI’s researchers in a blog post. “By exploiting the model’s ability to read text robustly, we find that even photographs of hand-written text can often fool the model.”\n","user":"UH24GRBLL","ts":"1615373372.171500","thread_ts":"1615373326.171300","root":{"client_msg_id":"794d6404-70c5-4009-8c6b-27cf235adb8c","type":"message","text":"<https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron>","user":"UH24GRBLL","ts":"1615373326.171300","team":"T68168MUP","attachments":[{"service_name":"The Verge","title":"OpenAI’s state-of-the-art machine vision AI is fooled by handwritten notes","title_link":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron","text":"Reading is believing.","fallback":"The Verge: OpenAI’s state-of-the-art machine vision AI is fooled by handwritten notes","image_url":"https://cdn.vox-cdn.com/thumbor/SArfDFeVMgOfre78OYFqZX3MjmI=/0x146:1196x772/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/22353458/apple_ipod_test.jpg","image_width":478,"image_height":250,"ts":1615211398,"from_url":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron","image_bytes":65169,"service_icon":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/7395359/ios-icon.0.png","id":1,"original_url":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron"}],"blocks":[{"type":"rich_text","block_id":"n6Ti","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron"}]}]}],"thread_ts":"1615373326.171300","reply_count":13,"reply_users_count":6,"latest_reply":"1615381612.180700","reply_users":["UH24GRBLL","U7JQGPGCQ","U7HAYKY9X","UPUBAM63X","UC4QQPG4A","U017LQ3A59U"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"/hwU","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"“We refer to these attacks as typographic attacks,” write OpenAI’s researchers in a blog post. “By exploiting the model’s ability to read text robustly, we find that even photographs of hand-written text can often fool the model.”"}]},{"type":"rich_text_section","elements":[]}]}],"client_msg_id":"623ad1b9-479f-4213-be4f-aaf442899ec4"},{"type":"message","subtype":"thread_broadcast","text":"and the original source <https://openai.com/blog/multimodal-neurons/>","user":"UH24GRBLL","ts":"1615373481.171800","thread_ts":"1615373326.171300","root":{"client_msg_id":"794d6404-70c5-4009-8c6b-27cf235adb8c","type":"message","text":"<https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron>","user":"UH24GRBLL","ts":"1615373326.171300","team":"T68168MUP","attachments":[{"service_name":"The Verge","title":"OpenAI’s state-of-the-art machine vision AI is fooled by handwritten notes","title_link":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron","text":"Reading is believing.","fallback":"The Verge: OpenAI’s state-of-the-art machine vision AI is fooled by handwritten notes","image_url":"https://cdn.vox-cdn.com/thumbor/SArfDFeVMgOfre78OYFqZX3MjmI=/0x146:1196x772/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/22353458/apple_ipod_test.jpg","image_width":478,"image_height":250,"ts":1615211398,"from_url":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron","image_bytes":65169,"service_icon":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/7395359/ios-icon.0.png","id":1,"original_url":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron"}],"blocks":[{"type":"rich_text","block_id":"n6Ti","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron"}]}]}],"thread_ts":"1615373326.171300","reply_count":13,"reply_users_count":6,"latest_reply":"1615381612.180700","reply_users":["UH24GRBLL","U7JQGPGCQ","U7HAYKY9X","UPUBAM63X","UC4QQPG4A","U017LQ3A59U"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"r1s4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"and the original source "},{"type":"link","url":"https://openai.com/blog/multimodal-neurons/"}]}]}],"client_msg_id":"e8261ed5-8875-4971-8413-e0a110a284dd","edited":{"user":"UH24GRBLL","ts":"1615373523.000000"}},{"client_msg_id":"8072a106-0262-44e9-aba5-6da835920778","type":"message","text":"Tbh I find this hugely impressive rather than a reason to ridicule the model - I always thought image recognitions was based on just comparing some picture with other labeled pictures, so to have an algorithm that goes beyond that to say \"hold on there's some text here, let's read that\" seems quite a feat to me","user":"U7JQGPGCQ","ts":"1615373499.172100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"yIP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Tbh I find this hugely impressive rather than a reason to ridicule the model - I always thought image recognitions was based on just comparing some picture with other labeled pictures, so to have an algorithm that goes beyond that to say \"hold on there's some text here, let's read that\" seems quite a feat to me"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"87b3a185-be25-415a-aa1f-a89b4f449771","type":"message","text":"that it is","user":"UH24GRBLL","ts":"1615373514.172300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"n4C=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"that it is"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"356384dc-9527-47d6-ae0b-9e8b05464ad8","type":"message","text":"on the flipside, it really does mean that it has no concept of what an iPod is or looks like memorized","user":"UH24GRBLL","ts":"1615373542.172700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7phF","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"on the flipside, it really does mean that it has no concept of what an iPod is or looks like memorized"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"f0ea46a3-f266-4144-b93d-5e52c41d71aa","type":"message","text":"there's no crosschecking with other, known knowledge","user":"UH24GRBLL","ts":"1615373565.172900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Ib+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"there's no crosschecking with other, known knowledge"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"1ed00b35-3ab9-4843-a985-0bbf44c0a2a4","type":"message","text":"That's amazing. Have you heard about the \"bird or bicycle\" challenge? Or single-pixel attacks? Apparently, it's fairly easy to fool image captioning NNs by changing one single pixel. Conversely, it's basically impossible to make a NN that can distinguish between a bird and a bicycle with 100% accuracy","user":"U7HAYKY9X","ts":"1615375011.176000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"u6V","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"That's amazing. Have you heard about the \"bird or bicycle\" challenge? Or single-pixel attacks? Apparently, it's fairly easy to fool image captioning NNs by changing one single pixel. Conversely, it's basically impossible to make a NN that can distinguish between a bird and a bicycle with 100% accuracy"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"35784a6b-0b4e-4000-a486-fc1f9dcbf354","type":"message","text":"yeah, I know about those","user":"UH24GRBLL","ts":"1615375435.176600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Bfpx","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"yeah, I know about those"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"923db631-30a6-4eaa-9f83-2dcea54c7907","type":"message","text":"the catch is that you have to basically train a NN to fool the NN","user":"UH24GRBLL","ts":"1615375449.176800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"t3=","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"the catch is that you have to basically train a NN to fool the NN"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"e46b15f6-0a4e-43c9-9080-62aedb0ccdc9","type":"message","text":"this is much simpler","user":"UH24GRBLL","ts":"1615375453.177000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UnP","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"this is much simpler"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"eebc7950-2af9-4454-ae4e-eba806fa993a","type":"message","text":"There's a paper where people printed out some neural slop patterns taped them to their hoodies and were defeating CV models very easily","user":"UPUBAM63X","ts":"1615375531.178200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"deqt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's a paper where people printed out some neural slop patterns taped them to their hoodies and were defeating CV models very easily"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"d199acd9-e209-454a-9183-24d05a40cf72","type":"message","text":"Those have a name, although I forget that atm, is it just adversarial examples? I don't think so, but yeah those are pretty common.","user":"UC4QQPG4A","ts":"1615377530.180000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"8Hyz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Those have a name, although I forget that atm, is it just adversarial examples? I don't think so, but yeah those are pretty common."}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"},{"client_msg_id":"88a3c047-568a-4da8-af80-28ee187dd33a","type":"message","text":"Couldn't this just indicate that many of the image in the training set had labelled inside them?","user":"U017LQ3A59U","ts":"1615381612.180700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1Ox","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Couldn't this just indicate that many of the image in the training set had labelled inside them?"}]}]}],"thread_ts":"1615373326.171300","parent_user_id":"UH24GRBLL"}]