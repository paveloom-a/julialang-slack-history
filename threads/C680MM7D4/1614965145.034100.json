[{"client_msg_id":"7565e6ef-56ec-426b-9019-2a26b8ceef55","type":"message","text":"PyTorch is getting JAX like code transforms: <https://twitter.com/cHHillee/status/1367621541693857794>","user":"UDGT4PM41","ts":"1614965145.034100","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/cHHillee|@cHHillee>: Since your transformation takes in Python code and outputs Python source code, they're\n1. Automatically composable with each other\n2. Automatically composable with anything else (like Torchscript).\n3. Able to be dumped out as Python code. \n\nHere's an example (2/4) <https://pbs.twimg.com/media/EvrDp5TVkAAJt7z.png>","ts":1614901359,"author_name":"Horace He","author_link":"https://twitter.com/cHHillee/status/1367621541693857794","author_icon":"https://pbs.twimg.com/profile_images/918522465478987776/4rqdxVqQ_normal.jpg","author_subname":"@cHHillee","text":"Since your transformation takes in Python code and outputs Python source code, they're\n1. Automatically composable with each other\n2. Automatically composable with anything else (like Torchscript).\n3. Able to be dumped out as Python code. \n\nHere's an example (2/4) <https://pbs.twimg.com/media/EvrDp5TVkAAJt7z.png>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/cHHillee/status/1367621541693857794","image_url":"https://pbs.twimg.com/media/EvrDp5TVkAAJt7z.png","image_width":811,"image_height":433,"image_bytes":49251,"id":1,"original_url":"https://twitter.com/cHHillee/status/1367621541693857794","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"=cO9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"PyTorch is getting JAX like code transforms: "},{"type":"link","url":"https://twitter.com/cHHillee/status/1367621541693857794"}]}]}],"thread_ts":"1614965145.034100","reply_count":33,"reply_users_count":6,"latest_reply":"1615682675.425200","reply_users":["UDGT4PM41","U017D621ELC","UMY1LV01G","U011V2YN59N","UN3R6SDDW","U69BL50BF"],"subscribed":false},{"client_msg_id":"1a0f1b94-a685-48da-b2c2-9f7f92740e40","type":"message","text":"<@UMY1LV01G>","user":"UDGT4PM41","ts":"1614965399.034900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"irr","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UMY1LV01G"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"4ca47b9f-0a78-4c99-985b-65af067fe8dd","type":"message","text":"TF includes dynamic graphs from Pytorch\nPytorch includes functional transforms from JAX\nWhat next?","user":"U017D621ELC","ts":"1614966282.035800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"1ilM2","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"TF includes dynamic graphs from Pytorch\nPytorch includes functional transforms from JAX\nWhat next?"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"7c3cb641-767f-4c30-84f6-d08d915f4002","type":"message","text":"The convergence between both frameworks was inevitable once PyTorch started eating TF's lunch for research and looking into edge/mobile deployment","user":"UMY1LV01G","ts":"1614966383.036000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"MCRdn","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The convergence between both frameworks was inevitable once PyTorch started eating TF's lunch for research and looking into edge/mobile deployment"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"8453bd4f-519a-483f-bb2e-9f55a080ff8a","type":"message","text":"I'm not sure how I feel about the new graph framework. It looks nice, but does feel a bit \"bolted on\" and adds to the kitchen sink","user":"UMY1LV01G","ts":"1614966494.036200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"hV8I3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'm not sure how I feel about the new graph framework. It looks nice, but does feel a bit \"bolted on\" and adds to the kitchen sink"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41","reactions":[{"name":"confused","users":["U017D621ELC","UKG4WF8PJ"],"count":2}]},{"client_msg_id":"ef8091a7-1f2a-4dc1-a7ad-a155c0a3bb47","type":"message","text":"JAX definitely has the cleanest conceptual model and least amount of API bloat. I guess we'll see if their strategy of outsourcing higher level libraries to the community pays off, or if the core library accumulates more and more orthogonal features.","user":"UMY1LV01G","ts":"1614966678.036700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"w5IL","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"JAX definitely has the cleanest conceptual model and least amount of API bloat. I guess we'll see if their strategy of outsourcing higher level libraries to the community pays off, or if the core library accumulates more and more orthogonal features."}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41","reactions":[{"name":"heart","users":["U017D621ELC","UKG4WF8PJ"],"count":2}]},{"client_msg_id":"b0217498-953e-4907-b55c-ae66a596db7b","type":"message","text":"PyTorch started off small, after all. Though in fairness they never claimed to be just a library like JAX does","user":"UMY1LV01G","ts":"1614966722.036900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"b+A","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"PyTorch started off small, after all. Though in fairness they never claimed to be just a library like JAX does"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"d373c6a9-1830-4e64-be56-339345b913a4","type":"message","text":"I hurts how much money and effort are being put into making python fast.","user":"U011V2YN59N","ts":"1614973220.041300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"zcc","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I hurts how much money and effort are being put into making python fast."}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41","reactions":[{"name":"100","users":["UDGT4PM41","U93BUBZP0"],"count":2},{"name":"disappointed_relieved","users":["U017D621ELC"],"count":1}]},{"client_msg_id":"85d12e6a-17c4-4b1f-9f26-6b0e9a73b5e8","type":"message","text":"when like python is very unpleasant to write","user":"U011V2YN59N","ts":"1614973389.042100","team":"T68168MUP","edited":{"user":"U011V2YN59N","ts":"1614973396.000000"},"blocks":[{"type":"rich_text","block_id":"6mXQt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"when like python is very unpleasant to write"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41","reactions":[{"name":"+1","users":["U93BUBZP0"],"count":1}]},{"client_msg_id":"c4c4f3b0-005d-43ec-bc2c-8e4f764b10a8","type":"message","text":"<@UMY1LV01G> Definitely agree that Jax the least amount of API float - not sure if I agree that it has the cleanest conceptual model :stuck_out_tongue: Or well, I'd argue that perhaps it's the cleanest, but that doesn't make it the easiest to reason about.\n\nI do sympathize with your concerns about FX haha - in some sense it's 100% bolted on. PyTorch was never meant to have a dynamic graph representation.\n\nEssentially, the hope is that there are a subset of programs that users want function transformations for, where they're willing to deal with the limitations that come from trying to acquire a graph in Python.","user":"UN3R6SDDW","ts":"1615438766.268100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"7Fg","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UMY1LV01G"},{"type":"text","text":" Definitely agree that Jax the least amount of API float - not sure if I agree that it has the cleanest conceptual model "},{"type":"emoji","name":"stuck_out_tongue"},{"type":"text","text":" Or well, I'd argue that perhaps it's the cleanest, but that doesn't make it the easiest to reason about.\n\nI do sympathize with your concerns about FX haha - in some sense it's 100% bolted on. PyTorch was never meant to have a dynamic graph representation.\n\nEssentially, the hope is that there are a subset of programs that users want function transformations for, where they're willing to deal with the limitations that come from trying to acquire a graph in Python."}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"0f0c80b4-6670-4a1d-95a3-eddc47fd182a","type":"message","text":"Hi Horace :)\nFWIW I do think fx is a worthwhile addition and will eliminate whole class of nasty hacks people have been doing in the name of getting good performance out of network primitives. I think my point about JAX would've been better phrased as \"fewer moving parts\" since Torch's autograd is pretty dang simple conceptually (while running circles around e.g. TF when it comes to resource usage in practice). What I hope is that we're seeing a breakdown of the old \"private island\" model of incompatible library ecosystems with these newer libraries. Julia obviously has the benefit of hindsight and not being the first mover in that respect.","user":"UMY1LV01G","ts":"1615441620.269100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"RPbj","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Hi Horace :)\nFWIW I do think fx is a worthwhile addition and will eliminate whole class of nasty hacks people have been doing in the name of getting good performance out of network primitives. I think my point about JAX would've been better phrased as \"fewer moving parts\" since Torch's autograd is pretty dang simple conceptually (while running circles around e.g. TF when it comes to resource usage in practice). What I hope is that we're seeing a breakdown of the old \"private island\" model of incompatible library ecosystems with these newer libraries. Julia obviously has the benefit of hindsight and not being the first mover in that respect."}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"1a9830c8-f154-4ca8-9573-3e90ee60c6e4","type":"message","text":"<@UMY1LV01G> well, I'm not sure any of these newer libraries really resolve the issue of \"private island\" (unless you mean that different transforms can compose with each other).\n\nI definitely think Julia has a significant advantage here - no disagreements about that :stuck_out_tongue: I think there's a lot of really cool things happening on Julia, which is why I lurk on this slack sometimes.","user":"UN3R6SDDW","ts":"1615513076.325000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"bJj4","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UMY1LV01G"},{"type":"text","text":" well, I'm not sure any of these newer libraries really resolve the issue of \"private island\" (unless you mean that different transforms can compose with each other).\n\nI definitely think Julia has a significant advantage here - no disagreements about that "},{"type":"emoji","name":"stuck_out_tongue"},{"type":"text","text":" I think there's a lot of really cool things happening on Julia, which is why I lurk on this slack sometimes."}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"5989ddb5-b245-4d08-80b4-b695cfd24083","type":"message","text":"<@UN3R6SDDW> Maybe \"Julia for Torch\" can happen without Jeff Bezanson working at FB? :joy:","user":"UDGT4PM41","ts":"1615517424.326300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"JU0S","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UN3R6SDDW"},{"type":"text","text":" Maybe \"Julia for Torch\" can happen without Jeff Bezanson working at FB? "},{"type":"emoji","name":"joy"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"6818f1b0-c6b5-4e11-94a1-ea6ecca25d5a","type":"message","text":"<@UDGT4PM41> what would you want out of \"Julia for Torch\"?","user":"UN3R6SDDW","ts":"1615517646.326500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2Ir","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UDGT4PM41"},{"type":"text","text":" what would you want out of \"Julia for Torch\"?"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"5efa4dfa-0047-48e7-8fa9-519b9e819fe0","type":"message","text":"With where Julia's at now, it would take a tiny tiny fraction of the money Google put into the s4tf ship to get something better. We can get you in touch with Jeremy Howard, Who's  been mulling  Julia instead of swift as a next gen FastAI language (Swift is pretty much dead in that regard now). Yann Was also discussing some interest In Julia on twitter","user":"UDGT4PM41","ts":"1615517675.326700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"6b0U","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"With where Julia's at now, it would take a tiny tiny fraction of the money Google put into the s4tf ship to get something better. We can get you in touch with Jeremy Howard, Who's  been mulling  Julia instead of swift as a next gen FastAI language (Swift is pretty much dead in that regard now). Yann Was also discussing some interest In Julia on twitter"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"3729b863-70b2-4552-9a2a-03d7ff0f7a6a","type":"message","text":"<@UN3R6SDDW> Facebook support to get Julia to the point where it can be used for internal use and production, which would in turn benefit the Julia community and benefit Facebook by reducing programming overhead","user":"UDGT4PM41","ts":"1615517757.326900","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1615517799.000000"},"blocks":[{"type":"rich_text","block_id":"VSry","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UN3R6SDDW"},{"type":"text","text":" Facebook support to get Julia to the point where it can be used for internal use and production, which would in turn benefit the Julia community and benefit Facebook by reducing programming overhead"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"aa88e2f3-41eb-4434-80c1-ddc85fe9e622","type":"message","text":"Can write vendor agnostic GPU kernels in pure Julia, manipulate large graphs for GNNs, and we're on the verge of small zero runtime static binaries, all done by hacking normal compiler hooks. So can deploy to mobile and WASM","user":"UDGT4PM41","ts":"1615517897.327200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Kj1E+","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Can write vendor agnostic GPU kernels in pure Julia, manipulate large graphs for GNNs, and we're on the verge of small zero runtime static binaries, all done by hacking normal compiler hooks. So can deploy to mobile and WASM"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"c732c356-803c-4178-88a8-fed5c1a78c25","type":"message","text":"And whatever weird differentiable programming with weird datastructure usecases will pop up in the future. No islands so no need to rewrite scipy or diffeqs, or Pymc3 to work together in and with ML models. One array type system","user":"UDGT4PM41","ts":"1615518001.327400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"o/EQU","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"And whatever weird differentiable programming with weird datastructure usecases will pop up in the future. No islands so no need to rewrite scipy or diffeqs, or Pymc3 to work together in and with ML models. One array type system"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"cb06fc82-adae-42b5-92e2-e29c15ec68bc","type":"message","text":"<https://github.com/JuliaFolds/FLoops.jl> composable transuders with loop frontend that run distributed, GPU, CPU. Einsum + macro that runs does CPU codegen faster than openblas <https://github.com/mcabbott/Tullio.jl> using Julia's native vectorization capabilities. The possibilities and ecosystem has many many gems of which people are unaware.","user":"UDGT4PM41","ts":"1615518165.327600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Kbcx","elements":[{"type":"rich_text_section","elements":[{"type":"link","url":"https://github.com/JuliaFolds/FLoops.jl"},{"type":"text","text":" composable transuders with loop frontend that run distributed, GPU, CPU. Einsum + macro that runs does CPU codegen faster than openblas "},{"type":"link","url":"https://github.com/mcabbott/Tullio.jl"},{"type":"text","text":" using Julia's native vectorization capabilities. The possibilities and ecosystem has many many gems of which people are unaware."}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"9bb412fe-2332-4ed8-a85a-f14568521116","type":"message","text":"Re Julia's popularity: It's already doubling every 18 months and I think it's ripe for a phase shift. A FAANG taking notice might trigger that","user":"UDGT4PM41","ts":"1615518253.327800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Rzz5H","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Re Julia's popularity: It's already doubling every 18 months and I think it's ripe for a phase shift. A FAANG taking notice might trigger that"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"a0908c14-36ed-46b2-8773-c82560c2082d","type":"message","text":"The ecosystem is large, so instead of listing every conceivable package you might be interested in (DS, ML, Stats, Backend agnostic 3d plotting etc( and there's even a mature web MVC framework), if you have any specific areas of concern I can help with pointers","user":"UDGT4PM41","ts":"1615518503.328000","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1615518531.000000"},"blocks":[{"type":"rich_text","block_id":"r=BoB","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The ecosystem is large, so instead of listing every conceivable package you might be interested in (DS, ML, Stats, Backend agnostic 3d plotting etc( and there's even a mature web MVC framework), if you have any specific areas of concern I can help with pointers"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"21f52ebe-146f-4d74-a8e8-79095a005042","type":"message","text":"Then there's the emergent combinatorial explosion of packages that emerge out of these composable pieces, and so on up the tower of abstraction. Here's some amazing accidental composability. With just a little bit more of a push to accelerate the process , there could be a huge output: <https://twitter.com/KenoFischer/status/1369853531423993858>\n\nAnother example, homomorphic encrypted ML in flux.jl. It's generic so no need for any sort of new package with additional  C++ Tensorflow spaghetti , just reusing code with new types of arrays: <https://juliacomputing.com/blog/2019/11/encrypted-machine-learning/> Possibilities are endless","user":"UDGT4PM41","ts":"1615518879.328300","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1615518935.000000"},"attachments":[{"fallback":"<https://twitter.com/KenoFischer|@KenoFischer>: I should be pretty used to #julialang's extreme composability by now, but c'mon, this just just cool! Literally no code changes required in either package - first thing I tried. <https://pbs.twimg.com/media/EwKyDrfXEAAcDTt.png>","ts":1615433507,"author_name":"Keno Fischer","author_link":"https://twitter.com/KenoFischer/status/1369853531423993858","author_icon":"https://pbs.twimg.com/profile_images/1133949652234047489/_J3gif9e_normal.png","author_subname":"@KenoFischer","text":"I should be pretty used to #julialang's extreme composability by now, but c'mon, this just just cool! Literally no code changes required in either package - first thing I tried. <https://pbs.twimg.com/media/EwKyDrfXEAAcDTt.png>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/KenoFischer/status/1369853531423993858","image_url":"https://pbs.twimg.com/media/EwKyDrfXEAAcDTt.png","image_width":339,"image_height":231,"image_bytes":22032,"id":1,"original_url":"https://twitter.com/KenoFischer/status/1369853531423993858","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"fjI","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Then there's the emergent combinatorial explosion of packages that emerge out of these composable pieces, and so on up the tower of abstraction. Here's some amazing accidental composability. With just a little bit more of a push to accelerate the process , there could be a huge output: "},{"type":"link","url":"https://twitter.com/KenoFischer/status/1369853531423993858"},{"type":"text","text":"\n\nAnother example, homomorphic encrypted ML in flux.jl. It's generic so no need for any sort of new package with additional  C++ Tensorflow spaghetti , just reusing code with new types of arrays: "},{"type":"link","url":"https://juliacomputing.com/blog/2019/11/encrypted-machine-learning/"},{"type":"text","text":" Possibilities are endless"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"63fc42de-369a-4a61-8c1a-641f804e32a5","type":"message","text":"One last thing. Either a  FB or FastAI adoption of Julia would create a near instant explosion in use and popularity. People are just unfamiliar with just how much better Julia is (It's just like Numba, right??!) but also concerned about  niche status (and admittedly some rough edges for more \"boring\" deep learning usecases\", . Without those  restraints, the community will be huge very fast. In the meantime, without that, will have to wait for the ML stack hit an organic  inflection point, but I think that will eventually  happen, even outside ML. In six months to a year how will people react when they can deploy a fast multithreaded web app using task parallelism and diff programming to a .so?","user":"UDGT4PM41","ts":"1615519955.328900","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1615520151.000000"},"blocks":[{"type":"rich_text","block_id":"fjh","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One last thing. Either a  FB or FastAI adoption of Julia would create a near instant explosion in use and popularity. People are just unfamiliar with just how much better Julia is (It's just like Numba, right??!) but also concerned about  niche status (and admittedly some rough edges for more \"boring\" deep learning usecases\", . Without those  restraints, the community will be huge very fast. In the meantime, without that, will have to wait for the ML stack hit an organic  inflection point, but I think that will eventually  happen, even outside ML. In six months to a year how will people react when they can deploy a fast multithreaded web app using task parallelism and diff programming to a .so?"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41","reactions":[{"name":"juliaheartpulse","users":["U017D621ELC"],"count":1}]},{"client_msg_id":"9a2d1290-7a89-4208-af04-c3431126d329","type":"message","text":"<@UDGT4PM41> I'm with you about Julia being very cool, and have seen most of the stuff you mentioned - although thanks for the sales pitch anyways :stuck_out_tongue: However, most of this just seems like general \"it would be really nice if Facebook put funding into Julia\". I'm not saying that's not possible, but it would probably be an easier transition if there was some nice way for Julia to provide value to the PyTorch ecosystem now.","user":"UN3R6SDDW","ts":"1615599177.359400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"L0sN","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UDGT4PM41"},{"type":"text","text":" I'm with you about Julia being very cool, and have seen most of the stuff you mentioned - although thanks for the sales pitch anyways "},{"type":"emoji","name":"stuck_out_tongue"},{"type":"text","text":" However, most of this just seems like general \"it would be really nice if Facebook put funding into Julia\". I'm not saying that's not possible, but it would probably be an easier transition if there was some nice way for Julia to provide value to the PyTorch ecosystem now."}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"7ecad7af-ed4e-445e-8cb9-b0ed9ac24898","type":"message","text":"<@UN3R6SDDW> I get that! By the way, I have absolutely zero affiliation with Julia computing or any direct commercial interest in what I said (except second order career effects). I just love Julia and would love to see more interest / use so I can use it more (packages, collab etc)","user":"UDGT4PM41","ts":"1615681353.421700","team":"T68168MUP","edited":{"user":"UDGT4PM41","ts":"1615681371.000000"},"blocks":[{"type":"rich_text","block_id":"dae","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"UN3R6SDDW"},{"type":"text","text":" I get that! By the way, I have absolutely zero affiliation with Julia computing or any direct commercial interest in what I said (except second order career effects). I just love Julia and would love to see more interest / use so I can use it more (packages, collab etc)"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"type":"message","subtype":"thread_broadcast","text":"Regarding \"some nice way for Julia to provide value to the PyTorch ecosystem now.\"\n\nI can see a couple of approaches: 1. Writing custom GPU /TPU kernels in Julia, which can be called from pytorch, with automatic wrapper generation. <@U69BL50BF> might be able to comment on that.\n\n2. Writing custom array or scalar types in Julia, for pytorch\n\n3. Symbolic simplification and optimization of pytorch code using modeling toolkit and <https://discourse.julialang.org/t/ann-symbolics-jl-a-modern-computer-algebra-system-for-a-modern-language/56251/119>\n\n4.  moving aten/ torch  backend from C++ to Julia. More people from the community can hack on that vs c++.\n\nAnyone else have other ideas?","user":"UDGT4PM41","ts":"1615681593.422900","thread_ts":"1614965145.034100","root":{"client_msg_id":"7565e6ef-56ec-426b-9019-2a26b8ceef55","type":"message","text":"PyTorch is getting JAX like code transforms: <https://twitter.com/cHHillee/status/1367621541693857794>","user":"UDGT4PM41","ts":"1614965145.034100","team":"T68168MUP","attachments":[{"fallback":"<https://twitter.com/cHHillee|@cHHillee>: Since your transformation takes in Python code and outputs Python source code, they're\n1. Automatically composable with each other\n2. Automatically composable with anything else (like Torchscript).\n3. Able to be dumped out as Python code. \n\nHere's an example (2/4) <https://pbs.twimg.com/media/EvrDp5TVkAAJt7z.png>","ts":1614901359,"author_name":"Horace He","author_link":"https://twitter.com/cHHillee/status/1367621541693857794","author_icon":"https://pbs.twimg.com/profile_images/918522465478987776/4rqdxVqQ_normal.jpg","author_subname":"@cHHillee","text":"Since your transformation takes in Python code and outputs Python source code, they're\n1. Automatically composable with each other\n2. Automatically composable with anything else (like Torchscript).\n3. Able to be dumped out as Python code. \n\nHere's an example (2/4) <https://pbs.twimg.com/media/EvrDp5TVkAAJt7z.png>","service_name":"twitter","service_url":"https://twitter.com/","from_url":"https://twitter.com/cHHillee/status/1367621541693857794","image_url":"https://pbs.twimg.com/media/EvrDp5TVkAAJt7z.png","image_width":811,"image_height":433,"image_bytes":49251,"id":1,"original_url":"https://twitter.com/cHHillee/status/1367621541693857794","footer":"Twitter","footer_icon":"https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"}],"blocks":[{"type":"rich_text","block_id":"=cO9","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"PyTorch is getting JAX like code transforms: "},{"type":"link","url":"https://twitter.com/cHHillee/status/1367621541693857794"}]}]}],"thread_ts":"1614965145.034100","reply_count":33,"reply_users_count":6,"latest_reply":"1615682675.425200","reply_users":["UDGT4PM41","U017D621ELC","UMY1LV01G","U011V2YN59N","UN3R6SDDW","U69BL50BF"],"subscribed":false},"attachments":[{"service_name":"JuliaLang","title":"[ANN] Symbolics.jl: A Modern Computer Algebra System for a Modern Language","title_link":"https://discourse.julialang.org/t/ann-symbolics-jl-a-modern-computer-algebra-system-for-a-modern-language/56251/119","text":"Very interesting. Can you guide me to literature about why SCAS need more than real and complex numbers? I also very interested about your experience about bridging the gaps between SCASs and MCASs.","fallback":"JuliaLang: [ANN] Symbolics.jl: A Modern Computer Algebra System for a Modern Language","thumb_url":"https://aws1.discourse-cdn.com/business5/uploads/julialang/original/2X/1/12829a7ba92b924d4ce81099cbf99785bee9b405.png","ts":1615663496,"from_url":"https://discourse.julialang.org/t/ann-symbolics-jl-a-modern-computer-algebra-system-for-a-modern-language/56251/119","thumb_width":408,"thumb_height":263,"service_icon":"https://aws1.discourse-cdn.com/business5/uploads/julialang/optimized/2X/6/6ca888e296f59ca2a599807f7d5edd489e3d1829_2_180x180.png","id":1,"original_url":"https://discourse.julialang.org/t/ann-symbolics-jl-a-modern-computer-algebra-system-for-a-modern-language/56251/119"}],"blocks":[{"type":"rich_text","block_id":"cW5","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Regarding \"some nice way for Julia to provide value to the PyTorch ecosystem now.\"\n\nI can see a couple of approaches: 1. Writing custom GPU /TPU kernels in Julia, which can be called from pytorch, with automatic wrapper generation. "},{"type":"user","user_id":"U69BL50BF"},{"type":"text","text":" might be able to comment on that.\n\n2. Writing custom array or scalar types in Julia, for pytorch\n\n3. Symbolic simplification and optimization of pytorch code using modeling toolkit and "},{"type":"link","url":"https://discourse.julialang.org/t/ann-symbolics-jl-a-modern-computer-algebra-system-for-a-modern-language/56251/119"},{"type":"text","text":"\n\n4.  moving aten/ torch  backend from C++ to Julia. More people from the community can hack on that vs c++.\n\nAnyone else have other ideas?"}]}]}],"client_msg_id":"e3023b2b-7935-4087-8c54-cc0a51e088b0","edited":{"user":"UDGT4PM41","ts":"1615681666.000000"}},{"client_msg_id":"6640e2c3-1f1c-4125-80ea-c9df49aa7a91","type":"message","text":"For the other way there is: <https://github.com/FluxML/Torch.jl>","user":"UDGT4PM41","ts":"1615681759.423400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"iCeWM","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For the other way there is: "},{"type":"link","url":"https://github.com/FluxML/Torch.jl"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"3f7be71e-32f1-4589-90d5-89ca61a90cd9","type":"message","text":"ReversePropogation.jl is the first attempt at the symbolics-based AD system <https://github.com/dpsanders/ReversePropagation.jl>","user":"U69BL50BF","ts":"1615682283.423900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"a7qE","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"ReversePropogation.jl is the first attempt at the symbolics-based AD system "},{"type":"link","url":"https://github.com/dpsanders/ReversePropagation.jl"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"7798a86f-cbd5-45e8-89e3-0277475513f3","type":"message","text":"I don't think there's much of a competitive advantage to be found in the quasi-static machine learning regime, so I think everyone is fighting for technical scraps and it's not the best game to play.","user":"U69BL50BF","ts":"1615682400.424100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/ME","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I don't think there's much of a competitive advantage to be found in the quasi-static machine learning regime, so I think everyone is fighting for technical scraps and it's not the best game to play."}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"01a26091-baff-43aa-b760-c583e9627715","type":"message","text":"Somebody working on PyTorch wrote this at some point haha: <https://github.com/bwasti/torch_julia>","user":"UN3R6SDDW","ts":"1615682482.424300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"m7L","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Somebody working on PyTorch wrote this at some point haha: "},{"type":"link","url":"https://github.com/bwasti/torch_julia"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"d8cca96d-0487-47b7-984c-65c2d5a81439","type":"message","text":"<@U69BL50BF> what's the \"quasi-static\" ML regime?","user":"UN3R6SDDW","ts":"1615682522.424500","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"qiPw","elements":[{"type":"rich_text_section","elements":[{"type":"user","user_id":"U69BL50BF"},{"type":"text","text":" what's the \"quasi-static\" ML regime?"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"057e870d-1dcc-4605-aa36-3ce8243d0e39","type":"message","text":"&gt; Somebody working on PyTorch wrote this at some point haha: <https://github.com/bwasti/torch_julia>\nIf you want to see a fun one <https://github.com/sbi-benchmark/diffeqtorch>","user":"U69BL50BF","ts":"1615682617.424700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Aw2","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"Somebody working on PyTorch wrote this at some point haha: "},{"type":"link","url":"https://github.com/bwasti/torch_julia"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"If you want to see a fun one "},{"type":"link","url":"https://github.com/sbi-benchmark/diffeqtorch"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"b81983dd-ccbc-49e2-939a-e27786b5f8a1","type":"message","text":"&gt; what's the \"quasi-static\" ML regime?\nRead <https://www.stochasticlifestyle.com/generalizing-automatic-differentiation-to-automatic-sparsity-uncertainty-stability-and-parallelism/> on non-standard interpretation","user":"U69BL50BF","ts":"1615682660.424900","team":"T68168MUP","attachments":[{"service_name":"Stochastic Lifestyle","title":"Generalizing Automatic Differentiation to Automatic Sparsity, Uncertainty, Stability, and Parallelism - Stochastic Lifestyle","title_link":"https://www.stochasticlifestyle.com/generalizing-automatic-differentiation-to-automatic-sparsity-uncertainty-stability-and-parallelism/","text":"Automatic differentiation is a \"compiler trick\" whereby a code that calculates f(x) is transformed into a code that calculates f'(x). This trick and its two forms, forward and reverse mode automatic differentiation, have become the pervasive backbone behind all of the machine learning libraries. If you ask what PyTorch or Flux.jl is doing that's special, the answer is really that it's doing automatic differentiation over some functions. What I want to dig into in this blog post is a simple question: what is the trick behind automatic differentiation, why is it always differentiation, and are there other mathematical problems we can be focusing this trick towards? While very technical discussions on this can be found in our recent paper titled \"ModelingToolkit: A Composable Graph Transformation System For Equation-Based Modeling\" and descriptions of methods like intrusive uncertainty quantification, I want ... READ MORE","fallback":"Stochastic Lifestyle: Generalizing Automatic Differentiation to Automatic Sparsity, Uncertainty, Stability, and Parallelism - Stochastic Lifestyle","thumb_url":"https://www.stochasticlifestyle.com/wp-content/themes/chrisrack/style/faviPic2.PNG","fields":[{"title":"Written by","value":"Christopher Rackauckas","short":true},{"title":"Est. reading time","value":"14 minutes","short":true}],"ts":1615383832,"from_url":"https://www.stochasticlifestyle.com/generalizing-automatic-differentiation-to-automatic-sparsity-uncertainty-stability-and-parallelism/","thumb_width":669,"thumb_height":891,"service_icon":"https://i2.wp.com/www.stochasticlifestyle.com/wp-content/uploads/2016/01/cropped-faviPic.png?fit=180%2C180&#038;ssl=1","id":1,"original_url":"https://www.stochasticlifestyle.com/generalizing-automatic-differentiation-to-automatic-sparsity-uncertainty-stability-and-parallelism/"}],"blocks":[{"type":"rich_text","block_id":"0nH","elements":[{"type":"rich_text_quote","elements":[{"type":"text","text":"what's the \"quasi-static\" ML regime?"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"Read "},{"type":"link","url":"https://www.stochasticlifestyle.com/generalizing-automatic-differentiation-to-automatic-sparsity-uncertainty-stability-and-parallelism/"},{"type":"text","text":" on non-standard interpretation"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"},{"client_msg_id":"5ff6278d-3c32-455d-a45f-77e0693bb7ca","type":"message","text":"Now, when can what forms of non-standard interpretation be done?","user":"U69BL50BF","ts":"1615682675.425200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"UMMTp","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Now, when can what forms of non-standard interpretation be done?"}]}]}],"thread_ts":"1614965145.034100","parent_user_id":"UDGT4PM41"}]