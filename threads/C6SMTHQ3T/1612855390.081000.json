[{"client_msg_id":"52a8859f-ac34-4364-8bc0-feea29138fe3","type":"message","text":"On a tangent, when should I use `Threads.@threads`, and when is `Threads.@spawn` more appropriate?","user":"UC6LC14MA","ts":"1612855390.081000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"LGC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"On a tangent, when should I use "},{"type":"text","text":"Threads.@threads","style":{"code":true}},{"type":"text","text":", and when is "},{"type":"text","text":"Threads.@spawn","style":{"code":true}},{"type":"text","text":" more appropriate?"}]}]}],"thread_ts":"1612855390.081000","reply_count":11,"reply_users_count":4,"latest_reply":"1612976945.084700","reply_users":["U8D9768Q6","UC6LC14MA","U6740K1SP","UC7AF7NSU"],"subscribed":false},{"client_msg_id":"70f91371-32e1-4952-9583-103eeaf2c8a4","type":"message","text":"One major difference is that `Threads.@threads` is not composable. I.e. you can't nest them","user":"U8D9768Q6","ts":"1612885836.082000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/hDS","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"One major difference is that "},{"type":"text","text":"Threads.@threads","style":{"code":true}},{"type":"text","text":" is not composable. I.e. you can't nest them"}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"},{"client_msg_id":"989dc4df-25a4-47a5-a024-c016b1c578c8","type":"message","text":"Right, I see how that will be useful for multidimensional loops","user":"UC6LC14MA","ts":"1612886598.082200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"vawMi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Right, I see how that will be useful for multidimensional loops"}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"},{"client_msg_id":"0809e46e-cc17-4234-aa30-0791e05f62de","type":"message","text":"Yeah, `@threads for` is a static schedule — and it splits your work (the iteration space) up into `nthreaads()` parts (based upon indexing).","user":"U6740K1SP","ts":"1612893338.082600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"R2R3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yeah, "},{"type":"text","text":"@threads for","style":{"code":true}},{"type":"text","text":" is a static schedule — and it splits your work (the iteration space) up into "},{"type":"text","text":"nthreaads()","style":{"code":true}},{"type":"text","text":" parts (based upon indexing)."}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"},{"client_msg_id":"e82efd1e-a3ed-4cad-aa5c-c829c40e46a0","type":"message","text":"As compared to `for …; Threads.@spawn` , which would create one task per iteration that can be consumed by any thread and does not require an indexable iterable.","user":"U6740K1SP","ts":"1612893386.082800","team":"T68168MUP","edited":{"user":"U6740K1SP","ts":"1612893820.000000"},"blocks":[{"type":"rich_text","block_id":"VEcg","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"As compared to "},{"type":"text","text":"for …; Threads.@spawn","style":{"code":true}},{"type":"text","text":" , which would create one task per iteration that can be consumed by any thread and does not require an indexable iterable."}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"},{"client_msg_id":"70d2f106-d64e-498f-8d42-6e94a83a5af6","type":"message","text":"`@threads` is good for _lots_ of small iterations that take roughly the same amount of time. Manually `@spawn`ing tasks is good for beefier individual work-items that can have wildly different runtimes.","user":"U6740K1SP","ts":"1612893519.083000","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"krVQ4","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"`@threads` is good for "},{"type":"text","text":"lots","style":{"italic":true}},{"type":"text","text":" of small iterations that take roughly the same amount of time. Manually "},{"type":"text","text":"@spawn","style":{"code":true}},{"type":"text","text":"ing tasks is good for beefier individual work-items that can have wildly different runtimes."}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"},{"client_msg_id":"d044ae81-5f5f-4d71-bb33-96cd83bf1fa0","type":"message","text":"FLoops.jl / ThreadsX.jl / Folds.jl / Transducers.jl cover both of these spaces","user":"U8D9768Q6","ts":"1612894378.083300","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"2JKBr","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"FLoops.jl / ThreadsX.jl / Folds.jl / Transducers.jl cover both of these spaces"}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"},{"client_msg_id":"d7801857-d808-4a52-8f21-770f4a51d50c","type":"message","text":"Yup! Or, look at any data parallel API with `basesize` option or similar. It's a parameter for interpolating one-task-per-iteration and the \"static scheduling\" used by `@threads`.","user":"UC7AF7NSU","ts":"1612927547.083700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Cj2Qz","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Yup! Or, look at any data parallel API with "},{"type":"text","text":"basesize","style":{"code":true}},{"type":"text","text":" option or similar. It's a parameter for interpolating one-task-per-iteration and the \"static scheduling\" used by "},{"type":"text","text":"@threads","style":{"code":true}},{"type":"text","text":"."}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"},{"client_msg_id":"0575509d-ae92-429c-9a2c-f91e9399bdf8","type":"message","text":"I'd say _never_ write `for …; Threads.@spawn` (unless you know what you are doing, of course). The `for` loop is a sign that you need a _data parallel_ API while `@spawn` is a _task parallel_ API. Operating at a high-level of abstraction is better because, e.g.,: you'd experience less bugs; more collections can be supported; execution mechanism can be swapped out after writing the algorithm. Writing `@spawn` is like writing `goto` when you can use `for`.","user":"UC7AF7NSU","ts":"1612927610.083900","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"ytf8k","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I'd say "},{"type":"text","text":"never","style":{"italic":true}},{"type":"text","text":" write "},{"type":"text","text":"for …; Threads.@spawn","style":{"code":true}},{"type":"text","text":" (unless you know what you are doing, of course). The "},{"type":"text","text":"for","style":{"code":true}},{"type":"text","text":" loop is a sign that you need a "},{"type":"text","text":"data parallel","style":{"italic":true}},{"type":"text","text":" API while "},{"type":"text","text":"@spawn","style":{"code":true}},{"type":"text","text":" is a "},{"type":"text","text":"task parallel","style":{"italic":true}},{"type":"text","text":" API. Operating at a high-level of abstraction is better because, e.g.,: you'd experience less bugs; more collections can be supported; execution mechanism can be swapped out after writing the algorithm. Writing "},{"type":"text","text":"@spawn","style":{"code":true}},{"type":"text","text":" is like writing "},{"type":"text","text":"goto","style":{"code":true}},{"type":"text","text":" when you can use "},{"type":"text","text":"for","style":{"code":true}},{"type":"text","text":"."}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA","reactions":[{"name":"+1","users":["UH8A351DJ","U8D9768Q6"],"count":2}]},{"client_msg_id":"d381302a-9076-4f96-a08d-054ee6280c21","type":"message","text":"It seems I have much to learn :slightly_smiling_face:","user":"UC6LC14MA","ts":"1612941344.084200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Dw5Z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"It seems I have much to learn "},{"type":"emoji","name":"slightly_smiling_face"}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"},{"client_msg_id":"09d269c1-a96a-4734-b872-aa2efa572896","type":"message","text":"Another thing, if I have a BLAS bottleneck somewhere in my loop, i.e. on step is a single BLAS call, for which everything else needs to wait; does changing the number of BLAS threads during runtime work (reliably)?","user":"UC6LC14MA","ts":"1612941837.084400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"wxhUi","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Another thing, if I have a BLAS bottleneck somewhere in my loop, i.e. on step is a single BLAS call, for which everything else needs to wait; does changing the number of BLAS threads during runtime work (reliably)?"}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"},{"client_msg_id":"994bc000-5b9a-4625-99a5-a95e59d8e14d","type":"message","text":"There's `set_num_threads` <https://docs.julialang.org/en/v1.7-dev/stdlib/LinearAlgebra/#LinearAlgebra.BLAS.set_num_threads> but I don't know if it is \"reliable enough\" (e.g., if it is thread-safe)","user":"UC7AF7NSU","ts":"1612976945.084700","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"/aGB0","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"There's "},{"type":"text","text":"set_num_threads","style":{"code":true}},{"type":"text","text":" "},{"type":"link","url":"https://docs.julialang.org/en/v1.7-dev/stdlib/LinearAlgebra/#LinearAlgebra.BLAS.set_num_threads"},{"type":"text","text":" but I don't know if it is \"reliable enough\" (e.g., if it is thread-safe)"}]}]}],"thread_ts":"1612855390.081000","parent_user_id":"UC6LC14MA"}]