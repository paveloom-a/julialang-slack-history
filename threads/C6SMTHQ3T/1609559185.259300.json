[{"client_msg_id":"45b51b37-ec4c-48b0-a9c1-1c1574d2ebf3","type":"message","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n<https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485>","user":"UAUPJLBQX","ts":"1609559185.259300","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1609559225.000000"},"blocks":[{"type":"rich_text","block_id":"mKtdO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n"},{"type":"link","url":"https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485"}]}]}],"thread_ts":"1609559185.259300","reply_count":3,"reply_users_count":2,"latest_reply":"1610095667.287600","reply_users":["UC6SUUPRC","UAUPJLBQX"],"subscribed":false,"reactions":[{"name":"+1","users":["U7THT3TM3","U881D0W2C"],"count":2}]},{"type":"message","subtype":"thread_broadcast","text":"I’m quite interested in this approach but I’m wondering what’s the difference between `@spawn` and this approach, should one always call that C API directly to get minimal threading overhead?","user":"UC6SUUPRC","ts":"1610055133.278000","thread_ts":"1609559185.259300","root":{"client_msg_id":"45b51b37-ec4c-48b0-a9c1-1c1574d2ebf3","type":"message","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n<https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485>","user":"UAUPJLBQX","ts":"1609559185.259300","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1609559225.000000"},"blocks":[{"type":"rich_text","block_id":"mKtdO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n"},{"type":"link","url":"https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485"}]}]}],"thread_ts":"1609559185.259300","reply_count":3,"reply_users_count":2,"latest_reply":"1610095667.287600","reply_users":["UC6SUUPRC","UAUPJLBQX"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"Mk3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m quite interested in this approach but I’m wondering what’s the difference between "},{"type":"text","text":"@spawn","style":{"code":true}},{"type":"text","text":" and this approach, should one always call that C API directly to get minimal threading overhead?"}]}]}],"client_msg_id":"130e3d74-e79f-4f2b-887f-680b920318a6"},{"client_msg_id":"4a9a60c4-6630-4e50-85c1-ef94e6f1c35e","type":"message","text":"MKL exceeds 300 GFLOPS for 100x100 matrices on my cascadelake desktop, that puts the matmul at around 6.5 microseconds.\nThat is many times faster than just `@benchmark wait(Threads.@spawn(() -&gt; nothing))`, on a different computer:\n```julia&gt; @benchmark wait(Threads.@spawn(() -&gt; nothing))\nBenchmarkTools.Trial:\n  memory estimate:  416 bytes\n  allocs estimate:  4\n  --------------\n  minimum time:     1.418 μs (0.00% GC)\n  median time:      42.268 μs (0.00% GC)\n  mean time:        40.971 μs (0.00% GC)\n  maximum time:     65.329 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1```\n40 microseond mean or 42 median for a trivial task that does no work.\nVersus 6.5 microseconds to perform the entire matmul.\n\nSo I don't really know what I can do, but `@spawn` is definitely not it.","user":"UAUPJLBQX","ts":"1610095343.287400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NYQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"MKL exceeds 300 GFLOPS for 100x100 matrices on my cascadelake desktop, that puts the matmul at around 6.5 microseconds.\nThat is many times faster than just "},{"type":"text","text":"@benchmark wait(Threads.@spawn(() -> nothing))","style":{"code":true}},{"type":"text","text":", on a different computer:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @benchmark wait(Threads.@spawn(() -> nothing))\nBenchmarkTools.Trial:\n  memory estimate:  416 bytes\n  allocs estimate:  4\n  --------------\n  minimum time:     1.418 μs (0.00% GC)\n  median time:      42.268 μs (0.00% GC)\n  mean time:        40.971 μs (0.00% GC)\n  maximum time:     65.329 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"40 microseond mean or 42 median for a trivial task that does no work.\nVersus 6.5 microseconds to perform the entire matmul.\n\nSo I don't really know what I can do, but "},{"type":"text","text":"@spawn","style":{"code":true}},{"type":"text","text":" is definitely not it."}]}]}],"thread_ts":"1609559185.259300","parent_user_id":"UAUPJLBQX"},{"client_msg_id":"1453a736-5e4e-49bc-8f29-537b33094346","type":"message","text":"The low level approach I was taking was hoping to try and bypass the scheduler, by pinning the tasks to a specific thread, like `Threads.@threads` <https://github.com/JuliaLang/julia/blob/83bee67631bc3d532b6b0bc47b02753ad5865673/base/threadingconstructs.jl#L21>","user":"UAUPJLBQX","ts":"1610095667.287600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lo7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The low level approach I was taking was hoping to try and bypass the scheduler, by pinning the tasks to a specific thread, like "},{"type":"text","text":"Threads.@threads","style":{"code":true}},{"type":"text","text":" "},{"type":"link","url":"https://github.com/JuliaLang/julia/blob/83bee67631bc3d532b6b0bc47b02753ad5865673/base/threadingconstructs.jl#L21"}]}]}],"thread_ts":"1609559185.259300","parent_user_id":"UAUPJLBQX"}]