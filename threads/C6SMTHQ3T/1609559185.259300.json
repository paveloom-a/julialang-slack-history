[{"client_msg_id":"45b51b37-ec4c-48b0-a9c1-1c1574d2ebf3","type":"message","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n<https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485>","user":"UAUPJLBQX","ts":"1609559185.259300","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1609559225.000000"},"blocks":[{"type":"rich_text","block_id":"mKtdO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n"},{"type":"link","url":"https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485"}]}]}],"thread_ts":"1609559185.259300","reply_count":1,"reply_users_count":1,"latest_reply":"1610055133.278000","reply_users":["UC6SUUPRC"],"subscribed":false,"reactions":[{"name":"+1","users":["U7THT3TM3","U881D0W2C"],"count":2}]},{"type":"message","subtype":"thread_broadcast","text":"I’m quite interested in this approach but I’m wondering what’s the difference between `@spawn` and this approach, should one always call that C API directly to get minimal threading overhead?","user":"UC6SUUPRC","ts":"1610055133.278000","thread_ts":"1609559185.259300","root":{"client_msg_id":"45b51b37-ec4c-48b0-a9c1-1c1574d2ebf3","type":"message","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n<https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485>","user":"UAUPJLBQX","ts":"1609559185.259300","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1609559225.000000"},"blocks":[{"type":"rich_text","block_id":"mKtdO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n"},{"type":"link","url":"https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485"}]}]}],"thread_ts":"1609559185.259300","reply_count":1,"reply_users_count":1,"latest_reply":"1610055133.278000","reply_users":["UC6SUUPRC"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"Mk3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m quite interested in this approach but I’m wondering what’s the difference between "},{"type":"text","text":"@spawn","style":{"code":true}},{"type":"text","text":" and this approach, should one always call that C API directly to get minimal threading overhead?"}]}]}],"client_msg_id":"130e3d74-e79f-4f2b-887f-680b920318a6"}]