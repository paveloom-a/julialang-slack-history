[{"client_msg_id":"45b51b37-ec4c-48b0-a9c1-1c1574d2ebf3","type":"message","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n<https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485>","user":"UAUPJLBQX","ts":"1609559185.259300","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1609559225.000000"},"blocks":[{"type":"rich_text","block_id":"mKtdO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n"},{"type":"link","url":"https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485"}]}]}],"thread_ts":"1609559185.259300","reply_count":8,"reply_users_count":2,"latest_reply":"1610128846.289100","reply_users":["UC6SUUPRC","UAUPJLBQX"],"subscribed":false,"reactions":[{"name":"+1","users":["U7THT3TM3","U881D0W2C"],"count":2}]},{"type":"message","subtype":"thread_broadcast","text":"I’m quite interested in this approach but I’m wondering what’s the difference between `@spawn` and this approach, should one always call that C API directly to get minimal threading overhead?","user":"UC6SUUPRC","ts":"1610055133.278000","thread_ts":"1609559185.259300","root":{"client_msg_id":"45b51b37-ec4c-48b0-a9c1-1c1574d2ebf3","type":"message","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n<https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485>","user":"UAUPJLBQX","ts":"1609559185.259300","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1609559225.000000"},"blocks":[{"type":"rich_text","block_id":"mKtdO","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Anyone have experience dealing with threading overhead? I'm wondering if there's some API I'm not aware of that could make it actually feasible to compete with MKL for small matrices.\nCreating tasks seems to be faster than using channels.\n"},{"type":"link","url":"https://github.com/JuliaLinearAlgebra/Octavian.jl/issues/24#issuecomment-753420485"}]}]}],"thread_ts":"1609559185.259300","reply_count":8,"reply_users_count":2,"latest_reply":"1610128846.289100","reply_users":["UC6SUUPRC","UAUPJLBQX"],"subscribed":false},"blocks":[{"type":"rich_text","block_id":"Mk3","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I’m quite interested in this approach but I’m wondering what’s the difference between "},{"type":"text","text":"@spawn","style":{"code":true}},{"type":"text","text":" and this approach, should one always call that C API directly to get minimal threading overhead?"}]}]}],"client_msg_id":"130e3d74-e79f-4f2b-887f-680b920318a6"},{"client_msg_id":"4a9a60c4-6630-4e50-85c1-ef94e6f1c35e","type":"message","text":"MKL exceeds 300 GFLOPS for 100x100 matrices on my cascadelake desktop, that puts the matmul at around 6.5 microseconds.\nThat is many times faster than just `@benchmark wait(Threads.@spawn(() -&gt; nothing))`, on a different computer:\n```julia&gt; @benchmark wait(Threads.@spawn(() -&gt; nothing))\nBenchmarkTools.Trial:\n  memory estimate:  416 bytes\n  allocs estimate:  4\n  --------------\n  minimum time:     1.418 μs (0.00% GC)\n  median time:      42.268 μs (0.00% GC)\n  mean time:        40.971 μs (0.00% GC)\n  maximum time:     65.329 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1```\n40 microseond mean or 42 median for a trivial task that does no work.\nVersus 6.5 microseconds to perform the entire matmul.\n\nSo I don't really know what I can do, but `@spawn` is definitely not it.","user":"UAUPJLBQX","ts":"1610095343.287400","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"NYQ","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"MKL exceeds 300 GFLOPS for 100x100 matrices on my cascadelake desktop, that puts the matmul at around 6.5 microseconds.\nThat is many times faster than just "},{"type":"text","text":"@benchmark wait(Threads.@spawn(() -> nothing))","style":{"code":true}},{"type":"text","text":", on a different computer:\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @benchmark wait(Threads.@spawn(() -> nothing))\nBenchmarkTools.Trial:\n  memory estimate:  416 bytes\n  allocs estimate:  4\n  --------------\n  minimum time:     1.418 μs (0.00% GC)\n  median time:      42.268 μs (0.00% GC)\n  mean time:        40.971 μs (0.00% GC)\n  maximum time:     65.329 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     1"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"40 microseond mean or 42 median for a trivial task that does no work.\nVersus 6.5 microseconds to perform the entire matmul.\n\nSo I don't really know what I can do, but "},{"type":"text","text":"@spawn","style":{"code":true}},{"type":"text","text":" is definitely not it."}]}]}],"thread_ts":"1609559185.259300","parent_user_id":"UAUPJLBQX"},{"client_msg_id":"1453a736-5e4e-49bc-8f29-537b33094346","type":"message","text":"The low level approach I was taking was hoping to try and bypass the scheduler, by pinning the tasks to a specific thread, like `Threads.@threads` <https://github.com/JuliaLang/julia/blob/83bee67631bc3d532b6b0bc47b02753ad5865673/base/threadingconstructs.jl#L21>","user":"UAUPJLBQX","ts":"1610095667.287600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"lo7","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The low level approach I was taking was hoping to try and bypass the scheduler, by pinning the tasks to a specific thread, like "},{"type":"text","text":"Threads.@threads","style":{"code":true}},{"type":"text","text":" "},{"type":"link","url":"https://github.com/JuliaLang/julia/blob/83bee67631bc3d532b6b0bc47b02753ad5865673/base/threadingconstructs.jl#L21"}]}]}],"thread_ts":"1609559185.259300","parent_user_id":"UAUPJLBQX"},{"client_msg_id":"d6504e67-6f3e-405f-ad36-6677b0b739af","type":"message","text":"I see, so I guess if there is a static schedule known it’s best not to use Julia’s?","user":"UC6SUUPRC","ts":"1610125066.288200","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"5l7/z","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"I see, so I guess if there is a static schedule known it’s best not to use Julia’s?"}]}]}],"thread_ts":"1609559185.259300","parent_user_id":"UAUPJLBQX"},{"client_msg_id":"39e402a4-2605-4567-8a7f-17a533a8bdf4","type":"message","text":"For comparison, same computer as the `wait(Threads.@spawn(() -&gt; nothing))`:\n```julia&gt; @benchmark wait(PaddedMatrices.runfunc(() -&gt; nothing, 2))\nBenchmarkTools.Trial:\n  memory estimate:  476 bytes\n  allocs estimate:  5\n  --------------\n  minimum time:     2.067 μs (0.00% GC)\n  median time:      2.640 μs (0.00% GC)\n  mean time:        2.644 μs (0.00% GC)\n  maximum time:     8.880 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     9```\n(Requires PaddedMatrices master. I'll probably make a release this weekend.)","user":"UAUPJLBQX","ts":"1610125815.288400","team":"T68168MUP","edited":{"user":"UAUPJLBQX","ts":"1610126646.000000"},"blocks":[{"type":"rich_text","block_id":"ZIC","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"For comparison, same computer as the "},{"type":"text","text":"wait(Threads.@spawn(() -> nothing))","style":{"code":true}},{"type":"text","text":":\n"}]},{"type":"rich_text_preformatted","elements":[{"type":"text","text":"julia> @benchmark wait(PaddedMatrices.runfunc(() -> nothing, 2))\nBenchmarkTools.Trial:\n  memory estimate:  476 bytes\n  allocs estimate:  5\n  --------------\n  minimum time:     2.067 μs (0.00% GC)\n  median time:      2.640 μs (0.00% GC)\n  mean time:        2.644 μs (0.00% GC)\n  maximum time:     8.880 μs (0.00% GC)\n  --------------\n  samples:          10000\n  evals/sample:     9"}]},{"type":"rich_text_section","elements":[{"type":"text","text":"(Requires PaddedMatrices master. I'll probably make a release this weekend.)"}]}]}],"thread_ts":"1609559185.259300","parent_user_id":"UAUPJLBQX"},{"client_msg_id":"a00afd43-9d11-4c41-a626-4fc7c04e7e6d","type":"message","text":"The `2` also is the id of the thread it runs on. I figured it'd probably help when starting a lot of tasks to pin each to their own, separate, thread.","user":"UAUPJLBQX","ts":"1610125889.288600","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"Q0B","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"The "},{"type":"text","text":"2","style":{"code":true}},{"type":"text","text":" also is the id of the thread it runs on. I figured it'd probably help when starting a lot of tasks to pin each to their own, separate, thread."}]}]}],"thread_ts":"1609559185.259300","parent_user_id":"UAUPJLBQX"},{"client_msg_id":"9bb62533-a61a-40cd-9025-6a41a5fe2a7b","type":"message","text":"Should I make a PR to add a `Threads.@spawnat` macro (doing the above)?\nWhy isn't there one already?","user":"UAUPJLBQX","ts":"1610126593.288800","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"oIt","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"Should I make a PR to add a "},{"type":"text","text":"Threads.@spawnat","style":{"code":true}},{"type":"text","text":" macro (doing the above)?\nWhy isn't there one already?"}]}]}],"thread_ts":"1609559185.259300","parent_user_id":"UAUPJLBQX"},{"client_msg_id":"f721c459-ca99-4e6c-8e3e-633c7cd87de5","type":"message","text":"so if I understand correctly, `PaddedMatrices.runfunc(() -&gt; nothing, 2)` runs a task on a specified thread (which is `2` in this case) instead of schedule that at runtime, so if I want to use it to run on multiple threads, I will need to manually specify the thread id?","user":"UC6SUUPRC","ts":"1610128846.289100","team":"T68168MUP","blocks":[{"type":"rich_text","block_id":"O/Z6","elements":[{"type":"rich_text_section","elements":[{"type":"text","text":"so if I understand correctly, "},{"type":"text","text":"PaddedMatrices.runfunc(() -> nothing, 2)","style":{"code":true}},{"type":"text","text":" runs a task on a specified thread (which is "},{"type":"text","text":"2","style":{"code":true}},{"type":"text","text":" in this case) instead of schedule that at runtime, so if I want to use it to run on multiple threads, I will need to manually specify the thread id?"}]}]}],"thread_ts":"1609559185.259300","parent_user_id":"UAUPJLBQX"}]